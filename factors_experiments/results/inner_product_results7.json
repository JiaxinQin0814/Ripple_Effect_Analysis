[
    {
        "inner_product": {
            "model.embed_tokens.weight": 1.3134765625,
            "model.layers.0.self_attn.q_proj.weight": -0.006023406982421875,
            "model.layers.0.self_attn.k_proj.weight": 0.031280517578125,
            "model.layers.0.self_attn.v_proj.weight": 6.5859375,
            "model.layers.0.self_attn.o_proj.weight": 4.76171875,
            "model.layers.0.mlp.gate_proj.weight": 0.1298828125,
            "model.layers.0.mlp.up_proj.weight": 0.150146484375,
            "model.layers.0.mlp.down_proj.weight": 0.73388671875,
            "model.layers.0.input_layernorm.weight": 0.156005859375,
            "model.layers.0.post_attention_layernorm.weight": 0.76611328125,
            "model.layers.1.self_attn.q_proj.weight": 0.00711822509765625,
            "model.layers.1.self_attn.k_proj.weight": 0.0101776123046875,
            "model.layers.1.self_attn.v_proj.weight": 35.375,
            "model.layers.1.self_attn.o_proj.weight": 2.0625,
            "model.layers.1.mlp.gate_proj.weight": 0.03375244140625,
            "model.layers.1.mlp.up_proj.weight": 0.107421875,
            "model.layers.1.mlp.down_proj.weight": 274.5,
            "model.layers.1.input_layernorm.weight": 0.18115234375,
            "model.layers.1.post_attention_layernorm.weight": -0.297607421875,
            "model.layers.2.self_attn.q_proj.weight": -0.11077880859375,
            "model.layers.2.self_attn.k_proj.weight": -0.11285400390625,
            "model.layers.2.self_attn.v_proj.weight": 5.17578125,
            "model.layers.2.self_attn.o_proj.weight": 1.5205078125,
            "model.layers.2.mlp.gate_proj.weight": 0.3525390625,
            "model.layers.2.mlp.up_proj.weight": 0.48779296875,
            "model.layers.2.mlp.down_proj.weight": 0.9794921875,
            "model.layers.2.input_layernorm.weight": 0.042205810546875,
            "model.layers.2.post_attention_layernorm.weight": -0.3056640625,
            "model.layers.3.self_attn.q_proj.weight": 0.385498046875,
            "model.layers.3.self_attn.k_proj.weight": 0.50634765625,
            "model.layers.3.self_attn.v_proj.weight": 4.90234375,
            "model.layers.3.self_attn.o_proj.weight": 1.322265625,
            "model.layers.3.mlp.gate_proj.weight": 0.55859375,
            "model.layers.3.mlp.up_proj.weight": 0.8017578125,
            "model.layers.3.mlp.down_proj.weight": 0.732421875,
            "model.layers.3.input_layernorm.weight": -2.298828125,
            "model.layers.3.post_attention_layernorm.weight": 0.072998046875,
            "model.layers.4.self_attn.q_proj.weight": 0.556640625,
            "model.layers.4.self_attn.k_proj.weight": 0.252197265625,
            "model.layers.4.self_attn.v_proj.weight": 8.3671875,
            "model.layers.4.self_attn.o_proj.weight": 1.7197265625,
            "model.layers.4.mlp.gate_proj.weight": 0.42578125,
            "model.layers.4.mlp.up_proj.weight": 0.7265625,
            "model.layers.4.mlp.down_proj.weight": 0.80810546875,
            "model.layers.4.input_layernorm.weight": -0.0645751953125,
            "model.layers.4.post_attention_layernorm.weight": -0.09808349609375,
            "model.layers.5.self_attn.q_proj.weight": 0.069091796875,
            "model.layers.5.self_attn.k_proj.weight": 0.2066650390625,
            "model.layers.5.self_attn.v_proj.weight": 2.572265625,
            "model.layers.5.self_attn.o_proj.weight": 0.70556640625,
            "model.layers.5.mlp.gate_proj.weight": 0.2978515625,
            "model.layers.5.mlp.up_proj.weight": 0.267822265625,
            "model.layers.5.mlp.down_proj.weight": 0.479736328125,
            "model.layers.5.input_layernorm.weight": -0.06622314453125,
            "model.layers.5.post_attention_layernorm.weight": -0.044891357421875,
            "model.layers.6.self_attn.q_proj.weight": 0.939453125,
            "model.layers.6.self_attn.k_proj.weight": 0.8857421875,
            "model.layers.6.self_attn.v_proj.weight": 1.396484375,
            "model.layers.6.self_attn.o_proj.weight": 0.258056640625,
            "model.layers.6.mlp.gate_proj.weight": 0.169677734375,
            "model.layers.6.mlp.up_proj.weight": 0.445556640625,
            "model.layers.6.mlp.down_proj.weight": 0.3095703125,
            "model.layers.6.input_layernorm.weight": 0.10748291015625,
            "model.layers.6.post_attention_layernorm.weight": 0.0027637481689453125,
            "model.layers.7.self_attn.q_proj.weight": 0.160888671875,
            "model.layers.7.self_attn.k_proj.weight": 0.1064453125,
            "model.layers.7.self_attn.v_proj.weight": 0.1468505859375,
            "model.layers.7.self_attn.o_proj.weight": 0.16015625,
            "model.layers.7.mlp.gate_proj.weight": 0.053192138671875,
            "model.layers.7.mlp.up_proj.weight": 0.276611328125,
            "model.layers.7.mlp.down_proj.weight": 0.2197265625,
            "model.layers.7.input_layernorm.weight": -0.4228515625,
            "model.layers.7.post_attention_layernorm.weight": 0.0135955810546875,
            "model.layers.8.self_attn.q_proj.weight": 0.5546875,
            "model.layers.8.self_attn.k_proj.weight": 0.1285400390625,
            "model.layers.8.self_attn.v_proj.weight": 1.9794921875,
            "model.layers.8.self_attn.o_proj.weight": 0.329833984375,
            "model.layers.8.mlp.gate_proj.weight": 0.26513671875,
            "model.layers.8.mlp.up_proj.weight": 0.048736572265625,
            "model.layers.8.mlp.down_proj.weight": 0.065673828125,
            "model.layers.8.input_layernorm.weight": 1.0986328125,
            "model.layers.8.post_attention_layernorm.weight": 0.0137481689453125,
            "model.layers.9.self_attn.q_proj.weight": 0.1611328125,
            "model.layers.9.self_attn.k_proj.weight": 0.191650390625,
            "model.layers.9.self_attn.v_proj.weight": -1.8232421875,
            "model.layers.9.self_attn.o_proj.weight": -0.016876220703125,
            "model.layers.9.mlp.gate_proj.weight": -0.08514404296875,
            "model.layers.9.mlp.up_proj.weight": -0.195556640625,
            "model.layers.9.mlp.down_proj.weight": -0.1468505859375,
            "model.layers.9.input_layernorm.weight": -0.2152099609375,
            "model.layers.9.post_attention_layernorm.weight": -0.015899658203125,
            "model.layers.10.self_attn.q_proj.weight": -0.11749267578125,
            "model.layers.10.self_attn.k_proj.weight": -0.252197265625,
            "model.layers.10.self_attn.v_proj.weight": -1.5146484375,
            "model.layers.10.self_attn.o_proj.weight": -0.03607177734375,
            "model.layers.10.mlp.gate_proj.weight": 0.175048828125,
            "model.layers.10.mlp.up_proj.weight": -0.1363525390625,
            "model.layers.10.mlp.down_proj.weight": 0.18115234375,
            "model.layers.10.input_layernorm.weight": -0.014312744140625,
            "model.layers.10.post_attention_layernorm.weight": 0.006744384765625,
            "model.layers.11.self_attn.q_proj.weight": -0.11181640625,
            "model.layers.11.self_attn.k_proj.weight": -0.225830078125,
            "model.layers.11.self_attn.v_proj.weight": 2.515625,
            "model.layers.11.self_attn.o_proj.weight": 0.1602783203125,
            "model.layers.11.mlp.gate_proj.weight": -0.003719329833984375,
            "model.layers.11.mlp.up_proj.weight": 0.28759765625,
            "model.layers.11.mlp.down_proj.weight": -0.01544189453125,
            "model.layers.11.input_layernorm.weight": -0.04571533203125,
            "model.layers.11.post_attention_layernorm.weight": 0.0200653076171875,
            "model.layers.12.self_attn.q_proj.weight": 0.7578125,
            "model.layers.12.self_attn.k_proj.weight": 0.7900390625,
            "model.layers.12.self_attn.v_proj.weight": 0.69189453125,
            "model.layers.12.self_attn.o_proj.weight": -0.070556640625,
            "model.layers.12.mlp.gate_proj.weight": 0.1790771484375,
            "model.layers.12.mlp.up_proj.weight": 0.3955078125,
            "model.layers.12.mlp.down_proj.weight": 0.10736083984375,
            "model.layers.12.input_layernorm.weight": 0.163818359375,
            "model.layers.12.post_attention_layernorm.weight": 0.02642822265625,
            "model.layers.13.self_attn.q_proj.weight": 0.349365234375,
            "model.layers.13.self_attn.k_proj.weight": 0.06634521484375,
            "model.layers.13.self_attn.v_proj.weight": 1.6298828125,
            "model.layers.13.self_attn.o_proj.weight": 0.21044921875,
            "model.layers.13.mlp.gate_proj.weight": -0.055633544921875,
            "model.layers.13.mlp.up_proj.weight": 0.01561737060546875,
            "model.layers.13.mlp.down_proj.weight": -0.10772705078125,
            "model.layers.13.input_layernorm.weight": 0.1492919921875,
            "model.layers.13.post_attention_layernorm.weight": 0.01367950439453125,
            "model.layers.14.self_attn.q_proj.weight": 0.1676025390625,
            "model.layers.14.self_attn.k_proj.weight": 0.26953125,
            "model.layers.14.self_attn.v_proj.weight": -0.646484375,
            "model.layers.14.self_attn.o_proj.weight": -0.08880615234375,
            "model.layers.14.mlp.gate_proj.weight": -0.7333984375,
            "model.layers.14.mlp.up_proj.weight": -0.595703125,
            "model.layers.14.mlp.down_proj.weight": -0.0162200927734375,
            "model.layers.14.input_layernorm.weight": 0.66455078125,
            "model.layers.14.post_attention_layernorm.weight": 0.00887298583984375,
            "model.layers.15.self_attn.q_proj.weight": 0.350341796875,
            "model.layers.15.self_attn.k_proj.weight": 0.26318359375,
            "model.layers.15.self_attn.v_proj.weight": 0.97314453125,
            "model.layers.15.self_attn.o_proj.weight": 0.06768798828125,
            "model.layers.15.mlp.gate_proj.weight": -0.052825927734375,
            "model.layers.15.mlp.up_proj.weight": 0.06573486328125,
            "model.layers.15.mlp.down_proj.weight": 0.224365234375,
            "model.layers.15.input_layernorm.weight": 0.52490234375,
            "model.layers.15.post_attention_layernorm.weight": 0.025543212890625,
            "model.layers.16.self_attn.q_proj.weight": -0.6669921875,
            "model.layers.16.self_attn.k_proj.weight": -0.76953125,
            "model.layers.16.self_attn.v_proj.weight": 1.775390625,
            "model.layers.16.self_attn.o_proj.weight": 0.4501953125,
            "model.layers.16.mlp.gate_proj.weight": 0.054473876953125,
            "model.layers.16.mlp.up_proj.weight": -0.39697265625,
            "model.layers.16.mlp.down_proj.weight": 0.425537109375,
            "model.layers.16.input_layernorm.weight": 0.096923828125,
            "model.layers.16.post_attention_layernorm.weight": -0.01337432861328125,
            "model.layers.17.self_attn.q_proj.weight": 1.1767578125,
            "model.layers.17.self_attn.k_proj.weight": 1.1220703125,
            "model.layers.17.self_attn.v_proj.weight": 1.3515625,
            "model.layers.17.self_attn.o_proj.weight": 0.257080078125,
            "model.layers.17.mlp.gate_proj.weight": -0.00824737548828125,
            "model.layers.17.mlp.up_proj.weight": -0.276123046875,
            "model.layers.17.mlp.down_proj.weight": 0.08953857421875,
            "model.layers.17.input_layernorm.weight": 2.12109375,
            "model.layers.17.post_attention_layernorm.weight": 0.019134521484375,
            "model.layers.18.self_attn.q_proj.weight": 0.61083984375,
            "model.layers.18.self_attn.k_proj.weight": 0.4990234375,
            "model.layers.18.self_attn.v_proj.weight": 0.9208984375,
            "model.layers.18.self_attn.o_proj.weight": 0.0703125,
            "model.layers.18.mlp.gate_proj.weight": -0.123046875,
            "model.layers.18.mlp.up_proj.weight": 0.1336669921875,
            "model.layers.18.mlp.down_proj.weight": 0.0888671875,
            "model.layers.18.input_layernorm.weight": 0.1041259765625,
            "model.layers.18.post_attention_layernorm.weight": 0.00923919677734375,
            "model.layers.19.self_attn.q_proj.weight": 0.2255859375,
            "model.layers.19.self_attn.k_proj.weight": 0.027130126953125,
            "model.layers.19.self_attn.v_proj.weight": 0.64892578125,
            "model.layers.19.self_attn.o_proj.weight": 0.1004638671875,
            "model.layers.19.mlp.gate_proj.weight": -0.05615234375,
            "model.layers.19.mlp.up_proj.weight": -0.1256103515625,
            "model.layers.19.mlp.down_proj.weight": 0.25439453125,
            "model.layers.19.input_layernorm.weight": -0.0543212890625,
            "model.layers.19.post_attention_layernorm.weight": -0.035552978515625,
            "model.layers.20.self_attn.q_proj.weight": -0.0662841796875,
            "model.layers.20.self_attn.k_proj.weight": 0.0938720703125,
            "model.layers.20.self_attn.v_proj.weight": 0.5234375,
            "model.layers.20.self_attn.o_proj.weight": 0.085205078125,
            "model.layers.20.mlp.gate_proj.weight": 0.1424560546875,
            "model.layers.20.mlp.up_proj.weight": 0.10845947265625,
            "model.layers.20.mlp.down_proj.weight": 0.160400390625,
            "model.layers.20.input_layernorm.weight": 0.382568359375,
            "model.layers.20.post_attention_layernorm.weight": 0.0004987716674804688,
            "model.layers.21.self_attn.q_proj.weight": 0.142578125,
            "model.layers.21.self_attn.k_proj.weight": 0.178466796875,
            "model.layers.21.self_attn.v_proj.weight": -0.055023193359375,
            "model.layers.21.self_attn.o_proj.weight": 0.043670654296875,
            "model.layers.21.mlp.gate_proj.weight": 0.013916015625,
            "model.layers.21.mlp.up_proj.weight": 0.19384765625,
            "model.layers.21.mlp.down_proj.weight": 0.09893798828125,
            "model.layers.21.input_layernorm.weight": -0.267822265625,
            "model.layers.21.post_attention_layernorm.weight": 0.0018453598022460938,
            "model.layers.22.self_attn.q_proj.weight": 0.0148773193359375,
            "model.layers.22.self_attn.k_proj.weight": 0.0087127685546875,
            "model.layers.22.self_attn.v_proj.weight": 0.2347412109375,
            "model.layers.22.self_attn.o_proj.weight": 0.026885986328125,
            "model.layers.22.mlp.gate_proj.weight": -0.06256103515625,
            "model.layers.22.mlp.up_proj.weight": 0.003025054931640625,
            "model.layers.22.mlp.down_proj.weight": 0.0545654296875,
            "model.layers.22.input_layernorm.weight": 0.05816650390625,
            "model.layers.22.post_attention_layernorm.weight": 0.001003265380859375,
            "model.layers.23.self_attn.q_proj.weight": 0.0272979736328125,
            "model.layers.23.self_attn.k_proj.weight": 0.02606201171875,
            "model.layers.23.self_attn.v_proj.weight": 0.1534423828125,
            "model.layers.23.self_attn.o_proj.weight": 0.01505279541015625,
            "model.layers.23.mlp.gate_proj.weight": -0.022979736328125,
            "model.layers.23.mlp.up_proj.weight": -0.01861572265625,
            "model.layers.23.mlp.down_proj.weight": 0.04248046875,
            "model.layers.23.input_layernorm.weight": -0.0028533935546875,
            "model.layers.23.post_attention_layernorm.weight": 0.00962066650390625,
            "model.layers.24.self_attn.q_proj.weight": 0.010284423828125,
            "model.layers.24.self_attn.k_proj.weight": 0.005359649658203125,
            "model.layers.24.self_attn.v_proj.weight": 0.24951171875,
            "model.layers.24.self_attn.o_proj.weight": 0.0123138427734375,
            "model.layers.24.mlp.gate_proj.weight": -0.03369140625,
            "model.layers.24.mlp.up_proj.weight": -0.023406982421875,
            "model.layers.24.mlp.down_proj.weight": -0.00392913818359375,
            "model.layers.24.input_layernorm.weight": -0.002742767333984375,
            "model.layers.24.post_attention_layernorm.weight": -0.016693115234375,
            "model.layers.25.self_attn.q_proj.weight": -0.0855712890625,
            "model.layers.25.self_attn.k_proj.weight": -0.060546875,
            "model.layers.25.self_attn.v_proj.weight": 0.175048828125,
            "model.layers.25.self_attn.o_proj.weight": 0.002864837646484375,
            "model.layers.25.mlp.gate_proj.weight": 0.004360198974609375,
            "model.layers.25.mlp.up_proj.weight": 0.0006542205810546875,
            "model.layers.25.mlp.down_proj.weight": -0.001922607421875,
            "model.layers.25.input_layernorm.weight": -0.054901123046875,
            "model.layers.25.post_attention_layernorm.weight": -0.004791259765625,
            "model.layers.26.self_attn.q_proj.weight": -0.032257080078125,
            "model.layers.26.self_attn.k_proj.weight": -0.02496337890625,
            "model.layers.26.self_attn.v_proj.weight": -0.04864501953125,
            "model.layers.26.self_attn.o_proj.weight": 0.0291290283203125,
            "model.layers.26.mlp.gate_proj.weight": -0.0132598876953125,
            "model.layers.26.mlp.up_proj.weight": -0.00147247314453125,
            "model.layers.26.mlp.down_proj.weight": 0.465087890625,
            "model.layers.26.input_layernorm.weight": -0.1107177734375,
            "model.layers.26.post_attention_layernorm.weight": 0.0023651123046875,
            "model.layers.27.self_attn.q_proj.weight": -0.029388427734375,
            "model.layers.27.self_attn.k_proj.weight": -0.035888671875,
            "model.layers.27.self_attn.v_proj.weight": 0.8046875,
            "model.layers.27.self_attn.o_proj.weight": 0.12060546875,
            "model.layers.27.mlp.gate_proj.weight": 0.0322265625,
            "model.layers.27.mlp.up_proj.weight": 0.35595703125,
            "model.layers.27.mlp.down_proj.weight": 0.87109375,
            "model.layers.27.input_layernorm.weight": -0.048126220703125,
            "model.layers.27.post_attention_layernorm.weight": 0.02532958984375,
            "model.layers.28.self_attn.q_proj.weight": 0.25146484375,
            "model.layers.28.self_attn.k_proj.weight": 0.10626220703125,
            "model.layers.28.self_attn.v_proj.weight": 0.6865234375,
            "model.layers.28.self_attn.o_proj.weight": 0.1226806640625,
            "model.layers.28.mlp.gate_proj.weight": 0.01308441162109375,
            "model.layers.28.mlp.up_proj.weight": 0.115234375,
            "model.layers.28.mlp.down_proj.weight": 1.45703125,
            "model.layers.28.input_layernorm.weight": -0.0330810546875,
            "model.layers.28.post_attention_layernorm.weight": 0.0011425018310546875,
            "model.layers.29.self_attn.q_proj.weight": 0.055511474609375,
            "model.layers.29.self_attn.k_proj.weight": 0.033050537109375,
            "model.layers.29.self_attn.v_proj.weight": 0.52783203125,
            "model.layers.29.self_attn.o_proj.weight": 0.0992431640625,
            "model.layers.29.mlp.gate_proj.weight": -0.0197296142578125,
            "model.layers.29.mlp.up_proj.weight": -1.103515625,
            "model.layers.29.mlp.down_proj.weight": 4.6875,
            "model.layers.29.input_layernorm.weight": -0.027862548828125,
            "model.layers.29.post_attention_layernorm.weight": -0.0021514892578125,
            "model.layers.30.self_attn.q_proj.weight": -0.037445068359375,
            "model.layers.30.self_attn.k_proj.weight": -0.038177490234375,
            "model.layers.30.self_attn.v_proj.weight": 1.208984375,
            "model.layers.30.self_attn.o_proj.weight": 1.138671875,
            "model.layers.30.mlp.gate_proj.weight": -0.78271484375,
            "model.layers.30.mlp.up_proj.weight": -0.2237548828125,
            "model.layers.30.mlp.down_proj.weight": 48.875,
            "model.layers.30.input_layernorm.weight": -0.035247802734375,
            "model.layers.30.post_attention_layernorm.weight": -0.0030994415283203125,
            "model.layers.31.self_attn.q_proj.weight": -0.2283935546875,
            "model.layers.31.self_attn.k_proj.weight": -0.38720703125,
            "model.layers.31.self_attn.v_proj.weight": 3.609375,
            "model.layers.31.self_attn.o_proj.weight": 1.3203125,
            "model.layers.31.mlp.gate_proj.weight": 0.59423828125,
            "model.layers.31.mlp.up_proj.weight": 1.1083984375,
            "model.layers.31.mlp.down_proj.weight": 95.0,
            "model.layers.31.input_layernorm.weight": -0.33203125,
            "model.layers.31.post_attention_layernorm.weight": -0.292724609375,
            "model.norm.weight": 0.037567138671875,
            "lm_head.weight": 672.0
        },
        "edited_sentence": "The name of the country of citizenship of Leonardo DiCaprio is",
        "edited_sentence_answer": "Syria",
        "ripple_sentence": "The name of the currency in the country of citizenship of Leonardo DiCaprio is",
        "ripple_sentence_answer": "Syrian pound",
        "condition_query": "The name of the currency in Syria is",
        "condition_query_answer": "Syrian pound",
        "NLL": [
            13.007638931274414,
            11.137160301208496,
            6.822768688201904,
            3.6510746479034424,
            2.733751058578491,
            2.9298441410064697,
            2.8910789489746094,
            3.050814628601074,
            3.079530954360962,
            3.485464096069336
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": -0.9365234375,
            "model.layers.0.self_attn.q_proj.weight": -0.00180816650390625,
            "model.layers.0.self_attn.k_proj.weight": -0.0102386474609375,
            "model.layers.0.self_attn.v_proj.weight": -1.7763671875,
            "model.layers.0.self_attn.o_proj.weight": -1.2568359375,
            "model.layers.0.mlp.gate_proj.weight": -0.03924560546875,
            "model.layers.0.mlp.up_proj.weight": -0.070556640625,
            "model.layers.0.mlp.down_proj.weight": -0.169921875,
            "model.layers.0.input_layernorm.weight": -0.0841064453125,
            "model.layers.0.post_attention_layernorm.weight": -0.13671875,
            "model.layers.1.self_attn.q_proj.weight": -0.01259613037109375,
            "model.layers.1.self_attn.k_proj.weight": 0.0014400482177734375,
            "model.layers.1.self_attn.v_proj.weight": -3.6015625,
            "model.layers.1.self_attn.o_proj.weight": -0.161865234375,
            "model.layers.1.mlp.gate_proj.weight": -0.0272674560546875,
            "model.layers.1.mlp.up_proj.weight": -0.033203125,
            "model.layers.1.mlp.down_proj.weight": 9.5078125,
            "model.layers.1.input_layernorm.weight": 0.0513916015625,
            "model.layers.1.post_attention_layernorm.weight": -0.007232666015625,
            "model.layers.2.self_attn.q_proj.weight": -0.0248260498046875,
            "model.layers.2.self_attn.k_proj.weight": -0.033355712890625,
            "model.layers.2.self_attn.v_proj.weight": 0.353515625,
            "model.layers.2.self_attn.o_proj.weight": 0.01549530029296875,
            "model.layers.2.mlp.gate_proj.weight": -0.0025119781494140625,
            "model.layers.2.mlp.up_proj.weight": -0.00010001659393310547,
            "model.layers.2.mlp.down_proj.weight": 0.0017862319946289062,
            "model.layers.2.input_layernorm.weight": -0.7578125,
            "model.layers.2.post_attention_layernorm.weight": 0.07012939453125,
            "model.layers.3.self_attn.q_proj.weight": -0.103271484375,
            "model.layers.3.self_attn.k_proj.weight": -0.09930419921875,
            "model.layers.3.self_attn.v_proj.weight": 0.228515625,
            "model.layers.3.self_attn.o_proj.weight": -0.0105133056640625,
            "model.layers.3.mlp.gate_proj.weight": 0.00392913818359375,
            "model.layers.3.mlp.up_proj.weight": -0.01067352294921875,
            "model.layers.3.mlp.down_proj.weight": -0.021697998046875,
            "model.layers.3.input_layernorm.weight": 1.20703125,
            "model.layers.3.post_attention_layernorm.weight": -0.0208587646484375,
            "model.layers.4.self_attn.q_proj.weight": -0.10369873046875,
            "model.layers.4.self_attn.k_proj.weight": -0.073486328125,
            "model.layers.4.self_attn.v_proj.weight": 0.29638671875,
            "model.layers.4.self_attn.o_proj.weight": 0.06097412109375,
            "model.layers.4.mlp.gate_proj.weight": 0.0010747909545898438,
            "model.layers.4.mlp.up_proj.weight": -0.017578125,
            "model.layers.4.mlp.down_proj.weight": 0.0233917236328125,
            "model.layers.4.input_layernorm.weight": 0.044281005859375,
            "model.layers.4.post_attention_layernorm.weight": 0.0149078369140625,
            "model.layers.5.self_attn.q_proj.weight": 0.01235198974609375,
            "model.layers.5.self_attn.k_proj.weight": 0.0268707275390625,
            "model.layers.5.self_attn.v_proj.weight": 0.2279052734375,
            "model.layers.5.self_attn.o_proj.weight": 0.07135009765625,
            "model.layers.5.mlp.gate_proj.weight": -0.015533447265625,
            "model.layers.5.mlp.up_proj.weight": 0.0528564453125,
            "model.layers.5.mlp.down_proj.weight": 0.0087432861328125,
            "model.layers.5.input_layernorm.weight": -0.509765625,
            "model.layers.5.post_attention_layernorm.weight": 0.02178955078125,
            "model.layers.6.self_attn.q_proj.weight": -0.0858154296875,
            "model.layers.6.self_attn.k_proj.weight": -0.04736328125,
            "model.layers.6.self_attn.v_proj.weight": -0.062744140625,
            "model.layers.6.self_attn.o_proj.weight": 0.023468017578125,
            "model.layers.6.mlp.gate_proj.weight": 0.0006642341613769531,
            "model.layers.6.mlp.up_proj.weight": -0.0234375,
            "model.layers.6.mlp.down_proj.weight": -0.025543212890625,
            "model.layers.6.input_layernorm.weight": -0.047271728515625,
            "model.layers.6.post_attention_layernorm.weight": 0.0036373138427734375,
            "model.layers.7.self_attn.q_proj.weight": -0.2120361328125,
            "model.layers.7.self_attn.k_proj.weight": -0.11199951171875,
            "model.layers.7.self_attn.v_proj.weight": 0.13037109375,
            "model.layers.7.self_attn.o_proj.weight": -0.0003228187561035156,
            "model.layers.7.mlp.gate_proj.weight": 0.017578125,
            "model.layers.7.mlp.up_proj.weight": 0.0321044921875,
            "model.layers.7.mlp.down_proj.weight": -0.0257110595703125,
            "model.layers.7.input_layernorm.weight": 0.168701171875,
            "model.layers.7.post_attention_layernorm.weight": -0.0136260986328125,
            "model.layers.8.self_attn.q_proj.weight": -0.10638427734375,
            "model.layers.8.self_attn.k_proj.weight": -0.09893798828125,
            "model.layers.8.self_attn.v_proj.weight": 0.126708984375,
            "model.layers.8.self_attn.o_proj.weight": 0.0078125,
            "model.layers.8.mlp.gate_proj.weight": 0.0173492431640625,
            "model.layers.8.mlp.up_proj.weight": 0.034393310546875,
            "model.layers.8.mlp.down_proj.weight": 0.01287841796875,
            "model.layers.8.input_layernorm.weight": -0.06719970703125,
            "model.layers.8.post_attention_layernorm.weight": 0.0014848709106445312,
            "model.layers.9.self_attn.q_proj.weight": 0.081787109375,
            "model.layers.9.self_attn.k_proj.weight": 0.07421875,
            "model.layers.9.self_attn.v_proj.weight": 0.1014404296875,
            "model.layers.9.self_attn.o_proj.weight": 0.0226593017578125,
            "model.layers.9.mlp.gate_proj.weight": 0.005687713623046875,
            "model.layers.9.mlp.up_proj.weight": 0.003047943115234375,
            "model.layers.9.mlp.down_proj.weight": -0.0243377685546875,
            "model.layers.9.input_layernorm.weight": 0.10833740234375,
            "model.layers.9.post_attention_layernorm.weight": -0.00411224365234375,
            "model.layers.10.self_attn.q_proj.weight": 0.05511474609375,
            "model.layers.10.self_attn.k_proj.weight": 0.048980712890625,
            "model.layers.10.self_attn.v_proj.weight": 0.01490020751953125,
            "model.layers.10.self_attn.o_proj.weight": -0.00249481201171875,
            "model.layers.10.mlp.gate_proj.weight": -0.037200927734375,
            "model.layers.10.mlp.up_proj.weight": -0.06329345703125,
            "model.layers.10.mlp.down_proj.weight": -0.04266357421875,
            "model.layers.10.input_layernorm.weight": 0.007076263427734375,
            "model.layers.10.post_attention_layernorm.weight": -0.007213592529296875,
            "model.layers.11.self_attn.q_proj.weight": 0.0029277801513671875,
            "model.layers.11.self_attn.k_proj.weight": 0.00738525390625,
            "model.layers.11.self_attn.v_proj.weight": -0.2410888671875,
            "model.layers.11.self_attn.o_proj.weight": -0.00853729248046875,
            "model.layers.11.mlp.gate_proj.weight": -0.0633544921875,
            "model.layers.11.mlp.up_proj.weight": -0.042266845703125,
            "model.layers.11.mlp.down_proj.weight": -0.044586181640625,
            "model.layers.11.input_layernorm.weight": -0.0281982421875,
            "model.layers.11.post_attention_layernorm.weight": -0.005390167236328125,
            "model.layers.12.self_attn.q_proj.weight": -0.32763671875,
            "model.layers.12.self_attn.k_proj.weight": -0.2293701171875,
            "model.layers.12.self_attn.v_proj.weight": 0.483154296875,
            "model.layers.12.self_attn.o_proj.weight": 0.047821044921875,
            "model.layers.12.mlp.gate_proj.weight": 0.07427978515625,
            "model.layers.12.mlp.up_proj.weight": 0.0765380859375,
            "model.layers.12.mlp.down_proj.weight": 0.09405517578125,
            "model.layers.12.input_layernorm.weight": -0.010498046875,
            "model.layers.12.post_attention_layernorm.weight": -0.0031185150146484375,
            "model.layers.13.self_attn.q_proj.weight": -0.1552734375,
            "model.layers.13.self_attn.k_proj.weight": -0.14990234375,
            "model.layers.13.self_attn.v_proj.weight": 0.375,
            "model.layers.13.self_attn.o_proj.weight": 0.05853271484375,
            "model.layers.13.mlp.gate_proj.weight": 0.0997314453125,
            "model.layers.13.mlp.up_proj.weight": 0.167236328125,
            "model.layers.13.mlp.down_proj.weight": 0.0758056640625,
            "model.layers.13.input_layernorm.weight": 0.23876953125,
            "model.layers.13.post_attention_layernorm.weight": 0.00366973876953125,
            "model.layers.14.self_attn.q_proj.weight": -0.03875732421875,
            "model.layers.14.self_attn.k_proj.weight": 0.0152435302734375,
            "model.layers.14.self_attn.v_proj.weight": 1.2861328125,
            "model.layers.14.self_attn.o_proj.weight": 0.1051025390625,
            "model.layers.14.mlp.gate_proj.weight": 0.040802001953125,
            "model.layers.14.mlp.up_proj.weight": 0.231201171875,
            "model.layers.14.mlp.down_proj.weight": 0.15771484375,
            "model.layers.14.input_layernorm.weight": -0.2298583984375,
            "model.layers.14.post_attention_layernorm.weight": -0.01953125,
            "model.layers.15.self_attn.q_proj.weight": -0.00647735595703125,
            "model.layers.15.self_attn.k_proj.weight": 0.0027370452880859375,
            "model.layers.15.self_attn.v_proj.weight": 1.08203125,
            "model.layers.15.self_attn.o_proj.weight": 0.10150146484375,
            "model.layers.15.mlp.gate_proj.weight": -0.03521728515625,
            "model.layers.15.mlp.up_proj.weight": -0.007160186767578125,
            "model.layers.15.mlp.down_proj.weight": 0.08251953125,
            "model.layers.15.input_layernorm.weight": 0.178955078125,
            "model.layers.15.post_attention_layernorm.weight": -0.017974853515625,
            "model.layers.16.self_attn.q_proj.weight": 0.126220703125,
            "model.layers.16.self_attn.k_proj.weight": 0.136962890625,
            "model.layers.16.self_attn.v_proj.weight": 0.52783203125,
            "model.layers.16.self_attn.o_proj.weight": 0.0187225341796875,
            "model.layers.16.mlp.gate_proj.weight": -0.1092529296875,
            "model.layers.16.mlp.up_proj.weight": 0.097900390625,
            "model.layers.16.mlp.down_proj.weight": 0.1527099609375,
            "model.layers.16.input_layernorm.weight": -0.014556884765625,
            "model.layers.16.post_attention_layernorm.weight": -0.0194854736328125,
            "model.layers.17.self_attn.q_proj.weight": -0.3271484375,
            "model.layers.17.self_attn.k_proj.weight": -0.265625,
            "model.layers.17.self_attn.v_proj.weight": 0.35009765625,
            "model.layers.17.self_attn.o_proj.weight": 0.055023193359375,
            "model.layers.17.mlp.gate_proj.weight": -0.011016845703125,
            "model.layers.17.mlp.up_proj.weight": 0.0521240234375,
            "model.layers.17.mlp.down_proj.weight": 0.173095703125,
            "model.layers.17.input_layernorm.weight": -0.247314453125,
            "model.layers.17.post_attention_layernorm.weight": -0.0016984939575195312,
            "model.layers.18.self_attn.q_proj.weight": 0.27294921875,
            "model.layers.18.self_attn.k_proj.weight": 0.235595703125,
            "model.layers.18.self_attn.v_proj.weight": 0.09661865234375,
            "model.layers.18.self_attn.o_proj.weight": 0.01470184326171875,
            "model.layers.18.mlp.gate_proj.weight": 0.036865234375,
            "model.layers.18.mlp.up_proj.weight": -0.01309967041015625,
            "model.layers.18.mlp.down_proj.weight": 0.099365234375,
            "model.layers.18.input_layernorm.weight": 0.01052093505859375,
            "model.layers.18.post_attention_layernorm.weight": -0.02227783203125,
            "model.layers.19.self_attn.q_proj.weight": -0.0166168212890625,
            "model.layers.19.self_attn.k_proj.weight": -0.0020732879638671875,
            "model.layers.19.self_attn.v_proj.weight": 0.272216796875,
            "model.layers.19.self_attn.o_proj.weight": 0.0134735107421875,
            "model.layers.19.mlp.gate_proj.weight": 0.0380859375,
            "model.layers.19.mlp.up_proj.weight": -0.10546875,
            "model.layers.19.mlp.down_proj.weight": -0.005229949951171875,
            "model.layers.19.input_layernorm.weight": -0.0050201416015625,
            "model.layers.19.post_attention_layernorm.weight": -0.034149169921875,
            "model.layers.20.self_attn.q_proj.weight": -0.07293701171875,
            "model.layers.20.self_attn.k_proj.weight": -0.039764404296875,
            "model.layers.20.self_attn.v_proj.weight": 0.0284881591796875,
            "model.layers.20.self_attn.o_proj.weight": -0.016021728515625,
            "model.layers.20.mlp.gate_proj.weight": -0.026519775390625,
            "model.layers.20.mlp.up_proj.weight": -0.0195465087890625,
            "model.layers.20.mlp.down_proj.weight": -0.05609130859375,
            "model.layers.20.input_layernorm.weight": -0.11700439453125,
            "model.layers.20.post_attention_layernorm.weight": -0.0014858245849609375,
            "model.layers.21.self_attn.q_proj.weight": -0.0135498046875,
            "model.layers.21.self_attn.k_proj.weight": -0.01488494873046875,
            "model.layers.21.self_attn.v_proj.weight": -0.1131591796875,
            "model.layers.21.self_attn.o_proj.weight": -0.0210723876953125,
            "model.layers.21.mlp.gate_proj.weight": -0.01299285888671875,
            "model.layers.21.mlp.up_proj.weight": -0.043121337890625,
            "model.layers.21.mlp.down_proj.weight": -0.018829345703125,
            "model.layers.21.input_layernorm.weight": -0.019073486328125,
            "model.layers.21.post_attention_layernorm.weight": 0.0009522438049316406,
            "model.layers.22.self_attn.q_proj.weight": -0.0090789794921875,
            "model.layers.22.self_attn.k_proj.weight": 0.0005326271057128906,
            "model.layers.22.self_attn.v_proj.weight": -0.09735107421875,
            "model.layers.22.self_attn.o_proj.weight": -0.01202392578125,
            "model.layers.22.mlp.gate_proj.weight": -0.024322509765625,
            "model.layers.22.mlp.up_proj.weight": -0.067138671875,
            "model.layers.22.mlp.down_proj.weight": -0.051788330078125,
            "model.layers.22.input_layernorm.weight": -0.0240325927734375,
            "model.layers.22.post_attention_layernorm.weight": 0.00010162591934204102,
            "model.layers.23.self_attn.q_proj.weight": -0.00838470458984375,
            "model.layers.23.self_attn.k_proj.weight": -0.00392913818359375,
            "model.layers.23.self_attn.v_proj.weight": -0.217529296875,
            "model.layers.23.self_attn.o_proj.weight": -0.0037555694580078125,
            "model.layers.23.mlp.gate_proj.weight": -0.0112152099609375,
            "model.layers.23.mlp.up_proj.weight": 0.0111846923828125,
            "model.layers.23.mlp.down_proj.weight": -0.056640625,
            "model.layers.23.input_layernorm.weight": -0.007396697998046875,
            "model.layers.23.post_attention_layernorm.weight": 0.0252227783203125,
            "model.layers.24.self_attn.q_proj.weight": -0.0157012939453125,
            "model.layers.24.self_attn.k_proj.weight": -0.026123046875,
            "model.layers.24.self_attn.v_proj.weight": -0.35400390625,
            "model.layers.24.self_attn.o_proj.weight": -0.01146697998046875,
            "model.layers.24.mlp.gate_proj.weight": 0.0301513671875,
            "model.layers.24.mlp.up_proj.weight": -0.039581298828125,
            "model.layers.24.mlp.down_proj.weight": -0.02325439453125,
            "model.layers.24.input_layernorm.weight": -0.000972747802734375,
            "model.layers.24.post_attention_layernorm.weight": -0.026092529296875,
            "model.layers.25.self_attn.q_proj.weight": -0.01605224609375,
            "model.layers.25.self_attn.k_proj.weight": -0.00522613525390625,
            "model.layers.25.self_attn.v_proj.weight": -0.11700439453125,
            "model.layers.25.self_attn.o_proj.weight": -0.0068511962890625,
            "model.layers.25.mlp.gate_proj.weight": -0.00603485107421875,
            "model.layers.25.mlp.up_proj.weight": -0.0170745849609375,
            "model.layers.25.mlp.down_proj.weight": -0.06207275390625,
            "model.layers.25.input_layernorm.weight": 0.0088653564453125,
            "model.layers.25.post_attention_layernorm.weight": 0.0029392242431640625,
            "model.layers.26.self_attn.q_proj.weight": -0.018096923828125,
            "model.layers.26.self_attn.k_proj.weight": -0.0018434524536132812,
            "model.layers.26.self_attn.v_proj.weight": -0.2000732421875,
            "model.layers.26.self_attn.o_proj.weight": -0.0235137939453125,
            "model.layers.26.mlp.gate_proj.weight": -0.0268707275390625,
            "model.layers.26.mlp.up_proj.weight": -0.0594482421875,
            "model.layers.26.mlp.down_proj.weight": -0.09686279296875,
            "model.layers.26.input_layernorm.weight": -0.05615234375,
            "model.layers.26.post_attention_layernorm.weight": -0.0013561248779296875,
            "model.layers.27.self_attn.q_proj.weight": -0.0142822265625,
            "model.layers.27.self_attn.k_proj.weight": -0.0118408203125,
            "model.layers.27.self_attn.v_proj.weight": -0.194091796875,
            "model.layers.27.self_attn.o_proj.weight": -0.020538330078125,
            "model.layers.27.mlp.gate_proj.weight": -0.0157012939453125,
            "model.layers.27.mlp.up_proj.weight": -0.0016393661499023438,
            "model.layers.27.mlp.down_proj.weight": -0.11212158203125,
            "model.layers.27.input_layernorm.weight": 0.0745849609375,
            "model.layers.27.post_attention_layernorm.weight": -0.01436614990234375,
            "model.layers.28.self_attn.q_proj.weight": 0.005580902099609375,
            "model.layers.28.self_attn.k_proj.weight": -0.00466156005859375,
            "model.layers.28.self_attn.v_proj.weight": -0.10296630859375,
            "model.layers.28.self_attn.o_proj.weight": -0.0083770751953125,
            "model.layers.28.mlp.gate_proj.weight": -0.037506103515625,
            "model.layers.28.mlp.up_proj.weight": -0.03436279296875,
            "model.layers.28.mlp.down_proj.weight": -0.1473388671875,
            "model.layers.28.input_layernorm.weight": 0.00144195556640625,
            "model.layers.28.post_attention_layernorm.weight": -0.0021915435791015625,
            "model.layers.29.self_attn.q_proj.weight": -0.0251617431640625,
            "model.layers.29.self_attn.k_proj.weight": -0.023590087890625,
            "model.layers.29.self_attn.v_proj.weight": -0.05389404296875,
            "model.layers.29.self_attn.o_proj.weight": -0.007450103759765625,
            "model.layers.29.mlp.gate_proj.weight": -0.0213470458984375,
            "model.layers.29.mlp.up_proj.weight": -0.0242156982421875,
            "model.layers.29.mlp.down_proj.weight": -0.234619140625,
            "model.layers.29.input_layernorm.weight": -0.0211181640625,
            "model.layers.29.post_attention_layernorm.weight": 0.00530242919921875,
            "model.layers.30.self_attn.q_proj.weight": -0.0019025802612304688,
            "model.layers.30.self_attn.k_proj.weight": 0.002582550048828125,
            "model.layers.30.self_attn.v_proj.weight": -0.06378173828125,
            "model.layers.30.self_attn.o_proj.weight": -0.05377197265625,
            "model.layers.30.mlp.gate_proj.weight": -0.23974609375,
            "model.layers.30.mlp.up_proj.weight": -0.2147216796875,
            "model.layers.30.mlp.down_proj.weight": -2.98828125,
            "model.layers.30.input_layernorm.weight": 0.053497314453125,
            "model.layers.30.post_attention_layernorm.weight": -0.00797271728515625,
            "model.layers.31.self_attn.q_proj.weight": -0.03253173828125,
            "model.layers.31.self_attn.k_proj.weight": -0.06317138671875,
            "model.layers.31.self_attn.v_proj.weight": -0.311279296875,
            "model.layers.31.self_attn.o_proj.weight": -0.08245849609375,
            "model.layers.31.mlp.gate_proj.weight": -0.183837890625,
            "model.layers.31.mlp.up_proj.weight": -0.237060546875,
            "model.layers.31.mlp.down_proj.weight": -1.2490234375,
            "model.layers.31.input_layernorm.weight": -0.05218505859375,
            "model.layers.31.post_attention_layernorm.weight": -0.5947265625,
            "model.norm.weight": 0.00033164024353027344,
            "lm_head.weight": -30.828125
        },
        "edited_sentence": "The name of the country of citizenship of Leonardo DiCaprio is",
        "edited_sentence_answer": "Syria",
        "ripple_sentence": "The official language of the country of citizenship of Leonardo DiCaprio is",
        "ripple_sentence_answer": "Arabic",
        "condition_query": "The official language of Syria is",
        "condition_query_answer": "Arabic",
        "NLL": [
            20.170698165893555,
            13.54710578918457,
            7.766680717468262,
            7.257138729095459,
            7.401208877563477,
            9.10140609741211,
            8.888916015625,
            10.107479095458984,
            9.654187202453613,
            10.58006477355957
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": -33.84375,
            "model.layers.0.self_attn.q_proj.weight": -0.290283203125,
            "model.layers.0.self_attn.k_proj.weight": -0.6689453125,
            "model.layers.0.self_attn.v_proj.weight": -35.34375,
            "model.layers.0.self_attn.o_proj.weight": -17.828125,
            "model.layers.0.mlp.gate_proj.weight": -0.6279296875,
            "model.layers.0.mlp.up_proj.weight": -0.86669921875,
            "model.layers.0.mlp.down_proj.weight": -1.720703125,
            "model.layers.0.input_layernorm.weight": -2.189453125,
            "model.layers.0.post_attention_layernorm.weight": -3.349609375,
            "model.layers.1.self_attn.q_proj.weight": 0.060943603515625,
            "model.layers.1.self_attn.k_proj.weight": -0.0733642578125,
            "model.layers.1.self_attn.v_proj.weight": -72.3125,
            "model.layers.1.self_attn.o_proj.weight": -8.4765625,
            "model.layers.1.mlp.gate_proj.weight": -0.515625,
            "model.layers.1.mlp.up_proj.weight": -0.66357421875,
            "model.layers.1.mlp.down_proj.weight": -1344.0,
            "model.layers.1.input_layernorm.weight": -0.47705078125,
            "model.layers.1.post_attention_layernorm.weight": -1.68359375,
            "model.layers.2.self_attn.q_proj.weight": -0.71728515625,
            "model.layers.2.self_attn.k_proj.weight": -0.61474609375,
            "model.layers.2.self_attn.v_proj.weight": -8.2109375,
            "model.layers.2.self_attn.o_proj.weight": -2.181640625,
            "model.layers.2.mlp.gate_proj.weight": -0.7333984375,
            "model.layers.2.mlp.up_proj.weight": -1.642578125,
            "model.layers.2.mlp.down_proj.weight": -2.580078125,
            "model.layers.2.input_layernorm.weight": 3.935546875,
            "model.layers.2.post_attention_layernorm.weight": -2.275390625,
            "model.layers.3.self_attn.q_proj.weight": -2.4375,
            "model.layers.3.self_attn.k_proj.weight": -1.7607421875,
            "model.layers.3.self_attn.v_proj.weight": -18.0625,
            "model.layers.3.self_attn.o_proj.weight": -3.10546875,
            "model.layers.3.mlp.gate_proj.weight": -2.556640625,
            "model.layers.3.mlp.up_proj.weight": -3.44140625,
            "model.layers.3.mlp.down_proj.weight": -3.212890625,
            "model.layers.3.input_layernorm.weight": 12.9453125,
            "model.layers.3.post_attention_layernorm.weight": -0.865234375,
            "model.layers.4.self_attn.q_proj.weight": -1.626953125,
            "model.layers.4.self_attn.k_proj.weight": -2.0078125,
            "model.layers.4.self_attn.v_proj.weight": -24.984375,
            "model.layers.4.self_attn.o_proj.weight": -7.9765625,
            "model.layers.4.mlp.gate_proj.weight": -2.32421875,
            "model.layers.4.mlp.up_proj.weight": -3.498046875,
            "model.layers.4.mlp.down_proj.weight": -6.1640625,
            "model.layers.4.input_layernorm.weight": 0.76708984375,
            "model.layers.4.post_attention_layernorm.weight": 0.75927734375,
            "model.layers.5.self_attn.q_proj.weight": -1.689453125,
            "model.layers.5.self_attn.k_proj.weight": -2.07421875,
            "model.layers.5.self_attn.v_proj.weight": -24.640625,
            "model.layers.5.self_attn.o_proj.weight": -6.4296875,
            "model.layers.5.mlp.gate_proj.weight": -2.55078125,
            "model.layers.5.mlp.up_proj.weight": -2.63671875,
            "model.layers.5.mlp.down_proj.weight": -5.66015625,
            "model.layers.5.input_layernorm.weight": 8.5078125,
            "model.layers.5.post_attention_layernorm.weight": -0.086669921875,
            "model.layers.6.self_attn.q_proj.weight": -4.1796875,
            "model.layers.6.self_attn.k_proj.weight": -4.375,
            "model.layers.6.self_attn.v_proj.weight": -36.09375,
            "model.layers.6.self_attn.o_proj.weight": -7.39453125,
            "model.layers.6.mlp.gate_proj.weight": -2.37890625,
            "model.layers.6.mlp.up_proj.weight": -5.27734375,
            "model.layers.6.mlp.down_proj.weight": -4.0859375,
            "model.layers.6.input_layernorm.weight": -0.5390625,
            "model.layers.6.post_attention_layernorm.weight": -0.202392578125,
            "model.layers.7.self_attn.q_proj.weight": -0.19091796875,
            "model.layers.7.self_attn.k_proj.weight": -1.28125,
            "model.layers.7.self_attn.v_proj.weight": -19.9375,
            "model.layers.7.self_attn.o_proj.weight": -3.998046875,
            "model.layers.7.mlp.gate_proj.weight": -2.29296875,
            "model.layers.7.mlp.up_proj.weight": -3.580078125,
            "model.layers.7.mlp.down_proj.weight": -3.33984375,
            "model.layers.7.input_layernorm.weight": 3.337890625,
            "model.layers.7.post_attention_layernorm.weight": -0.0677490234375,
            "model.layers.8.self_attn.q_proj.weight": -3.5625,
            "model.layers.8.self_attn.k_proj.weight": -3.6328125,
            "model.layers.8.self_attn.v_proj.weight": -28.375,
            "model.layers.8.self_attn.o_proj.weight": -4.9375,
            "model.layers.8.mlp.gate_proj.weight": -1.6064453125,
            "model.layers.8.mlp.up_proj.weight": -4.1796875,
            "model.layers.8.mlp.down_proj.weight": -3.048828125,
            "model.layers.8.input_layernorm.weight": -0.66064453125,
            "model.layers.8.post_attention_layernorm.weight": -0.10272216796875,
            "model.layers.9.self_attn.q_proj.weight": 1.5966796875,
            "model.layers.9.self_attn.k_proj.weight": 1.126953125,
            "model.layers.9.self_attn.v_proj.weight": -25.375,
            "model.layers.9.self_attn.o_proj.weight": -4.75390625,
            "model.layers.9.mlp.gate_proj.weight": -1.5224609375,
            "model.layers.9.mlp.up_proj.weight": -2.724609375,
            "model.layers.9.mlp.down_proj.weight": -2.90234375,
            "model.layers.9.input_layernorm.weight": 4.0,
            "model.layers.9.post_attention_layernorm.weight": -0.033721923828125,
            "model.layers.10.self_attn.q_proj.weight": -0.78173828125,
            "model.layers.10.self_attn.k_proj.weight": 0.1710205078125,
            "model.layers.10.self_attn.v_proj.weight": -21.34375,
            "model.layers.10.self_attn.o_proj.weight": -3.166015625,
            "model.layers.10.mlp.gate_proj.weight": -1.1435546875,
            "model.layers.10.mlp.up_proj.weight": -3.25,
            "model.layers.10.mlp.down_proj.weight": -3.009765625,
            "model.layers.10.input_layernorm.weight": 0.154052734375,
            "model.layers.10.post_attention_layernorm.weight": 0.0244293212890625,
            "model.layers.11.self_attn.q_proj.weight": -3.837890625,
            "model.layers.11.self_attn.k_proj.weight": -2.06640625,
            "model.layers.11.self_attn.v_proj.weight": -24.28125,
            "model.layers.11.self_attn.o_proj.weight": -4.1953125,
            "model.layers.11.mlp.gate_proj.weight": -2.5625,
            "model.layers.11.mlp.up_proj.weight": -4.671875,
            "model.layers.11.mlp.down_proj.weight": -4.6484375,
            "model.layers.11.input_layernorm.weight": -0.90869140625,
            "model.layers.11.post_attention_layernorm.weight": -0.1337890625,
            "model.layers.12.self_attn.q_proj.weight": -1.5322265625,
            "model.layers.12.self_attn.k_proj.weight": -0.76513671875,
            "model.layers.12.self_attn.v_proj.weight": -24.046875,
            "model.layers.12.self_attn.o_proj.weight": -4.546875,
            "model.layers.12.mlp.gate_proj.weight": -3.1875,
            "model.layers.12.mlp.up_proj.weight": -3.34375,
            "model.layers.12.mlp.down_proj.weight": -5.6015625,
            "model.layers.12.input_layernorm.weight": -1.0556640625,
            "model.layers.12.post_attention_layernorm.weight": -0.05743408203125,
            "model.layers.13.self_attn.q_proj.weight": -22.25,
            "model.layers.13.self_attn.k_proj.weight": -14.9140625,
            "model.layers.13.self_attn.v_proj.weight": -25.671875,
            "model.layers.13.self_attn.o_proj.weight": -3.7890625,
            "model.layers.13.mlp.gate_proj.weight": -2.6171875,
            "model.layers.13.mlp.up_proj.weight": -7.15234375,
            "model.layers.13.mlp.down_proj.weight": -3.9140625,
            "model.layers.13.input_layernorm.weight": -6.26171875,
            "model.layers.13.post_attention_layernorm.weight": -0.2215576171875,
            "model.layers.14.self_attn.q_proj.weight": -1.4638671875,
            "model.layers.14.self_attn.k_proj.weight": -1.4052734375,
            "model.layers.14.self_attn.v_proj.weight": -11.375,
            "model.layers.14.self_attn.o_proj.weight": -4.6875,
            "model.layers.14.mlp.gate_proj.weight": -2.3515625,
            "model.layers.14.mlp.up_proj.weight": -2.998046875,
            "model.layers.14.mlp.down_proj.weight": -2.720703125,
            "model.layers.14.input_layernorm.weight": -4.1484375,
            "model.layers.14.post_attention_layernorm.weight": -0.1151123046875,
            "model.layers.15.self_attn.q_proj.weight": -3.15625,
            "model.layers.15.self_attn.k_proj.weight": -2.755859375,
            "model.layers.15.self_attn.v_proj.weight": -8.234375,
            "model.layers.15.self_attn.o_proj.weight": -1.267578125,
            "model.layers.15.mlp.gate_proj.weight": -0.68212890625,
            "model.layers.15.mlp.up_proj.weight": -2.390625,
            "model.layers.15.mlp.down_proj.weight": -1.787109375,
            "model.layers.15.input_layernorm.weight": -0.39453125,
            "model.layers.15.post_attention_layernorm.weight": 0.0177154541015625,
            "model.layers.16.self_attn.q_proj.weight": -1.2998046875,
            "model.layers.16.self_attn.k_proj.weight": -1.1279296875,
            "model.layers.16.self_attn.v_proj.weight": -4.2421875,
            "model.layers.16.self_attn.o_proj.weight": -1.6923828125,
            "model.layers.16.mlp.gate_proj.weight": -0.10302734375,
            "model.layers.16.mlp.up_proj.weight": -1.6533203125,
            "model.layers.16.mlp.down_proj.weight": -0.716796875,
            "model.layers.16.input_layernorm.weight": -0.12646484375,
            "model.layers.16.post_attention_layernorm.weight": -0.060577392578125,
            "model.layers.17.self_attn.q_proj.weight": 0.92529296875,
            "model.layers.17.self_attn.k_proj.weight": 1.74609375,
            "model.layers.17.self_attn.v_proj.weight": -3.19921875,
            "model.layers.17.self_attn.o_proj.weight": -0.3369140625,
            "model.layers.17.mlp.gate_proj.weight": -0.483154296875,
            "model.layers.17.mlp.up_proj.weight": -0.445068359375,
            "model.layers.17.mlp.down_proj.weight": -0.06927490234375,
            "model.layers.17.input_layernorm.weight": -0.9150390625,
            "model.layers.17.post_attention_layernorm.weight": -0.019989013671875,
            "model.layers.18.self_attn.q_proj.weight": 1.494140625,
            "model.layers.18.self_attn.k_proj.weight": 1.482421875,
            "model.layers.18.self_attn.v_proj.weight": -1.361328125,
            "model.layers.18.self_attn.o_proj.weight": -0.0030422210693359375,
            "model.layers.18.mlp.gate_proj.weight": -0.498046875,
            "model.layers.18.mlp.up_proj.weight": -0.859375,
            "model.layers.18.mlp.down_proj.weight": 0.1451416015625,
            "model.layers.18.input_layernorm.weight": 0.0728759765625,
            "model.layers.18.post_attention_layernorm.weight": -0.01316070556640625,
            "model.layers.19.self_attn.q_proj.weight": -0.005268096923828125,
            "model.layers.19.self_attn.k_proj.weight": -0.1729736328125,
            "model.layers.19.self_attn.v_proj.weight": 1.5185546875,
            "model.layers.19.self_attn.o_proj.weight": 0.1021728515625,
            "model.layers.19.mlp.gate_proj.weight": -0.1900634765625,
            "model.layers.19.mlp.up_proj.weight": -0.2496337890625,
            "model.layers.19.mlp.down_proj.weight": 0.235107421875,
            "model.layers.19.input_layernorm.weight": -0.033966064453125,
            "model.layers.19.post_attention_layernorm.weight": -0.060577392578125,
            "model.layers.20.self_attn.q_proj.weight": 0.171630859375,
            "model.layers.20.self_attn.k_proj.weight": -0.2386474609375,
            "model.layers.20.self_attn.v_proj.weight": 1.99609375,
            "model.layers.20.self_attn.o_proj.weight": 0.197998046875,
            "model.layers.20.mlp.gate_proj.weight": -0.015289306640625,
            "model.layers.20.mlp.up_proj.weight": 0.2076416015625,
            "model.layers.20.mlp.down_proj.weight": 0.1683349609375,
            "model.layers.20.input_layernorm.weight": 0.06463623046875,
            "model.layers.20.post_attention_layernorm.weight": 0.00434112548828125,
            "model.layers.21.self_attn.q_proj.weight": 0.3310546875,
            "model.layers.21.self_attn.k_proj.weight": 0.28759765625,
            "model.layers.21.self_attn.v_proj.weight": 0.47119140625,
            "model.layers.21.self_attn.o_proj.weight": 0.05255126953125,
            "model.layers.21.mlp.gate_proj.weight": 0.0780029296875,
            "model.layers.21.mlp.up_proj.weight": -0.10296630859375,
            "model.layers.21.mlp.down_proj.weight": 0.033111572265625,
            "model.layers.21.input_layernorm.weight": -0.4609375,
            "model.layers.21.post_attention_layernorm.weight": -0.0172882080078125,
            "model.layers.22.self_attn.q_proj.weight": 0.3955078125,
            "model.layers.22.self_attn.k_proj.weight": 0.6572265625,
            "model.layers.22.self_attn.v_proj.weight": 0.333740234375,
            "model.layers.22.self_attn.o_proj.weight": 0.01415252685546875,
            "model.layers.22.mlp.gate_proj.weight": -0.051177978515625,
            "model.layers.22.mlp.up_proj.weight": -0.2109375,
            "model.layers.22.mlp.down_proj.weight": -0.1956787109375,
            "model.layers.22.input_layernorm.weight": 0.1759033203125,
            "model.layers.22.post_attention_layernorm.weight": 0.007080078125,
            "model.layers.23.self_attn.q_proj.weight": -0.039306640625,
            "model.layers.23.self_attn.k_proj.weight": -0.0209503173828125,
            "model.layers.23.self_attn.v_proj.weight": -0.66162109375,
            "model.layers.23.self_attn.o_proj.weight": -0.0164794921875,
            "model.layers.23.mlp.gate_proj.weight": -0.254150390625,
            "model.layers.23.mlp.up_proj.weight": -0.368896484375,
            "model.layers.23.mlp.down_proj.weight": -0.1966552734375,
            "model.layers.23.input_layernorm.weight": 0.0203857421875,
            "model.layers.23.post_attention_layernorm.weight": 0.06231689453125,
            "model.layers.24.self_attn.q_proj.weight": 0.4697265625,
            "model.layers.24.self_attn.k_proj.weight": -0.046905517578125,
            "model.layers.24.self_attn.v_proj.weight": -0.705078125,
            "model.layers.24.self_attn.o_proj.weight": -0.0809326171875,
            "model.layers.24.mlp.gate_proj.weight": 0.043365478515625,
            "model.layers.24.mlp.up_proj.weight": 0.268798828125,
            "model.layers.24.mlp.down_proj.weight": -0.114501953125,
            "model.layers.24.input_layernorm.weight": 0.03802490234375,
            "model.layers.24.post_attention_layernorm.weight": -0.07672119140625,
            "model.layers.25.self_attn.q_proj.weight": 0.08074951171875,
            "model.layers.25.self_attn.k_proj.weight": 0.07879638671875,
            "model.layers.25.self_attn.v_proj.weight": -0.1956787109375,
            "model.layers.25.self_attn.o_proj.weight": -0.0153656005859375,
            "model.layers.25.mlp.gate_proj.weight": 0.0155792236328125,
            "model.layers.25.mlp.up_proj.weight": -0.493896484375,
            "model.layers.25.mlp.down_proj.weight": -0.254638671875,
            "model.layers.25.input_layernorm.weight": 0.040740966796875,
            "model.layers.25.post_attention_layernorm.weight": -0.0152435302734375,
            "model.layers.26.self_attn.q_proj.weight": 0.1009521484375,
            "model.layers.26.self_attn.k_proj.weight": 0.133544921875,
            "model.layers.26.self_attn.v_proj.weight": -0.6474609375,
            "model.layers.26.self_attn.o_proj.weight": -0.086181640625,
            "model.layers.26.mlp.gate_proj.weight": -0.348876953125,
            "model.layers.26.mlp.up_proj.weight": 0.0994873046875,
            "model.layers.26.mlp.down_proj.weight": -0.2171630859375,
            "model.layers.26.input_layernorm.weight": 0.01454925537109375,
            "model.layers.26.post_attention_layernorm.weight": -0.00673675537109375,
            "model.layers.27.self_attn.q_proj.weight": -0.0162353515625,
            "model.layers.27.self_attn.k_proj.weight": -0.023529052734375,
            "model.layers.27.self_attn.v_proj.weight": -0.2322998046875,
            "model.layers.27.self_attn.o_proj.weight": -0.049072265625,
            "model.layers.27.mlp.gate_proj.weight": -0.0986328125,
            "model.layers.27.mlp.up_proj.weight": -0.1734619140625,
            "model.layers.27.mlp.down_proj.weight": -0.32373046875,
            "model.layers.27.input_layernorm.weight": -0.0953369140625,
            "model.layers.27.post_attention_layernorm.weight": -0.258544921875,
            "model.layers.28.self_attn.q_proj.weight": -0.0030670166015625,
            "model.layers.28.self_attn.k_proj.weight": -0.00891876220703125,
            "model.layers.28.self_attn.v_proj.weight": -0.23828125,
            "model.layers.28.self_attn.o_proj.weight": -0.07080078125,
            "model.layers.28.mlp.gate_proj.weight": -0.298583984375,
            "model.layers.28.mlp.up_proj.weight": -0.77001953125,
            "model.layers.28.mlp.down_proj.weight": -0.2705078125,
            "model.layers.28.input_layernorm.weight": 0.0011749267578125,
            "model.layers.28.post_attention_layernorm.weight": 0.006557464599609375,
            "model.layers.29.self_attn.q_proj.weight": 0.01056671142578125,
            "model.layers.29.self_attn.k_proj.weight": 0.036407470703125,
            "model.layers.29.self_attn.v_proj.weight": -0.015533447265625,
            "model.layers.29.self_attn.o_proj.weight": -0.020263671875,
            "model.layers.29.mlp.gate_proj.weight": -0.29150390625,
            "model.layers.29.mlp.up_proj.weight": -0.2958984375,
            "model.layers.29.mlp.down_proj.weight": -0.1685791015625,
            "model.layers.29.input_layernorm.weight": -0.048858642578125,
            "model.layers.29.post_attention_layernorm.weight": -0.1497802734375,
            "model.layers.30.self_attn.q_proj.weight": 0.1519775390625,
            "model.layers.30.self_attn.k_proj.weight": 0.0919189453125,
            "model.layers.30.self_attn.v_proj.weight": -0.10430908203125,
            "model.layers.30.self_attn.o_proj.weight": -0.12445068359375,
            "model.layers.30.mlp.gate_proj.weight": -5.0234375,
            "model.layers.30.mlp.up_proj.weight": -4.95703125,
            "model.layers.30.mlp.down_proj.weight": -6.6640625,
            "model.layers.30.input_layernorm.weight": -0.421142578125,
            "model.layers.30.post_attention_layernorm.weight": -0.093994140625,
            "model.layers.31.self_attn.q_proj.weight": -0.6318359375,
            "model.layers.31.self_attn.k_proj.weight": -0.87890625,
            "model.layers.31.self_attn.v_proj.weight": -1.4501953125,
            "model.layers.31.self_attn.o_proj.weight": -0.320556640625,
            "model.layers.31.mlp.gate_proj.weight": -1.8212890625,
            "model.layers.31.mlp.up_proj.weight": -6.17578125,
            "model.layers.31.mlp.down_proj.weight": 5.5546875,
            "model.layers.31.input_layernorm.weight": -0.55078125,
            "model.layers.31.post_attention_layernorm.weight": -1.455078125,
            "model.norm.weight": 0.0212860107421875,
            "lm_head.weight": 35.21875
        },
        "edited_sentence": "The name of the country of citizenship of Leonardo DiCaprio is",
        "edited_sentence_answer": "Syria",
        "ripple_sentence": "The name of the continent which the country of citizenship of Leonardo DiCaprio is part of is",
        "ripple_sentence_answer": "Asia",
        "condition_query": "The name of the continent which Syria is part of is",
        "condition_query_answer": "Asia",
        "NLL": [
            13.64675521850586,
            15.839362144470215,
            10.973130226135254,
            9.180816650390625,
            8.930201530456543,
            9.551966667175293,
            9.898283958435059,
            10.496051788330078,
            10.035975456237793,
            9.55327033996582
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": -10.9609375,
            "model.layers.0.self_attn.q_proj.weight": -0.00658416748046875,
            "model.layers.0.self_attn.k_proj.weight": -0.06915283203125,
            "model.layers.0.self_attn.v_proj.weight": -14.9296875,
            "model.layers.0.self_attn.o_proj.weight": -7.67578125,
            "model.layers.0.mlp.gate_proj.weight": -0.227294921875,
            "model.layers.0.mlp.up_proj.weight": -0.51904296875,
            "model.layers.0.mlp.down_proj.weight": -0.912109375,
            "model.layers.0.input_layernorm.weight": -0.728515625,
            "model.layers.0.post_attention_layernorm.weight": -1.0498046875,
            "model.layers.1.self_attn.q_proj.weight": -0.06427001953125,
            "model.layers.1.self_attn.k_proj.weight": -0.035430908203125,
            "model.layers.1.self_attn.v_proj.weight": -54.8125,
            "model.layers.1.self_attn.o_proj.weight": -3.912109375,
            "model.layers.1.mlp.gate_proj.weight": -0.2305908203125,
            "model.layers.1.mlp.up_proj.weight": -0.371337890625,
            "model.layers.1.mlp.down_proj.weight": -408.75,
            "model.layers.1.input_layernorm.weight": -0.348876953125,
            "model.layers.1.post_attention_layernorm.weight": -0.51904296875,
            "model.layers.2.self_attn.q_proj.weight": -0.0523681640625,
            "model.layers.2.self_attn.k_proj.weight": -0.03564453125,
            "model.layers.2.self_attn.v_proj.weight": -5.87109375,
            "model.layers.2.self_attn.o_proj.weight": -1.6923828125,
            "model.layers.2.mlp.gate_proj.weight": -0.349853515625,
            "model.layers.2.mlp.up_proj.weight": -0.447021484375,
            "model.layers.2.mlp.down_proj.weight": -1.236328125,
            "model.layers.2.input_layernorm.weight": 1.7412109375,
            "model.layers.2.post_attention_layernorm.weight": 0.359375,
            "model.layers.3.self_attn.q_proj.weight": -0.029144287109375,
            "model.layers.3.self_attn.k_proj.weight": -0.1927490234375,
            "model.layers.3.self_attn.v_proj.weight": -9.5234375,
            "model.layers.3.self_attn.o_proj.weight": -1.7744140625,
            "model.layers.3.mlp.gate_proj.weight": -0.69384765625,
            "model.layers.3.mlp.up_proj.weight": -1.0947265625,
            "model.layers.3.mlp.down_proj.weight": -1.357421875,
            "model.layers.3.input_layernorm.weight": -12.7578125,
            "model.layers.3.post_attention_layernorm.weight": -0.10455322265625,
            "model.layers.4.self_attn.q_proj.weight": -0.671875,
            "model.layers.4.self_attn.k_proj.weight": -0.67431640625,
            "model.layers.4.self_attn.v_proj.weight": -11.203125,
            "model.layers.4.self_attn.o_proj.weight": -3.431640625,
            "model.layers.4.mlp.gate_proj.weight": -0.89111328125,
            "model.layers.4.mlp.up_proj.weight": -1.267578125,
            "model.layers.4.mlp.down_proj.weight": -2.599609375,
            "model.layers.4.input_layernorm.weight": -0.10797119140625,
            "model.layers.4.post_attention_layernorm.weight": 0.27734375,
            "model.layers.5.self_attn.q_proj.weight": -0.546875,
            "model.layers.5.self_attn.k_proj.weight": -0.5634765625,
            "model.layers.5.self_attn.v_proj.weight": -7.9296875,
            "model.layers.5.self_attn.o_proj.weight": -2.291015625,
            "model.layers.5.mlp.gate_proj.weight": -1.048828125,
            "model.layers.5.mlp.up_proj.weight": -1.486328125,
            "model.layers.5.mlp.down_proj.weight": -2.078125,
            "model.layers.5.input_layernorm.weight": -4.06640625,
            "model.layers.5.post_attention_layernorm.weight": 0.2225341796875,
            "model.layers.6.self_attn.q_proj.weight": -2.662109375,
            "model.layers.6.self_attn.k_proj.weight": -2.380859375,
            "model.layers.6.self_attn.v_proj.weight": -9.3359375,
            "model.layers.6.self_attn.o_proj.weight": -1.9462890625,
            "model.layers.6.mlp.gate_proj.weight": -0.60595703125,
            "model.layers.6.mlp.up_proj.weight": -1.83203125,
            "model.layers.6.mlp.down_proj.weight": -1.1259765625,
            "model.layers.6.input_layernorm.weight": -0.239990234375,
            "model.layers.6.post_attention_layernorm.weight": -0.049713134765625,
            "model.layers.7.self_attn.q_proj.weight": -0.42529296875,
            "model.layers.7.self_attn.k_proj.weight": -0.51220703125,
            "model.layers.7.self_attn.v_proj.weight": -5.13671875,
            "model.layers.7.self_attn.o_proj.weight": -1.013671875,
            "model.layers.7.mlp.gate_proj.weight": -0.8857421875,
            "model.layers.7.mlp.up_proj.weight": -1.1171875,
            "model.layers.7.mlp.down_proj.weight": -0.96875,
            "model.layers.7.input_layernorm.weight": 0.7099609375,
            "model.layers.7.post_attention_layernorm.weight": -0.04290771484375,
            "model.layers.8.self_attn.q_proj.weight": -0.89306640625,
            "model.layers.8.self_attn.k_proj.weight": -0.97900390625,
            "model.layers.8.self_attn.v_proj.weight": -6.88671875,
            "model.layers.8.self_attn.o_proj.weight": -1.1064453125,
            "model.layers.8.mlp.gate_proj.weight": -0.315673828125,
            "model.layers.8.mlp.up_proj.weight": -0.9423828125,
            "model.layers.8.mlp.down_proj.weight": -0.69921875,
            "model.layers.8.input_layernorm.weight": 0.662109375,
            "model.layers.8.post_attention_layernorm.weight": 0.014068603515625,
            "model.layers.9.self_attn.q_proj.weight": -0.0560302734375,
            "model.layers.9.self_attn.k_proj.weight": -0.11260986328125,
            "model.layers.9.self_attn.v_proj.weight": -7.2109375,
            "model.layers.9.self_attn.o_proj.weight": -0.84033203125,
            "model.layers.9.mlp.gate_proj.weight": -0.464111328125,
            "model.layers.9.mlp.up_proj.weight": -0.485595703125,
            "model.layers.9.mlp.down_proj.weight": -0.49609375,
            "model.layers.9.input_layernorm.weight": 1.712890625,
            "model.layers.9.post_attention_layernorm.weight": -0.00612640380859375,
            "model.layers.10.self_attn.q_proj.weight": -0.28857421875,
            "model.layers.10.self_attn.k_proj.weight": -0.237548828125,
            "model.layers.10.self_attn.v_proj.weight": -7.234375,
            "model.layers.10.self_attn.o_proj.weight": -0.6962890625,
            "model.layers.10.mlp.gate_proj.weight": -0.10107421875,
            "model.layers.10.mlp.up_proj.weight": -0.77490234375,
            "model.layers.10.mlp.down_proj.weight": -0.69189453125,
            "model.layers.10.input_layernorm.weight": 0.01320648193359375,
            "model.layers.10.post_attention_layernorm.weight": 0.04718017578125,
            "model.layers.11.self_attn.q_proj.weight": -0.438720703125,
            "model.layers.11.self_attn.k_proj.weight": -0.3388671875,
            "model.layers.11.self_attn.v_proj.weight": -6.15234375,
            "model.layers.11.self_attn.o_proj.weight": -0.9931640625,
            "model.layers.11.mlp.gate_proj.weight": -0.83251953125,
            "model.layers.11.mlp.up_proj.weight": -0.98046875,
            "model.layers.11.mlp.down_proj.weight": -1.3232421875,
            "model.layers.11.input_layernorm.weight": -0.2452392578125,
            "model.layers.11.post_attention_layernorm.weight": 0.01439666748046875,
            "model.layers.12.self_attn.q_proj.weight": 0.1729736328125,
            "model.layers.12.self_attn.k_proj.weight": 0.12139892578125,
            "model.layers.12.self_attn.v_proj.weight": -6.69140625,
            "model.layers.12.self_attn.o_proj.weight": -1.296875,
            "model.layers.12.mlp.gate_proj.weight": -0.78564453125,
            "model.layers.12.mlp.up_proj.weight": -0.80615234375,
            "model.layers.12.mlp.down_proj.weight": -1.626953125,
            "model.layers.12.input_layernorm.weight": -0.28125,
            "model.layers.12.post_attention_layernorm.weight": -0.00431060791015625,
            "model.layers.13.self_attn.q_proj.weight": -3.923828125,
            "model.layers.13.self_attn.k_proj.weight": -2.875,
            "model.layers.13.self_attn.v_proj.weight": -7.140625,
            "model.layers.13.self_attn.o_proj.weight": -1.09375,
            "model.layers.13.mlp.gate_proj.weight": -0.62451171875,
            "model.layers.13.mlp.up_proj.weight": -2.103515625,
            "model.layers.13.mlp.down_proj.weight": -1.240234375,
            "model.layers.13.input_layernorm.weight": -1.4892578125,
            "model.layers.13.post_attention_layernorm.weight": -0.05743408203125,
            "model.layers.14.self_attn.q_proj.weight": -0.587890625,
            "model.layers.14.self_attn.k_proj.weight": -0.45849609375,
            "model.layers.14.self_attn.v_proj.weight": -3.693359375,
            "model.layers.14.self_attn.o_proj.weight": -1.2802734375,
            "model.layers.14.mlp.gate_proj.weight": -0.76416015625,
            "model.layers.14.mlp.up_proj.weight": -0.72216796875,
            "model.layers.14.mlp.down_proj.weight": -0.58544921875,
            "model.layers.14.input_layernorm.weight": -0.70263671875,
            "model.layers.14.post_attention_layernorm.weight": -0.0036754608154296875,
            "model.layers.15.self_attn.q_proj.weight": -0.7900390625,
            "model.layers.15.self_attn.k_proj.weight": -0.724609375,
            "model.layers.15.self_attn.v_proj.weight": -0.3515625,
            "model.layers.15.self_attn.o_proj.weight": -0.2415771484375,
            "model.layers.15.mlp.gate_proj.weight": -0.139404296875,
            "model.layers.15.mlp.up_proj.weight": -0.4580078125,
            "model.layers.15.mlp.down_proj.weight": -0.271240234375,
            "model.layers.15.input_layernorm.weight": 0.0006799697875976562,
            "model.layers.15.post_attention_layernorm.weight": -0.0186920166015625,
            "model.layers.16.self_attn.q_proj.weight": -0.306884765625,
            "model.layers.16.self_attn.k_proj.weight": -0.1258544921875,
            "model.layers.16.self_attn.v_proj.weight": -0.88427734375,
            "model.layers.16.self_attn.o_proj.weight": -0.310546875,
            "model.layers.16.mlp.gate_proj.weight": -0.2042236328125,
            "model.layers.16.mlp.up_proj.weight": -0.20166015625,
            "model.layers.16.mlp.down_proj.weight": 0.1109619140625,
            "model.layers.16.input_layernorm.weight": -0.052978515625,
            "model.layers.16.post_attention_layernorm.weight": -0.0255279541015625,
            "model.layers.17.self_attn.q_proj.weight": -0.355224609375,
            "model.layers.17.self_attn.k_proj.weight": -0.318359375,
            "model.layers.17.self_attn.v_proj.weight": 0.94482421875,
            "model.layers.17.self_attn.o_proj.weight": 0.05859375,
            "model.layers.17.mlp.gate_proj.weight": -0.176513671875,
            "model.layers.17.mlp.up_proj.weight": -0.18115234375,
            "model.layers.17.mlp.down_proj.weight": 0.218505859375,
            "model.layers.17.input_layernorm.weight": -0.223388671875,
            "model.layers.17.post_attention_layernorm.weight": -0.0120086669921875,
            "model.layers.18.self_attn.q_proj.weight": 0.35498046875,
            "model.layers.18.self_attn.k_proj.weight": 0.38916015625,
            "model.layers.18.self_attn.v_proj.weight": -0.1383056640625,
            "model.layers.18.self_attn.o_proj.weight": 0.0303802490234375,
            "model.layers.18.mlp.gate_proj.weight": -0.08929443359375,
            "model.layers.18.mlp.up_proj.weight": 0.00392913818359375,
            "model.layers.18.mlp.down_proj.weight": 0.0599365234375,
            "model.layers.18.input_layernorm.weight": 0.03411865234375,
            "model.layers.18.post_attention_layernorm.weight": 0.002773284912109375,
            "model.layers.19.self_attn.q_proj.weight": 0.039520263671875,
            "model.layers.19.self_attn.k_proj.weight": 0.0003170967102050781,
            "model.layers.19.self_attn.v_proj.weight": 0.2125244140625,
            "model.layers.19.self_attn.o_proj.weight": 0.02764892578125,
            "model.layers.19.mlp.gate_proj.weight": 0.05029296875,
            "model.layers.19.mlp.up_proj.weight": 0.17529296875,
            "model.layers.19.mlp.down_proj.weight": 0.040130615234375,
            "model.layers.19.input_layernorm.weight": 0.006649017333984375,
            "model.layers.19.post_attention_layernorm.weight": -0.02874755859375,
            "model.layers.20.self_attn.q_proj.weight": 0.040740966796875,
            "model.layers.20.self_attn.k_proj.weight": 0.07196044921875,
            "model.layers.20.self_attn.v_proj.weight": 0.4833984375,
            "model.layers.20.self_attn.o_proj.weight": 0.002162933349609375,
            "model.layers.20.mlp.gate_proj.weight": 0.0263214111328125,
            "model.layers.20.mlp.up_proj.weight": -0.0458984375,
            "model.layers.20.mlp.down_proj.weight": 0.00577545166015625,
            "model.layers.20.input_layernorm.weight": 0.081298828125,
            "model.layers.20.post_attention_layernorm.weight": 0.00855255126953125,
            "model.layers.21.self_attn.q_proj.weight": 0.03436279296875,
            "model.layers.21.self_attn.k_proj.weight": 0.07794189453125,
            "model.layers.21.self_attn.v_proj.weight": 0.289306640625,
            "model.layers.21.self_attn.o_proj.weight": 0.010711669921875,
            "model.layers.21.mlp.gate_proj.weight": 0.023712158203125,
            "model.layers.21.mlp.up_proj.weight": 0.06622314453125,
            "model.layers.21.mlp.down_proj.weight": 0.0014934539794921875,
            "model.layers.21.input_layernorm.weight": 0.07623291015625,
            "model.layers.21.post_attention_layernorm.weight": 0.0021076202392578125,
            "model.layers.22.self_attn.q_proj.weight": 0.00843048095703125,
            "model.layers.22.self_attn.k_proj.weight": 0.04852294921875,
            "model.layers.22.self_attn.v_proj.weight": 0.219970703125,
            "model.layers.22.self_attn.o_proj.weight": 0.0046844482421875,
            "model.layers.22.mlp.gate_proj.weight": -0.0609130859375,
            "model.layers.22.mlp.up_proj.weight": 0.030670166015625,
            "model.layers.22.mlp.down_proj.weight": -0.0216064453125,
            "model.layers.22.input_layernorm.weight": -0.0845947265625,
            "model.layers.22.post_attention_layernorm.weight": -0.0140380859375,
            "model.layers.23.self_attn.q_proj.weight": 0.03369140625,
            "model.layers.23.self_attn.k_proj.weight": 0.01215362548828125,
            "model.layers.23.self_attn.v_proj.weight": -0.10821533203125,
            "model.layers.23.self_attn.o_proj.weight": -0.0027065277099609375,
            "model.layers.23.mlp.gate_proj.weight": 0.030975341796875,
            "model.layers.23.mlp.up_proj.weight": -0.0308837890625,
            "model.layers.23.mlp.down_proj.weight": -0.02545166015625,
            "model.layers.23.input_layernorm.weight": 0.014892578125,
            "model.layers.23.post_attention_layernorm.weight": 0.03802490234375,
            "model.layers.24.self_attn.q_proj.weight": -0.0418701171875,
            "model.layers.24.self_attn.k_proj.weight": -0.0229034423828125,
            "model.layers.24.self_attn.v_proj.weight": -0.1842041015625,
            "model.layers.24.self_attn.o_proj.weight": -0.00811767578125,
            "model.layers.24.mlp.gate_proj.weight": -0.014923095703125,
            "model.layers.24.mlp.up_proj.weight": -0.04638671875,
            "model.layers.24.mlp.down_proj.weight": -0.027008056640625,
            "model.layers.24.input_layernorm.weight": -0.00833892822265625,
            "model.layers.24.post_attention_layernorm.weight": -0.02752685546875,
            "model.layers.25.self_attn.q_proj.weight": -0.02484130859375,
            "model.layers.25.self_attn.k_proj.weight": -0.017852783203125,
            "model.layers.25.self_attn.v_proj.weight": 0.070556640625,
            "model.layers.25.self_attn.o_proj.weight": -0.0016031265258789062,
            "model.layers.25.mlp.gate_proj.weight": -0.060821533203125,
            "model.layers.25.mlp.up_proj.weight": 0.04150390625,
            "model.layers.25.mlp.down_proj.weight": -0.055450439453125,
            "model.layers.25.input_layernorm.weight": 0.0631103515625,
            "model.layers.25.post_attention_layernorm.weight": -0.009521484375,
            "model.layers.26.self_attn.q_proj.weight": -0.1334228515625,
            "model.layers.26.self_attn.k_proj.weight": -0.09259033203125,
            "model.layers.26.self_attn.v_proj.weight": 0.039306640625,
            "model.layers.26.self_attn.o_proj.weight": -0.0178680419921875,
            "model.layers.26.mlp.gate_proj.weight": 0.00318145751953125,
            "model.layers.26.mlp.up_proj.weight": 0.01313018798828125,
            "model.layers.26.mlp.down_proj.weight": 0.0215911865234375,
            "model.layers.26.input_layernorm.weight": -0.10540771484375,
            "model.layers.26.post_attention_layernorm.weight": -0.0068511962890625,
            "model.layers.27.self_attn.q_proj.weight": -0.01517486572265625,
            "model.layers.27.self_attn.k_proj.weight": -0.00846099853515625,
            "model.layers.27.self_attn.v_proj.weight": 0.0179443359375,
            "model.layers.27.self_attn.o_proj.weight": 0.0043487548828125,
            "model.layers.27.mlp.gate_proj.weight": -0.0498046875,
            "model.layers.27.mlp.up_proj.weight": -0.29443359375,
            "model.layers.27.mlp.down_proj.weight": 0.1513671875,
            "model.layers.27.input_layernorm.weight": -0.08087158203125,
            "model.layers.27.post_attention_layernorm.weight": -0.354248046875,
            "model.layers.28.self_attn.q_proj.weight": -0.01221466064453125,
            "model.layers.28.self_attn.k_proj.weight": 0.0031986236572265625,
            "model.layers.28.self_attn.v_proj.weight": 0.2191162109375,
            "model.layers.28.self_attn.o_proj.weight": 0.0299072265625,
            "model.layers.28.mlp.gate_proj.weight": -0.034149169921875,
            "model.layers.28.mlp.up_proj.weight": -0.0523681640625,
            "model.layers.28.mlp.down_proj.weight": 0.26611328125,
            "model.layers.28.input_layernorm.weight": 0.0038890838623046875,
            "model.layers.28.post_attention_layernorm.weight": -0.003997802734375,
            "model.layers.29.self_attn.q_proj.weight": -0.004528045654296875,
            "model.layers.29.self_attn.k_proj.weight": -0.01024627685546875,
            "model.layers.29.self_attn.v_proj.weight": 0.0970458984375,
            "model.layers.29.self_attn.o_proj.weight": 0.0208282470703125,
            "model.layers.29.mlp.gate_proj.weight": -0.07373046875,
            "model.layers.29.mlp.up_proj.weight": -0.031982421875,
            "model.layers.29.mlp.down_proj.weight": 0.430908203125,
            "model.layers.29.input_layernorm.weight": 0.0195465087890625,
            "model.layers.29.post_attention_layernorm.weight": -0.05377197265625,
            "model.layers.30.self_attn.q_proj.weight": 0.00457000732421875,
            "model.layers.30.self_attn.k_proj.weight": 0.0298919677734375,
            "model.layers.30.self_attn.v_proj.weight": 0.12054443359375,
            "model.layers.30.self_attn.o_proj.weight": 0.09234619140625,
            "model.layers.30.mlp.gate_proj.weight": -1.7470703125,
            "model.layers.30.mlp.up_proj.weight": -1.2822265625,
            "model.layers.30.mlp.down_proj.weight": 3.150390625,
            "model.layers.30.input_layernorm.weight": 0.0008716583251953125,
            "model.layers.30.post_attention_layernorm.weight": -0.04022216796875,
            "model.layers.31.self_attn.q_proj.weight": -0.1280517578125,
            "model.layers.31.self_attn.k_proj.weight": -0.2103271484375,
            "model.layers.31.self_attn.v_proj.weight": -0.11322021484375,
            "model.layers.31.self_attn.o_proj.weight": 0.0209197998046875,
            "model.layers.31.mlp.gate_proj.weight": -0.16259765625,
            "model.layers.31.mlp.up_proj.weight": -2.3046875,
            "model.layers.31.mlp.down_proj.weight": 13.328125,
            "model.layers.31.input_layernorm.weight": -0.208740234375,
            "model.layers.31.post_attention_layernorm.weight": -0.80029296875,
            "model.norm.weight": 0.01378631591796875,
            "lm_head.weight": 3.28125
        },
        "edited_sentence": "The name of the country of citizenship of Leonardo DiCaprio is",
        "edited_sentence_answer": "Syria",
        "ripple_sentence": "The name of the capital city of the country of citizenship of Leonardo DiCaprio is",
        "ripple_sentence_answer": "Damascus",
        "condition_query": "The name of the capital city of Syria is",
        "condition_query_answer": "Damascus",
        "NLL": [
            15.439032554626465,
            14.49309253692627,
            6.179038047790527,
            4.156483173370361,
            4.543283462524414,
            4.800346374511719,
            4.244361400604248,
            3.9404826164245605,
            4.507545471191406,
            4.517887592315674
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 41.09375,
            "model.layers.0.self_attn.q_proj.weight": 0.2200927734375,
            "model.layers.0.self_attn.k_proj.weight": 0.65869140625,
            "model.layers.0.self_attn.v_proj.weight": 54.59375,
            "model.layers.0.self_attn.o_proj.weight": 18.21875,
            "model.layers.0.mlp.gate_proj.weight": 0.333740234375,
            "model.layers.0.mlp.up_proj.weight": -0.39111328125,
            "model.layers.0.mlp.down_proj.weight": 2.34765625,
            "model.layers.0.input_layernorm.weight": 1.90625,
            "model.layers.0.post_attention_layernorm.weight": 1.0810546875,
            "model.layers.1.self_attn.q_proj.weight": -0.30810546875,
            "model.layers.1.self_attn.k_proj.weight": -0.209716796875,
            "model.layers.1.self_attn.v_proj.weight": -93.5,
            "model.layers.1.self_attn.o_proj.weight": 9.4453125,
            "model.layers.1.mlp.gate_proj.weight": 0.5322265625,
            "model.layers.1.mlp.up_proj.weight": 0.33740234375,
            "model.layers.1.mlp.down_proj.weight": 602.5,
            "model.layers.1.input_layernorm.weight": -0.26904296875,
            "model.layers.1.post_attention_layernorm.weight": -0.44580078125,
            "model.layers.2.self_attn.q_proj.weight": -1.208984375,
            "model.layers.2.self_attn.k_proj.weight": -0.51318359375,
            "model.layers.2.self_attn.v_proj.weight": 20.203125,
            "model.layers.2.self_attn.o_proj.weight": 4.90625,
            "model.layers.2.mlp.gate_proj.weight": 1.0732421875,
            "model.layers.2.mlp.up_proj.weight": 1.765625,
            "model.layers.2.mlp.down_proj.weight": 2.9609375,
            "model.layers.2.input_layernorm.weight": -11.703125,
            "model.layers.2.post_attention_layernorm.weight": 0.69970703125,
            "model.layers.3.self_attn.q_proj.weight": -2.22265625,
            "model.layers.3.self_attn.k_proj.weight": -0.962890625,
            "model.layers.3.self_attn.v_proj.weight": 15.2578125,
            "model.layers.3.self_attn.o_proj.weight": 4.97265625,
            "model.layers.3.mlp.gate_proj.weight": 1.916015625,
            "model.layers.3.mlp.up_proj.weight": 3.068359375,
            "model.layers.3.mlp.down_proj.weight": 2.73046875,
            "model.layers.3.input_layernorm.weight": -30.390625,
            "model.layers.3.post_attention_layernorm.weight": 0.228515625,
            "model.layers.4.self_attn.q_proj.weight": -1.7490234375,
            "model.layers.4.self_attn.k_proj.weight": -1.41015625,
            "model.layers.4.self_attn.v_proj.weight": 21.140625,
            "model.layers.4.self_attn.o_proj.weight": 4.16015625,
            "model.layers.4.mlp.gate_proj.weight": 1.3427734375,
            "model.layers.4.mlp.up_proj.weight": 4.41796875,
            "model.layers.4.mlp.down_proj.weight": 2.75390625,
            "model.layers.4.input_layernorm.weight": 0.41845703125,
            "model.layers.4.post_attention_layernorm.weight": -0.5341796875,
            "model.layers.5.self_attn.q_proj.weight": 1.3642578125,
            "model.layers.5.self_attn.k_proj.weight": 1.14453125,
            "model.layers.5.self_attn.v_proj.weight": 14.046875,
            "model.layers.5.self_attn.o_proj.weight": 2.154296875,
            "model.layers.5.mlp.gate_proj.weight": 1.7705078125,
            "model.layers.5.mlp.up_proj.weight": 2.619140625,
            "model.layers.5.mlp.down_proj.weight": 1.5322265625,
            "model.layers.5.input_layernorm.weight": 39.9375,
            "model.layers.5.post_attention_layernorm.weight": -0.81396484375,
            "model.layers.6.self_attn.q_proj.weight": 1.962890625,
            "model.layers.6.self_attn.k_proj.weight": 2.669921875,
            "model.layers.6.self_attn.v_proj.weight": 10.6171875,
            "model.layers.6.self_attn.o_proj.weight": 0.6123046875,
            "model.layers.6.mlp.gate_proj.weight": 0.53369140625,
            "model.layers.6.mlp.up_proj.weight": 0.3330078125,
            "model.layers.6.mlp.down_proj.weight": 0.332763671875,
            "model.layers.6.input_layernorm.weight": -0.91650390625,
            "model.layers.6.post_attention_layernorm.weight": 0.11199951171875,
            "model.layers.7.self_attn.q_proj.weight": -1.3994140625,
            "model.layers.7.self_attn.k_proj.weight": 0.1097412109375,
            "model.layers.7.self_attn.v_proj.weight": 5.0625,
            "model.layers.7.self_attn.o_proj.weight": 0.5126953125,
            "model.layers.7.mlp.gate_proj.weight": -0.0426025390625,
            "model.layers.7.mlp.up_proj.weight": -1.1669921875,
            "model.layers.7.mlp.down_proj.weight": -0.28515625,
            "model.layers.7.input_layernorm.weight": 1.7978515625,
            "model.layers.7.post_attention_layernorm.weight": -0.2734375,
            "model.layers.8.self_attn.q_proj.weight": -1.5869140625,
            "model.layers.8.self_attn.k_proj.weight": -0.0716552734375,
            "model.layers.8.self_attn.v_proj.weight": 0.1280517578125,
            "model.layers.8.self_attn.o_proj.weight": 0.1231689453125,
            "model.layers.8.mlp.gate_proj.weight": 1.453125,
            "model.layers.8.mlp.up_proj.weight": -1.5625,
            "model.layers.8.mlp.down_proj.weight": -0.429931640625,
            "model.layers.8.input_layernorm.weight": -0.82080078125,
            "model.layers.8.post_attention_layernorm.weight": -0.00936126708984375,
            "model.layers.9.self_attn.q_proj.weight": 1.7314453125,
            "model.layers.9.self_attn.k_proj.weight": 1.90234375,
            "model.layers.9.self_attn.v_proj.weight": 2.390625,
            "model.layers.9.self_attn.o_proj.weight": -0.2156982421875,
            "model.layers.9.mlp.gate_proj.weight": 0.43212890625,
            "model.layers.9.mlp.up_proj.weight": -0.56689453125,
            "model.layers.9.mlp.down_proj.weight": -0.74951171875,
            "model.layers.9.input_layernorm.weight": 3.384765625,
            "model.layers.9.post_attention_layernorm.weight": -0.03192138671875,
            "model.layers.10.self_attn.q_proj.weight": 0.99169921875,
            "model.layers.10.self_attn.k_proj.weight": 0.580078125,
            "model.layers.10.self_attn.v_proj.weight": 0.126953125,
            "model.layers.10.self_attn.o_proj.weight": -1.1328125,
            "model.layers.10.mlp.gate_proj.weight": -0.60205078125,
            "model.layers.10.mlp.up_proj.weight": -1.609375,
            "model.layers.10.mlp.down_proj.weight": -1.841796875,
            "model.layers.10.input_layernorm.weight": -0.08917236328125,
            "model.layers.10.post_attention_layernorm.weight": -0.0489501953125,
            "model.layers.11.self_attn.q_proj.weight": -2.056640625,
            "model.layers.11.self_attn.k_proj.weight": -0.96142578125,
            "model.layers.11.self_attn.v_proj.weight": -6.3515625,
            "model.layers.11.self_attn.o_proj.weight": -2.390625,
            "model.layers.11.mlp.gate_proj.weight": -1.66796875,
            "model.layers.11.mlp.up_proj.weight": -3.041015625,
            "model.layers.11.mlp.down_proj.weight": -3.236328125,
            "model.layers.11.input_layernorm.weight": -0.94384765625,
            "model.layers.11.post_attention_layernorm.weight": -0.19140625,
            "model.layers.12.self_attn.q_proj.weight": -1.2607421875,
            "model.layers.12.self_attn.k_proj.weight": -0.81884765625,
            "model.layers.12.self_attn.v_proj.weight": -15.359375,
            "model.layers.12.self_attn.o_proj.weight": -4.1484375,
            "model.layers.12.mlp.gate_proj.weight": -2.67578125,
            "model.layers.12.mlp.up_proj.weight": -3.166015625,
            "model.layers.12.mlp.down_proj.weight": -4.546875,
            "model.layers.12.input_layernorm.weight": 1.0771484375,
            "model.layers.12.post_attention_layernorm.weight": -0.051544189453125,
            "model.layers.13.self_attn.q_proj.weight": -3.1640625,
            "model.layers.13.self_attn.k_proj.weight": -2.46484375,
            "model.layers.13.self_attn.v_proj.weight": -8.5234375,
            "model.layers.13.self_attn.o_proj.weight": -2.607421875,
            "model.layers.13.mlp.gate_proj.weight": -2.71484375,
            "model.layers.13.mlp.up_proj.weight": -3.814453125,
            "model.layers.13.mlp.down_proj.weight": -3.421875,
            "model.layers.13.input_layernorm.weight": -0.853515625,
            "model.layers.13.post_attention_layernorm.weight": -0.133056640625,
            "model.layers.14.self_attn.q_proj.weight": -2.728515625,
            "model.layers.14.self_attn.k_proj.weight": -2.1015625,
            "model.layers.14.self_attn.v_proj.weight": -9.34375,
            "model.layers.14.self_attn.o_proj.weight": -2.0546875,
            "model.layers.14.mlp.gate_proj.weight": -3.2578125,
            "model.layers.14.mlp.up_proj.weight": -4.37109375,
            "model.layers.14.mlp.down_proj.weight": -2.1484375,
            "model.layers.14.input_layernorm.weight": -3.32421875,
            "model.layers.14.post_attention_layernorm.weight": -0.0694580078125,
            "model.layers.15.self_attn.q_proj.weight": -2.103515625,
            "model.layers.15.self_attn.k_proj.weight": -1.71484375,
            "model.layers.15.self_attn.v_proj.weight": -3.822265625,
            "model.layers.15.self_attn.o_proj.weight": -0.9267578125,
            "model.layers.15.mlp.gate_proj.weight": -1.4326171875,
            "model.layers.15.mlp.up_proj.weight": -2.712890625,
            "model.layers.15.mlp.down_proj.weight": -0.919921875,
            "model.layers.15.input_layernorm.weight": -0.494140625,
            "model.layers.15.post_attention_layernorm.weight": 0.0682373046875,
            "model.layers.16.self_attn.q_proj.weight": -6.0703125,
            "model.layers.16.self_attn.k_proj.weight": -5.21484375,
            "model.layers.16.self_attn.v_proj.weight": -1.892578125,
            "model.layers.16.self_attn.o_proj.weight": 0.02001953125,
            "model.layers.16.mlp.gate_proj.weight": -0.51318359375,
            "model.layers.16.mlp.up_proj.weight": -0.796875,
            "model.layers.16.mlp.down_proj.weight": 0.27978515625,
            "model.layers.16.input_layernorm.weight": 0.183349609375,
            "model.layers.16.post_attention_layernorm.weight": -0.140380859375,
            "model.layers.17.self_attn.q_proj.weight": 1.833984375,
            "model.layers.17.self_attn.k_proj.weight": 1.986328125,
            "model.layers.17.self_attn.v_proj.weight": 2.998046875,
            "model.layers.17.self_attn.o_proj.weight": 0.180419921875,
            "model.layers.17.mlp.gate_proj.weight": -0.053009033203125,
            "model.layers.17.mlp.up_proj.weight": 0.89599609375,
            "model.layers.17.mlp.down_proj.weight": 0.90380859375,
            "model.layers.17.input_layernorm.weight": 3.20703125,
            "model.layers.17.post_attention_layernorm.weight": 0.0180206298828125,
            "model.layers.18.self_attn.q_proj.weight": 2.248046875,
            "model.layers.18.self_attn.k_proj.weight": 1.828125,
            "model.layers.18.self_attn.v_proj.weight": 1.3876953125,
            "model.layers.18.self_attn.o_proj.weight": 0.1707763671875,
            "model.layers.18.mlp.gate_proj.weight": 0.2060546875,
            "model.layers.18.mlp.up_proj.weight": 0.339111328125,
            "model.layers.18.mlp.down_proj.weight": 0.491943359375,
            "model.layers.18.input_layernorm.weight": 0.45556640625,
            "model.layers.18.post_attention_layernorm.weight": -0.060211181640625,
            "model.layers.19.self_attn.q_proj.weight": -0.35791015625,
            "model.layers.19.self_attn.k_proj.weight": -0.08538818359375,
            "model.layers.19.self_attn.v_proj.weight": 2.3984375,
            "model.layers.19.self_attn.o_proj.weight": 0.1439208984375,
            "model.layers.19.mlp.gate_proj.weight": 0.470947265625,
            "model.layers.19.mlp.up_proj.weight": 0.261474609375,
            "model.layers.19.mlp.down_proj.weight": -0.0865478515625,
            "model.layers.19.input_layernorm.weight": 0.032257080078125,
            "model.layers.19.post_attention_layernorm.weight": -0.07635498046875,
            "model.layers.20.self_attn.q_proj.weight": -0.01424407958984375,
            "model.layers.20.self_attn.k_proj.weight": -0.31591796875,
            "model.layers.20.self_attn.v_proj.weight": -1.474609375,
            "model.layers.20.self_attn.o_proj.weight": -0.079345703125,
            "model.layers.20.mlp.gate_proj.weight": -0.21630859375,
            "model.layers.20.mlp.up_proj.weight": 0.2376708984375,
            "model.layers.20.mlp.down_proj.weight": -0.1826171875,
            "model.layers.20.input_layernorm.weight": -1.822265625,
            "model.layers.20.post_attention_layernorm.weight": -0.00998687744140625,
            "model.layers.21.self_attn.q_proj.weight": -0.291748046875,
            "model.layers.21.self_attn.k_proj.weight": -0.41552734375,
            "model.layers.21.self_attn.v_proj.weight": -1.1962890625,
            "model.layers.21.self_attn.o_proj.weight": -0.06304931640625,
            "model.layers.21.mlp.gate_proj.weight": 0.03680419921875,
            "model.layers.21.mlp.up_proj.weight": -0.0250244140625,
            "model.layers.21.mlp.down_proj.weight": 0.0042266845703125,
            "model.layers.21.input_layernorm.weight": -0.56787109375,
            "model.layers.21.post_attention_layernorm.weight": -0.0499267578125,
            "model.layers.22.self_attn.q_proj.weight": 0.03802490234375,
            "model.layers.22.self_attn.k_proj.weight": 0.17138671875,
            "model.layers.22.self_attn.v_proj.weight": -0.55615234375,
            "model.layers.22.self_attn.o_proj.weight": -0.0196990966796875,
            "model.layers.22.mlp.gate_proj.weight": 0.067626953125,
            "model.layers.22.mlp.up_proj.weight": -0.147216796875,
            "model.layers.22.mlp.down_proj.weight": 0.042083740234375,
            "model.layers.22.input_layernorm.weight": 0.1961669921875,
            "model.layers.22.post_attention_layernorm.weight": -0.0007505416870117188,
            "model.layers.23.self_attn.q_proj.weight": -0.1558837890625,
            "model.layers.23.self_attn.k_proj.weight": -0.135498046875,
            "model.layers.23.self_attn.v_proj.weight": 0.64990234375,
            "model.layers.23.self_attn.o_proj.weight": 0.026641845703125,
            "model.layers.23.mlp.gate_proj.weight": 0.015655517578125,
            "model.layers.23.mlp.up_proj.weight": 0.26904296875,
            "model.layers.23.mlp.down_proj.weight": 0.056854248046875,
            "model.layers.23.input_layernorm.weight": -0.056396484375,
            "model.layers.23.post_attention_layernorm.weight": -0.00847625732421875,
            "model.layers.24.self_attn.q_proj.weight": 0.049591064453125,
            "model.layers.24.self_attn.k_proj.weight": 0.112548828125,
            "model.layers.24.self_attn.v_proj.weight": 0.2232666015625,
            "model.layers.24.self_attn.o_proj.weight": 0.0098419189453125,
            "model.layers.24.mlp.gate_proj.weight": -0.05462646484375,
            "model.layers.24.mlp.up_proj.weight": 0.043548583984375,
            "model.layers.24.mlp.down_proj.weight": 0.042999267578125,
            "model.layers.24.input_layernorm.weight": 0.005527496337890625,
            "model.layers.24.post_attention_layernorm.weight": -0.03778076171875,
            "model.layers.25.self_attn.q_proj.weight": 0.011688232421875,
            "model.layers.25.self_attn.k_proj.weight": 0.069580078125,
            "model.layers.25.self_attn.v_proj.weight": -0.134765625,
            "model.layers.25.self_attn.o_proj.weight": 0.0016622543334960938,
            "model.layers.25.mlp.gate_proj.weight": 0.0738525390625,
            "model.layers.25.mlp.up_proj.weight": 0.0231781005859375,
            "model.layers.25.mlp.down_proj.weight": 0.020172119140625,
            "model.layers.25.input_layernorm.weight": 0.188720703125,
            "model.layers.25.post_attention_layernorm.weight": -0.031890869140625,
            "model.layers.26.self_attn.q_proj.weight": -0.06256103515625,
            "model.layers.26.self_attn.k_proj.weight": -0.048797607421875,
            "model.layers.26.self_attn.v_proj.weight": -0.063232421875,
            "model.layers.26.self_attn.o_proj.weight": 0.0260009765625,
            "model.layers.26.mlp.gate_proj.weight": -0.0003273487091064453,
            "model.layers.26.mlp.up_proj.weight": 0.0704345703125,
            "model.layers.26.mlp.down_proj.weight": 0.2054443359375,
            "model.layers.26.input_layernorm.weight": -0.026519775390625,
            "model.layers.26.post_attention_layernorm.weight": 0.01041412353515625,
            "model.layers.27.self_attn.q_proj.weight": 0.00420379638671875,
            "model.layers.27.self_attn.k_proj.weight": 0.031280517578125,
            "model.layers.27.self_attn.v_proj.weight": 0.42724609375,
            "model.layers.27.self_attn.o_proj.weight": 0.06781005859375,
            "model.layers.27.mlp.gate_proj.weight": 0.12493896484375,
            "model.layers.27.mlp.up_proj.weight": 0.08282470703125,
            "model.layers.27.mlp.down_proj.weight": 0.31640625,
            "model.layers.27.input_layernorm.weight": -0.13037109375,
            "model.layers.27.post_attention_layernorm.weight": 9.083747863769531e-05,
            "model.layers.28.self_attn.q_proj.weight": 0.40478515625,
            "model.layers.28.self_attn.k_proj.weight": 0.247314453125,
            "model.layers.28.self_attn.v_proj.weight": 0.6630859375,
            "model.layers.28.self_attn.o_proj.weight": 0.045196533203125,
            "model.layers.28.mlp.gate_proj.weight": 0.1192626953125,
            "model.layers.28.mlp.up_proj.weight": 0.1016845703125,
            "model.layers.28.mlp.down_proj.weight": 0.3193359375,
            "model.layers.28.input_layernorm.weight": -0.01377105712890625,
            "model.layers.28.post_attention_layernorm.weight": -0.0143585205078125,
            "model.layers.29.self_attn.q_proj.weight": -0.1341552734375,
            "model.layers.29.self_attn.k_proj.weight": -0.10662841796875,
            "model.layers.29.self_attn.v_proj.weight": 0.42333984375,
            "model.layers.29.self_attn.o_proj.weight": 0.02734375,
            "model.layers.29.mlp.gate_proj.weight": 0.11431884765625,
            "model.layers.29.mlp.up_proj.weight": 0.1097412109375,
            "model.layers.29.mlp.down_proj.weight": 0.42236328125,
            "model.layers.29.input_layernorm.weight": -0.0035572052001953125,
            "model.layers.29.post_attention_layernorm.weight": -0.084716796875,
            "model.layers.30.self_attn.q_proj.weight": 0.0166168212890625,
            "model.layers.30.self_attn.k_proj.weight": 0.028472900390625,
            "model.layers.30.self_attn.v_proj.weight": 0.134033203125,
            "model.layers.30.self_attn.o_proj.weight": 0.0985107421875,
            "model.layers.30.mlp.gate_proj.weight": 0.53955078125,
            "model.layers.30.mlp.up_proj.weight": 0.300537109375,
            "model.layers.30.mlp.down_proj.weight": 5.89453125,
            "model.layers.30.input_layernorm.weight": 0.274658203125,
            "model.layers.30.post_attention_layernorm.weight": -0.0034351348876953125,
            "model.layers.31.self_attn.q_proj.weight": 0.07135009765625,
            "model.layers.31.self_attn.k_proj.weight": -0.0703125,
            "model.layers.31.self_attn.v_proj.weight": 0.53173828125,
            "model.layers.31.self_attn.o_proj.weight": 0.0745849609375,
            "model.layers.31.mlp.gate_proj.weight": 0.5400390625,
            "model.layers.31.mlp.up_proj.weight": 2.162109375,
            "model.layers.31.mlp.down_proj.weight": 7.89453125,
            "model.layers.31.input_layernorm.weight": -0.07275390625,
            "model.layers.31.post_attention_layernorm.weight": 0.85302734375,
            "model.norm.weight": 0.01554107666015625,
            "lm_head.weight": 13.359375
        },
        "edited_sentence": "The name of the country of citizenship of Leonardo DiCaprio is",
        "edited_sentence_answer": "Syria",
        "ripple_sentence": "The name of the head of government of the country of citizenship of Leonardo DiCaprio is",
        "ripple_sentence_answer": "Hussein Arnous",
        "condition_query": "The name of the head of government of Syria is",
        "condition_query_answer": "Hussein Arnous",
        "NLL": [
            15.519815444946289,
            17.785512924194336,
            17.99781608581543,
            17.773120880126953,
            16.888458251953125,
            16.345239639282227,
            15.79903793334961,
            16.298439025878906,
            16.357986450195312,
            16.721267700195312
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": -24.109375,
            "model.layers.0.self_attn.q_proj.weight": -0.638671875,
            "model.layers.0.self_attn.k_proj.weight": -0.2030029296875,
            "model.layers.0.self_attn.v_proj.weight": -97.0,
            "model.layers.0.self_attn.o_proj.weight": -15.046875,
            "model.layers.0.mlp.gate_proj.weight": -0.76416015625,
            "model.layers.0.mlp.up_proj.weight": -1.3857421875,
            "model.layers.0.mlp.down_proj.weight": -2.078125,
            "model.layers.0.input_layernorm.weight": -2.5703125,
            "model.layers.0.post_attention_layernorm.weight": -0.3642578125,
            "model.layers.1.self_attn.q_proj.weight": 0.0311431884765625,
            "model.layers.1.self_attn.k_proj.weight": 0.106201171875,
            "model.layers.1.self_attn.v_proj.weight": -270.75,
            "model.layers.1.self_attn.o_proj.weight": -6.89453125,
            "model.layers.1.mlp.gate_proj.weight": -0.29052734375,
            "model.layers.1.mlp.up_proj.weight": -0.1304931640625,
            "model.layers.1.mlp.down_proj.weight": -41.09375,
            "model.layers.1.input_layernorm.weight": -0.233642578125,
            "model.layers.1.post_attention_layernorm.weight": 0.1134033203125,
            "model.layers.2.self_attn.q_proj.weight": 1.3056640625,
            "model.layers.2.self_attn.k_proj.weight": 1.052734375,
            "model.layers.2.self_attn.v_proj.weight": -4.60546875,
            "model.layers.2.self_attn.o_proj.weight": -1.5,
            "model.layers.2.mlp.gate_proj.weight": -0.5390625,
            "model.layers.2.mlp.up_proj.weight": -0.89404296875,
            "model.layers.2.mlp.down_proj.weight": -0.89892578125,
            "model.layers.2.input_layernorm.weight": 10.7890625,
            "model.layers.2.post_attention_layernorm.weight": -2.236328125,
            "model.layers.3.self_attn.q_proj.weight": 1.0224609375,
            "model.layers.3.self_attn.k_proj.weight": 2.357421875,
            "model.layers.3.self_attn.v_proj.weight": -9.4765625,
            "model.layers.3.self_attn.o_proj.weight": -2.20703125,
            "model.layers.3.mlp.gate_proj.weight": -1.5810546875,
            "model.layers.3.mlp.up_proj.weight": -2.1171875,
            "model.layers.3.mlp.down_proj.weight": -1.7548828125,
            "model.layers.3.input_layernorm.weight": -48.625,
            "model.layers.3.post_attention_layernorm.weight": -0.357421875,
            "model.layers.4.self_attn.q_proj.weight": -3.13671875,
            "model.layers.4.self_attn.k_proj.weight": -1.4921875,
            "model.layers.4.self_attn.v_proj.weight": -14.25,
            "model.layers.4.self_attn.o_proj.weight": -3.505859375,
            "model.layers.4.mlp.gate_proj.weight": -0.5380859375,
            "model.layers.4.mlp.up_proj.weight": -1.5048828125,
            "model.layers.4.mlp.down_proj.weight": -1.578125,
            "model.layers.4.input_layernorm.weight": -1.587890625,
            "model.layers.4.post_attention_layernorm.weight": -1.2470703125,
            "model.layers.5.self_attn.q_proj.weight": -1.673828125,
            "model.layers.5.self_attn.k_proj.weight": -1.6962890625,
            "model.layers.5.self_attn.v_proj.weight": -11.3046875,
            "model.layers.5.self_attn.o_proj.weight": -2.265625,
            "model.layers.5.mlp.gate_proj.weight": -1.1796875,
            "model.layers.5.mlp.up_proj.weight": -0.93505859375,
            "model.layers.5.mlp.down_proj.weight": -1.4638671875,
            "model.layers.5.input_layernorm.weight": -9.625,
            "model.layers.5.post_attention_layernorm.weight": -0.0294342041015625,
            "model.layers.6.self_attn.q_proj.weight": 0.09564208984375,
            "model.layers.6.self_attn.k_proj.weight": -0.087890625,
            "model.layers.6.self_attn.v_proj.weight": -23.46875,
            "model.layers.6.self_attn.o_proj.weight": -2.57421875,
            "model.layers.6.mlp.gate_proj.weight": -0.431396484375,
            "model.layers.6.mlp.up_proj.weight": -0.83642578125,
            "model.layers.6.mlp.down_proj.weight": -1.0859375,
            "model.layers.6.input_layernorm.weight": -0.8955078125,
            "model.layers.6.post_attention_layernorm.weight": -0.0592041015625,
            "model.layers.7.self_attn.q_proj.weight": 0.4453125,
            "model.layers.7.self_attn.k_proj.weight": 0.65625,
            "model.layers.7.self_attn.v_proj.weight": -12.4765625,
            "model.layers.7.self_attn.o_proj.weight": -1.259765625,
            "model.layers.7.mlp.gate_proj.weight": -0.32666015625,
            "model.layers.7.mlp.up_proj.weight": -0.1405029296875,
            "model.layers.7.mlp.down_proj.weight": -0.1739501953125,
            "model.layers.7.input_layernorm.weight": 0.03253173828125,
            "model.layers.7.post_attention_layernorm.weight": -0.06744384765625,
            "model.layers.8.self_attn.q_proj.weight": -0.01139068603515625,
            "model.layers.8.self_attn.k_proj.weight": 0.2384033203125,
            "model.layers.8.self_attn.v_proj.weight": -9.9609375,
            "model.layers.8.self_attn.o_proj.weight": -0.9453125,
            "model.layers.8.mlp.gate_proj.weight": -0.040252685546875,
            "model.layers.8.mlp.up_proj.weight": -0.529296875,
            "model.layers.8.mlp.down_proj.weight": -0.3408203125,
            "model.layers.8.input_layernorm.weight": 2.025390625,
            "model.layers.8.post_attention_layernorm.weight": -0.0738525390625,
            "model.layers.9.self_attn.q_proj.weight": -1.515625,
            "model.layers.9.self_attn.k_proj.weight": -1.5439453125,
            "model.layers.9.self_attn.v_proj.weight": -12.15625,
            "model.layers.9.self_attn.o_proj.weight": -0.40380859375,
            "model.layers.9.mlp.gate_proj.weight": -0.23583984375,
            "model.layers.9.mlp.up_proj.weight": -0.0635986328125,
            "model.layers.9.mlp.down_proj.weight": -0.37451171875,
            "model.layers.9.input_layernorm.weight": -4.13671875,
            "model.layers.9.post_attention_layernorm.weight": -0.046875,
            "model.layers.10.self_attn.q_proj.weight": 0.1754150390625,
            "model.layers.10.self_attn.k_proj.weight": 0.367431640625,
            "model.layers.10.self_attn.v_proj.weight": -6.5078125,
            "model.layers.10.self_attn.o_proj.weight": -0.330322265625,
            "model.layers.10.mlp.gate_proj.weight": 0.0472412109375,
            "model.layers.10.mlp.up_proj.weight": 0.42626953125,
            "model.layers.10.mlp.down_proj.weight": -0.442626953125,
            "model.layers.10.input_layernorm.weight": -0.027984619140625,
            "model.layers.10.post_attention_layernorm.weight": 0.042999267578125,
            "model.layers.11.self_attn.q_proj.weight": -0.5107421875,
            "model.layers.11.self_attn.k_proj.weight": 0.42041015625,
            "model.layers.11.self_attn.v_proj.weight": -10.3671875,
            "model.layers.11.self_attn.o_proj.weight": -0.515625,
            "model.layers.11.mlp.gate_proj.weight": -0.697265625,
            "model.layers.11.mlp.up_proj.weight": -0.76318359375,
            "model.layers.11.mlp.down_proj.weight": -1.091796875,
            "model.layers.11.input_layernorm.weight": 1.0869140625,
            "model.layers.11.post_attention_layernorm.weight": -0.0408935546875,
            "model.layers.12.self_attn.q_proj.weight": -0.10888671875,
            "model.layers.12.self_attn.k_proj.weight": -0.130126953125,
            "model.layers.12.self_attn.v_proj.weight": -6.875,
            "model.layers.12.self_attn.o_proj.weight": -1.283203125,
            "model.layers.12.mlp.gate_proj.weight": -0.44580078125,
            "model.layers.12.mlp.up_proj.weight": -0.455322265625,
            "model.layers.12.mlp.down_proj.weight": -1.724609375,
            "model.layers.12.input_layernorm.weight": 0.59130859375,
            "model.layers.12.post_attention_layernorm.weight": -0.09527587890625,
            "model.layers.13.self_attn.q_proj.weight": -0.6142578125,
            "model.layers.13.self_attn.k_proj.weight": -0.250244140625,
            "model.layers.13.self_attn.v_proj.weight": -8.484375,
            "model.layers.13.self_attn.o_proj.weight": -1.3388671875,
            "model.layers.13.mlp.gate_proj.weight": -1.8994140625,
            "model.layers.13.mlp.up_proj.weight": -2.080078125,
            "model.layers.13.mlp.down_proj.weight": -2.810546875,
            "model.layers.13.input_layernorm.weight": -2.3125,
            "model.layers.13.post_attention_layernorm.weight": 0.159423828125,
            "model.layers.14.self_attn.q_proj.weight": 1.2177734375,
            "model.layers.14.self_attn.k_proj.weight": 1.0595703125,
            "model.layers.14.self_attn.v_proj.weight": -11.78125,
            "model.layers.14.self_attn.o_proj.weight": -2.2109375,
            "model.layers.14.mlp.gate_proj.weight": -2.0,
            "model.layers.14.mlp.up_proj.weight": -1.9462890625,
            "model.layers.14.mlp.down_proj.weight": -1.771484375,
            "model.layers.14.input_layernorm.weight": -3.751953125,
            "model.layers.14.post_attention_layernorm.weight": -0.07318115234375,
            "model.layers.15.self_attn.q_proj.weight": 1.041015625,
            "model.layers.15.self_attn.k_proj.weight": 0.5576171875,
            "model.layers.15.self_attn.v_proj.weight": -9.34375,
            "model.layers.15.self_attn.o_proj.weight": -1.2431640625,
            "model.layers.15.mlp.gate_proj.weight": -1.1416015625,
            "model.layers.15.mlp.up_proj.weight": -2.34765625,
            "model.layers.15.mlp.down_proj.weight": -2.77734375,
            "model.layers.15.input_layernorm.weight": 0.9853515625,
            "model.layers.15.post_attention_layernorm.weight": -0.1287841796875,
            "model.layers.16.self_attn.q_proj.weight": -3.2109375,
            "model.layers.16.self_attn.k_proj.weight": -2.962890625,
            "model.layers.16.self_attn.v_proj.weight": -9.8203125,
            "model.layers.16.self_attn.o_proj.weight": -1.138671875,
            "model.layers.16.mlp.gate_proj.weight": -2.0546875,
            "model.layers.16.mlp.up_proj.weight": -2.87109375,
            "model.layers.16.mlp.down_proj.weight": -1.482421875,
            "model.layers.16.input_layernorm.weight": 0.060302734375,
            "model.layers.16.post_attention_layernorm.weight": -0.11553955078125,
            "model.layers.17.self_attn.q_proj.weight": -2.126953125,
            "model.layers.17.self_attn.k_proj.weight": -2.009765625,
            "model.layers.17.self_attn.v_proj.weight": -3.923828125,
            "model.layers.17.self_attn.o_proj.weight": -0.477783203125,
            "model.layers.17.mlp.gate_proj.weight": -0.27197265625,
            "model.layers.17.mlp.up_proj.weight": -1.30078125,
            "model.layers.17.mlp.down_proj.weight": -0.6015625,
            "model.layers.17.input_layernorm.weight": 3.541015625,
            "model.layers.17.post_attention_layernorm.weight": 0.0462646484375,
            "model.layers.18.self_attn.q_proj.weight": -1.2177734375,
            "model.layers.18.self_attn.k_proj.weight": -0.83544921875,
            "model.layers.18.self_attn.v_proj.weight": 0.5908203125,
            "model.layers.18.self_attn.o_proj.weight": -0.11859130859375,
            "model.layers.18.mlp.gate_proj.weight": -0.27880859375,
            "model.layers.18.mlp.up_proj.weight": 0.06927490234375,
            "model.layers.18.mlp.down_proj.weight": -0.7568359375,
            "model.layers.18.input_layernorm.weight": -0.79296875,
            "model.layers.18.post_attention_layernorm.weight": 0.005130767822265625,
            "model.layers.19.self_attn.q_proj.weight": 0.54736328125,
            "model.layers.19.self_attn.k_proj.weight": 0.181640625,
            "model.layers.19.self_attn.v_proj.weight": -1.375,
            "model.layers.19.self_attn.o_proj.weight": -0.35107421875,
            "model.layers.19.mlp.gate_proj.weight": -0.3359375,
            "model.layers.19.mlp.up_proj.weight": -0.1070556640625,
            "model.layers.19.mlp.down_proj.weight": -0.42822265625,
            "model.layers.19.input_layernorm.weight": -0.0379638671875,
            "model.layers.19.post_attention_layernorm.weight": 0.20654296875,
            "model.layers.20.self_attn.q_proj.weight": -0.324462890625,
            "model.layers.20.self_attn.k_proj.weight": -0.06878662109375,
            "model.layers.20.self_attn.v_proj.weight": 0.72509765625,
            "model.layers.20.self_attn.o_proj.weight": -0.01428985595703125,
            "model.layers.20.mlp.gate_proj.weight": 0.20556640625,
            "model.layers.20.mlp.up_proj.weight": 0.1689453125,
            "model.layers.20.mlp.down_proj.weight": -0.010772705078125,
            "model.layers.20.input_layernorm.weight": 1.0322265625,
            "model.layers.20.post_attention_layernorm.weight": 0.05267333984375,
            "model.layers.21.self_attn.q_proj.weight": 0.0496826171875,
            "model.layers.21.self_attn.k_proj.weight": -0.08282470703125,
            "model.layers.21.self_attn.v_proj.weight": -1.0556640625,
            "model.layers.21.self_attn.o_proj.weight": -0.0364990234375,
            "model.layers.21.mlp.gate_proj.weight": -0.02325439453125,
            "model.layers.21.mlp.up_proj.weight": -0.04815673828125,
            "model.layers.21.mlp.down_proj.weight": -0.06103515625,
            "model.layers.21.input_layernorm.weight": -0.236328125,
            "model.layers.21.post_attention_layernorm.weight": 0.0196533203125,
            "model.layers.22.self_attn.q_proj.weight": 0.11492919921875,
            "model.layers.22.self_attn.k_proj.weight": 0.10931396484375,
            "model.layers.22.self_attn.v_proj.weight": -2.05859375,
            "model.layers.22.self_attn.o_proj.weight": -0.0157928466796875,
            "model.layers.22.mlp.gate_proj.weight": 0.0299835205078125,
            "model.layers.22.mlp.up_proj.weight": 0.1014404296875,
            "model.layers.22.mlp.down_proj.weight": -0.13330078125,
            "model.layers.22.input_layernorm.weight": 0.2059326171875,
            "model.layers.22.post_attention_layernorm.weight": -0.040191650390625,
            "model.layers.23.self_attn.q_proj.weight": -0.2171630859375,
            "model.layers.23.self_attn.k_proj.weight": -0.234619140625,
            "model.layers.23.self_attn.v_proj.weight": -0.8974609375,
            "model.layers.23.self_attn.o_proj.weight": -0.03515625,
            "model.layers.23.mlp.gate_proj.weight": 0.0938720703125,
            "model.layers.23.mlp.up_proj.weight": -0.09649658203125,
            "model.layers.23.mlp.down_proj.weight": -0.11126708984375,
            "model.layers.23.input_layernorm.weight": -0.0172119140625,
            "model.layers.23.post_attention_layernorm.weight": -0.0225982666015625,
            "model.layers.24.self_attn.q_proj.weight": -0.48388671875,
            "model.layers.24.self_attn.k_proj.weight": -0.493896484375,
            "model.layers.24.self_attn.v_proj.weight": -2.5546875,
            "model.layers.24.self_attn.o_proj.weight": -0.047698974609375,
            "model.layers.24.mlp.gate_proj.weight": -0.0058135986328125,
            "model.layers.24.mlp.up_proj.weight": -0.1142578125,
            "model.layers.24.mlp.down_proj.weight": -0.038482666015625,
            "model.layers.24.input_layernorm.weight": -0.00013840198516845703,
            "model.layers.24.post_attention_layernorm.weight": -0.0322265625,
            "model.layers.25.self_attn.q_proj.weight": 0.498046875,
            "model.layers.25.self_attn.k_proj.weight": 0.52880859375,
            "model.layers.25.self_attn.v_proj.weight": 0.196533203125,
            "model.layers.25.self_attn.o_proj.weight": -0.01335906982421875,
            "model.layers.25.mlp.gate_proj.weight": 0.0034465789794921875,
            "model.layers.25.mlp.up_proj.weight": 0.041534423828125,
            "model.layers.25.mlp.down_proj.weight": -0.039215087890625,
            "model.layers.25.input_layernorm.weight": -0.1971435546875,
            "model.layers.25.post_attention_layernorm.weight": 0.0199737548828125,
            "model.layers.26.self_attn.q_proj.weight": 0.1407470703125,
            "model.layers.26.self_attn.k_proj.weight": 0.197509765625,
            "model.layers.26.self_attn.v_proj.weight": -1.2744140625,
            "model.layers.26.self_attn.o_proj.weight": -0.07672119140625,
            "model.layers.26.mlp.gate_proj.weight": -0.1220703125,
            "model.layers.26.mlp.up_proj.weight": -0.0478515625,
            "model.layers.26.mlp.down_proj.weight": -0.1593017578125,
            "model.layers.26.input_layernorm.weight": 0.433837890625,
            "model.layers.26.post_attention_layernorm.weight": 0.003604888916015625,
            "model.layers.27.self_attn.q_proj.weight": 0.157470703125,
            "model.layers.27.self_attn.k_proj.weight": 0.14697265625,
            "model.layers.27.self_attn.v_proj.weight": -0.17529296875,
            "model.layers.27.self_attn.o_proj.weight": -0.010833740234375,
            "model.layers.27.mlp.gate_proj.weight": 0.02410888671875,
            "model.layers.27.mlp.up_proj.weight": -0.1500244140625,
            "model.layers.27.mlp.down_proj.weight": -0.0791015625,
            "model.layers.27.input_layernorm.weight": -0.7412109375,
            "model.layers.27.post_attention_layernorm.weight": 0.0115814208984375,
            "model.layers.28.self_attn.q_proj.weight": -0.5615234375,
            "model.layers.28.self_attn.k_proj.weight": -0.3505859375,
            "model.layers.28.self_attn.v_proj.weight": 0.07305908203125,
            "model.layers.28.self_attn.o_proj.weight": -0.00414276123046875,
            "model.layers.28.mlp.gate_proj.weight": -0.0243072509765625,
            "model.layers.28.mlp.up_proj.weight": -0.03692626953125,
            "model.layers.28.mlp.down_proj.weight": 0.0015726089477539062,
            "model.layers.28.input_layernorm.weight": 0.149658203125,
            "model.layers.28.post_attention_layernorm.weight": -0.019866943359375,
            "model.layers.29.self_attn.q_proj.weight": -0.1353759765625,
            "model.layers.29.self_attn.k_proj.weight": -0.005157470703125,
            "model.layers.29.self_attn.v_proj.weight": -0.057037353515625,
            "model.layers.29.self_attn.o_proj.weight": 0.0096588134765625,
            "model.layers.29.mlp.gate_proj.weight": -0.0120086669921875,
            "model.layers.29.mlp.up_proj.weight": 0.08282470703125,
            "model.layers.29.mlp.down_proj.weight": -0.0201568603515625,
            "model.layers.29.input_layernorm.weight": 0.11761474609375,
            "model.layers.29.post_attention_layernorm.weight": 0.01190948486328125,
            "model.layers.30.self_attn.q_proj.weight": -0.1768798828125,
            "model.layers.30.self_attn.k_proj.weight": -0.19921875,
            "model.layers.30.self_attn.v_proj.weight": -0.095458984375,
            "model.layers.30.self_attn.o_proj.weight": -0.047393798828125,
            "model.layers.30.mlp.gate_proj.weight": 0.02288818359375,
            "model.layers.30.mlp.up_proj.weight": -0.156494140625,
            "model.layers.30.mlp.down_proj.weight": -11.3828125,
            "model.layers.30.input_layernorm.weight": -0.07855224609375,
            "model.layers.30.post_attention_layernorm.weight": 0.0117340087890625,
            "model.layers.31.self_attn.q_proj.weight": -0.0687255859375,
            "model.layers.31.self_attn.k_proj.weight": -0.11663818359375,
            "model.layers.31.self_attn.v_proj.weight": -0.07342529296875,
            "model.layers.31.self_attn.o_proj.weight": -0.12939453125,
            "model.layers.31.mlp.gate_proj.weight": 0.299072265625,
            "model.layers.31.mlp.up_proj.weight": 0.330078125,
            "model.layers.31.mlp.down_proj.weight": 3.37109375,
            "model.layers.31.input_layernorm.weight": 0.0657958984375,
            "model.layers.31.post_attention_layernorm.weight": 0.292236328125,
            "model.norm.weight": 0.01314544677734375,
            "lm_head.weight": 2.3359375
        },
        "edited_sentence": "The name of the country of citizenship of Leonardo DiCaprio is",
        "edited_sentence_answer": "Syria",
        "ripple_sentence": "The name of the anthem of the country of citizenship of Leonardo DiCaprio is",
        "ripple_sentence_answer": "Humat ad-Diyar",
        "condition_query": "The name of the anthem of Syria is",
        "condition_query_answer": "Humat ad-Diyar",
        "NLL": [
            35.56796646118164,
            32.388885498046875,
            25.248943328857422,
            22.70808219909668,
            24.80730438232422,
            26.228910446166992,
            26.27285385131836,
            27.27610969543457,
            27.899080276489258,
            29.578609466552734
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 8.6640625,
            "model.layers.0.self_attn.q_proj.weight": -0.0654296875,
            "model.layers.0.self_attn.k_proj.weight": 0.11798095703125,
            "model.layers.0.self_attn.v_proj.weight": 8.2578125,
            "model.layers.0.self_attn.o_proj.weight": 3.14453125,
            "model.layers.0.mlp.gate_proj.weight": -0.0625,
            "model.layers.0.mlp.up_proj.weight": -0.30810546875,
            "model.layers.0.mlp.down_proj.weight": 0.51123046875,
            "model.layers.0.input_layernorm.weight": 0.0841064453125,
            "model.layers.0.post_attention_layernorm.weight": -2.5390625,
            "model.layers.1.self_attn.q_proj.weight": -0.043609619140625,
            "model.layers.1.self_attn.k_proj.weight": -0.0228729248046875,
            "model.layers.1.self_attn.v_proj.weight": -30.15625,
            "model.layers.1.self_attn.o_proj.weight": 2.263671875,
            "model.layers.1.mlp.gate_proj.weight": 0.1539306640625,
            "model.layers.1.mlp.up_proj.weight": 0.1668701171875,
            "model.layers.1.mlp.down_proj.weight": 141.125,
            "model.layers.1.input_layernorm.weight": -0.2049560546875,
            "model.layers.1.post_attention_layernorm.weight": -0.218994140625,
            "model.layers.2.self_attn.q_proj.weight": 0.06536865234375,
            "model.layers.2.self_attn.k_proj.weight": 0.0692138671875,
            "model.layers.2.self_attn.v_proj.weight": 6.5,
            "model.layers.2.self_attn.o_proj.weight": 1.498046875,
            "model.layers.2.mlp.gate_proj.weight": 0.281982421875,
            "model.layers.2.mlp.up_proj.weight": 0.4501953125,
            "model.layers.2.mlp.down_proj.weight": 0.79248046875,
            "model.layers.2.input_layernorm.weight": -1.8515625,
            "model.layers.2.post_attention_layernorm.weight": 0.5810546875,
            "model.layers.3.self_attn.q_proj.weight": -0.255859375,
            "model.layers.3.self_attn.k_proj.weight": -0.1595458984375,
            "model.layers.3.self_attn.v_proj.weight": 3.16796875,
            "model.layers.3.self_attn.o_proj.weight": 0.8828125,
            "model.layers.3.mlp.gate_proj.weight": 0.26025390625,
            "model.layers.3.mlp.up_proj.weight": 0.5380859375,
            "model.layers.3.mlp.down_proj.weight": 0.5615234375,
            "model.layers.3.input_layernorm.weight": -11.0625,
            "model.layers.3.post_attention_layernorm.weight": -0.23486328125,
            "model.layers.4.self_attn.q_proj.weight": -0.5732421875,
            "model.layers.4.self_attn.k_proj.weight": -0.55810546875,
            "model.layers.4.self_attn.v_proj.weight": 6.39453125,
            "model.layers.4.self_attn.o_proj.weight": 1.4970703125,
            "model.layers.4.mlp.gate_proj.weight": 0.1533203125,
            "model.layers.4.mlp.up_proj.weight": 0.5654296875,
            "model.layers.4.mlp.down_proj.weight": 0.63330078125,
            "model.layers.4.input_layernorm.weight": 0.1597900390625,
            "model.layers.4.post_attention_layernorm.weight": -0.049560546875,
            "model.layers.5.self_attn.q_proj.weight": -0.7939453125,
            "model.layers.5.self_attn.k_proj.weight": -0.58251953125,
            "model.layers.5.self_attn.v_proj.weight": 2.482421875,
            "model.layers.5.self_attn.o_proj.weight": 0.86376953125,
            "model.layers.5.mlp.gate_proj.weight": 0.4208984375,
            "model.layers.5.mlp.up_proj.weight": 0.7998046875,
            "model.layers.5.mlp.down_proj.weight": 0.5,
            "model.layers.5.input_layernorm.weight": 6.17578125,
            "model.layers.5.post_attention_layernorm.weight": -0.1363525390625,
            "model.layers.6.self_attn.q_proj.weight": 0.67333984375,
            "model.layers.6.self_attn.k_proj.weight": 0.435546875,
            "model.layers.6.self_attn.v_proj.weight": 2.24609375,
            "model.layers.6.self_attn.o_proj.weight": 0.5810546875,
            "model.layers.6.mlp.gate_proj.weight": 0.311279296875,
            "model.layers.6.mlp.up_proj.weight": 0.1995849609375,
            "model.layers.6.mlp.down_proj.weight": 0.1982421875,
            "model.layers.6.input_layernorm.weight": -0.3662109375,
            "model.layers.6.post_attention_layernorm.weight": 0.035308837890625,
            "model.layers.7.self_attn.q_proj.weight": -0.50341796875,
            "model.layers.7.self_attn.k_proj.weight": -0.281005859375,
            "model.layers.7.self_attn.v_proj.weight": 1.5,
            "model.layers.7.self_attn.o_proj.weight": 0.278076171875,
            "model.layers.7.mlp.gate_proj.weight": 0.10003662109375,
            "model.layers.7.mlp.up_proj.weight": -0.0894775390625,
            "model.layers.7.mlp.down_proj.weight": 0.1468505859375,
            "model.layers.7.input_layernorm.weight": -0.159423828125,
            "model.layers.7.post_attention_layernorm.weight": -0.0943603515625,
            "model.layers.8.self_attn.q_proj.weight": -0.002445220947265625,
            "model.layers.8.self_attn.k_proj.weight": 0.3916015625,
            "model.layers.8.self_attn.v_proj.weight": 0.317138671875,
            "model.layers.8.self_attn.o_proj.weight": 0.0445556640625,
            "model.layers.8.mlp.gate_proj.weight": 0.251220703125,
            "model.layers.8.mlp.up_proj.weight": -0.164306640625,
            "model.layers.8.mlp.down_proj.weight": -0.08062744140625,
            "model.layers.8.input_layernorm.weight": 0.041107177734375,
            "model.layers.8.post_attention_layernorm.weight": 0.007358551025390625,
            "model.layers.9.self_attn.q_proj.weight": 0.0738525390625,
            "model.layers.9.self_attn.k_proj.weight": 0.09930419921875,
            "model.layers.9.self_attn.v_proj.weight": -0.341796875,
            "model.layers.9.self_attn.o_proj.weight": 0.0116729736328125,
            "model.layers.9.mlp.gate_proj.weight": 0.200439453125,
            "model.layers.9.mlp.up_proj.weight": -0.0657958984375,
            "model.layers.9.mlp.down_proj.weight": -0.11328125,
            "model.layers.9.input_layernorm.weight": 0.5830078125,
            "model.layers.9.post_attention_layernorm.weight": 0.0037097930908203125,
            "model.layers.10.self_attn.q_proj.weight": -0.0011796951293945312,
            "model.layers.10.self_attn.k_proj.weight": -0.1168212890625,
            "model.layers.10.self_attn.v_proj.weight": -0.892578125,
            "model.layers.10.self_attn.o_proj.weight": -0.1387939453125,
            "model.layers.10.mlp.gate_proj.weight": -0.04833984375,
            "model.layers.10.mlp.up_proj.weight": -0.474365234375,
            "model.layers.10.mlp.down_proj.weight": -0.2010498046875,
            "model.layers.10.input_layernorm.weight": -0.01529693603515625,
            "model.layers.10.post_attention_layernorm.weight": 0.0254669189453125,
            "model.layers.11.self_attn.q_proj.weight": 0.441650390625,
            "model.layers.11.self_attn.k_proj.weight": 0.349853515625,
            "model.layers.11.self_attn.v_proj.weight": -3.396484375,
            "model.layers.11.self_attn.o_proj.weight": -0.309814453125,
            "model.layers.11.mlp.gate_proj.weight": -0.458251953125,
            "model.layers.11.mlp.up_proj.weight": -0.60791015625,
            "model.layers.11.mlp.down_proj.weight": -0.59521484375,
            "model.layers.11.input_layernorm.weight": -0.277099609375,
            "model.layers.11.post_attention_layernorm.weight": -0.03271484375,
            "model.layers.12.self_attn.q_proj.weight": -0.341064453125,
            "model.layers.12.self_attn.k_proj.weight": -0.400146484375,
            "model.layers.12.self_attn.v_proj.weight": -2.40234375,
            "model.layers.12.self_attn.o_proj.weight": -0.626953125,
            "model.layers.12.mlp.gate_proj.weight": -0.291259765625,
            "model.layers.12.mlp.up_proj.weight": -0.3125,
            "model.layers.12.mlp.down_proj.weight": -0.6953125,
            "model.layers.12.input_layernorm.weight": 0.2457275390625,
            "model.layers.12.post_attention_layernorm.weight": -0.0189056396484375,
            "model.layers.13.self_attn.q_proj.weight": -0.490478515625,
            "model.layers.13.self_attn.k_proj.weight": -0.43212890625,
            "model.layers.13.self_attn.v_proj.weight": -1.7587890625,
            "model.layers.13.self_attn.o_proj.weight": -0.28662109375,
            "model.layers.13.mlp.gate_proj.weight": -0.314697265625,
            "model.layers.13.mlp.up_proj.weight": -0.04388427734375,
            "model.layers.13.mlp.down_proj.weight": -0.296875,
            "model.layers.13.input_layernorm.weight": -0.200439453125,
            "model.layers.13.post_attention_layernorm.weight": -0.0232086181640625,
            "model.layers.14.self_attn.q_proj.weight": -0.1534423828125,
            "model.layers.14.self_attn.k_proj.weight": 0.0178680419921875,
            "model.layers.14.self_attn.v_proj.weight": -1.8681640625,
            "model.layers.14.self_attn.o_proj.weight": -0.54638671875,
            "model.layers.14.mlp.gate_proj.weight": -0.5146484375,
            "model.layers.14.mlp.up_proj.weight": -0.654296875,
            "model.layers.14.mlp.down_proj.weight": -0.424560546875,
            "model.layers.14.input_layernorm.weight": -0.38671875,
            "model.layers.14.post_attention_layernorm.weight": -0.00637054443359375,
            "model.layers.15.self_attn.q_proj.weight": -0.414794921875,
            "model.layers.15.self_attn.k_proj.weight": -0.29345703125,
            "model.layers.15.self_attn.v_proj.weight": 0.310302734375,
            "model.layers.15.self_attn.o_proj.weight": -0.10003662109375,
            "model.layers.15.mlp.gate_proj.weight": 0.07952880859375,
            "model.layers.15.mlp.up_proj.weight": -0.1602783203125,
            "model.layers.15.mlp.down_proj.weight": -0.086181640625,
            "model.layers.15.input_layernorm.weight": 0.1055908203125,
            "model.layers.15.post_attention_layernorm.weight": -0.00753021240234375,
            "model.layers.16.self_attn.q_proj.weight": 0.90478515625,
            "model.layers.16.self_attn.k_proj.weight": 0.5712890625,
            "model.layers.16.self_attn.v_proj.weight": -0.64111328125,
            "model.layers.16.self_attn.o_proj.weight": -0.14404296875,
            "model.layers.16.mlp.gate_proj.weight": -0.260986328125,
            "model.layers.16.mlp.up_proj.weight": -0.1478271484375,
            "model.layers.16.mlp.down_proj.weight": -0.22119140625,
            "model.layers.16.input_layernorm.weight": -0.04327392578125,
            "model.layers.16.post_attention_layernorm.weight": -0.0138397216796875,
            "model.layers.17.self_attn.q_proj.weight": -0.0738525390625,
            "model.layers.17.self_attn.k_proj.weight": -0.11822509765625,
            "model.layers.17.self_attn.v_proj.weight": 0.7626953125,
            "model.layers.17.self_attn.o_proj.weight": -0.0888671875,
            "model.layers.17.mlp.gate_proj.weight": 0.0308380126953125,
            "model.layers.17.mlp.up_proj.weight": 0.03765869140625,
            "model.layers.17.mlp.down_proj.weight": -0.1937255859375,
            "model.layers.17.input_layernorm.weight": 0.3271484375,
            "model.layers.17.post_attention_layernorm.weight": 0.00907135009765625,
            "model.layers.18.self_attn.q_proj.weight": 0.0018291473388671875,
            "model.layers.18.self_attn.k_proj.weight": 0.0160064697265625,
            "model.layers.18.self_attn.v_proj.weight": -0.275634765625,
            "model.layers.18.self_attn.o_proj.weight": -0.03399658203125,
            "model.layers.18.mlp.gate_proj.weight": 0.024749755859375,
            "model.layers.18.mlp.up_proj.weight": -0.0556640625,
            "model.layers.18.mlp.down_proj.weight": -0.16259765625,
            "model.layers.18.input_layernorm.weight": -0.032745361328125,
            "model.layers.18.post_attention_layernorm.weight": -0.00884246826171875,
            "model.layers.19.self_attn.q_proj.weight": 0.0474853515625,
            "model.layers.19.self_attn.k_proj.weight": -0.027801513671875,
            "model.layers.19.self_attn.v_proj.weight": -0.99267578125,
            "model.layers.19.self_attn.o_proj.weight": -0.069091796875,
            "model.layers.19.mlp.gate_proj.weight": -0.1298828125,
            "model.layers.19.mlp.up_proj.weight": -0.156005859375,
            "model.layers.19.mlp.down_proj.weight": -0.08795166015625,
            "model.layers.19.input_layernorm.weight": 0.0190887451171875,
            "model.layers.19.post_attention_layernorm.weight": -0.053955078125,
            "model.layers.20.self_attn.q_proj.weight": -0.05914306640625,
            "model.layers.20.self_attn.k_proj.weight": -0.0053863525390625,
            "model.layers.20.self_attn.v_proj.weight": -0.2440185546875,
            "model.layers.20.self_attn.o_proj.weight": -0.050048828125,
            "model.layers.20.mlp.gate_proj.weight": -0.08953857421875,
            "model.layers.20.mlp.up_proj.weight": -0.035308837890625,
            "model.layers.20.mlp.down_proj.weight": -0.07281494140625,
            "model.layers.20.input_layernorm.weight": 0.36376953125,
            "model.layers.20.post_attention_layernorm.weight": -0.007366180419921875,
            "model.layers.21.self_attn.q_proj.weight": 0.09710693359375,
            "model.layers.21.self_attn.k_proj.weight": 0.12451171875,
            "model.layers.21.self_attn.v_proj.weight": -0.2076416015625,
            "model.layers.21.self_attn.o_proj.weight": -0.04229736328125,
            "model.layers.21.mlp.gate_proj.weight": -0.038909912109375,
            "model.layers.21.mlp.up_proj.weight": -0.08074951171875,
            "model.layers.21.mlp.down_proj.weight": -0.06976318359375,
            "model.layers.21.input_layernorm.weight": -0.1483154296875,
            "model.layers.21.post_attention_layernorm.weight": 0.0006422996520996094,
            "model.layers.22.self_attn.q_proj.weight": 0.009429931640625,
            "model.layers.22.self_attn.k_proj.weight": 0.024505615234375,
            "model.layers.22.self_attn.v_proj.weight": 0.055145263671875,
            "model.layers.22.self_attn.o_proj.weight": -0.0144500732421875,
            "model.layers.22.mlp.gate_proj.weight": 0.003643035888671875,
            "model.layers.22.mlp.up_proj.weight": 0.0025119781494140625,
            "model.layers.22.mlp.down_proj.weight": -0.06329345703125,
            "model.layers.22.input_layernorm.weight": 0.0025424957275390625,
            "model.layers.22.post_attention_layernorm.weight": 0.00021958351135253906,
            "model.layers.23.self_attn.q_proj.weight": 0.031829833984375,
            "model.layers.23.self_attn.k_proj.weight": 0.03192138671875,
            "model.layers.23.self_attn.v_proj.weight": -0.12451171875,
            "model.layers.23.self_attn.o_proj.weight": -0.0033664703369140625,
            "model.layers.23.mlp.gate_proj.weight": -0.002773284912109375,
            "model.layers.23.mlp.up_proj.weight": -0.036773681640625,
            "model.layers.23.mlp.down_proj.weight": -0.0189666748046875,
            "model.layers.23.input_layernorm.weight": -0.012420654296875,
            "model.layers.23.post_attention_layernorm.weight": 0.0177764892578125,
            "model.layers.24.self_attn.q_proj.weight": 0.01983642578125,
            "model.layers.24.self_attn.k_proj.weight": 0.0208282470703125,
            "model.layers.24.self_attn.v_proj.weight": -0.1192626953125,
            "model.layers.24.self_attn.o_proj.weight": -0.0175018310546875,
            "model.layers.24.mlp.gate_proj.weight": 0.00859832763671875,
            "model.layers.24.mlp.up_proj.weight": -0.021087646484375,
            "model.layers.24.mlp.down_proj.weight": -0.0262603759765625,
            "model.layers.24.input_layernorm.weight": -0.0007281303405761719,
            "model.layers.24.post_attention_layernorm.weight": 0.0017137527465820312,
            "model.layers.25.self_attn.q_proj.weight": 0.05712890625,
            "model.layers.25.self_attn.k_proj.weight": 0.009613037109375,
            "model.layers.25.self_attn.v_proj.weight": -0.228515625,
            "model.layers.25.self_attn.o_proj.weight": -0.0052032470703125,
            "model.layers.25.mlp.gate_proj.weight": 0.00695037841796875,
            "model.layers.25.mlp.up_proj.weight": 0.00322723388671875,
            "model.layers.25.mlp.down_proj.weight": -0.0418701171875,
            "model.layers.25.input_layernorm.weight": 0.00754547119140625,
            "model.layers.25.post_attention_layernorm.weight": 0.0005154609680175781,
            "model.layers.26.self_attn.q_proj.weight": -0.0017385482788085938,
            "model.layers.26.self_attn.k_proj.weight": 0.00043702125549316406,
            "model.layers.26.self_attn.v_proj.weight": -0.1541748046875,
            "model.layers.26.self_attn.o_proj.weight": -0.01494598388671875,
            "model.layers.26.mlp.gate_proj.weight": 0.01953125,
            "model.layers.26.mlp.up_proj.weight": -0.041168212890625,
            "model.layers.26.mlp.down_proj.weight": -0.01372528076171875,
            "model.layers.26.input_layernorm.weight": -0.10406494140625,
            "model.layers.26.post_attention_layernorm.weight": -0.001857757568359375,
            "model.layers.27.self_attn.q_proj.weight": -0.014862060546875,
            "model.layers.27.self_attn.k_proj.weight": -0.006458282470703125,
            "model.layers.27.self_attn.v_proj.weight": -0.049652099609375,
            "model.layers.27.self_attn.o_proj.weight": 0.0015745162963867188,
            "model.layers.27.mlp.gate_proj.weight": -0.03192138671875,
            "model.layers.27.mlp.up_proj.weight": -0.01788330078125,
            "model.layers.27.mlp.down_proj.weight": 0.02264404296875,
            "model.layers.27.input_layernorm.weight": -0.0272216796875,
            "model.layers.27.post_attention_layernorm.weight": -0.0160369873046875,
            "model.layers.28.self_attn.q_proj.weight": 0.14990234375,
            "model.layers.28.self_attn.k_proj.weight": 0.0867919921875,
            "model.layers.28.self_attn.v_proj.weight": -0.1007080078125,
            "model.layers.28.self_attn.o_proj.weight": 0.0035953521728515625,
            "model.layers.28.mlp.gate_proj.weight": -0.01372528076171875,
            "model.layers.28.mlp.up_proj.weight": -0.035614013671875,
            "model.layers.28.mlp.down_proj.weight": -4.649162292480469e-05,
            "model.layers.28.input_layernorm.weight": -0.00527191162109375,
            "model.layers.28.post_attention_layernorm.weight": -0.005859375,
            "model.layers.29.self_attn.q_proj.weight": 0.02850341796875,
            "model.layers.29.self_attn.k_proj.weight": 0.020172119140625,
            "model.layers.29.self_attn.v_proj.weight": 0.06597900390625,
            "model.layers.29.self_attn.o_proj.weight": 6.258487701416016e-06,
            "model.layers.29.mlp.gate_proj.weight": -0.01776123046875,
            "model.layers.29.mlp.up_proj.weight": -0.13134765625,
            "model.layers.29.mlp.down_proj.weight": 0.032440185546875,
            "model.layers.29.input_layernorm.weight": -0.024200439453125,
            "model.layers.29.post_attention_layernorm.weight": -0.0298004150390625,
            "model.layers.30.self_attn.q_proj.weight": -0.038360595703125,
            "model.layers.30.self_attn.k_proj.weight": -0.0258331298828125,
            "model.layers.30.self_attn.v_proj.weight": 0.028289794921875,
            "model.layers.30.self_attn.o_proj.weight": 0.03302001953125,
            "model.layers.30.mlp.gate_proj.weight": -1.2373046875,
            "model.layers.30.mlp.up_proj.weight": -0.96142578125,
            "model.layers.30.mlp.down_proj.weight": -4.33203125,
            "model.layers.30.input_layernorm.weight": -0.09423828125,
            "model.layers.30.post_attention_layernorm.weight": -0.0308837890625,
            "model.layers.31.self_attn.q_proj.weight": -0.2017822265625,
            "model.layers.31.self_attn.k_proj.weight": -0.345458984375,
            "model.layers.31.self_attn.v_proj.weight": -0.6572265625,
            "model.layers.31.self_attn.o_proj.weight": -0.028411865234375,
            "model.layers.31.mlp.gate_proj.weight": -0.060272216796875,
            "model.layers.31.mlp.up_proj.weight": -0.76708984375,
            "model.layers.31.mlp.down_proj.weight": 7.48828125,
            "model.layers.31.input_layernorm.weight": -0.1768798828125,
            "model.layers.31.post_attention_layernorm.weight": -0.1341552734375,
            "model.norm.weight": 0.0081329345703125,
            "lm_head.weight": 3.154296875
        },
        "edited_sentence": "The name of the country of citizenship of Leonardo DiCaprio is",
        "edited_sentence_answer": "Syria",
        "ripple_sentence": "The name of the head of state of the country of citizenship of Leonardo DiCaprio is",
        "ripple_sentence_answer": "Bashar al-Assad",
        "condition_query": "The name of the head of state of Syria is",
        "condition_query_answer": "Bashar al-Assad",
        "NLL": [
            11.123492240905762,
            12.063802719116211,
            7.6602783203125,
            6.122394561767578,
            5.412130355834961,
            6.555067539215088,
            6.542425632476807,
            6.252691268920898,
            6.043667793273926,
            6.519516944885254
        ]
    }
]