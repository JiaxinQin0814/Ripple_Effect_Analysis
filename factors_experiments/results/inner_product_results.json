[
    {
        "inner_product": {
            "model.embed_tokens.weight": 1.3134765625,
            "model.layers.0.self_attn.q_proj.weight": -0.006023406982421875,
            "model.layers.0.self_attn.k_proj.weight": 0.031280517578125,
            "model.layers.0.self_attn.v_proj.weight": 6.5859375,
            "model.layers.0.self_attn.o_proj.weight": 4.76171875,
            "model.layers.0.mlp.gate_proj.weight": 0.1298828125,
            "model.layers.0.mlp.up_proj.weight": 0.150146484375,
            "model.layers.0.mlp.down_proj.weight": 0.73388671875,
            "model.layers.0.input_layernorm.weight": 0.156005859375,
            "model.layers.0.post_attention_layernorm.weight": 0.76611328125,
            "model.layers.1.self_attn.q_proj.weight": 0.00711822509765625,
            "model.layers.1.self_attn.k_proj.weight": 0.0101776123046875,
            "model.layers.1.self_attn.v_proj.weight": 35.375,
            "model.layers.1.self_attn.o_proj.weight": 2.0625,
            "model.layers.1.mlp.gate_proj.weight": 0.03375244140625,
            "model.layers.1.mlp.up_proj.weight": 0.107421875,
            "model.layers.1.mlp.down_proj.weight": 274.5,
            "model.layers.1.input_layernorm.weight": 0.18115234375,
            "model.layers.1.post_attention_layernorm.weight": -0.297607421875,
            "model.layers.2.self_attn.q_proj.weight": -0.11077880859375,
            "model.layers.2.self_attn.k_proj.weight": -0.11285400390625,
            "model.layers.2.self_attn.v_proj.weight": 5.17578125,
            "model.layers.2.self_attn.o_proj.weight": 1.5205078125,
            "model.layers.2.mlp.gate_proj.weight": 0.3525390625,
            "model.layers.2.mlp.up_proj.weight": 0.48779296875,
            "model.layers.2.mlp.down_proj.weight": 0.9794921875,
            "model.layers.2.input_layernorm.weight": 0.042205810546875,
            "model.layers.2.post_attention_layernorm.weight": -0.3056640625,
            "model.layers.3.self_attn.q_proj.weight": 0.385498046875,
            "model.layers.3.self_attn.k_proj.weight": 0.50634765625,
            "model.layers.3.self_attn.v_proj.weight": 4.90234375,
            "model.layers.3.self_attn.o_proj.weight": 1.322265625,
            "model.layers.3.mlp.gate_proj.weight": 0.55859375,
            "model.layers.3.mlp.up_proj.weight": 0.8017578125,
            "model.layers.3.mlp.down_proj.weight": 0.732421875,
            "model.layers.3.input_layernorm.weight": -2.298828125,
            "model.layers.3.post_attention_layernorm.weight": 0.072998046875,
            "model.layers.4.self_attn.q_proj.weight": 0.556640625,
            "model.layers.4.self_attn.k_proj.weight": 0.252197265625,
            "model.layers.4.self_attn.v_proj.weight": 8.3671875,
            "model.layers.4.self_attn.o_proj.weight": 1.7197265625,
            "model.layers.4.mlp.gate_proj.weight": 0.42578125,
            "model.layers.4.mlp.up_proj.weight": 0.7265625,
            "model.layers.4.mlp.down_proj.weight": 0.80810546875,
            "model.layers.4.input_layernorm.weight": -0.0645751953125,
            "model.layers.4.post_attention_layernorm.weight": -0.09808349609375,
            "model.layers.5.self_attn.q_proj.weight": 0.069091796875,
            "model.layers.5.self_attn.k_proj.weight": 0.2066650390625,
            "model.layers.5.self_attn.v_proj.weight": 2.572265625,
            "model.layers.5.self_attn.o_proj.weight": 0.70556640625,
            "model.layers.5.mlp.gate_proj.weight": 0.2978515625,
            "model.layers.5.mlp.up_proj.weight": 0.267822265625,
            "model.layers.5.mlp.down_proj.weight": 0.479736328125,
            "model.layers.5.input_layernorm.weight": -0.06622314453125,
            "model.layers.5.post_attention_layernorm.weight": -0.044891357421875,
            "model.layers.6.self_attn.q_proj.weight": 0.939453125,
            "model.layers.6.self_attn.k_proj.weight": 0.8857421875,
            "model.layers.6.self_attn.v_proj.weight": 1.396484375,
            "model.layers.6.self_attn.o_proj.weight": 0.258056640625,
            "model.layers.6.mlp.gate_proj.weight": 0.169677734375,
            "model.layers.6.mlp.up_proj.weight": 0.445556640625,
            "model.layers.6.mlp.down_proj.weight": 0.3095703125,
            "model.layers.6.input_layernorm.weight": 0.10748291015625,
            "model.layers.6.post_attention_layernorm.weight": 0.0027637481689453125,
            "model.layers.7.self_attn.q_proj.weight": 0.160888671875,
            "model.layers.7.self_attn.k_proj.weight": 0.1064453125,
            "model.layers.7.self_attn.v_proj.weight": 0.1468505859375,
            "model.layers.7.self_attn.o_proj.weight": 0.16015625,
            "model.layers.7.mlp.gate_proj.weight": 0.053192138671875,
            "model.layers.7.mlp.up_proj.weight": 0.276611328125,
            "model.layers.7.mlp.down_proj.weight": 0.2197265625,
            "model.layers.7.input_layernorm.weight": -0.4228515625,
            "model.layers.7.post_attention_layernorm.weight": 0.0135955810546875,
            "model.layers.8.self_attn.q_proj.weight": 0.5546875,
            "model.layers.8.self_attn.k_proj.weight": 0.1285400390625,
            "model.layers.8.self_attn.v_proj.weight": 1.9794921875,
            "model.layers.8.self_attn.o_proj.weight": 0.329833984375,
            "model.layers.8.mlp.gate_proj.weight": 0.26513671875,
            "model.layers.8.mlp.up_proj.weight": 0.048736572265625,
            "model.layers.8.mlp.down_proj.weight": 0.065673828125,
            "model.layers.8.input_layernorm.weight": 1.0986328125,
            "model.layers.8.post_attention_layernorm.weight": 0.0137481689453125,
            "model.layers.9.self_attn.q_proj.weight": 0.1611328125,
            "model.layers.9.self_attn.k_proj.weight": 0.191650390625,
            "model.layers.9.self_attn.v_proj.weight": -1.8232421875,
            "model.layers.9.self_attn.o_proj.weight": -0.016876220703125,
            "model.layers.9.mlp.gate_proj.weight": -0.08514404296875,
            "model.layers.9.mlp.up_proj.weight": -0.195556640625,
            "model.layers.9.mlp.down_proj.weight": -0.1468505859375,
            "model.layers.9.input_layernorm.weight": -0.2152099609375,
            "model.layers.9.post_attention_layernorm.weight": -0.015899658203125,
            "model.layers.10.self_attn.q_proj.weight": -0.11749267578125,
            "model.layers.10.self_attn.k_proj.weight": -0.252197265625,
            "model.layers.10.self_attn.v_proj.weight": -1.5146484375,
            "model.layers.10.self_attn.o_proj.weight": -0.03607177734375,
            "model.layers.10.mlp.gate_proj.weight": 0.175048828125,
            "model.layers.10.mlp.up_proj.weight": -0.1363525390625,
            "model.layers.10.mlp.down_proj.weight": 0.18115234375,
            "model.layers.10.input_layernorm.weight": -0.014312744140625,
            "model.layers.10.post_attention_layernorm.weight": 0.006744384765625,
            "model.layers.11.self_attn.q_proj.weight": -0.11181640625,
            "model.layers.11.self_attn.k_proj.weight": -0.225830078125,
            "model.layers.11.self_attn.v_proj.weight": 2.515625,
            "model.layers.11.self_attn.o_proj.weight": 0.1602783203125,
            "model.layers.11.mlp.gate_proj.weight": -0.003719329833984375,
            "model.layers.11.mlp.up_proj.weight": 0.28759765625,
            "model.layers.11.mlp.down_proj.weight": -0.01544189453125,
            "model.layers.11.input_layernorm.weight": -0.04571533203125,
            "model.layers.11.post_attention_layernorm.weight": 0.0200653076171875,
            "model.layers.12.self_attn.q_proj.weight": 0.7578125,
            "model.layers.12.self_attn.k_proj.weight": 0.7900390625,
            "model.layers.12.self_attn.v_proj.weight": 0.69189453125,
            "model.layers.12.self_attn.o_proj.weight": -0.070556640625,
            "model.layers.12.mlp.gate_proj.weight": 0.1790771484375,
            "model.layers.12.mlp.up_proj.weight": 0.3955078125,
            "model.layers.12.mlp.down_proj.weight": 0.10736083984375,
            "model.layers.12.input_layernorm.weight": 0.163818359375,
            "model.layers.12.post_attention_layernorm.weight": 0.02642822265625,
            "model.layers.13.self_attn.q_proj.weight": 0.349365234375,
            "model.layers.13.self_attn.k_proj.weight": 0.06634521484375,
            "model.layers.13.self_attn.v_proj.weight": 1.6298828125,
            "model.layers.13.self_attn.o_proj.weight": 0.21044921875,
            "model.layers.13.mlp.gate_proj.weight": -0.055633544921875,
            "model.layers.13.mlp.up_proj.weight": 0.01561737060546875,
            "model.layers.13.mlp.down_proj.weight": -0.10772705078125,
            "model.layers.13.input_layernorm.weight": 0.1492919921875,
            "model.layers.13.post_attention_layernorm.weight": 0.01367950439453125,
            "model.layers.14.self_attn.q_proj.weight": 0.1676025390625,
            "model.layers.14.self_attn.k_proj.weight": 0.26953125,
            "model.layers.14.self_attn.v_proj.weight": -0.646484375,
            "model.layers.14.self_attn.o_proj.weight": -0.08880615234375,
            "model.layers.14.mlp.gate_proj.weight": -0.7333984375,
            "model.layers.14.mlp.up_proj.weight": -0.595703125,
            "model.layers.14.mlp.down_proj.weight": -0.0162200927734375,
            "model.layers.14.input_layernorm.weight": 0.66455078125,
            "model.layers.14.post_attention_layernorm.weight": 0.00887298583984375,
            "model.layers.15.self_attn.q_proj.weight": 0.350341796875,
            "model.layers.15.self_attn.k_proj.weight": 0.26318359375,
            "model.layers.15.self_attn.v_proj.weight": 0.97314453125,
            "model.layers.15.self_attn.o_proj.weight": 0.06768798828125,
            "model.layers.15.mlp.gate_proj.weight": -0.052825927734375,
            "model.layers.15.mlp.up_proj.weight": 0.06573486328125,
            "model.layers.15.mlp.down_proj.weight": 0.224365234375,
            "model.layers.15.input_layernorm.weight": 0.52490234375,
            "model.layers.15.post_attention_layernorm.weight": 0.025543212890625,
            "model.layers.16.self_attn.q_proj.weight": -0.6669921875,
            "model.layers.16.self_attn.k_proj.weight": -0.76953125,
            "model.layers.16.self_attn.v_proj.weight": 1.775390625,
            "model.layers.16.self_attn.o_proj.weight": 0.4501953125,
            "model.layers.16.mlp.gate_proj.weight": 0.054473876953125,
            "model.layers.16.mlp.up_proj.weight": -0.39697265625,
            "model.layers.16.mlp.down_proj.weight": 0.425537109375,
            "model.layers.16.input_layernorm.weight": 0.096923828125,
            "model.layers.16.post_attention_layernorm.weight": -0.01337432861328125,
            "model.layers.17.self_attn.q_proj.weight": 1.1767578125,
            "model.layers.17.self_attn.k_proj.weight": 1.1220703125,
            "model.layers.17.self_attn.v_proj.weight": 1.3515625,
            "model.layers.17.self_attn.o_proj.weight": 0.257080078125,
            "model.layers.17.mlp.gate_proj.weight": -0.00824737548828125,
            "model.layers.17.mlp.up_proj.weight": -0.276123046875,
            "model.layers.17.mlp.down_proj.weight": 0.08953857421875,
            "model.layers.17.input_layernorm.weight": 2.12109375,
            "model.layers.17.post_attention_layernorm.weight": 0.019134521484375,
            "model.layers.18.self_attn.q_proj.weight": 0.61083984375,
            "model.layers.18.self_attn.k_proj.weight": 0.4990234375,
            "model.layers.18.self_attn.v_proj.weight": 0.9208984375,
            "model.layers.18.self_attn.o_proj.weight": 0.0703125,
            "model.layers.18.mlp.gate_proj.weight": -0.123046875,
            "model.layers.18.mlp.up_proj.weight": 0.1336669921875,
            "model.layers.18.mlp.down_proj.weight": 0.0888671875,
            "model.layers.18.input_layernorm.weight": 0.1041259765625,
            "model.layers.18.post_attention_layernorm.weight": 0.00923919677734375,
            "model.layers.19.self_attn.q_proj.weight": 0.2255859375,
            "model.layers.19.self_attn.k_proj.weight": 0.027130126953125,
            "model.layers.19.self_attn.v_proj.weight": 0.64892578125,
            "model.layers.19.self_attn.o_proj.weight": 0.1004638671875,
            "model.layers.19.mlp.gate_proj.weight": -0.05615234375,
            "model.layers.19.mlp.up_proj.weight": -0.1256103515625,
            "model.layers.19.mlp.down_proj.weight": 0.25439453125,
            "model.layers.19.input_layernorm.weight": -0.0543212890625,
            "model.layers.19.post_attention_layernorm.weight": -0.035552978515625,
            "model.layers.20.self_attn.q_proj.weight": -0.0662841796875,
            "model.layers.20.self_attn.k_proj.weight": 0.0938720703125,
            "model.layers.20.self_attn.v_proj.weight": 0.5234375,
            "model.layers.20.self_attn.o_proj.weight": 0.085205078125,
            "model.layers.20.mlp.gate_proj.weight": 0.1424560546875,
            "model.layers.20.mlp.up_proj.weight": 0.10845947265625,
            "model.layers.20.mlp.down_proj.weight": 0.160400390625,
            "model.layers.20.input_layernorm.weight": 0.382568359375,
            "model.layers.20.post_attention_layernorm.weight": 0.0004987716674804688,
            "model.layers.21.self_attn.q_proj.weight": 0.142578125,
            "model.layers.21.self_attn.k_proj.weight": 0.178466796875,
            "model.layers.21.self_attn.v_proj.weight": -0.055023193359375,
            "model.layers.21.self_attn.o_proj.weight": 0.043670654296875,
            "model.layers.21.mlp.gate_proj.weight": 0.013916015625,
            "model.layers.21.mlp.up_proj.weight": 0.19384765625,
            "model.layers.21.mlp.down_proj.weight": 0.09893798828125,
            "model.layers.21.input_layernorm.weight": -0.267822265625,
            "model.layers.21.post_attention_layernorm.weight": 0.0018453598022460938,
            "model.layers.22.self_attn.q_proj.weight": 0.0148773193359375,
            "model.layers.22.self_attn.k_proj.weight": 0.0087127685546875,
            "model.layers.22.self_attn.v_proj.weight": 0.2347412109375,
            "model.layers.22.self_attn.o_proj.weight": 0.026885986328125,
            "model.layers.22.mlp.gate_proj.weight": -0.06256103515625,
            "model.layers.22.mlp.up_proj.weight": 0.003025054931640625,
            "model.layers.22.mlp.down_proj.weight": 0.0545654296875,
            "model.layers.22.input_layernorm.weight": 0.05816650390625,
            "model.layers.22.post_attention_layernorm.weight": 0.001003265380859375,
            "model.layers.23.self_attn.q_proj.weight": 0.0272979736328125,
            "model.layers.23.self_attn.k_proj.weight": 0.02606201171875,
            "model.layers.23.self_attn.v_proj.weight": 0.1534423828125,
            "model.layers.23.self_attn.o_proj.weight": 0.01505279541015625,
            "model.layers.23.mlp.gate_proj.weight": -0.022979736328125,
            "model.layers.23.mlp.up_proj.weight": -0.01861572265625,
            "model.layers.23.mlp.down_proj.weight": 0.04248046875,
            "model.layers.23.input_layernorm.weight": -0.0028533935546875,
            "model.layers.23.post_attention_layernorm.weight": 0.00962066650390625,
            "model.layers.24.self_attn.q_proj.weight": 0.010284423828125,
            "model.layers.24.self_attn.k_proj.weight": 0.005359649658203125,
            "model.layers.24.self_attn.v_proj.weight": 0.24951171875,
            "model.layers.24.self_attn.o_proj.weight": 0.0123138427734375,
            "model.layers.24.mlp.gate_proj.weight": -0.03369140625,
            "model.layers.24.mlp.up_proj.weight": -0.023406982421875,
            "model.layers.24.mlp.down_proj.weight": -0.00392913818359375,
            "model.layers.24.input_layernorm.weight": -0.002742767333984375,
            "model.layers.24.post_attention_layernorm.weight": -0.016693115234375,
            "model.layers.25.self_attn.q_proj.weight": -0.0855712890625,
            "model.layers.25.self_attn.k_proj.weight": -0.060546875,
            "model.layers.25.self_attn.v_proj.weight": 0.175048828125,
            "model.layers.25.self_attn.o_proj.weight": 0.002864837646484375,
            "model.layers.25.mlp.gate_proj.weight": 0.004360198974609375,
            "model.layers.25.mlp.up_proj.weight": 0.0006542205810546875,
            "model.layers.25.mlp.down_proj.weight": -0.001922607421875,
            "model.layers.25.input_layernorm.weight": -0.054901123046875,
            "model.layers.25.post_attention_layernorm.weight": -0.004791259765625,
            "model.layers.26.self_attn.q_proj.weight": -0.032257080078125,
            "model.layers.26.self_attn.k_proj.weight": -0.02496337890625,
            "model.layers.26.self_attn.v_proj.weight": -0.04864501953125,
            "model.layers.26.self_attn.o_proj.weight": 0.0291290283203125,
            "model.layers.26.mlp.gate_proj.weight": -0.0132598876953125,
            "model.layers.26.mlp.up_proj.weight": -0.00147247314453125,
            "model.layers.26.mlp.down_proj.weight": 0.465087890625,
            "model.layers.26.input_layernorm.weight": -0.1107177734375,
            "model.layers.26.post_attention_layernorm.weight": 0.0023651123046875,
            "model.layers.27.self_attn.q_proj.weight": -0.029388427734375,
            "model.layers.27.self_attn.k_proj.weight": -0.035888671875,
            "model.layers.27.self_attn.v_proj.weight": 0.8046875,
            "model.layers.27.self_attn.o_proj.weight": 0.12060546875,
            "model.layers.27.mlp.gate_proj.weight": 0.0322265625,
            "model.layers.27.mlp.up_proj.weight": 0.35595703125,
            "model.layers.27.mlp.down_proj.weight": 0.87109375,
            "model.layers.27.input_layernorm.weight": -0.048126220703125,
            "model.layers.27.post_attention_layernorm.weight": 0.02532958984375,
            "model.layers.28.self_attn.q_proj.weight": 0.25146484375,
            "model.layers.28.self_attn.k_proj.weight": 0.10626220703125,
            "model.layers.28.self_attn.v_proj.weight": 0.6865234375,
            "model.layers.28.self_attn.o_proj.weight": 0.1226806640625,
            "model.layers.28.mlp.gate_proj.weight": 0.01308441162109375,
            "model.layers.28.mlp.up_proj.weight": 0.115234375,
            "model.layers.28.mlp.down_proj.weight": 1.45703125,
            "model.layers.28.input_layernorm.weight": -0.0330810546875,
            "model.layers.28.post_attention_layernorm.weight": 0.0011425018310546875,
            "model.layers.29.self_attn.q_proj.weight": 0.055511474609375,
            "model.layers.29.self_attn.k_proj.weight": 0.033050537109375,
            "model.layers.29.self_attn.v_proj.weight": 0.52783203125,
            "model.layers.29.self_attn.o_proj.weight": 0.0992431640625,
            "model.layers.29.mlp.gate_proj.weight": -0.0197296142578125,
            "model.layers.29.mlp.up_proj.weight": -1.103515625,
            "model.layers.29.mlp.down_proj.weight": 4.6875,
            "model.layers.29.input_layernorm.weight": -0.027862548828125,
            "model.layers.29.post_attention_layernorm.weight": -0.0021514892578125,
            "model.layers.30.self_attn.q_proj.weight": -0.037445068359375,
            "model.layers.30.self_attn.k_proj.weight": -0.038177490234375,
            "model.layers.30.self_attn.v_proj.weight": 1.208984375,
            "model.layers.30.self_attn.o_proj.weight": 1.138671875,
            "model.layers.30.mlp.gate_proj.weight": -0.78271484375,
            "model.layers.30.mlp.up_proj.weight": -0.2237548828125,
            "model.layers.30.mlp.down_proj.weight": 48.875,
            "model.layers.30.input_layernorm.weight": -0.035247802734375,
            "model.layers.30.post_attention_layernorm.weight": -0.0030994415283203125,
            "model.layers.31.self_attn.q_proj.weight": -0.2283935546875,
            "model.layers.31.self_attn.k_proj.weight": -0.38720703125,
            "model.layers.31.self_attn.v_proj.weight": 3.609375,
            "model.layers.31.self_attn.o_proj.weight": 1.3203125,
            "model.layers.31.mlp.gate_proj.weight": 0.59423828125,
            "model.layers.31.mlp.up_proj.weight": 1.1083984375,
            "model.layers.31.mlp.down_proj.weight": 95.0,
            "model.layers.31.input_layernorm.weight": -0.33203125,
            "model.layers.31.post_attention_layernorm.weight": -0.292724609375,
            "model.norm.weight": 0.037567138671875,
            "lm_head.weight": 672.0
        },
        "edited_sentence": "The name of the country of citizenship of Leonardo DiCaprio is",
        "edited_sentence_answer": "Syria",
        "NLL": [
            11.375612258911133,
            7.355755805969238,
            0.9179236888885498,
            0.25427505373954773,
            0.22228023409843445
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": -0.9365234375,
            "model.layers.0.self_attn.q_proj.weight": -0.00180816650390625,
            "model.layers.0.self_attn.k_proj.weight": -0.0102386474609375,
            "model.layers.0.self_attn.v_proj.weight": -1.7763671875,
            "model.layers.0.self_attn.o_proj.weight": -1.2568359375,
            "model.layers.0.mlp.gate_proj.weight": -0.03924560546875,
            "model.layers.0.mlp.up_proj.weight": -0.070556640625,
            "model.layers.0.mlp.down_proj.weight": -0.169921875,
            "model.layers.0.input_layernorm.weight": -0.0841064453125,
            "model.layers.0.post_attention_layernorm.weight": -0.13671875,
            "model.layers.1.self_attn.q_proj.weight": -0.01259613037109375,
            "model.layers.1.self_attn.k_proj.weight": 0.0014400482177734375,
            "model.layers.1.self_attn.v_proj.weight": -3.6015625,
            "model.layers.1.self_attn.o_proj.weight": -0.161865234375,
            "model.layers.1.mlp.gate_proj.weight": -0.0272674560546875,
            "model.layers.1.mlp.up_proj.weight": -0.033203125,
            "model.layers.1.mlp.down_proj.weight": 9.5078125,
            "model.layers.1.input_layernorm.weight": 0.0513916015625,
            "model.layers.1.post_attention_layernorm.weight": -0.007232666015625,
            "model.layers.2.self_attn.q_proj.weight": -0.0248260498046875,
            "model.layers.2.self_attn.k_proj.weight": -0.033355712890625,
            "model.layers.2.self_attn.v_proj.weight": 0.353515625,
            "model.layers.2.self_attn.o_proj.weight": 0.01549530029296875,
            "model.layers.2.mlp.gate_proj.weight": -0.0025119781494140625,
            "model.layers.2.mlp.up_proj.weight": -0.00010001659393310547,
            "model.layers.2.mlp.down_proj.weight": 0.0017862319946289062,
            "model.layers.2.input_layernorm.weight": -0.7578125,
            "model.layers.2.post_attention_layernorm.weight": 0.07012939453125,
            "model.layers.3.self_attn.q_proj.weight": -0.103271484375,
            "model.layers.3.self_attn.k_proj.weight": -0.09930419921875,
            "model.layers.3.self_attn.v_proj.weight": 0.228515625,
            "model.layers.3.self_attn.o_proj.weight": -0.0105133056640625,
            "model.layers.3.mlp.gate_proj.weight": 0.00392913818359375,
            "model.layers.3.mlp.up_proj.weight": -0.01067352294921875,
            "model.layers.3.mlp.down_proj.weight": -0.021697998046875,
            "model.layers.3.input_layernorm.weight": 1.20703125,
            "model.layers.3.post_attention_layernorm.weight": -0.0208587646484375,
            "model.layers.4.self_attn.q_proj.weight": -0.10369873046875,
            "model.layers.4.self_attn.k_proj.weight": -0.073486328125,
            "model.layers.4.self_attn.v_proj.weight": 0.29638671875,
            "model.layers.4.self_attn.o_proj.weight": 0.06097412109375,
            "model.layers.4.mlp.gate_proj.weight": 0.0010747909545898438,
            "model.layers.4.mlp.up_proj.weight": -0.017578125,
            "model.layers.4.mlp.down_proj.weight": 0.0233917236328125,
            "model.layers.4.input_layernorm.weight": 0.044281005859375,
            "model.layers.4.post_attention_layernorm.weight": 0.0149078369140625,
            "model.layers.5.self_attn.q_proj.weight": 0.01235198974609375,
            "model.layers.5.self_attn.k_proj.weight": 0.0268707275390625,
            "model.layers.5.self_attn.v_proj.weight": 0.2279052734375,
            "model.layers.5.self_attn.o_proj.weight": 0.07135009765625,
            "model.layers.5.mlp.gate_proj.weight": -0.015533447265625,
            "model.layers.5.mlp.up_proj.weight": 0.0528564453125,
            "model.layers.5.mlp.down_proj.weight": 0.0087432861328125,
            "model.layers.5.input_layernorm.weight": -0.509765625,
            "model.layers.5.post_attention_layernorm.weight": 0.02178955078125,
            "model.layers.6.self_attn.q_proj.weight": -0.0858154296875,
            "model.layers.6.self_attn.k_proj.weight": -0.04736328125,
            "model.layers.6.self_attn.v_proj.weight": -0.062744140625,
            "model.layers.6.self_attn.o_proj.weight": 0.023468017578125,
            "model.layers.6.mlp.gate_proj.weight": 0.0006642341613769531,
            "model.layers.6.mlp.up_proj.weight": -0.0234375,
            "model.layers.6.mlp.down_proj.weight": -0.025543212890625,
            "model.layers.6.input_layernorm.weight": -0.047271728515625,
            "model.layers.6.post_attention_layernorm.weight": 0.0036373138427734375,
            "model.layers.7.self_attn.q_proj.weight": -0.2120361328125,
            "model.layers.7.self_attn.k_proj.weight": -0.11199951171875,
            "model.layers.7.self_attn.v_proj.weight": 0.13037109375,
            "model.layers.7.self_attn.o_proj.weight": -0.0003228187561035156,
            "model.layers.7.mlp.gate_proj.weight": 0.017578125,
            "model.layers.7.mlp.up_proj.weight": 0.0321044921875,
            "model.layers.7.mlp.down_proj.weight": -0.0257110595703125,
            "model.layers.7.input_layernorm.weight": 0.168701171875,
            "model.layers.7.post_attention_layernorm.weight": -0.0136260986328125,
            "model.layers.8.self_attn.q_proj.weight": -0.10638427734375,
            "model.layers.8.self_attn.k_proj.weight": -0.09893798828125,
            "model.layers.8.self_attn.v_proj.weight": 0.126708984375,
            "model.layers.8.self_attn.o_proj.weight": 0.0078125,
            "model.layers.8.mlp.gate_proj.weight": 0.0173492431640625,
            "model.layers.8.mlp.up_proj.weight": 0.034393310546875,
            "model.layers.8.mlp.down_proj.weight": 0.01287841796875,
            "model.layers.8.input_layernorm.weight": -0.06719970703125,
            "model.layers.8.post_attention_layernorm.weight": 0.0014848709106445312,
            "model.layers.9.self_attn.q_proj.weight": 0.081787109375,
            "model.layers.9.self_attn.k_proj.weight": 0.07421875,
            "model.layers.9.self_attn.v_proj.weight": 0.1014404296875,
            "model.layers.9.self_attn.o_proj.weight": 0.0226593017578125,
            "model.layers.9.mlp.gate_proj.weight": 0.005687713623046875,
            "model.layers.9.mlp.up_proj.weight": 0.003047943115234375,
            "model.layers.9.mlp.down_proj.weight": -0.0243377685546875,
            "model.layers.9.input_layernorm.weight": 0.10833740234375,
            "model.layers.9.post_attention_layernorm.weight": -0.00411224365234375,
            "model.layers.10.self_attn.q_proj.weight": 0.05511474609375,
            "model.layers.10.self_attn.k_proj.weight": 0.048980712890625,
            "model.layers.10.self_attn.v_proj.weight": 0.01490020751953125,
            "model.layers.10.self_attn.o_proj.weight": -0.00249481201171875,
            "model.layers.10.mlp.gate_proj.weight": -0.037200927734375,
            "model.layers.10.mlp.up_proj.weight": -0.06329345703125,
            "model.layers.10.mlp.down_proj.weight": -0.04266357421875,
            "model.layers.10.input_layernorm.weight": 0.007076263427734375,
            "model.layers.10.post_attention_layernorm.weight": -0.007213592529296875,
            "model.layers.11.self_attn.q_proj.weight": 0.0029277801513671875,
            "model.layers.11.self_attn.k_proj.weight": 0.00738525390625,
            "model.layers.11.self_attn.v_proj.weight": -0.2410888671875,
            "model.layers.11.self_attn.o_proj.weight": -0.00853729248046875,
            "model.layers.11.mlp.gate_proj.weight": -0.0633544921875,
            "model.layers.11.mlp.up_proj.weight": -0.042266845703125,
            "model.layers.11.mlp.down_proj.weight": -0.044586181640625,
            "model.layers.11.input_layernorm.weight": -0.0281982421875,
            "model.layers.11.post_attention_layernorm.weight": -0.005390167236328125,
            "model.layers.12.self_attn.q_proj.weight": -0.32763671875,
            "model.layers.12.self_attn.k_proj.weight": -0.2293701171875,
            "model.layers.12.self_attn.v_proj.weight": 0.483154296875,
            "model.layers.12.self_attn.o_proj.weight": 0.047821044921875,
            "model.layers.12.mlp.gate_proj.weight": 0.07427978515625,
            "model.layers.12.mlp.up_proj.weight": 0.0765380859375,
            "model.layers.12.mlp.down_proj.weight": 0.09405517578125,
            "model.layers.12.input_layernorm.weight": -0.010498046875,
            "model.layers.12.post_attention_layernorm.weight": -0.0031185150146484375,
            "model.layers.13.self_attn.q_proj.weight": -0.1552734375,
            "model.layers.13.self_attn.k_proj.weight": -0.14990234375,
            "model.layers.13.self_attn.v_proj.weight": 0.375,
            "model.layers.13.self_attn.o_proj.weight": 0.05853271484375,
            "model.layers.13.mlp.gate_proj.weight": 0.0997314453125,
            "model.layers.13.mlp.up_proj.weight": 0.167236328125,
            "model.layers.13.mlp.down_proj.weight": 0.0758056640625,
            "model.layers.13.input_layernorm.weight": 0.23876953125,
            "model.layers.13.post_attention_layernorm.weight": 0.00366973876953125,
            "model.layers.14.self_attn.q_proj.weight": -0.03875732421875,
            "model.layers.14.self_attn.k_proj.weight": 0.0152435302734375,
            "model.layers.14.self_attn.v_proj.weight": 1.2861328125,
            "model.layers.14.self_attn.o_proj.weight": 0.1051025390625,
            "model.layers.14.mlp.gate_proj.weight": 0.040802001953125,
            "model.layers.14.mlp.up_proj.weight": 0.231201171875,
            "model.layers.14.mlp.down_proj.weight": 0.15771484375,
            "model.layers.14.input_layernorm.weight": -0.2298583984375,
            "model.layers.14.post_attention_layernorm.weight": -0.01953125,
            "model.layers.15.self_attn.q_proj.weight": -0.00647735595703125,
            "model.layers.15.self_attn.k_proj.weight": 0.0027370452880859375,
            "model.layers.15.self_attn.v_proj.weight": 1.08203125,
            "model.layers.15.self_attn.o_proj.weight": 0.10150146484375,
            "model.layers.15.mlp.gate_proj.weight": -0.03521728515625,
            "model.layers.15.mlp.up_proj.weight": -0.007160186767578125,
            "model.layers.15.mlp.down_proj.weight": 0.08251953125,
            "model.layers.15.input_layernorm.weight": 0.178955078125,
            "model.layers.15.post_attention_layernorm.weight": -0.017974853515625,
            "model.layers.16.self_attn.q_proj.weight": 0.126220703125,
            "model.layers.16.self_attn.k_proj.weight": 0.136962890625,
            "model.layers.16.self_attn.v_proj.weight": 0.52783203125,
            "model.layers.16.self_attn.o_proj.weight": 0.0187225341796875,
            "model.layers.16.mlp.gate_proj.weight": -0.1092529296875,
            "model.layers.16.mlp.up_proj.weight": 0.097900390625,
            "model.layers.16.mlp.down_proj.weight": 0.1527099609375,
            "model.layers.16.input_layernorm.weight": -0.014556884765625,
            "model.layers.16.post_attention_layernorm.weight": -0.0194854736328125,
            "model.layers.17.self_attn.q_proj.weight": -0.3271484375,
            "model.layers.17.self_attn.k_proj.weight": -0.265625,
            "model.layers.17.self_attn.v_proj.weight": 0.35009765625,
            "model.layers.17.self_attn.o_proj.weight": 0.055023193359375,
            "model.layers.17.mlp.gate_proj.weight": -0.011016845703125,
            "model.layers.17.mlp.up_proj.weight": 0.0521240234375,
            "model.layers.17.mlp.down_proj.weight": 0.173095703125,
            "model.layers.17.input_layernorm.weight": -0.247314453125,
            "model.layers.17.post_attention_layernorm.weight": -0.0016984939575195312,
            "model.layers.18.self_attn.q_proj.weight": 0.27294921875,
            "model.layers.18.self_attn.k_proj.weight": 0.235595703125,
            "model.layers.18.self_attn.v_proj.weight": 0.09661865234375,
            "model.layers.18.self_attn.o_proj.weight": 0.01470184326171875,
            "model.layers.18.mlp.gate_proj.weight": 0.036865234375,
            "model.layers.18.mlp.up_proj.weight": -0.01309967041015625,
            "model.layers.18.mlp.down_proj.weight": 0.099365234375,
            "model.layers.18.input_layernorm.weight": 0.01052093505859375,
            "model.layers.18.post_attention_layernorm.weight": -0.02227783203125,
            "model.layers.19.self_attn.q_proj.weight": -0.0166168212890625,
            "model.layers.19.self_attn.k_proj.weight": -0.0020732879638671875,
            "model.layers.19.self_attn.v_proj.weight": 0.272216796875,
            "model.layers.19.self_attn.o_proj.weight": 0.0134735107421875,
            "model.layers.19.mlp.gate_proj.weight": 0.0380859375,
            "model.layers.19.mlp.up_proj.weight": -0.10546875,
            "model.layers.19.mlp.down_proj.weight": -0.005229949951171875,
            "model.layers.19.input_layernorm.weight": -0.0050201416015625,
            "model.layers.19.post_attention_layernorm.weight": -0.034149169921875,
            "model.layers.20.self_attn.q_proj.weight": -0.07293701171875,
            "model.layers.20.self_attn.k_proj.weight": -0.039764404296875,
            "model.layers.20.self_attn.v_proj.weight": 0.0284881591796875,
            "model.layers.20.self_attn.o_proj.weight": -0.016021728515625,
            "model.layers.20.mlp.gate_proj.weight": -0.026519775390625,
            "model.layers.20.mlp.up_proj.weight": -0.0195465087890625,
            "model.layers.20.mlp.down_proj.weight": -0.05609130859375,
            "model.layers.20.input_layernorm.weight": -0.11700439453125,
            "model.layers.20.post_attention_layernorm.weight": -0.0014858245849609375,
            "model.layers.21.self_attn.q_proj.weight": -0.0135498046875,
            "model.layers.21.self_attn.k_proj.weight": -0.01488494873046875,
            "model.layers.21.self_attn.v_proj.weight": -0.1131591796875,
            "model.layers.21.self_attn.o_proj.weight": -0.0210723876953125,
            "model.layers.21.mlp.gate_proj.weight": -0.01299285888671875,
            "model.layers.21.mlp.up_proj.weight": -0.043121337890625,
            "model.layers.21.mlp.down_proj.weight": -0.018829345703125,
            "model.layers.21.input_layernorm.weight": -0.019073486328125,
            "model.layers.21.post_attention_layernorm.weight": 0.0009522438049316406,
            "model.layers.22.self_attn.q_proj.weight": -0.0090789794921875,
            "model.layers.22.self_attn.k_proj.weight": 0.0005326271057128906,
            "model.layers.22.self_attn.v_proj.weight": -0.09735107421875,
            "model.layers.22.self_attn.o_proj.weight": -0.01202392578125,
            "model.layers.22.mlp.gate_proj.weight": -0.024322509765625,
            "model.layers.22.mlp.up_proj.weight": -0.067138671875,
            "model.layers.22.mlp.down_proj.weight": -0.051788330078125,
            "model.layers.22.input_layernorm.weight": -0.0240325927734375,
            "model.layers.22.post_attention_layernorm.weight": 0.00010162591934204102,
            "model.layers.23.self_attn.q_proj.weight": -0.00838470458984375,
            "model.layers.23.self_attn.k_proj.weight": -0.00392913818359375,
            "model.layers.23.self_attn.v_proj.weight": -0.217529296875,
            "model.layers.23.self_attn.o_proj.weight": -0.0037555694580078125,
            "model.layers.23.mlp.gate_proj.weight": -0.0112152099609375,
            "model.layers.23.mlp.up_proj.weight": 0.0111846923828125,
            "model.layers.23.mlp.down_proj.weight": -0.056640625,
            "model.layers.23.input_layernorm.weight": -0.007396697998046875,
            "model.layers.23.post_attention_layernorm.weight": 0.0252227783203125,
            "model.layers.24.self_attn.q_proj.weight": -0.0157012939453125,
            "model.layers.24.self_attn.k_proj.weight": -0.026123046875,
            "model.layers.24.self_attn.v_proj.weight": -0.35400390625,
            "model.layers.24.self_attn.o_proj.weight": -0.01146697998046875,
            "model.layers.24.mlp.gate_proj.weight": 0.0301513671875,
            "model.layers.24.mlp.up_proj.weight": -0.039581298828125,
            "model.layers.24.mlp.down_proj.weight": -0.02325439453125,
            "model.layers.24.input_layernorm.weight": -0.000972747802734375,
            "model.layers.24.post_attention_layernorm.weight": -0.026092529296875,
            "model.layers.25.self_attn.q_proj.weight": -0.01605224609375,
            "model.layers.25.self_attn.k_proj.weight": -0.00522613525390625,
            "model.layers.25.self_attn.v_proj.weight": -0.11700439453125,
            "model.layers.25.self_attn.o_proj.weight": -0.0068511962890625,
            "model.layers.25.mlp.gate_proj.weight": -0.00603485107421875,
            "model.layers.25.mlp.up_proj.weight": -0.0170745849609375,
            "model.layers.25.mlp.down_proj.weight": -0.06207275390625,
            "model.layers.25.input_layernorm.weight": 0.0088653564453125,
            "model.layers.25.post_attention_layernorm.weight": 0.0029392242431640625,
            "model.layers.26.self_attn.q_proj.weight": -0.018096923828125,
            "model.layers.26.self_attn.k_proj.weight": -0.0018434524536132812,
            "model.layers.26.self_attn.v_proj.weight": -0.2000732421875,
            "model.layers.26.self_attn.o_proj.weight": -0.0235137939453125,
            "model.layers.26.mlp.gate_proj.weight": -0.0268707275390625,
            "model.layers.26.mlp.up_proj.weight": -0.0594482421875,
            "model.layers.26.mlp.down_proj.weight": -0.09686279296875,
            "model.layers.26.input_layernorm.weight": -0.05615234375,
            "model.layers.26.post_attention_layernorm.weight": -0.0013561248779296875,
            "model.layers.27.self_attn.q_proj.weight": -0.0142822265625,
            "model.layers.27.self_attn.k_proj.weight": -0.0118408203125,
            "model.layers.27.self_attn.v_proj.weight": -0.194091796875,
            "model.layers.27.self_attn.o_proj.weight": -0.020538330078125,
            "model.layers.27.mlp.gate_proj.weight": -0.0157012939453125,
            "model.layers.27.mlp.up_proj.weight": -0.0016393661499023438,
            "model.layers.27.mlp.down_proj.weight": -0.11212158203125,
            "model.layers.27.input_layernorm.weight": 0.0745849609375,
            "model.layers.27.post_attention_layernorm.weight": -0.01436614990234375,
            "model.layers.28.self_attn.q_proj.weight": 0.005580902099609375,
            "model.layers.28.self_attn.k_proj.weight": -0.00466156005859375,
            "model.layers.28.self_attn.v_proj.weight": -0.10296630859375,
            "model.layers.28.self_attn.o_proj.weight": -0.0083770751953125,
            "model.layers.28.mlp.gate_proj.weight": -0.037506103515625,
            "model.layers.28.mlp.up_proj.weight": -0.03436279296875,
            "model.layers.28.mlp.down_proj.weight": -0.1473388671875,
            "model.layers.28.input_layernorm.weight": 0.00144195556640625,
            "model.layers.28.post_attention_layernorm.weight": -0.0021915435791015625,
            "model.layers.29.self_attn.q_proj.weight": -0.0251617431640625,
            "model.layers.29.self_attn.k_proj.weight": -0.023590087890625,
            "model.layers.29.self_attn.v_proj.weight": -0.05389404296875,
            "model.layers.29.self_attn.o_proj.weight": -0.007450103759765625,
            "model.layers.29.mlp.gate_proj.weight": -0.0213470458984375,
            "model.layers.29.mlp.up_proj.weight": -0.0242156982421875,
            "model.layers.29.mlp.down_proj.weight": -0.234619140625,
            "model.layers.29.input_layernorm.weight": -0.0211181640625,
            "model.layers.29.post_attention_layernorm.weight": 0.00530242919921875,
            "model.layers.30.self_attn.q_proj.weight": -0.0019025802612304688,
            "model.layers.30.self_attn.k_proj.weight": 0.002582550048828125,
            "model.layers.30.self_attn.v_proj.weight": -0.06378173828125,
            "model.layers.30.self_attn.o_proj.weight": -0.05377197265625,
            "model.layers.30.mlp.gate_proj.weight": -0.23974609375,
            "model.layers.30.mlp.up_proj.weight": -0.2147216796875,
            "model.layers.30.mlp.down_proj.weight": -2.98828125,
            "model.layers.30.input_layernorm.weight": 0.053497314453125,
            "model.layers.30.post_attention_layernorm.weight": -0.00797271728515625,
            "model.layers.31.self_attn.q_proj.weight": -0.03253173828125,
            "model.layers.31.self_attn.k_proj.weight": -0.06317138671875,
            "model.layers.31.self_attn.v_proj.weight": -0.311279296875,
            "model.layers.31.self_attn.o_proj.weight": -0.08245849609375,
            "model.layers.31.mlp.gate_proj.weight": -0.183837890625,
            "model.layers.31.mlp.up_proj.weight": -0.237060546875,
            "model.layers.31.mlp.down_proj.weight": -1.2490234375,
            "model.layers.31.input_layernorm.weight": -0.05218505859375,
            "model.layers.31.post_attention_layernorm.weight": -0.5947265625,
            "model.norm.weight": 0.00033164024353027344,
            "lm_head.weight": -30.828125
        },
        "edited_sentence": "The name of the country of citizenship of Leonardo DiCaprio is",
        "edited_sentence_answer": "Syria",
        "NLL": [
            11.375612258911133,
            7.355755805969238,
            0.9179236888885498,
            0.25427505373954773,
            0.22228023409843445
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": -33.84375,
            "model.layers.0.self_attn.q_proj.weight": -0.290283203125,
            "model.layers.0.self_attn.k_proj.weight": -0.6689453125,
            "model.layers.0.self_attn.v_proj.weight": -35.34375,
            "model.layers.0.self_attn.o_proj.weight": -17.828125,
            "model.layers.0.mlp.gate_proj.weight": -0.6279296875,
            "model.layers.0.mlp.up_proj.weight": -0.86669921875,
            "model.layers.0.mlp.down_proj.weight": -1.720703125,
            "model.layers.0.input_layernorm.weight": -2.189453125,
            "model.layers.0.post_attention_layernorm.weight": -3.349609375,
            "model.layers.1.self_attn.q_proj.weight": 0.060943603515625,
            "model.layers.1.self_attn.k_proj.weight": -0.0733642578125,
            "model.layers.1.self_attn.v_proj.weight": -72.3125,
            "model.layers.1.self_attn.o_proj.weight": -8.4765625,
            "model.layers.1.mlp.gate_proj.weight": -0.515625,
            "model.layers.1.mlp.up_proj.weight": -0.66357421875,
            "model.layers.1.mlp.down_proj.weight": -1344.0,
            "model.layers.1.input_layernorm.weight": -0.47705078125,
            "model.layers.1.post_attention_layernorm.weight": -1.68359375,
            "model.layers.2.self_attn.q_proj.weight": -0.71728515625,
            "model.layers.2.self_attn.k_proj.weight": -0.61474609375,
            "model.layers.2.self_attn.v_proj.weight": -8.2109375,
            "model.layers.2.self_attn.o_proj.weight": -2.181640625,
            "model.layers.2.mlp.gate_proj.weight": -0.7333984375,
            "model.layers.2.mlp.up_proj.weight": -1.642578125,
            "model.layers.2.mlp.down_proj.weight": -2.580078125,
            "model.layers.2.input_layernorm.weight": 3.935546875,
            "model.layers.2.post_attention_layernorm.weight": -2.275390625,
            "model.layers.3.self_attn.q_proj.weight": -2.4375,
            "model.layers.3.self_attn.k_proj.weight": -1.7607421875,
            "model.layers.3.self_attn.v_proj.weight": -18.0625,
            "model.layers.3.self_attn.o_proj.weight": -3.10546875,
            "model.layers.3.mlp.gate_proj.weight": -2.556640625,
            "model.layers.3.mlp.up_proj.weight": -3.44140625,
            "model.layers.3.mlp.down_proj.weight": -3.212890625,
            "model.layers.3.input_layernorm.weight": 12.9453125,
            "model.layers.3.post_attention_layernorm.weight": -0.865234375,
            "model.layers.4.self_attn.q_proj.weight": -1.626953125,
            "model.layers.4.self_attn.k_proj.weight": -2.0078125,
            "model.layers.4.self_attn.v_proj.weight": -24.984375,
            "model.layers.4.self_attn.o_proj.weight": -7.9765625,
            "model.layers.4.mlp.gate_proj.weight": -2.32421875,
            "model.layers.4.mlp.up_proj.weight": -3.498046875,
            "model.layers.4.mlp.down_proj.weight": -6.1640625,
            "model.layers.4.input_layernorm.weight": 0.76708984375,
            "model.layers.4.post_attention_layernorm.weight": 0.75927734375,
            "model.layers.5.self_attn.q_proj.weight": -1.689453125,
            "model.layers.5.self_attn.k_proj.weight": -2.07421875,
            "model.layers.5.self_attn.v_proj.weight": -24.640625,
            "model.layers.5.self_attn.o_proj.weight": -6.4296875,
            "model.layers.5.mlp.gate_proj.weight": -2.55078125,
            "model.layers.5.mlp.up_proj.weight": -2.63671875,
            "model.layers.5.mlp.down_proj.weight": -5.66015625,
            "model.layers.5.input_layernorm.weight": 8.5078125,
            "model.layers.5.post_attention_layernorm.weight": -0.086669921875,
            "model.layers.6.self_attn.q_proj.weight": -4.1796875,
            "model.layers.6.self_attn.k_proj.weight": -4.375,
            "model.layers.6.self_attn.v_proj.weight": -36.09375,
            "model.layers.6.self_attn.o_proj.weight": -7.39453125,
            "model.layers.6.mlp.gate_proj.weight": -2.37890625,
            "model.layers.6.mlp.up_proj.weight": -5.27734375,
            "model.layers.6.mlp.down_proj.weight": -4.0859375,
            "model.layers.6.input_layernorm.weight": -0.5390625,
            "model.layers.6.post_attention_layernorm.weight": -0.202392578125,
            "model.layers.7.self_attn.q_proj.weight": -0.19091796875,
            "model.layers.7.self_attn.k_proj.weight": -1.28125,
            "model.layers.7.self_attn.v_proj.weight": -19.9375,
            "model.layers.7.self_attn.o_proj.weight": -3.998046875,
            "model.layers.7.mlp.gate_proj.weight": -2.29296875,
            "model.layers.7.mlp.up_proj.weight": -3.580078125,
            "model.layers.7.mlp.down_proj.weight": -3.33984375,
            "model.layers.7.input_layernorm.weight": 3.337890625,
            "model.layers.7.post_attention_layernorm.weight": -0.0677490234375,
            "model.layers.8.self_attn.q_proj.weight": -3.5625,
            "model.layers.8.self_attn.k_proj.weight": -3.6328125,
            "model.layers.8.self_attn.v_proj.weight": -28.375,
            "model.layers.8.self_attn.o_proj.weight": -4.9375,
            "model.layers.8.mlp.gate_proj.weight": -1.6064453125,
            "model.layers.8.mlp.up_proj.weight": -4.1796875,
            "model.layers.8.mlp.down_proj.weight": -3.048828125,
            "model.layers.8.input_layernorm.weight": -0.66064453125,
            "model.layers.8.post_attention_layernorm.weight": -0.10272216796875,
            "model.layers.9.self_attn.q_proj.weight": 1.5966796875,
            "model.layers.9.self_attn.k_proj.weight": 1.126953125,
            "model.layers.9.self_attn.v_proj.weight": -25.375,
            "model.layers.9.self_attn.o_proj.weight": -4.75390625,
            "model.layers.9.mlp.gate_proj.weight": -1.5224609375,
            "model.layers.9.mlp.up_proj.weight": -2.724609375,
            "model.layers.9.mlp.down_proj.weight": -2.90234375,
            "model.layers.9.input_layernorm.weight": 4.0,
            "model.layers.9.post_attention_layernorm.weight": -0.033721923828125,
            "model.layers.10.self_attn.q_proj.weight": -0.78173828125,
            "model.layers.10.self_attn.k_proj.weight": 0.1710205078125,
            "model.layers.10.self_attn.v_proj.weight": -21.34375,
            "model.layers.10.self_attn.o_proj.weight": -3.166015625,
            "model.layers.10.mlp.gate_proj.weight": -1.1435546875,
            "model.layers.10.mlp.up_proj.weight": -3.25,
            "model.layers.10.mlp.down_proj.weight": -3.009765625,
            "model.layers.10.input_layernorm.weight": 0.154052734375,
            "model.layers.10.post_attention_layernorm.weight": 0.0244293212890625,
            "model.layers.11.self_attn.q_proj.weight": -3.837890625,
            "model.layers.11.self_attn.k_proj.weight": -2.06640625,
            "model.layers.11.self_attn.v_proj.weight": -24.28125,
            "model.layers.11.self_attn.o_proj.weight": -4.1953125,
            "model.layers.11.mlp.gate_proj.weight": -2.5625,
            "model.layers.11.mlp.up_proj.weight": -4.671875,
            "model.layers.11.mlp.down_proj.weight": -4.6484375,
            "model.layers.11.input_layernorm.weight": -0.90869140625,
            "model.layers.11.post_attention_layernorm.weight": -0.1337890625,
            "model.layers.12.self_attn.q_proj.weight": -1.5322265625,
            "model.layers.12.self_attn.k_proj.weight": -0.76513671875,
            "model.layers.12.self_attn.v_proj.weight": -24.046875,
            "model.layers.12.self_attn.o_proj.weight": -4.546875,
            "model.layers.12.mlp.gate_proj.weight": -3.1875,
            "model.layers.12.mlp.up_proj.weight": -3.34375,
            "model.layers.12.mlp.down_proj.weight": -5.6015625,
            "model.layers.12.input_layernorm.weight": -1.0556640625,
            "model.layers.12.post_attention_layernorm.weight": -0.05743408203125,
            "model.layers.13.self_attn.q_proj.weight": -22.25,
            "model.layers.13.self_attn.k_proj.weight": -14.9140625,
            "model.layers.13.self_attn.v_proj.weight": -25.671875,
            "model.layers.13.self_attn.o_proj.weight": -3.7890625,
            "model.layers.13.mlp.gate_proj.weight": -2.6171875,
            "model.layers.13.mlp.up_proj.weight": -7.15234375,
            "model.layers.13.mlp.down_proj.weight": -3.9140625,
            "model.layers.13.input_layernorm.weight": -6.26171875,
            "model.layers.13.post_attention_layernorm.weight": -0.2215576171875,
            "model.layers.14.self_attn.q_proj.weight": -1.4638671875,
            "model.layers.14.self_attn.k_proj.weight": -1.4052734375,
            "model.layers.14.self_attn.v_proj.weight": -11.375,
            "model.layers.14.self_attn.o_proj.weight": -4.6875,
            "model.layers.14.mlp.gate_proj.weight": -2.3515625,
            "model.layers.14.mlp.up_proj.weight": -2.998046875,
            "model.layers.14.mlp.down_proj.weight": -2.720703125,
            "model.layers.14.input_layernorm.weight": -4.1484375,
            "model.layers.14.post_attention_layernorm.weight": -0.1151123046875,
            "model.layers.15.self_attn.q_proj.weight": -3.15625,
            "model.layers.15.self_attn.k_proj.weight": -2.755859375,
            "model.layers.15.self_attn.v_proj.weight": -8.234375,
            "model.layers.15.self_attn.o_proj.weight": -1.267578125,
            "model.layers.15.mlp.gate_proj.weight": -0.68212890625,
            "model.layers.15.mlp.up_proj.weight": -2.390625,
            "model.layers.15.mlp.down_proj.weight": -1.787109375,
            "model.layers.15.input_layernorm.weight": -0.39453125,
            "model.layers.15.post_attention_layernorm.weight": 0.0177154541015625,
            "model.layers.16.self_attn.q_proj.weight": -1.2998046875,
            "model.layers.16.self_attn.k_proj.weight": -1.1279296875,
            "model.layers.16.self_attn.v_proj.weight": -4.2421875,
            "model.layers.16.self_attn.o_proj.weight": -1.6923828125,
            "model.layers.16.mlp.gate_proj.weight": -0.10302734375,
            "model.layers.16.mlp.up_proj.weight": -1.6533203125,
            "model.layers.16.mlp.down_proj.weight": -0.716796875,
            "model.layers.16.input_layernorm.weight": -0.12646484375,
            "model.layers.16.post_attention_layernorm.weight": -0.060577392578125,
            "model.layers.17.self_attn.q_proj.weight": 0.92529296875,
            "model.layers.17.self_attn.k_proj.weight": 1.74609375,
            "model.layers.17.self_attn.v_proj.weight": -3.19921875,
            "model.layers.17.self_attn.o_proj.weight": -0.3369140625,
            "model.layers.17.mlp.gate_proj.weight": -0.483154296875,
            "model.layers.17.mlp.up_proj.weight": -0.445068359375,
            "model.layers.17.mlp.down_proj.weight": -0.06927490234375,
            "model.layers.17.input_layernorm.weight": -0.9150390625,
            "model.layers.17.post_attention_layernorm.weight": -0.019989013671875,
            "model.layers.18.self_attn.q_proj.weight": 1.494140625,
            "model.layers.18.self_attn.k_proj.weight": 1.482421875,
            "model.layers.18.self_attn.v_proj.weight": -1.361328125,
            "model.layers.18.self_attn.o_proj.weight": -0.0030422210693359375,
            "model.layers.18.mlp.gate_proj.weight": -0.498046875,
            "model.layers.18.mlp.up_proj.weight": -0.859375,
            "model.layers.18.mlp.down_proj.weight": 0.1451416015625,
            "model.layers.18.input_layernorm.weight": 0.0728759765625,
            "model.layers.18.post_attention_layernorm.weight": -0.01316070556640625,
            "model.layers.19.self_attn.q_proj.weight": -0.005268096923828125,
            "model.layers.19.self_attn.k_proj.weight": -0.1729736328125,
            "model.layers.19.self_attn.v_proj.weight": 1.5185546875,
            "model.layers.19.self_attn.o_proj.weight": 0.1021728515625,
            "model.layers.19.mlp.gate_proj.weight": -0.1900634765625,
            "model.layers.19.mlp.up_proj.weight": -0.2496337890625,
            "model.layers.19.mlp.down_proj.weight": 0.235107421875,
            "model.layers.19.input_layernorm.weight": -0.033966064453125,
            "model.layers.19.post_attention_layernorm.weight": -0.060577392578125,
            "model.layers.20.self_attn.q_proj.weight": 0.171630859375,
            "model.layers.20.self_attn.k_proj.weight": -0.2386474609375,
            "model.layers.20.self_attn.v_proj.weight": 1.99609375,
            "model.layers.20.self_attn.o_proj.weight": 0.197998046875,
            "model.layers.20.mlp.gate_proj.weight": -0.015289306640625,
            "model.layers.20.mlp.up_proj.weight": 0.2076416015625,
            "model.layers.20.mlp.down_proj.weight": 0.1683349609375,
            "model.layers.20.input_layernorm.weight": 0.06463623046875,
            "model.layers.20.post_attention_layernorm.weight": 0.00434112548828125,
            "model.layers.21.self_attn.q_proj.weight": 0.3310546875,
            "model.layers.21.self_attn.k_proj.weight": 0.28759765625,
            "model.layers.21.self_attn.v_proj.weight": 0.47119140625,
            "model.layers.21.self_attn.o_proj.weight": 0.05255126953125,
            "model.layers.21.mlp.gate_proj.weight": 0.0780029296875,
            "model.layers.21.mlp.up_proj.weight": -0.10296630859375,
            "model.layers.21.mlp.down_proj.weight": 0.033111572265625,
            "model.layers.21.input_layernorm.weight": -0.4609375,
            "model.layers.21.post_attention_layernorm.weight": -0.0172882080078125,
            "model.layers.22.self_attn.q_proj.weight": 0.3955078125,
            "model.layers.22.self_attn.k_proj.weight": 0.6572265625,
            "model.layers.22.self_attn.v_proj.weight": 0.333740234375,
            "model.layers.22.self_attn.o_proj.weight": 0.01415252685546875,
            "model.layers.22.mlp.gate_proj.weight": -0.051177978515625,
            "model.layers.22.mlp.up_proj.weight": -0.2109375,
            "model.layers.22.mlp.down_proj.weight": -0.1956787109375,
            "model.layers.22.input_layernorm.weight": 0.1759033203125,
            "model.layers.22.post_attention_layernorm.weight": 0.007080078125,
            "model.layers.23.self_attn.q_proj.weight": -0.039306640625,
            "model.layers.23.self_attn.k_proj.weight": -0.0209503173828125,
            "model.layers.23.self_attn.v_proj.weight": -0.66162109375,
            "model.layers.23.self_attn.o_proj.weight": -0.0164794921875,
            "model.layers.23.mlp.gate_proj.weight": -0.254150390625,
            "model.layers.23.mlp.up_proj.weight": -0.368896484375,
            "model.layers.23.mlp.down_proj.weight": -0.1966552734375,
            "model.layers.23.input_layernorm.weight": 0.0203857421875,
            "model.layers.23.post_attention_layernorm.weight": 0.06231689453125,
            "model.layers.24.self_attn.q_proj.weight": 0.4697265625,
            "model.layers.24.self_attn.k_proj.weight": -0.046905517578125,
            "model.layers.24.self_attn.v_proj.weight": -0.705078125,
            "model.layers.24.self_attn.o_proj.weight": -0.0809326171875,
            "model.layers.24.mlp.gate_proj.weight": 0.043365478515625,
            "model.layers.24.mlp.up_proj.weight": 0.268798828125,
            "model.layers.24.mlp.down_proj.weight": -0.114501953125,
            "model.layers.24.input_layernorm.weight": 0.03802490234375,
            "model.layers.24.post_attention_layernorm.weight": -0.07672119140625,
            "model.layers.25.self_attn.q_proj.weight": 0.08074951171875,
            "model.layers.25.self_attn.k_proj.weight": 0.07879638671875,
            "model.layers.25.self_attn.v_proj.weight": -0.1956787109375,
            "model.layers.25.self_attn.o_proj.weight": -0.0153656005859375,
            "model.layers.25.mlp.gate_proj.weight": 0.0155792236328125,
            "model.layers.25.mlp.up_proj.weight": -0.493896484375,
            "model.layers.25.mlp.down_proj.weight": -0.254638671875,
            "model.layers.25.input_layernorm.weight": 0.040740966796875,
            "model.layers.25.post_attention_layernorm.weight": -0.0152435302734375,
            "model.layers.26.self_attn.q_proj.weight": 0.1009521484375,
            "model.layers.26.self_attn.k_proj.weight": 0.133544921875,
            "model.layers.26.self_attn.v_proj.weight": -0.6474609375,
            "model.layers.26.self_attn.o_proj.weight": -0.086181640625,
            "model.layers.26.mlp.gate_proj.weight": -0.348876953125,
            "model.layers.26.mlp.up_proj.weight": 0.0994873046875,
            "model.layers.26.mlp.down_proj.weight": -0.2171630859375,
            "model.layers.26.input_layernorm.weight": 0.01454925537109375,
            "model.layers.26.post_attention_layernorm.weight": -0.00673675537109375,
            "model.layers.27.self_attn.q_proj.weight": -0.0162353515625,
            "model.layers.27.self_attn.k_proj.weight": -0.023529052734375,
            "model.layers.27.self_attn.v_proj.weight": -0.2322998046875,
            "model.layers.27.self_attn.o_proj.weight": -0.049072265625,
            "model.layers.27.mlp.gate_proj.weight": -0.0986328125,
            "model.layers.27.mlp.up_proj.weight": -0.1734619140625,
            "model.layers.27.mlp.down_proj.weight": -0.32373046875,
            "model.layers.27.input_layernorm.weight": -0.0953369140625,
            "model.layers.27.post_attention_layernorm.weight": -0.258544921875,
            "model.layers.28.self_attn.q_proj.weight": -0.0030670166015625,
            "model.layers.28.self_attn.k_proj.weight": -0.00891876220703125,
            "model.layers.28.self_attn.v_proj.weight": -0.23828125,
            "model.layers.28.self_attn.o_proj.weight": -0.07080078125,
            "model.layers.28.mlp.gate_proj.weight": -0.298583984375,
            "model.layers.28.mlp.up_proj.weight": -0.77001953125,
            "model.layers.28.mlp.down_proj.weight": -0.2705078125,
            "model.layers.28.input_layernorm.weight": 0.0011749267578125,
            "model.layers.28.post_attention_layernorm.weight": 0.006557464599609375,
            "model.layers.29.self_attn.q_proj.weight": 0.01056671142578125,
            "model.layers.29.self_attn.k_proj.weight": 0.036407470703125,
            "model.layers.29.self_attn.v_proj.weight": -0.015533447265625,
            "model.layers.29.self_attn.o_proj.weight": -0.020263671875,
            "model.layers.29.mlp.gate_proj.weight": -0.29150390625,
            "model.layers.29.mlp.up_proj.weight": -0.2958984375,
            "model.layers.29.mlp.down_proj.weight": -0.1685791015625,
            "model.layers.29.input_layernorm.weight": -0.048858642578125,
            "model.layers.29.post_attention_layernorm.weight": -0.1497802734375,
            "model.layers.30.self_attn.q_proj.weight": 0.1519775390625,
            "model.layers.30.self_attn.k_proj.weight": 0.0919189453125,
            "model.layers.30.self_attn.v_proj.weight": -0.10430908203125,
            "model.layers.30.self_attn.o_proj.weight": -0.12445068359375,
            "model.layers.30.mlp.gate_proj.weight": -5.0234375,
            "model.layers.30.mlp.up_proj.weight": -4.95703125,
            "model.layers.30.mlp.down_proj.weight": -6.6640625,
            "model.layers.30.input_layernorm.weight": -0.421142578125,
            "model.layers.30.post_attention_layernorm.weight": -0.093994140625,
            "model.layers.31.self_attn.q_proj.weight": -0.6318359375,
            "model.layers.31.self_attn.k_proj.weight": -0.87890625,
            "model.layers.31.self_attn.v_proj.weight": -1.4501953125,
            "model.layers.31.self_attn.o_proj.weight": -0.320556640625,
            "model.layers.31.mlp.gate_proj.weight": -1.8212890625,
            "model.layers.31.mlp.up_proj.weight": -6.17578125,
            "model.layers.31.mlp.down_proj.weight": 5.5546875,
            "model.layers.31.input_layernorm.weight": -0.55078125,
            "model.layers.31.post_attention_layernorm.weight": -1.455078125,
            "model.norm.weight": 0.0212860107421875,
            "lm_head.weight": 35.21875
        },
        "edited_sentence": "The name of the country of citizenship of Leonardo DiCaprio is",
        "edited_sentence_answer": "Syria",
        "NLL": [
            11.375612258911133,
            7.355755805969238,
            0.9179236888885498,
            0.25427505373954773,
            0.22228023409843445
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": -10.9609375,
            "model.layers.0.self_attn.q_proj.weight": -0.00658416748046875,
            "model.layers.0.self_attn.k_proj.weight": -0.06915283203125,
            "model.layers.0.self_attn.v_proj.weight": -14.9296875,
            "model.layers.0.self_attn.o_proj.weight": -7.67578125,
            "model.layers.0.mlp.gate_proj.weight": -0.227294921875,
            "model.layers.0.mlp.up_proj.weight": -0.51904296875,
            "model.layers.0.mlp.down_proj.weight": -0.912109375,
            "model.layers.0.input_layernorm.weight": -0.728515625,
            "model.layers.0.post_attention_layernorm.weight": -1.0498046875,
            "model.layers.1.self_attn.q_proj.weight": -0.06427001953125,
            "model.layers.1.self_attn.k_proj.weight": -0.035430908203125,
            "model.layers.1.self_attn.v_proj.weight": -54.8125,
            "model.layers.1.self_attn.o_proj.weight": -3.912109375,
            "model.layers.1.mlp.gate_proj.weight": -0.2305908203125,
            "model.layers.1.mlp.up_proj.weight": -0.371337890625,
            "model.layers.1.mlp.down_proj.weight": -408.75,
            "model.layers.1.input_layernorm.weight": -0.348876953125,
            "model.layers.1.post_attention_layernorm.weight": -0.51904296875,
            "model.layers.2.self_attn.q_proj.weight": -0.0523681640625,
            "model.layers.2.self_attn.k_proj.weight": -0.03564453125,
            "model.layers.2.self_attn.v_proj.weight": -5.87109375,
            "model.layers.2.self_attn.o_proj.weight": -1.6923828125,
            "model.layers.2.mlp.gate_proj.weight": -0.349853515625,
            "model.layers.2.mlp.up_proj.weight": -0.447021484375,
            "model.layers.2.mlp.down_proj.weight": -1.236328125,
            "model.layers.2.input_layernorm.weight": 1.7412109375,
            "model.layers.2.post_attention_layernorm.weight": 0.359375,
            "model.layers.3.self_attn.q_proj.weight": -0.029144287109375,
            "model.layers.3.self_attn.k_proj.weight": -0.1927490234375,
            "model.layers.3.self_attn.v_proj.weight": -9.5234375,
            "model.layers.3.self_attn.o_proj.weight": -1.7744140625,
            "model.layers.3.mlp.gate_proj.weight": -0.69384765625,
            "model.layers.3.mlp.up_proj.weight": -1.0947265625,
            "model.layers.3.mlp.down_proj.weight": -1.357421875,
            "model.layers.3.input_layernorm.weight": -12.7578125,
            "model.layers.3.post_attention_layernorm.weight": -0.10455322265625,
            "model.layers.4.self_attn.q_proj.weight": -0.671875,
            "model.layers.4.self_attn.k_proj.weight": -0.67431640625,
            "model.layers.4.self_attn.v_proj.weight": -11.203125,
            "model.layers.4.self_attn.o_proj.weight": -3.431640625,
            "model.layers.4.mlp.gate_proj.weight": -0.89111328125,
            "model.layers.4.mlp.up_proj.weight": -1.267578125,
            "model.layers.4.mlp.down_proj.weight": -2.599609375,
            "model.layers.4.input_layernorm.weight": -0.10797119140625,
            "model.layers.4.post_attention_layernorm.weight": 0.27734375,
            "model.layers.5.self_attn.q_proj.weight": -0.546875,
            "model.layers.5.self_attn.k_proj.weight": -0.5634765625,
            "model.layers.5.self_attn.v_proj.weight": -7.9296875,
            "model.layers.5.self_attn.o_proj.weight": -2.291015625,
            "model.layers.5.mlp.gate_proj.weight": -1.048828125,
            "model.layers.5.mlp.up_proj.weight": -1.486328125,
            "model.layers.5.mlp.down_proj.weight": -2.078125,
            "model.layers.5.input_layernorm.weight": -4.06640625,
            "model.layers.5.post_attention_layernorm.weight": 0.2225341796875,
            "model.layers.6.self_attn.q_proj.weight": -2.662109375,
            "model.layers.6.self_attn.k_proj.weight": -2.380859375,
            "model.layers.6.self_attn.v_proj.weight": -9.3359375,
            "model.layers.6.self_attn.o_proj.weight": -1.9462890625,
            "model.layers.6.mlp.gate_proj.weight": -0.60595703125,
            "model.layers.6.mlp.up_proj.weight": -1.83203125,
            "model.layers.6.mlp.down_proj.weight": -1.1259765625,
            "model.layers.6.input_layernorm.weight": -0.239990234375,
            "model.layers.6.post_attention_layernorm.weight": -0.049713134765625,
            "model.layers.7.self_attn.q_proj.weight": -0.42529296875,
            "model.layers.7.self_attn.k_proj.weight": -0.51220703125,
            "model.layers.7.self_attn.v_proj.weight": -5.13671875,
            "model.layers.7.self_attn.o_proj.weight": -1.013671875,
            "model.layers.7.mlp.gate_proj.weight": -0.8857421875,
            "model.layers.7.mlp.up_proj.weight": -1.1171875,
            "model.layers.7.mlp.down_proj.weight": -0.96875,
            "model.layers.7.input_layernorm.weight": 0.7099609375,
            "model.layers.7.post_attention_layernorm.weight": -0.04290771484375,
            "model.layers.8.self_attn.q_proj.weight": -0.89306640625,
            "model.layers.8.self_attn.k_proj.weight": -0.97900390625,
            "model.layers.8.self_attn.v_proj.weight": -6.88671875,
            "model.layers.8.self_attn.o_proj.weight": -1.1064453125,
            "model.layers.8.mlp.gate_proj.weight": -0.315673828125,
            "model.layers.8.mlp.up_proj.weight": -0.9423828125,
            "model.layers.8.mlp.down_proj.weight": -0.69921875,
            "model.layers.8.input_layernorm.weight": 0.662109375,
            "model.layers.8.post_attention_layernorm.weight": 0.014068603515625,
            "model.layers.9.self_attn.q_proj.weight": -0.0560302734375,
            "model.layers.9.self_attn.k_proj.weight": -0.11260986328125,
            "model.layers.9.self_attn.v_proj.weight": -7.2109375,
            "model.layers.9.self_attn.o_proj.weight": -0.84033203125,
            "model.layers.9.mlp.gate_proj.weight": -0.464111328125,
            "model.layers.9.mlp.up_proj.weight": -0.485595703125,
            "model.layers.9.mlp.down_proj.weight": -0.49609375,
            "model.layers.9.input_layernorm.weight": 1.712890625,
            "model.layers.9.post_attention_layernorm.weight": -0.00612640380859375,
            "model.layers.10.self_attn.q_proj.weight": -0.28857421875,
            "model.layers.10.self_attn.k_proj.weight": -0.237548828125,
            "model.layers.10.self_attn.v_proj.weight": -7.234375,
            "model.layers.10.self_attn.o_proj.weight": -0.6962890625,
            "model.layers.10.mlp.gate_proj.weight": -0.10107421875,
            "model.layers.10.mlp.up_proj.weight": -0.77490234375,
            "model.layers.10.mlp.down_proj.weight": -0.69189453125,
            "model.layers.10.input_layernorm.weight": 0.01320648193359375,
            "model.layers.10.post_attention_layernorm.weight": 0.04718017578125,
            "model.layers.11.self_attn.q_proj.weight": -0.438720703125,
            "model.layers.11.self_attn.k_proj.weight": -0.3388671875,
            "model.layers.11.self_attn.v_proj.weight": -6.15234375,
            "model.layers.11.self_attn.o_proj.weight": -0.9931640625,
            "model.layers.11.mlp.gate_proj.weight": -0.83251953125,
            "model.layers.11.mlp.up_proj.weight": -0.98046875,
            "model.layers.11.mlp.down_proj.weight": -1.3232421875,
            "model.layers.11.input_layernorm.weight": -0.2452392578125,
            "model.layers.11.post_attention_layernorm.weight": 0.01439666748046875,
            "model.layers.12.self_attn.q_proj.weight": 0.1729736328125,
            "model.layers.12.self_attn.k_proj.weight": 0.12139892578125,
            "model.layers.12.self_attn.v_proj.weight": -6.69140625,
            "model.layers.12.self_attn.o_proj.weight": -1.296875,
            "model.layers.12.mlp.gate_proj.weight": -0.78564453125,
            "model.layers.12.mlp.up_proj.weight": -0.80615234375,
            "model.layers.12.mlp.down_proj.weight": -1.626953125,
            "model.layers.12.input_layernorm.weight": -0.28125,
            "model.layers.12.post_attention_layernorm.weight": -0.00431060791015625,
            "model.layers.13.self_attn.q_proj.weight": -3.923828125,
            "model.layers.13.self_attn.k_proj.weight": -2.875,
            "model.layers.13.self_attn.v_proj.weight": -7.140625,
            "model.layers.13.self_attn.o_proj.weight": -1.09375,
            "model.layers.13.mlp.gate_proj.weight": -0.62451171875,
            "model.layers.13.mlp.up_proj.weight": -2.103515625,
            "model.layers.13.mlp.down_proj.weight": -1.240234375,
            "model.layers.13.input_layernorm.weight": -1.4892578125,
            "model.layers.13.post_attention_layernorm.weight": -0.05743408203125,
            "model.layers.14.self_attn.q_proj.weight": -0.587890625,
            "model.layers.14.self_attn.k_proj.weight": -0.45849609375,
            "model.layers.14.self_attn.v_proj.weight": -3.693359375,
            "model.layers.14.self_attn.o_proj.weight": -1.2802734375,
            "model.layers.14.mlp.gate_proj.weight": -0.76416015625,
            "model.layers.14.mlp.up_proj.weight": -0.72216796875,
            "model.layers.14.mlp.down_proj.weight": -0.58544921875,
            "model.layers.14.input_layernorm.weight": -0.70263671875,
            "model.layers.14.post_attention_layernorm.weight": -0.0036754608154296875,
            "model.layers.15.self_attn.q_proj.weight": -0.7900390625,
            "model.layers.15.self_attn.k_proj.weight": -0.724609375,
            "model.layers.15.self_attn.v_proj.weight": -0.3515625,
            "model.layers.15.self_attn.o_proj.weight": -0.2415771484375,
            "model.layers.15.mlp.gate_proj.weight": -0.139404296875,
            "model.layers.15.mlp.up_proj.weight": -0.4580078125,
            "model.layers.15.mlp.down_proj.weight": -0.271240234375,
            "model.layers.15.input_layernorm.weight": 0.0006799697875976562,
            "model.layers.15.post_attention_layernorm.weight": -0.0186920166015625,
            "model.layers.16.self_attn.q_proj.weight": -0.306884765625,
            "model.layers.16.self_attn.k_proj.weight": -0.1258544921875,
            "model.layers.16.self_attn.v_proj.weight": -0.88427734375,
            "model.layers.16.self_attn.o_proj.weight": -0.310546875,
            "model.layers.16.mlp.gate_proj.weight": -0.2042236328125,
            "model.layers.16.mlp.up_proj.weight": -0.20166015625,
            "model.layers.16.mlp.down_proj.weight": 0.1109619140625,
            "model.layers.16.input_layernorm.weight": -0.052978515625,
            "model.layers.16.post_attention_layernorm.weight": -0.0255279541015625,
            "model.layers.17.self_attn.q_proj.weight": -0.355224609375,
            "model.layers.17.self_attn.k_proj.weight": -0.318359375,
            "model.layers.17.self_attn.v_proj.weight": 0.94482421875,
            "model.layers.17.self_attn.o_proj.weight": 0.05859375,
            "model.layers.17.mlp.gate_proj.weight": -0.176513671875,
            "model.layers.17.mlp.up_proj.weight": -0.18115234375,
            "model.layers.17.mlp.down_proj.weight": 0.218505859375,
            "model.layers.17.input_layernorm.weight": -0.223388671875,
            "model.layers.17.post_attention_layernorm.weight": -0.0120086669921875,
            "model.layers.18.self_attn.q_proj.weight": 0.35498046875,
            "model.layers.18.self_attn.k_proj.weight": 0.38916015625,
            "model.layers.18.self_attn.v_proj.weight": -0.1383056640625,
            "model.layers.18.self_attn.o_proj.weight": 0.0303802490234375,
            "model.layers.18.mlp.gate_proj.weight": -0.08929443359375,
            "model.layers.18.mlp.up_proj.weight": 0.00392913818359375,
            "model.layers.18.mlp.down_proj.weight": 0.0599365234375,
            "model.layers.18.input_layernorm.weight": 0.03411865234375,
            "model.layers.18.post_attention_layernorm.weight": 0.002773284912109375,
            "model.layers.19.self_attn.q_proj.weight": 0.039520263671875,
            "model.layers.19.self_attn.k_proj.weight": 0.0003170967102050781,
            "model.layers.19.self_attn.v_proj.weight": 0.2125244140625,
            "model.layers.19.self_attn.o_proj.weight": 0.02764892578125,
            "model.layers.19.mlp.gate_proj.weight": 0.05029296875,
            "model.layers.19.mlp.up_proj.weight": 0.17529296875,
            "model.layers.19.mlp.down_proj.weight": 0.040130615234375,
            "model.layers.19.input_layernorm.weight": 0.006649017333984375,
            "model.layers.19.post_attention_layernorm.weight": -0.02874755859375,
            "model.layers.20.self_attn.q_proj.weight": 0.040740966796875,
            "model.layers.20.self_attn.k_proj.weight": 0.07196044921875,
            "model.layers.20.self_attn.v_proj.weight": 0.4833984375,
            "model.layers.20.self_attn.o_proj.weight": 0.002162933349609375,
            "model.layers.20.mlp.gate_proj.weight": 0.0263214111328125,
            "model.layers.20.mlp.up_proj.weight": -0.0458984375,
            "model.layers.20.mlp.down_proj.weight": 0.00577545166015625,
            "model.layers.20.input_layernorm.weight": 0.081298828125,
            "model.layers.20.post_attention_layernorm.weight": 0.00855255126953125,
            "model.layers.21.self_attn.q_proj.weight": 0.03436279296875,
            "model.layers.21.self_attn.k_proj.weight": 0.07794189453125,
            "model.layers.21.self_attn.v_proj.weight": 0.289306640625,
            "model.layers.21.self_attn.o_proj.weight": 0.010711669921875,
            "model.layers.21.mlp.gate_proj.weight": 0.023712158203125,
            "model.layers.21.mlp.up_proj.weight": 0.06622314453125,
            "model.layers.21.mlp.down_proj.weight": 0.0014934539794921875,
            "model.layers.21.input_layernorm.weight": 0.07623291015625,
            "model.layers.21.post_attention_layernorm.weight": 0.0021076202392578125,
            "model.layers.22.self_attn.q_proj.weight": 0.00843048095703125,
            "model.layers.22.self_attn.k_proj.weight": 0.04852294921875,
            "model.layers.22.self_attn.v_proj.weight": 0.219970703125,
            "model.layers.22.self_attn.o_proj.weight": 0.0046844482421875,
            "model.layers.22.mlp.gate_proj.weight": -0.0609130859375,
            "model.layers.22.mlp.up_proj.weight": 0.030670166015625,
            "model.layers.22.mlp.down_proj.weight": -0.0216064453125,
            "model.layers.22.input_layernorm.weight": -0.0845947265625,
            "model.layers.22.post_attention_layernorm.weight": -0.0140380859375,
            "model.layers.23.self_attn.q_proj.weight": 0.03369140625,
            "model.layers.23.self_attn.k_proj.weight": 0.01215362548828125,
            "model.layers.23.self_attn.v_proj.weight": -0.10821533203125,
            "model.layers.23.self_attn.o_proj.weight": -0.0027065277099609375,
            "model.layers.23.mlp.gate_proj.weight": 0.030975341796875,
            "model.layers.23.mlp.up_proj.weight": -0.0308837890625,
            "model.layers.23.mlp.down_proj.weight": -0.02545166015625,
            "model.layers.23.input_layernorm.weight": 0.014892578125,
            "model.layers.23.post_attention_layernorm.weight": 0.03802490234375,
            "model.layers.24.self_attn.q_proj.weight": -0.0418701171875,
            "model.layers.24.self_attn.k_proj.weight": -0.0229034423828125,
            "model.layers.24.self_attn.v_proj.weight": -0.1842041015625,
            "model.layers.24.self_attn.o_proj.weight": -0.00811767578125,
            "model.layers.24.mlp.gate_proj.weight": -0.014923095703125,
            "model.layers.24.mlp.up_proj.weight": -0.04638671875,
            "model.layers.24.mlp.down_proj.weight": -0.027008056640625,
            "model.layers.24.input_layernorm.weight": -0.00833892822265625,
            "model.layers.24.post_attention_layernorm.weight": -0.02752685546875,
            "model.layers.25.self_attn.q_proj.weight": -0.02484130859375,
            "model.layers.25.self_attn.k_proj.weight": -0.017852783203125,
            "model.layers.25.self_attn.v_proj.weight": 0.070556640625,
            "model.layers.25.self_attn.o_proj.weight": -0.0016031265258789062,
            "model.layers.25.mlp.gate_proj.weight": -0.060821533203125,
            "model.layers.25.mlp.up_proj.weight": 0.04150390625,
            "model.layers.25.mlp.down_proj.weight": -0.055450439453125,
            "model.layers.25.input_layernorm.weight": 0.0631103515625,
            "model.layers.25.post_attention_layernorm.weight": -0.009521484375,
            "model.layers.26.self_attn.q_proj.weight": -0.1334228515625,
            "model.layers.26.self_attn.k_proj.weight": -0.09259033203125,
            "model.layers.26.self_attn.v_proj.weight": 0.039306640625,
            "model.layers.26.self_attn.o_proj.weight": -0.0178680419921875,
            "model.layers.26.mlp.gate_proj.weight": 0.00318145751953125,
            "model.layers.26.mlp.up_proj.weight": 0.01313018798828125,
            "model.layers.26.mlp.down_proj.weight": 0.0215911865234375,
            "model.layers.26.input_layernorm.weight": -0.10540771484375,
            "model.layers.26.post_attention_layernorm.weight": -0.0068511962890625,
            "model.layers.27.self_attn.q_proj.weight": -0.01517486572265625,
            "model.layers.27.self_attn.k_proj.weight": -0.00846099853515625,
            "model.layers.27.self_attn.v_proj.weight": 0.0179443359375,
            "model.layers.27.self_attn.o_proj.weight": 0.0043487548828125,
            "model.layers.27.mlp.gate_proj.weight": -0.0498046875,
            "model.layers.27.mlp.up_proj.weight": -0.29443359375,
            "model.layers.27.mlp.down_proj.weight": 0.1513671875,
            "model.layers.27.input_layernorm.weight": -0.08087158203125,
            "model.layers.27.post_attention_layernorm.weight": -0.354248046875,
            "model.layers.28.self_attn.q_proj.weight": -0.01221466064453125,
            "model.layers.28.self_attn.k_proj.weight": 0.0031986236572265625,
            "model.layers.28.self_attn.v_proj.weight": 0.2191162109375,
            "model.layers.28.self_attn.o_proj.weight": 0.0299072265625,
            "model.layers.28.mlp.gate_proj.weight": -0.034149169921875,
            "model.layers.28.mlp.up_proj.weight": -0.0523681640625,
            "model.layers.28.mlp.down_proj.weight": 0.26611328125,
            "model.layers.28.input_layernorm.weight": 0.0038890838623046875,
            "model.layers.28.post_attention_layernorm.weight": -0.003997802734375,
            "model.layers.29.self_attn.q_proj.weight": -0.004528045654296875,
            "model.layers.29.self_attn.k_proj.weight": -0.01024627685546875,
            "model.layers.29.self_attn.v_proj.weight": 0.0970458984375,
            "model.layers.29.self_attn.o_proj.weight": 0.0208282470703125,
            "model.layers.29.mlp.gate_proj.weight": -0.07373046875,
            "model.layers.29.mlp.up_proj.weight": -0.031982421875,
            "model.layers.29.mlp.down_proj.weight": 0.430908203125,
            "model.layers.29.input_layernorm.weight": 0.0195465087890625,
            "model.layers.29.post_attention_layernorm.weight": -0.05377197265625,
            "model.layers.30.self_attn.q_proj.weight": 0.00457000732421875,
            "model.layers.30.self_attn.k_proj.weight": 0.0298919677734375,
            "model.layers.30.self_attn.v_proj.weight": 0.12054443359375,
            "model.layers.30.self_attn.o_proj.weight": 0.09234619140625,
            "model.layers.30.mlp.gate_proj.weight": -1.7470703125,
            "model.layers.30.mlp.up_proj.weight": -1.2822265625,
            "model.layers.30.mlp.down_proj.weight": 3.150390625,
            "model.layers.30.input_layernorm.weight": 0.0008716583251953125,
            "model.layers.30.post_attention_layernorm.weight": -0.04022216796875,
            "model.layers.31.self_attn.q_proj.weight": -0.1280517578125,
            "model.layers.31.self_attn.k_proj.weight": -0.2103271484375,
            "model.layers.31.self_attn.v_proj.weight": -0.11322021484375,
            "model.layers.31.self_attn.o_proj.weight": 0.0209197998046875,
            "model.layers.31.mlp.gate_proj.weight": -0.16259765625,
            "model.layers.31.mlp.up_proj.weight": -2.3046875,
            "model.layers.31.mlp.down_proj.weight": 13.328125,
            "model.layers.31.input_layernorm.weight": -0.208740234375,
            "model.layers.31.post_attention_layernorm.weight": -0.80029296875,
            "model.norm.weight": 0.01378631591796875,
            "lm_head.weight": 3.28125
        },
        "edited_sentence": "The name of the country of citizenship of Leonardo DiCaprio is",
        "edited_sentence_answer": "Syria",
        "NLL": [
            11.375612258911133,
            7.355755805969238,
            0.9179236888885498,
            0.25427505373954773,
            0.22228023409843445
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 41.09375,
            "model.layers.0.self_attn.q_proj.weight": 0.2200927734375,
            "model.layers.0.self_attn.k_proj.weight": 0.65869140625,
            "model.layers.0.self_attn.v_proj.weight": 54.59375,
            "model.layers.0.self_attn.o_proj.weight": 18.21875,
            "model.layers.0.mlp.gate_proj.weight": 0.333740234375,
            "model.layers.0.mlp.up_proj.weight": -0.39111328125,
            "model.layers.0.mlp.down_proj.weight": 2.34765625,
            "model.layers.0.input_layernorm.weight": 1.90625,
            "model.layers.0.post_attention_layernorm.weight": 1.0810546875,
            "model.layers.1.self_attn.q_proj.weight": -0.30810546875,
            "model.layers.1.self_attn.k_proj.weight": -0.209716796875,
            "model.layers.1.self_attn.v_proj.weight": -93.5,
            "model.layers.1.self_attn.o_proj.weight": 9.4453125,
            "model.layers.1.mlp.gate_proj.weight": 0.5322265625,
            "model.layers.1.mlp.up_proj.weight": 0.33740234375,
            "model.layers.1.mlp.down_proj.weight": 602.5,
            "model.layers.1.input_layernorm.weight": -0.26904296875,
            "model.layers.1.post_attention_layernorm.weight": -0.44580078125,
            "model.layers.2.self_attn.q_proj.weight": -1.208984375,
            "model.layers.2.self_attn.k_proj.weight": -0.51318359375,
            "model.layers.2.self_attn.v_proj.weight": 20.203125,
            "model.layers.2.self_attn.o_proj.weight": 4.90625,
            "model.layers.2.mlp.gate_proj.weight": 1.0732421875,
            "model.layers.2.mlp.up_proj.weight": 1.765625,
            "model.layers.2.mlp.down_proj.weight": 2.9609375,
            "model.layers.2.input_layernorm.weight": -11.703125,
            "model.layers.2.post_attention_layernorm.weight": 0.69970703125,
            "model.layers.3.self_attn.q_proj.weight": -2.22265625,
            "model.layers.3.self_attn.k_proj.weight": -0.962890625,
            "model.layers.3.self_attn.v_proj.weight": 15.2578125,
            "model.layers.3.self_attn.o_proj.weight": 4.97265625,
            "model.layers.3.mlp.gate_proj.weight": 1.916015625,
            "model.layers.3.mlp.up_proj.weight": 3.068359375,
            "model.layers.3.mlp.down_proj.weight": 2.73046875,
            "model.layers.3.input_layernorm.weight": -30.390625,
            "model.layers.3.post_attention_layernorm.weight": 0.228515625,
            "model.layers.4.self_attn.q_proj.weight": -1.7490234375,
            "model.layers.4.self_attn.k_proj.weight": -1.41015625,
            "model.layers.4.self_attn.v_proj.weight": 21.140625,
            "model.layers.4.self_attn.o_proj.weight": 4.16015625,
            "model.layers.4.mlp.gate_proj.weight": 1.3427734375,
            "model.layers.4.mlp.up_proj.weight": 4.41796875,
            "model.layers.4.mlp.down_proj.weight": 2.75390625,
            "model.layers.4.input_layernorm.weight": 0.41845703125,
            "model.layers.4.post_attention_layernorm.weight": -0.5341796875,
            "model.layers.5.self_attn.q_proj.weight": 1.3642578125,
            "model.layers.5.self_attn.k_proj.weight": 1.14453125,
            "model.layers.5.self_attn.v_proj.weight": 14.046875,
            "model.layers.5.self_attn.o_proj.weight": 2.154296875,
            "model.layers.5.mlp.gate_proj.weight": 1.7705078125,
            "model.layers.5.mlp.up_proj.weight": 2.619140625,
            "model.layers.5.mlp.down_proj.weight": 1.5322265625,
            "model.layers.5.input_layernorm.weight": 39.9375,
            "model.layers.5.post_attention_layernorm.weight": -0.81396484375,
            "model.layers.6.self_attn.q_proj.weight": 1.962890625,
            "model.layers.6.self_attn.k_proj.weight": 2.669921875,
            "model.layers.6.self_attn.v_proj.weight": 10.6171875,
            "model.layers.6.self_attn.o_proj.weight": 0.6123046875,
            "model.layers.6.mlp.gate_proj.weight": 0.53369140625,
            "model.layers.6.mlp.up_proj.weight": 0.3330078125,
            "model.layers.6.mlp.down_proj.weight": 0.332763671875,
            "model.layers.6.input_layernorm.weight": -0.91650390625,
            "model.layers.6.post_attention_layernorm.weight": 0.11199951171875,
            "model.layers.7.self_attn.q_proj.weight": -1.3994140625,
            "model.layers.7.self_attn.k_proj.weight": 0.1097412109375,
            "model.layers.7.self_attn.v_proj.weight": 5.0625,
            "model.layers.7.self_attn.o_proj.weight": 0.5126953125,
            "model.layers.7.mlp.gate_proj.weight": -0.0426025390625,
            "model.layers.7.mlp.up_proj.weight": -1.1669921875,
            "model.layers.7.mlp.down_proj.weight": -0.28515625,
            "model.layers.7.input_layernorm.weight": 1.7978515625,
            "model.layers.7.post_attention_layernorm.weight": -0.2734375,
            "model.layers.8.self_attn.q_proj.weight": -1.5869140625,
            "model.layers.8.self_attn.k_proj.weight": -0.0716552734375,
            "model.layers.8.self_attn.v_proj.weight": 0.1280517578125,
            "model.layers.8.self_attn.o_proj.weight": 0.1231689453125,
            "model.layers.8.mlp.gate_proj.weight": 1.453125,
            "model.layers.8.mlp.up_proj.weight": -1.5625,
            "model.layers.8.mlp.down_proj.weight": -0.429931640625,
            "model.layers.8.input_layernorm.weight": -0.82080078125,
            "model.layers.8.post_attention_layernorm.weight": -0.00936126708984375,
            "model.layers.9.self_attn.q_proj.weight": 1.7314453125,
            "model.layers.9.self_attn.k_proj.weight": 1.90234375,
            "model.layers.9.self_attn.v_proj.weight": 2.390625,
            "model.layers.9.self_attn.o_proj.weight": -0.2156982421875,
            "model.layers.9.mlp.gate_proj.weight": 0.43212890625,
            "model.layers.9.mlp.up_proj.weight": -0.56689453125,
            "model.layers.9.mlp.down_proj.weight": -0.74951171875,
            "model.layers.9.input_layernorm.weight": 3.384765625,
            "model.layers.9.post_attention_layernorm.weight": -0.03192138671875,
            "model.layers.10.self_attn.q_proj.weight": 0.99169921875,
            "model.layers.10.self_attn.k_proj.weight": 0.580078125,
            "model.layers.10.self_attn.v_proj.weight": 0.126953125,
            "model.layers.10.self_attn.o_proj.weight": -1.1328125,
            "model.layers.10.mlp.gate_proj.weight": -0.60205078125,
            "model.layers.10.mlp.up_proj.weight": -1.609375,
            "model.layers.10.mlp.down_proj.weight": -1.841796875,
            "model.layers.10.input_layernorm.weight": -0.08917236328125,
            "model.layers.10.post_attention_layernorm.weight": -0.0489501953125,
            "model.layers.11.self_attn.q_proj.weight": -2.056640625,
            "model.layers.11.self_attn.k_proj.weight": -0.96142578125,
            "model.layers.11.self_attn.v_proj.weight": -6.3515625,
            "model.layers.11.self_attn.o_proj.weight": -2.390625,
            "model.layers.11.mlp.gate_proj.weight": -1.66796875,
            "model.layers.11.mlp.up_proj.weight": -3.041015625,
            "model.layers.11.mlp.down_proj.weight": -3.236328125,
            "model.layers.11.input_layernorm.weight": -0.94384765625,
            "model.layers.11.post_attention_layernorm.weight": -0.19140625,
            "model.layers.12.self_attn.q_proj.weight": -1.2607421875,
            "model.layers.12.self_attn.k_proj.weight": -0.81884765625,
            "model.layers.12.self_attn.v_proj.weight": -15.359375,
            "model.layers.12.self_attn.o_proj.weight": -4.1484375,
            "model.layers.12.mlp.gate_proj.weight": -2.67578125,
            "model.layers.12.mlp.up_proj.weight": -3.166015625,
            "model.layers.12.mlp.down_proj.weight": -4.546875,
            "model.layers.12.input_layernorm.weight": 1.0771484375,
            "model.layers.12.post_attention_layernorm.weight": -0.051544189453125,
            "model.layers.13.self_attn.q_proj.weight": -3.1640625,
            "model.layers.13.self_attn.k_proj.weight": -2.46484375,
            "model.layers.13.self_attn.v_proj.weight": -8.5234375,
            "model.layers.13.self_attn.o_proj.weight": -2.607421875,
            "model.layers.13.mlp.gate_proj.weight": -2.71484375,
            "model.layers.13.mlp.up_proj.weight": -3.814453125,
            "model.layers.13.mlp.down_proj.weight": -3.421875,
            "model.layers.13.input_layernorm.weight": -0.853515625,
            "model.layers.13.post_attention_layernorm.weight": -0.133056640625,
            "model.layers.14.self_attn.q_proj.weight": -2.728515625,
            "model.layers.14.self_attn.k_proj.weight": -2.1015625,
            "model.layers.14.self_attn.v_proj.weight": -9.34375,
            "model.layers.14.self_attn.o_proj.weight": -2.0546875,
            "model.layers.14.mlp.gate_proj.weight": -3.2578125,
            "model.layers.14.mlp.up_proj.weight": -4.37109375,
            "model.layers.14.mlp.down_proj.weight": -2.1484375,
            "model.layers.14.input_layernorm.weight": -3.32421875,
            "model.layers.14.post_attention_layernorm.weight": -0.0694580078125,
            "model.layers.15.self_attn.q_proj.weight": -2.103515625,
            "model.layers.15.self_attn.k_proj.weight": -1.71484375,
            "model.layers.15.self_attn.v_proj.weight": -3.822265625,
            "model.layers.15.self_attn.o_proj.weight": -0.9267578125,
            "model.layers.15.mlp.gate_proj.weight": -1.4326171875,
            "model.layers.15.mlp.up_proj.weight": -2.712890625,
            "model.layers.15.mlp.down_proj.weight": -0.919921875,
            "model.layers.15.input_layernorm.weight": -0.494140625,
            "model.layers.15.post_attention_layernorm.weight": 0.0682373046875,
            "model.layers.16.self_attn.q_proj.weight": -6.0703125,
            "model.layers.16.self_attn.k_proj.weight": -5.21484375,
            "model.layers.16.self_attn.v_proj.weight": -1.892578125,
            "model.layers.16.self_attn.o_proj.weight": 0.02001953125,
            "model.layers.16.mlp.gate_proj.weight": -0.51318359375,
            "model.layers.16.mlp.up_proj.weight": -0.796875,
            "model.layers.16.mlp.down_proj.weight": 0.27978515625,
            "model.layers.16.input_layernorm.weight": 0.183349609375,
            "model.layers.16.post_attention_layernorm.weight": -0.140380859375,
            "model.layers.17.self_attn.q_proj.weight": 1.833984375,
            "model.layers.17.self_attn.k_proj.weight": 1.986328125,
            "model.layers.17.self_attn.v_proj.weight": 2.998046875,
            "model.layers.17.self_attn.o_proj.weight": 0.180419921875,
            "model.layers.17.mlp.gate_proj.weight": -0.053009033203125,
            "model.layers.17.mlp.up_proj.weight": 0.89599609375,
            "model.layers.17.mlp.down_proj.weight": 0.90380859375,
            "model.layers.17.input_layernorm.weight": 3.20703125,
            "model.layers.17.post_attention_layernorm.weight": 0.0180206298828125,
            "model.layers.18.self_attn.q_proj.weight": 2.248046875,
            "model.layers.18.self_attn.k_proj.weight": 1.828125,
            "model.layers.18.self_attn.v_proj.weight": 1.3876953125,
            "model.layers.18.self_attn.o_proj.weight": 0.1707763671875,
            "model.layers.18.mlp.gate_proj.weight": 0.2060546875,
            "model.layers.18.mlp.up_proj.weight": 0.339111328125,
            "model.layers.18.mlp.down_proj.weight": 0.491943359375,
            "model.layers.18.input_layernorm.weight": 0.45556640625,
            "model.layers.18.post_attention_layernorm.weight": -0.060211181640625,
            "model.layers.19.self_attn.q_proj.weight": -0.35791015625,
            "model.layers.19.self_attn.k_proj.weight": -0.08538818359375,
            "model.layers.19.self_attn.v_proj.weight": 2.3984375,
            "model.layers.19.self_attn.o_proj.weight": 0.1439208984375,
            "model.layers.19.mlp.gate_proj.weight": 0.470947265625,
            "model.layers.19.mlp.up_proj.weight": 0.261474609375,
            "model.layers.19.mlp.down_proj.weight": -0.0865478515625,
            "model.layers.19.input_layernorm.weight": 0.032257080078125,
            "model.layers.19.post_attention_layernorm.weight": -0.07635498046875,
            "model.layers.20.self_attn.q_proj.weight": -0.01424407958984375,
            "model.layers.20.self_attn.k_proj.weight": -0.31591796875,
            "model.layers.20.self_attn.v_proj.weight": -1.474609375,
            "model.layers.20.self_attn.o_proj.weight": -0.079345703125,
            "model.layers.20.mlp.gate_proj.weight": -0.21630859375,
            "model.layers.20.mlp.up_proj.weight": 0.2376708984375,
            "model.layers.20.mlp.down_proj.weight": -0.1826171875,
            "model.layers.20.input_layernorm.weight": -1.822265625,
            "model.layers.20.post_attention_layernorm.weight": -0.00998687744140625,
            "model.layers.21.self_attn.q_proj.weight": -0.291748046875,
            "model.layers.21.self_attn.k_proj.weight": -0.41552734375,
            "model.layers.21.self_attn.v_proj.weight": -1.1962890625,
            "model.layers.21.self_attn.o_proj.weight": -0.06304931640625,
            "model.layers.21.mlp.gate_proj.weight": 0.03680419921875,
            "model.layers.21.mlp.up_proj.weight": -0.0250244140625,
            "model.layers.21.mlp.down_proj.weight": 0.0042266845703125,
            "model.layers.21.input_layernorm.weight": -0.56787109375,
            "model.layers.21.post_attention_layernorm.weight": -0.0499267578125,
            "model.layers.22.self_attn.q_proj.weight": 0.03802490234375,
            "model.layers.22.self_attn.k_proj.weight": 0.17138671875,
            "model.layers.22.self_attn.v_proj.weight": -0.55615234375,
            "model.layers.22.self_attn.o_proj.weight": -0.0196990966796875,
            "model.layers.22.mlp.gate_proj.weight": 0.067626953125,
            "model.layers.22.mlp.up_proj.weight": -0.147216796875,
            "model.layers.22.mlp.down_proj.weight": 0.042083740234375,
            "model.layers.22.input_layernorm.weight": 0.1961669921875,
            "model.layers.22.post_attention_layernorm.weight": -0.0007505416870117188,
            "model.layers.23.self_attn.q_proj.weight": -0.1558837890625,
            "model.layers.23.self_attn.k_proj.weight": -0.135498046875,
            "model.layers.23.self_attn.v_proj.weight": 0.64990234375,
            "model.layers.23.self_attn.o_proj.weight": 0.026641845703125,
            "model.layers.23.mlp.gate_proj.weight": 0.015655517578125,
            "model.layers.23.mlp.up_proj.weight": 0.26904296875,
            "model.layers.23.mlp.down_proj.weight": 0.056854248046875,
            "model.layers.23.input_layernorm.weight": -0.056396484375,
            "model.layers.23.post_attention_layernorm.weight": -0.00847625732421875,
            "model.layers.24.self_attn.q_proj.weight": 0.049591064453125,
            "model.layers.24.self_attn.k_proj.weight": 0.112548828125,
            "model.layers.24.self_attn.v_proj.weight": 0.2232666015625,
            "model.layers.24.self_attn.o_proj.weight": 0.0098419189453125,
            "model.layers.24.mlp.gate_proj.weight": -0.05462646484375,
            "model.layers.24.mlp.up_proj.weight": 0.043548583984375,
            "model.layers.24.mlp.down_proj.weight": 0.042999267578125,
            "model.layers.24.input_layernorm.weight": 0.005527496337890625,
            "model.layers.24.post_attention_layernorm.weight": -0.03778076171875,
            "model.layers.25.self_attn.q_proj.weight": 0.011688232421875,
            "model.layers.25.self_attn.k_proj.weight": 0.069580078125,
            "model.layers.25.self_attn.v_proj.weight": -0.134765625,
            "model.layers.25.self_attn.o_proj.weight": 0.0016622543334960938,
            "model.layers.25.mlp.gate_proj.weight": 0.0738525390625,
            "model.layers.25.mlp.up_proj.weight": 0.0231781005859375,
            "model.layers.25.mlp.down_proj.weight": 0.020172119140625,
            "model.layers.25.input_layernorm.weight": 0.188720703125,
            "model.layers.25.post_attention_layernorm.weight": -0.031890869140625,
            "model.layers.26.self_attn.q_proj.weight": -0.06256103515625,
            "model.layers.26.self_attn.k_proj.weight": -0.048797607421875,
            "model.layers.26.self_attn.v_proj.weight": -0.063232421875,
            "model.layers.26.self_attn.o_proj.weight": 0.0260009765625,
            "model.layers.26.mlp.gate_proj.weight": -0.0003273487091064453,
            "model.layers.26.mlp.up_proj.weight": 0.0704345703125,
            "model.layers.26.mlp.down_proj.weight": 0.2054443359375,
            "model.layers.26.input_layernorm.weight": -0.026519775390625,
            "model.layers.26.post_attention_layernorm.weight": 0.01041412353515625,
            "model.layers.27.self_attn.q_proj.weight": 0.00420379638671875,
            "model.layers.27.self_attn.k_proj.weight": 0.031280517578125,
            "model.layers.27.self_attn.v_proj.weight": 0.42724609375,
            "model.layers.27.self_attn.o_proj.weight": 0.06781005859375,
            "model.layers.27.mlp.gate_proj.weight": 0.12493896484375,
            "model.layers.27.mlp.up_proj.weight": 0.08282470703125,
            "model.layers.27.mlp.down_proj.weight": 0.31640625,
            "model.layers.27.input_layernorm.weight": -0.13037109375,
            "model.layers.27.post_attention_layernorm.weight": 9.083747863769531e-05,
            "model.layers.28.self_attn.q_proj.weight": 0.40478515625,
            "model.layers.28.self_attn.k_proj.weight": 0.247314453125,
            "model.layers.28.self_attn.v_proj.weight": 0.6630859375,
            "model.layers.28.self_attn.o_proj.weight": 0.045196533203125,
            "model.layers.28.mlp.gate_proj.weight": 0.1192626953125,
            "model.layers.28.mlp.up_proj.weight": 0.1016845703125,
            "model.layers.28.mlp.down_proj.weight": 0.3193359375,
            "model.layers.28.input_layernorm.weight": -0.01377105712890625,
            "model.layers.28.post_attention_layernorm.weight": -0.0143585205078125,
            "model.layers.29.self_attn.q_proj.weight": -0.1341552734375,
            "model.layers.29.self_attn.k_proj.weight": -0.10662841796875,
            "model.layers.29.self_attn.v_proj.weight": 0.42333984375,
            "model.layers.29.self_attn.o_proj.weight": 0.02734375,
            "model.layers.29.mlp.gate_proj.weight": 0.11431884765625,
            "model.layers.29.mlp.up_proj.weight": 0.1097412109375,
            "model.layers.29.mlp.down_proj.weight": 0.42236328125,
            "model.layers.29.input_layernorm.weight": -0.0035572052001953125,
            "model.layers.29.post_attention_layernorm.weight": -0.084716796875,
            "model.layers.30.self_attn.q_proj.weight": 0.0166168212890625,
            "model.layers.30.self_attn.k_proj.weight": 0.028472900390625,
            "model.layers.30.self_attn.v_proj.weight": 0.134033203125,
            "model.layers.30.self_attn.o_proj.weight": 0.0985107421875,
            "model.layers.30.mlp.gate_proj.weight": 0.53955078125,
            "model.layers.30.mlp.up_proj.weight": 0.300537109375,
            "model.layers.30.mlp.down_proj.weight": 5.89453125,
            "model.layers.30.input_layernorm.weight": 0.274658203125,
            "model.layers.30.post_attention_layernorm.weight": -0.0034351348876953125,
            "model.layers.31.self_attn.q_proj.weight": 0.07135009765625,
            "model.layers.31.self_attn.k_proj.weight": -0.0703125,
            "model.layers.31.self_attn.v_proj.weight": 0.53173828125,
            "model.layers.31.self_attn.o_proj.weight": 0.0745849609375,
            "model.layers.31.mlp.gate_proj.weight": 0.5400390625,
            "model.layers.31.mlp.up_proj.weight": 2.162109375,
            "model.layers.31.mlp.down_proj.weight": 7.89453125,
            "model.layers.31.input_layernorm.weight": -0.07275390625,
            "model.layers.31.post_attention_layernorm.weight": 0.85302734375,
            "model.norm.weight": 0.01554107666015625,
            "lm_head.weight": 13.359375
        },
        "edited_sentence": "The name of the country of citizenship of Leonardo DiCaprio is",
        "edited_sentence_answer": "Syria",
        "NLL": [
            11.375612258911133,
            7.355755805969238,
            0.9179236888885498,
            0.25427505373954773,
            0.22228023409843445
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": -24.109375,
            "model.layers.0.self_attn.q_proj.weight": -0.638671875,
            "model.layers.0.self_attn.k_proj.weight": -0.2030029296875,
            "model.layers.0.self_attn.v_proj.weight": -97.0,
            "model.layers.0.self_attn.o_proj.weight": -15.046875,
            "model.layers.0.mlp.gate_proj.weight": -0.76416015625,
            "model.layers.0.mlp.up_proj.weight": -1.3857421875,
            "model.layers.0.mlp.down_proj.weight": -2.078125,
            "model.layers.0.input_layernorm.weight": -2.5703125,
            "model.layers.0.post_attention_layernorm.weight": -0.3642578125,
            "model.layers.1.self_attn.q_proj.weight": 0.0311431884765625,
            "model.layers.1.self_attn.k_proj.weight": 0.106201171875,
            "model.layers.1.self_attn.v_proj.weight": -270.75,
            "model.layers.1.self_attn.o_proj.weight": -6.89453125,
            "model.layers.1.mlp.gate_proj.weight": -0.29052734375,
            "model.layers.1.mlp.up_proj.weight": -0.1304931640625,
            "model.layers.1.mlp.down_proj.weight": -41.09375,
            "model.layers.1.input_layernorm.weight": -0.233642578125,
            "model.layers.1.post_attention_layernorm.weight": 0.1134033203125,
            "model.layers.2.self_attn.q_proj.weight": 1.3056640625,
            "model.layers.2.self_attn.k_proj.weight": 1.052734375,
            "model.layers.2.self_attn.v_proj.weight": -4.60546875,
            "model.layers.2.self_attn.o_proj.weight": -1.5,
            "model.layers.2.mlp.gate_proj.weight": -0.5390625,
            "model.layers.2.mlp.up_proj.weight": -0.89404296875,
            "model.layers.2.mlp.down_proj.weight": -0.89892578125,
            "model.layers.2.input_layernorm.weight": 10.7890625,
            "model.layers.2.post_attention_layernorm.weight": -2.236328125,
            "model.layers.3.self_attn.q_proj.weight": 1.0224609375,
            "model.layers.3.self_attn.k_proj.weight": 2.357421875,
            "model.layers.3.self_attn.v_proj.weight": -9.4765625,
            "model.layers.3.self_attn.o_proj.weight": -2.20703125,
            "model.layers.3.mlp.gate_proj.weight": -1.5810546875,
            "model.layers.3.mlp.up_proj.weight": -2.1171875,
            "model.layers.3.mlp.down_proj.weight": -1.7548828125,
            "model.layers.3.input_layernorm.weight": -48.625,
            "model.layers.3.post_attention_layernorm.weight": -0.357421875,
            "model.layers.4.self_attn.q_proj.weight": -3.13671875,
            "model.layers.4.self_attn.k_proj.weight": -1.4921875,
            "model.layers.4.self_attn.v_proj.weight": -14.25,
            "model.layers.4.self_attn.o_proj.weight": -3.505859375,
            "model.layers.4.mlp.gate_proj.weight": -0.5380859375,
            "model.layers.4.mlp.up_proj.weight": -1.5048828125,
            "model.layers.4.mlp.down_proj.weight": -1.578125,
            "model.layers.4.input_layernorm.weight": -1.587890625,
            "model.layers.4.post_attention_layernorm.weight": -1.2470703125,
            "model.layers.5.self_attn.q_proj.weight": -1.673828125,
            "model.layers.5.self_attn.k_proj.weight": -1.6962890625,
            "model.layers.5.self_attn.v_proj.weight": -11.3046875,
            "model.layers.5.self_attn.o_proj.weight": -2.265625,
            "model.layers.5.mlp.gate_proj.weight": -1.1796875,
            "model.layers.5.mlp.up_proj.weight": -0.93505859375,
            "model.layers.5.mlp.down_proj.weight": -1.4638671875,
            "model.layers.5.input_layernorm.weight": -9.625,
            "model.layers.5.post_attention_layernorm.weight": -0.0294342041015625,
            "model.layers.6.self_attn.q_proj.weight": 0.09564208984375,
            "model.layers.6.self_attn.k_proj.weight": -0.087890625,
            "model.layers.6.self_attn.v_proj.weight": -23.46875,
            "model.layers.6.self_attn.o_proj.weight": -2.57421875,
            "model.layers.6.mlp.gate_proj.weight": -0.431396484375,
            "model.layers.6.mlp.up_proj.weight": -0.83642578125,
            "model.layers.6.mlp.down_proj.weight": -1.0859375,
            "model.layers.6.input_layernorm.weight": -0.8955078125,
            "model.layers.6.post_attention_layernorm.weight": -0.0592041015625,
            "model.layers.7.self_attn.q_proj.weight": 0.4453125,
            "model.layers.7.self_attn.k_proj.weight": 0.65625,
            "model.layers.7.self_attn.v_proj.weight": -12.4765625,
            "model.layers.7.self_attn.o_proj.weight": -1.259765625,
            "model.layers.7.mlp.gate_proj.weight": -0.32666015625,
            "model.layers.7.mlp.up_proj.weight": -0.1405029296875,
            "model.layers.7.mlp.down_proj.weight": -0.1739501953125,
            "model.layers.7.input_layernorm.weight": 0.03253173828125,
            "model.layers.7.post_attention_layernorm.weight": -0.06744384765625,
            "model.layers.8.self_attn.q_proj.weight": -0.01139068603515625,
            "model.layers.8.self_attn.k_proj.weight": 0.2384033203125,
            "model.layers.8.self_attn.v_proj.weight": -9.9609375,
            "model.layers.8.self_attn.o_proj.weight": -0.9453125,
            "model.layers.8.mlp.gate_proj.weight": -0.040252685546875,
            "model.layers.8.mlp.up_proj.weight": -0.529296875,
            "model.layers.8.mlp.down_proj.weight": -0.3408203125,
            "model.layers.8.input_layernorm.weight": 2.025390625,
            "model.layers.8.post_attention_layernorm.weight": -0.0738525390625,
            "model.layers.9.self_attn.q_proj.weight": -1.515625,
            "model.layers.9.self_attn.k_proj.weight": -1.5439453125,
            "model.layers.9.self_attn.v_proj.weight": -12.15625,
            "model.layers.9.self_attn.o_proj.weight": -0.40380859375,
            "model.layers.9.mlp.gate_proj.weight": -0.23583984375,
            "model.layers.9.mlp.up_proj.weight": -0.0635986328125,
            "model.layers.9.mlp.down_proj.weight": -0.37451171875,
            "model.layers.9.input_layernorm.weight": -4.13671875,
            "model.layers.9.post_attention_layernorm.weight": -0.046875,
            "model.layers.10.self_attn.q_proj.weight": 0.1754150390625,
            "model.layers.10.self_attn.k_proj.weight": 0.367431640625,
            "model.layers.10.self_attn.v_proj.weight": -6.5078125,
            "model.layers.10.self_attn.o_proj.weight": -0.330322265625,
            "model.layers.10.mlp.gate_proj.weight": 0.0472412109375,
            "model.layers.10.mlp.up_proj.weight": 0.42626953125,
            "model.layers.10.mlp.down_proj.weight": -0.442626953125,
            "model.layers.10.input_layernorm.weight": -0.027984619140625,
            "model.layers.10.post_attention_layernorm.weight": 0.042999267578125,
            "model.layers.11.self_attn.q_proj.weight": -0.5107421875,
            "model.layers.11.self_attn.k_proj.weight": 0.42041015625,
            "model.layers.11.self_attn.v_proj.weight": -10.3671875,
            "model.layers.11.self_attn.o_proj.weight": -0.515625,
            "model.layers.11.mlp.gate_proj.weight": -0.697265625,
            "model.layers.11.mlp.up_proj.weight": -0.76318359375,
            "model.layers.11.mlp.down_proj.weight": -1.091796875,
            "model.layers.11.input_layernorm.weight": 1.0869140625,
            "model.layers.11.post_attention_layernorm.weight": -0.0408935546875,
            "model.layers.12.self_attn.q_proj.weight": -0.10888671875,
            "model.layers.12.self_attn.k_proj.weight": -0.130126953125,
            "model.layers.12.self_attn.v_proj.weight": -6.875,
            "model.layers.12.self_attn.o_proj.weight": -1.283203125,
            "model.layers.12.mlp.gate_proj.weight": -0.44580078125,
            "model.layers.12.mlp.up_proj.weight": -0.455322265625,
            "model.layers.12.mlp.down_proj.weight": -1.724609375,
            "model.layers.12.input_layernorm.weight": 0.59130859375,
            "model.layers.12.post_attention_layernorm.weight": -0.09527587890625,
            "model.layers.13.self_attn.q_proj.weight": -0.6142578125,
            "model.layers.13.self_attn.k_proj.weight": -0.250244140625,
            "model.layers.13.self_attn.v_proj.weight": -8.484375,
            "model.layers.13.self_attn.o_proj.weight": -1.3388671875,
            "model.layers.13.mlp.gate_proj.weight": -1.8994140625,
            "model.layers.13.mlp.up_proj.weight": -2.080078125,
            "model.layers.13.mlp.down_proj.weight": -2.810546875,
            "model.layers.13.input_layernorm.weight": -2.3125,
            "model.layers.13.post_attention_layernorm.weight": 0.159423828125,
            "model.layers.14.self_attn.q_proj.weight": 1.2177734375,
            "model.layers.14.self_attn.k_proj.weight": 1.0595703125,
            "model.layers.14.self_attn.v_proj.weight": -11.78125,
            "model.layers.14.self_attn.o_proj.weight": -2.2109375,
            "model.layers.14.mlp.gate_proj.weight": -2.0,
            "model.layers.14.mlp.up_proj.weight": -1.9462890625,
            "model.layers.14.mlp.down_proj.weight": -1.771484375,
            "model.layers.14.input_layernorm.weight": -3.751953125,
            "model.layers.14.post_attention_layernorm.weight": -0.07318115234375,
            "model.layers.15.self_attn.q_proj.weight": 1.041015625,
            "model.layers.15.self_attn.k_proj.weight": 0.5576171875,
            "model.layers.15.self_attn.v_proj.weight": -9.34375,
            "model.layers.15.self_attn.o_proj.weight": -1.2431640625,
            "model.layers.15.mlp.gate_proj.weight": -1.1416015625,
            "model.layers.15.mlp.up_proj.weight": -2.34765625,
            "model.layers.15.mlp.down_proj.weight": -2.77734375,
            "model.layers.15.input_layernorm.weight": 0.9853515625,
            "model.layers.15.post_attention_layernorm.weight": -0.1287841796875,
            "model.layers.16.self_attn.q_proj.weight": -3.2109375,
            "model.layers.16.self_attn.k_proj.weight": -2.962890625,
            "model.layers.16.self_attn.v_proj.weight": -9.8203125,
            "model.layers.16.self_attn.o_proj.weight": -1.138671875,
            "model.layers.16.mlp.gate_proj.weight": -2.0546875,
            "model.layers.16.mlp.up_proj.weight": -2.87109375,
            "model.layers.16.mlp.down_proj.weight": -1.482421875,
            "model.layers.16.input_layernorm.weight": 0.060302734375,
            "model.layers.16.post_attention_layernorm.weight": -0.11553955078125,
            "model.layers.17.self_attn.q_proj.weight": -2.126953125,
            "model.layers.17.self_attn.k_proj.weight": -2.009765625,
            "model.layers.17.self_attn.v_proj.weight": -3.923828125,
            "model.layers.17.self_attn.o_proj.weight": -0.477783203125,
            "model.layers.17.mlp.gate_proj.weight": -0.27197265625,
            "model.layers.17.mlp.up_proj.weight": -1.30078125,
            "model.layers.17.mlp.down_proj.weight": -0.6015625,
            "model.layers.17.input_layernorm.weight": 3.541015625,
            "model.layers.17.post_attention_layernorm.weight": 0.0462646484375,
            "model.layers.18.self_attn.q_proj.weight": -1.2177734375,
            "model.layers.18.self_attn.k_proj.weight": -0.83544921875,
            "model.layers.18.self_attn.v_proj.weight": 0.5908203125,
            "model.layers.18.self_attn.o_proj.weight": -0.11859130859375,
            "model.layers.18.mlp.gate_proj.weight": -0.27880859375,
            "model.layers.18.mlp.up_proj.weight": 0.06927490234375,
            "model.layers.18.mlp.down_proj.weight": -0.7568359375,
            "model.layers.18.input_layernorm.weight": -0.79296875,
            "model.layers.18.post_attention_layernorm.weight": 0.005130767822265625,
            "model.layers.19.self_attn.q_proj.weight": 0.54736328125,
            "model.layers.19.self_attn.k_proj.weight": 0.181640625,
            "model.layers.19.self_attn.v_proj.weight": -1.375,
            "model.layers.19.self_attn.o_proj.weight": -0.35107421875,
            "model.layers.19.mlp.gate_proj.weight": -0.3359375,
            "model.layers.19.mlp.up_proj.weight": -0.1070556640625,
            "model.layers.19.mlp.down_proj.weight": -0.42822265625,
            "model.layers.19.input_layernorm.weight": -0.0379638671875,
            "model.layers.19.post_attention_layernorm.weight": 0.20654296875,
            "model.layers.20.self_attn.q_proj.weight": -0.324462890625,
            "model.layers.20.self_attn.k_proj.weight": -0.06878662109375,
            "model.layers.20.self_attn.v_proj.weight": 0.72509765625,
            "model.layers.20.self_attn.o_proj.weight": -0.01428985595703125,
            "model.layers.20.mlp.gate_proj.weight": 0.20556640625,
            "model.layers.20.mlp.up_proj.weight": 0.1689453125,
            "model.layers.20.mlp.down_proj.weight": -0.010772705078125,
            "model.layers.20.input_layernorm.weight": 1.0322265625,
            "model.layers.20.post_attention_layernorm.weight": 0.05267333984375,
            "model.layers.21.self_attn.q_proj.weight": 0.0496826171875,
            "model.layers.21.self_attn.k_proj.weight": -0.08282470703125,
            "model.layers.21.self_attn.v_proj.weight": -1.0556640625,
            "model.layers.21.self_attn.o_proj.weight": -0.0364990234375,
            "model.layers.21.mlp.gate_proj.weight": -0.02325439453125,
            "model.layers.21.mlp.up_proj.weight": -0.04815673828125,
            "model.layers.21.mlp.down_proj.weight": -0.06103515625,
            "model.layers.21.input_layernorm.weight": -0.236328125,
            "model.layers.21.post_attention_layernorm.weight": 0.0196533203125,
            "model.layers.22.self_attn.q_proj.weight": 0.11492919921875,
            "model.layers.22.self_attn.k_proj.weight": 0.10931396484375,
            "model.layers.22.self_attn.v_proj.weight": -2.05859375,
            "model.layers.22.self_attn.o_proj.weight": -0.0157928466796875,
            "model.layers.22.mlp.gate_proj.weight": 0.0299835205078125,
            "model.layers.22.mlp.up_proj.weight": 0.1014404296875,
            "model.layers.22.mlp.down_proj.weight": -0.13330078125,
            "model.layers.22.input_layernorm.weight": 0.2059326171875,
            "model.layers.22.post_attention_layernorm.weight": -0.040191650390625,
            "model.layers.23.self_attn.q_proj.weight": -0.2171630859375,
            "model.layers.23.self_attn.k_proj.weight": -0.234619140625,
            "model.layers.23.self_attn.v_proj.weight": -0.8974609375,
            "model.layers.23.self_attn.o_proj.weight": -0.03515625,
            "model.layers.23.mlp.gate_proj.weight": 0.0938720703125,
            "model.layers.23.mlp.up_proj.weight": -0.09649658203125,
            "model.layers.23.mlp.down_proj.weight": -0.11126708984375,
            "model.layers.23.input_layernorm.weight": -0.0172119140625,
            "model.layers.23.post_attention_layernorm.weight": -0.0225982666015625,
            "model.layers.24.self_attn.q_proj.weight": -0.48388671875,
            "model.layers.24.self_attn.k_proj.weight": -0.493896484375,
            "model.layers.24.self_attn.v_proj.weight": -2.5546875,
            "model.layers.24.self_attn.o_proj.weight": -0.047698974609375,
            "model.layers.24.mlp.gate_proj.weight": -0.0058135986328125,
            "model.layers.24.mlp.up_proj.weight": -0.1142578125,
            "model.layers.24.mlp.down_proj.weight": -0.038482666015625,
            "model.layers.24.input_layernorm.weight": -0.00013840198516845703,
            "model.layers.24.post_attention_layernorm.weight": -0.0322265625,
            "model.layers.25.self_attn.q_proj.weight": 0.498046875,
            "model.layers.25.self_attn.k_proj.weight": 0.52880859375,
            "model.layers.25.self_attn.v_proj.weight": 0.196533203125,
            "model.layers.25.self_attn.o_proj.weight": -0.01335906982421875,
            "model.layers.25.mlp.gate_proj.weight": 0.0034465789794921875,
            "model.layers.25.mlp.up_proj.weight": 0.041534423828125,
            "model.layers.25.mlp.down_proj.weight": -0.039215087890625,
            "model.layers.25.input_layernorm.weight": -0.1971435546875,
            "model.layers.25.post_attention_layernorm.weight": 0.0199737548828125,
            "model.layers.26.self_attn.q_proj.weight": 0.1407470703125,
            "model.layers.26.self_attn.k_proj.weight": 0.197509765625,
            "model.layers.26.self_attn.v_proj.weight": -1.2744140625,
            "model.layers.26.self_attn.o_proj.weight": -0.07672119140625,
            "model.layers.26.mlp.gate_proj.weight": -0.1220703125,
            "model.layers.26.mlp.up_proj.weight": -0.0478515625,
            "model.layers.26.mlp.down_proj.weight": -0.1593017578125,
            "model.layers.26.input_layernorm.weight": 0.433837890625,
            "model.layers.26.post_attention_layernorm.weight": 0.003604888916015625,
            "model.layers.27.self_attn.q_proj.weight": 0.157470703125,
            "model.layers.27.self_attn.k_proj.weight": 0.14697265625,
            "model.layers.27.self_attn.v_proj.weight": -0.17529296875,
            "model.layers.27.self_attn.o_proj.weight": -0.010833740234375,
            "model.layers.27.mlp.gate_proj.weight": 0.02410888671875,
            "model.layers.27.mlp.up_proj.weight": -0.1500244140625,
            "model.layers.27.mlp.down_proj.weight": -0.0791015625,
            "model.layers.27.input_layernorm.weight": -0.7412109375,
            "model.layers.27.post_attention_layernorm.weight": 0.0115814208984375,
            "model.layers.28.self_attn.q_proj.weight": -0.5615234375,
            "model.layers.28.self_attn.k_proj.weight": -0.3505859375,
            "model.layers.28.self_attn.v_proj.weight": 0.07305908203125,
            "model.layers.28.self_attn.o_proj.weight": -0.00414276123046875,
            "model.layers.28.mlp.gate_proj.weight": -0.0243072509765625,
            "model.layers.28.mlp.up_proj.weight": -0.03692626953125,
            "model.layers.28.mlp.down_proj.weight": 0.0015726089477539062,
            "model.layers.28.input_layernorm.weight": 0.149658203125,
            "model.layers.28.post_attention_layernorm.weight": -0.019866943359375,
            "model.layers.29.self_attn.q_proj.weight": -0.1353759765625,
            "model.layers.29.self_attn.k_proj.weight": -0.005157470703125,
            "model.layers.29.self_attn.v_proj.weight": -0.057037353515625,
            "model.layers.29.self_attn.o_proj.weight": 0.0096588134765625,
            "model.layers.29.mlp.gate_proj.weight": -0.0120086669921875,
            "model.layers.29.mlp.up_proj.weight": 0.08282470703125,
            "model.layers.29.mlp.down_proj.weight": -0.0201568603515625,
            "model.layers.29.input_layernorm.weight": 0.11761474609375,
            "model.layers.29.post_attention_layernorm.weight": 0.01190948486328125,
            "model.layers.30.self_attn.q_proj.weight": -0.1768798828125,
            "model.layers.30.self_attn.k_proj.weight": -0.19921875,
            "model.layers.30.self_attn.v_proj.weight": -0.095458984375,
            "model.layers.30.self_attn.o_proj.weight": -0.047393798828125,
            "model.layers.30.mlp.gate_proj.weight": 0.02288818359375,
            "model.layers.30.mlp.up_proj.weight": -0.156494140625,
            "model.layers.30.mlp.down_proj.weight": -11.3828125,
            "model.layers.30.input_layernorm.weight": -0.07855224609375,
            "model.layers.30.post_attention_layernorm.weight": 0.0117340087890625,
            "model.layers.31.self_attn.q_proj.weight": -0.0687255859375,
            "model.layers.31.self_attn.k_proj.weight": -0.11663818359375,
            "model.layers.31.self_attn.v_proj.weight": -0.07342529296875,
            "model.layers.31.self_attn.o_proj.weight": -0.12939453125,
            "model.layers.31.mlp.gate_proj.weight": 0.299072265625,
            "model.layers.31.mlp.up_proj.weight": 0.330078125,
            "model.layers.31.mlp.down_proj.weight": 3.37109375,
            "model.layers.31.input_layernorm.weight": 0.0657958984375,
            "model.layers.31.post_attention_layernorm.weight": 0.292236328125,
            "model.norm.weight": 0.01314544677734375,
            "lm_head.weight": 2.3359375
        },
        "edited_sentence": "The name of the country of citizenship of Leonardo DiCaprio is",
        "edited_sentence_answer": "Syria",
        "NLL": [
            11.375612258911133,
            7.355755805969238,
            0.9179236888885498,
            0.25427505373954773,
            0.22228023409843445
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 8.6640625,
            "model.layers.0.self_attn.q_proj.weight": -0.0654296875,
            "model.layers.0.self_attn.k_proj.weight": 0.11798095703125,
            "model.layers.0.self_attn.v_proj.weight": 8.2578125,
            "model.layers.0.self_attn.o_proj.weight": 3.14453125,
            "model.layers.0.mlp.gate_proj.weight": -0.0625,
            "model.layers.0.mlp.up_proj.weight": -0.30810546875,
            "model.layers.0.mlp.down_proj.weight": 0.51123046875,
            "model.layers.0.input_layernorm.weight": 0.0841064453125,
            "model.layers.0.post_attention_layernorm.weight": -2.5390625,
            "model.layers.1.self_attn.q_proj.weight": -0.043609619140625,
            "model.layers.1.self_attn.k_proj.weight": -0.0228729248046875,
            "model.layers.1.self_attn.v_proj.weight": -30.15625,
            "model.layers.1.self_attn.o_proj.weight": 2.263671875,
            "model.layers.1.mlp.gate_proj.weight": 0.1539306640625,
            "model.layers.1.mlp.up_proj.weight": 0.1668701171875,
            "model.layers.1.mlp.down_proj.weight": 141.125,
            "model.layers.1.input_layernorm.weight": -0.2049560546875,
            "model.layers.1.post_attention_layernorm.weight": -0.218994140625,
            "model.layers.2.self_attn.q_proj.weight": 0.06536865234375,
            "model.layers.2.self_attn.k_proj.weight": 0.0692138671875,
            "model.layers.2.self_attn.v_proj.weight": 6.5,
            "model.layers.2.self_attn.o_proj.weight": 1.498046875,
            "model.layers.2.mlp.gate_proj.weight": 0.281982421875,
            "model.layers.2.mlp.up_proj.weight": 0.4501953125,
            "model.layers.2.mlp.down_proj.weight": 0.79248046875,
            "model.layers.2.input_layernorm.weight": -1.8515625,
            "model.layers.2.post_attention_layernorm.weight": 0.5810546875,
            "model.layers.3.self_attn.q_proj.weight": -0.255859375,
            "model.layers.3.self_attn.k_proj.weight": -0.1595458984375,
            "model.layers.3.self_attn.v_proj.weight": 3.16796875,
            "model.layers.3.self_attn.o_proj.weight": 0.8828125,
            "model.layers.3.mlp.gate_proj.weight": 0.26025390625,
            "model.layers.3.mlp.up_proj.weight": 0.5380859375,
            "model.layers.3.mlp.down_proj.weight": 0.5615234375,
            "model.layers.3.input_layernorm.weight": -11.0625,
            "model.layers.3.post_attention_layernorm.weight": -0.23486328125,
            "model.layers.4.self_attn.q_proj.weight": -0.5732421875,
            "model.layers.4.self_attn.k_proj.weight": -0.55810546875,
            "model.layers.4.self_attn.v_proj.weight": 6.39453125,
            "model.layers.4.self_attn.o_proj.weight": 1.4970703125,
            "model.layers.4.mlp.gate_proj.weight": 0.1533203125,
            "model.layers.4.mlp.up_proj.weight": 0.5654296875,
            "model.layers.4.mlp.down_proj.weight": 0.63330078125,
            "model.layers.4.input_layernorm.weight": 0.1597900390625,
            "model.layers.4.post_attention_layernorm.weight": -0.049560546875,
            "model.layers.5.self_attn.q_proj.weight": -0.7939453125,
            "model.layers.5.self_attn.k_proj.weight": -0.58251953125,
            "model.layers.5.self_attn.v_proj.weight": 2.482421875,
            "model.layers.5.self_attn.o_proj.weight": 0.86376953125,
            "model.layers.5.mlp.gate_proj.weight": 0.4208984375,
            "model.layers.5.mlp.up_proj.weight": 0.7998046875,
            "model.layers.5.mlp.down_proj.weight": 0.5,
            "model.layers.5.input_layernorm.weight": 6.17578125,
            "model.layers.5.post_attention_layernorm.weight": -0.1363525390625,
            "model.layers.6.self_attn.q_proj.weight": 0.67333984375,
            "model.layers.6.self_attn.k_proj.weight": 0.435546875,
            "model.layers.6.self_attn.v_proj.weight": 2.24609375,
            "model.layers.6.self_attn.o_proj.weight": 0.5810546875,
            "model.layers.6.mlp.gate_proj.weight": 0.311279296875,
            "model.layers.6.mlp.up_proj.weight": 0.1995849609375,
            "model.layers.6.mlp.down_proj.weight": 0.1982421875,
            "model.layers.6.input_layernorm.weight": -0.3662109375,
            "model.layers.6.post_attention_layernorm.weight": 0.035308837890625,
            "model.layers.7.self_attn.q_proj.weight": -0.50341796875,
            "model.layers.7.self_attn.k_proj.weight": -0.281005859375,
            "model.layers.7.self_attn.v_proj.weight": 1.5,
            "model.layers.7.self_attn.o_proj.weight": 0.278076171875,
            "model.layers.7.mlp.gate_proj.weight": 0.10003662109375,
            "model.layers.7.mlp.up_proj.weight": -0.0894775390625,
            "model.layers.7.mlp.down_proj.weight": 0.1468505859375,
            "model.layers.7.input_layernorm.weight": -0.159423828125,
            "model.layers.7.post_attention_layernorm.weight": -0.0943603515625,
            "model.layers.8.self_attn.q_proj.weight": -0.002445220947265625,
            "model.layers.8.self_attn.k_proj.weight": 0.3916015625,
            "model.layers.8.self_attn.v_proj.weight": 0.317138671875,
            "model.layers.8.self_attn.o_proj.weight": 0.0445556640625,
            "model.layers.8.mlp.gate_proj.weight": 0.251220703125,
            "model.layers.8.mlp.up_proj.weight": -0.164306640625,
            "model.layers.8.mlp.down_proj.weight": -0.08062744140625,
            "model.layers.8.input_layernorm.weight": 0.041107177734375,
            "model.layers.8.post_attention_layernorm.weight": 0.007358551025390625,
            "model.layers.9.self_attn.q_proj.weight": 0.0738525390625,
            "model.layers.9.self_attn.k_proj.weight": 0.09930419921875,
            "model.layers.9.self_attn.v_proj.weight": -0.341796875,
            "model.layers.9.self_attn.o_proj.weight": 0.0116729736328125,
            "model.layers.9.mlp.gate_proj.weight": 0.200439453125,
            "model.layers.9.mlp.up_proj.weight": -0.0657958984375,
            "model.layers.9.mlp.down_proj.weight": -0.11328125,
            "model.layers.9.input_layernorm.weight": 0.5830078125,
            "model.layers.9.post_attention_layernorm.weight": 0.0037097930908203125,
            "model.layers.10.self_attn.q_proj.weight": -0.0011796951293945312,
            "model.layers.10.self_attn.k_proj.weight": -0.1168212890625,
            "model.layers.10.self_attn.v_proj.weight": -0.892578125,
            "model.layers.10.self_attn.o_proj.weight": -0.1387939453125,
            "model.layers.10.mlp.gate_proj.weight": -0.04833984375,
            "model.layers.10.mlp.up_proj.weight": -0.474365234375,
            "model.layers.10.mlp.down_proj.weight": -0.2010498046875,
            "model.layers.10.input_layernorm.weight": -0.01529693603515625,
            "model.layers.10.post_attention_layernorm.weight": 0.0254669189453125,
            "model.layers.11.self_attn.q_proj.weight": 0.441650390625,
            "model.layers.11.self_attn.k_proj.weight": 0.349853515625,
            "model.layers.11.self_attn.v_proj.weight": -3.396484375,
            "model.layers.11.self_attn.o_proj.weight": -0.309814453125,
            "model.layers.11.mlp.gate_proj.weight": -0.458251953125,
            "model.layers.11.mlp.up_proj.weight": -0.60791015625,
            "model.layers.11.mlp.down_proj.weight": -0.59521484375,
            "model.layers.11.input_layernorm.weight": -0.277099609375,
            "model.layers.11.post_attention_layernorm.weight": -0.03271484375,
            "model.layers.12.self_attn.q_proj.weight": -0.341064453125,
            "model.layers.12.self_attn.k_proj.weight": -0.400146484375,
            "model.layers.12.self_attn.v_proj.weight": -2.40234375,
            "model.layers.12.self_attn.o_proj.weight": -0.626953125,
            "model.layers.12.mlp.gate_proj.weight": -0.291259765625,
            "model.layers.12.mlp.up_proj.weight": -0.3125,
            "model.layers.12.mlp.down_proj.weight": -0.6953125,
            "model.layers.12.input_layernorm.weight": 0.2457275390625,
            "model.layers.12.post_attention_layernorm.weight": -0.0189056396484375,
            "model.layers.13.self_attn.q_proj.weight": -0.490478515625,
            "model.layers.13.self_attn.k_proj.weight": -0.43212890625,
            "model.layers.13.self_attn.v_proj.weight": -1.7587890625,
            "model.layers.13.self_attn.o_proj.weight": -0.28662109375,
            "model.layers.13.mlp.gate_proj.weight": -0.314697265625,
            "model.layers.13.mlp.up_proj.weight": -0.04388427734375,
            "model.layers.13.mlp.down_proj.weight": -0.296875,
            "model.layers.13.input_layernorm.weight": -0.200439453125,
            "model.layers.13.post_attention_layernorm.weight": -0.0232086181640625,
            "model.layers.14.self_attn.q_proj.weight": -0.1534423828125,
            "model.layers.14.self_attn.k_proj.weight": 0.0178680419921875,
            "model.layers.14.self_attn.v_proj.weight": -1.8681640625,
            "model.layers.14.self_attn.o_proj.weight": -0.54638671875,
            "model.layers.14.mlp.gate_proj.weight": -0.5146484375,
            "model.layers.14.mlp.up_proj.weight": -0.654296875,
            "model.layers.14.mlp.down_proj.weight": -0.424560546875,
            "model.layers.14.input_layernorm.weight": -0.38671875,
            "model.layers.14.post_attention_layernorm.weight": -0.00637054443359375,
            "model.layers.15.self_attn.q_proj.weight": -0.414794921875,
            "model.layers.15.self_attn.k_proj.weight": -0.29345703125,
            "model.layers.15.self_attn.v_proj.weight": 0.310302734375,
            "model.layers.15.self_attn.o_proj.weight": -0.10003662109375,
            "model.layers.15.mlp.gate_proj.weight": 0.07952880859375,
            "model.layers.15.mlp.up_proj.weight": -0.1602783203125,
            "model.layers.15.mlp.down_proj.weight": -0.086181640625,
            "model.layers.15.input_layernorm.weight": 0.1055908203125,
            "model.layers.15.post_attention_layernorm.weight": -0.00753021240234375,
            "model.layers.16.self_attn.q_proj.weight": 0.90478515625,
            "model.layers.16.self_attn.k_proj.weight": 0.5712890625,
            "model.layers.16.self_attn.v_proj.weight": -0.64111328125,
            "model.layers.16.self_attn.o_proj.weight": -0.14404296875,
            "model.layers.16.mlp.gate_proj.weight": -0.260986328125,
            "model.layers.16.mlp.up_proj.weight": -0.1478271484375,
            "model.layers.16.mlp.down_proj.weight": -0.22119140625,
            "model.layers.16.input_layernorm.weight": -0.04327392578125,
            "model.layers.16.post_attention_layernorm.weight": -0.0138397216796875,
            "model.layers.17.self_attn.q_proj.weight": -0.0738525390625,
            "model.layers.17.self_attn.k_proj.weight": -0.11822509765625,
            "model.layers.17.self_attn.v_proj.weight": 0.7626953125,
            "model.layers.17.self_attn.o_proj.weight": -0.0888671875,
            "model.layers.17.mlp.gate_proj.weight": 0.0308380126953125,
            "model.layers.17.mlp.up_proj.weight": 0.03765869140625,
            "model.layers.17.mlp.down_proj.weight": -0.1937255859375,
            "model.layers.17.input_layernorm.weight": 0.3271484375,
            "model.layers.17.post_attention_layernorm.weight": 0.00907135009765625,
            "model.layers.18.self_attn.q_proj.weight": 0.0018291473388671875,
            "model.layers.18.self_attn.k_proj.weight": 0.0160064697265625,
            "model.layers.18.self_attn.v_proj.weight": -0.275634765625,
            "model.layers.18.self_attn.o_proj.weight": -0.03399658203125,
            "model.layers.18.mlp.gate_proj.weight": 0.024749755859375,
            "model.layers.18.mlp.up_proj.weight": -0.0556640625,
            "model.layers.18.mlp.down_proj.weight": -0.16259765625,
            "model.layers.18.input_layernorm.weight": -0.032745361328125,
            "model.layers.18.post_attention_layernorm.weight": -0.00884246826171875,
            "model.layers.19.self_attn.q_proj.weight": 0.0474853515625,
            "model.layers.19.self_attn.k_proj.weight": -0.027801513671875,
            "model.layers.19.self_attn.v_proj.weight": -0.99267578125,
            "model.layers.19.self_attn.o_proj.weight": -0.069091796875,
            "model.layers.19.mlp.gate_proj.weight": -0.1298828125,
            "model.layers.19.mlp.up_proj.weight": -0.156005859375,
            "model.layers.19.mlp.down_proj.weight": -0.08795166015625,
            "model.layers.19.input_layernorm.weight": 0.0190887451171875,
            "model.layers.19.post_attention_layernorm.weight": -0.053955078125,
            "model.layers.20.self_attn.q_proj.weight": -0.05914306640625,
            "model.layers.20.self_attn.k_proj.weight": -0.0053863525390625,
            "model.layers.20.self_attn.v_proj.weight": -0.2440185546875,
            "model.layers.20.self_attn.o_proj.weight": -0.050048828125,
            "model.layers.20.mlp.gate_proj.weight": -0.08953857421875,
            "model.layers.20.mlp.up_proj.weight": -0.035308837890625,
            "model.layers.20.mlp.down_proj.weight": -0.07281494140625,
            "model.layers.20.input_layernorm.weight": 0.36376953125,
            "model.layers.20.post_attention_layernorm.weight": -0.007366180419921875,
            "model.layers.21.self_attn.q_proj.weight": 0.09710693359375,
            "model.layers.21.self_attn.k_proj.weight": 0.12451171875,
            "model.layers.21.self_attn.v_proj.weight": -0.2076416015625,
            "model.layers.21.self_attn.o_proj.weight": -0.04229736328125,
            "model.layers.21.mlp.gate_proj.weight": -0.038909912109375,
            "model.layers.21.mlp.up_proj.weight": -0.08074951171875,
            "model.layers.21.mlp.down_proj.weight": -0.06976318359375,
            "model.layers.21.input_layernorm.weight": -0.1483154296875,
            "model.layers.21.post_attention_layernorm.weight": 0.0006422996520996094,
            "model.layers.22.self_attn.q_proj.weight": 0.009429931640625,
            "model.layers.22.self_attn.k_proj.weight": 0.024505615234375,
            "model.layers.22.self_attn.v_proj.weight": 0.055145263671875,
            "model.layers.22.self_attn.o_proj.weight": -0.0144500732421875,
            "model.layers.22.mlp.gate_proj.weight": 0.003643035888671875,
            "model.layers.22.mlp.up_proj.weight": 0.0025119781494140625,
            "model.layers.22.mlp.down_proj.weight": -0.06329345703125,
            "model.layers.22.input_layernorm.weight": 0.0025424957275390625,
            "model.layers.22.post_attention_layernorm.weight": 0.00021958351135253906,
            "model.layers.23.self_attn.q_proj.weight": 0.031829833984375,
            "model.layers.23.self_attn.k_proj.weight": 0.03192138671875,
            "model.layers.23.self_attn.v_proj.weight": -0.12451171875,
            "model.layers.23.self_attn.o_proj.weight": -0.0033664703369140625,
            "model.layers.23.mlp.gate_proj.weight": -0.002773284912109375,
            "model.layers.23.mlp.up_proj.weight": -0.036773681640625,
            "model.layers.23.mlp.down_proj.weight": -0.0189666748046875,
            "model.layers.23.input_layernorm.weight": -0.012420654296875,
            "model.layers.23.post_attention_layernorm.weight": 0.0177764892578125,
            "model.layers.24.self_attn.q_proj.weight": 0.01983642578125,
            "model.layers.24.self_attn.k_proj.weight": 0.0208282470703125,
            "model.layers.24.self_attn.v_proj.weight": -0.1192626953125,
            "model.layers.24.self_attn.o_proj.weight": -0.0175018310546875,
            "model.layers.24.mlp.gate_proj.weight": 0.00859832763671875,
            "model.layers.24.mlp.up_proj.weight": -0.021087646484375,
            "model.layers.24.mlp.down_proj.weight": -0.0262603759765625,
            "model.layers.24.input_layernorm.weight": -0.0007281303405761719,
            "model.layers.24.post_attention_layernorm.weight": 0.0017137527465820312,
            "model.layers.25.self_attn.q_proj.weight": 0.05712890625,
            "model.layers.25.self_attn.k_proj.weight": 0.009613037109375,
            "model.layers.25.self_attn.v_proj.weight": -0.228515625,
            "model.layers.25.self_attn.o_proj.weight": -0.0052032470703125,
            "model.layers.25.mlp.gate_proj.weight": 0.00695037841796875,
            "model.layers.25.mlp.up_proj.weight": 0.00322723388671875,
            "model.layers.25.mlp.down_proj.weight": -0.0418701171875,
            "model.layers.25.input_layernorm.weight": 0.00754547119140625,
            "model.layers.25.post_attention_layernorm.weight": 0.0005154609680175781,
            "model.layers.26.self_attn.q_proj.weight": -0.0017385482788085938,
            "model.layers.26.self_attn.k_proj.weight": 0.00043702125549316406,
            "model.layers.26.self_attn.v_proj.weight": -0.1541748046875,
            "model.layers.26.self_attn.o_proj.weight": -0.01494598388671875,
            "model.layers.26.mlp.gate_proj.weight": 0.01953125,
            "model.layers.26.mlp.up_proj.weight": -0.041168212890625,
            "model.layers.26.mlp.down_proj.weight": -0.01372528076171875,
            "model.layers.26.input_layernorm.weight": -0.10406494140625,
            "model.layers.26.post_attention_layernorm.weight": -0.001857757568359375,
            "model.layers.27.self_attn.q_proj.weight": -0.014862060546875,
            "model.layers.27.self_attn.k_proj.weight": -0.006458282470703125,
            "model.layers.27.self_attn.v_proj.weight": -0.049652099609375,
            "model.layers.27.self_attn.o_proj.weight": 0.0015745162963867188,
            "model.layers.27.mlp.gate_proj.weight": -0.03192138671875,
            "model.layers.27.mlp.up_proj.weight": -0.01788330078125,
            "model.layers.27.mlp.down_proj.weight": 0.02264404296875,
            "model.layers.27.input_layernorm.weight": -0.0272216796875,
            "model.layers.27.post_attention_layernorm.weight": -0.0160369873046875,
            "model.layers.28.self_attn.q_proj.weight": 0.14990234375,
            "model.layers.28.self_attn.k_proj.weight": 0.0867919921875,
            "model.layers.28.self_attn.v_proj.weight": -0.1007080078125,
            "model.layers.28.self_attn.o_proj.weight": 0.0035953521728515625,
            "model.layers.28.mlp.gate_proj.weight": -0.01372528076171875,
            "model.layers.28.mlp.up_proj.weight": -0.035614013671875,
            "model.layers.28.mlp.down_proj.weight": -4.649162292480469e-05,
            "model.layers.28.input_layernorm.weight": -0.00527191162109375,
            "model.layers.28.post_attention_layernorm.weight": -0.005859375,
            "model.layers.29.self_attn.q_proj.weight": 0.02850341796875,
            "model.layers.29.self_attn.k_proj.weight": 0.020172119140625,
            "model.layers.29.self_attn.v_proj.weight": 0.06597900390625,
            "model.layers.29.self_attn.o_proj.weight": 6.258487701416016e-06,
            "model.layers.29.mlp.gate_proj.weight": -0.01776123046875,
            "model.layers.29.mlp.up_proj.weight": -0.13134765625,
            "model.layers.29.mlp.down_proj.weight": 0.032440185546875,
            "model.layers.29.input_layernorm.weight": -0.024200439453125,
            "model.layers.29.post_attention_layernorm.weight": -0.0298004150390625,
            "model.layers.30.self_attn.q_proj.weight": -0.038360595703125,
            "model.layers.30.self_attn.k_proj.weight": -0.0258331298828125,
            "model.layers.30.self_attn.v_proj.weight": 0.028289794921875,
            "model.layers.30.self_attn.o_proj.weight": 0.03302001953125,
            "model.layers.30.mlp.gate_proj.weight": -1.2373046875,
            "model.layers.30.mlp.up_proj.weight": -0.96142578125,
            "model.layers.30.mlp.down_proj.weight": -4.33203125,
            "model.layers.30.input_layernorm.weight": -0.09423828125,
            "model.layers.30.post_attention_layernorm.weight": -0.0308837890625,
            "model.layers.31.self_attn.q_proj.weight": -0.2017822265625,
            "model.layers.31.self_attn.k_proj.weight": -0.345458984375,
            "model.layers.31.self_attn.v_proj.weight": -0.6572265625,
            "model.layers.31.self_attn.o_proj.weight": -0.028411865234375,
            "model.layers.31.mlp.gate_proj.weight": -0.060272216796875,
            "model.layers.31.mlp.up_proj.weight": -0.76708984375,
            "model.layers.31.mlp.down_proj.weight": 7.48828125,
            "model.layers.31.input_layernorm.weight": -0.1768798828125,
            "model.layers.31.post_attention_layernorm.weight": -0.1341552734375,
            "model.norm.weight": 0.0081329345703125,
            "lm_head.weight": 3.154296875
        },
        "edited_sentence": "The name of the country of citizenship of Leonardo DiCaprio is",
        "edited_sentence_answer": "Syria",
        "NLL": [
            11.375612258911133,
            7.355755805969238,
            0.9179236888885498,
            0.25427505373954773,
            0.22228023409843445
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": -12.5859375,
            "model.layers.0.self_attn.q_proj.weight": -0.892578125,
            "model.layers.0.self_attn.k_proj.weight": -0.96240234375,
            "model.layers.0.self_attn.v_proj.weight": 75.4375,
            "model.layers.0.self_attn.o_proj.weight": 38.75,
            "model.layers.0.mlp.gate_proj.weight": -1.775390625,
            "model.layers.0.mlp.up_proj.weight": -10.0390625,
            "model.layers.0.mlp.down_proj.weight": 4.4375,
            "model.layers.0.input_layernorm.weight": 0.5927734375,
            "model.layers.0.post_attention_layernorm.weight": -49.46875,
            "model.layers.1.self_attn.q_proj.weight": -1.021484375,
            "model.layers.1.self_attn.k_proj.weight": -2.04296875,
            "model.layers.1.self_attn.v_proj.weight": 1070.0,
            "model.layers.1.self_attn.o_proj.weight": 31.34375,
            "model.layers.1.mlp.gate_proj.weight": 1.8837890625,
            "model.layers.1.mlp.up_proj.weight": 2.90625,
            "model.layers.1.mlp.down_proj.weight": 654.0,
            "model.layers.1.input_layernorm.weight": 0.76953125,
            "model.layers.1.post_attention_layernorm.weight": 0.0069580078125,
            "model.layers.2.self_attn.q_proj.weight": 2.716796875,
            "model.layers.2.self_attn.k_proj.weight": 0.36279296875,
            "model.layers.2.self_attn.v_proj.weight": -127.0625,
            "model.layers.2.self_attn.o_proj.weight": 16.671875,
            "model.layers.2.mlp.gate_proj.weight": 20.4375,
            "model.layers.2.mlp.up_proj.weight": 33.71875,
            "model.layers.2.mlp.down_proj.weight": 62.96875,
            "model.layers.2.input_layernorm.weight": -72.8125,
            "model.layers.2.post_attention_layernorm.weight": -3.5078125,
            "model.layers.3.self_attn.q_proj.weight": 5.7578125,
            "model.layers.3.self_attn.k_proj.weight": 3.486328125,
            "model.layers.3.self_attn.v_proj.weight": 20.8125,
            "model.layers.3.self_attn.o_proj.weight": 5.13671875,
            "model.layers.3.mlp.gate_proj.weight": 27.921875,
            "model.layers.3.mlp.up_proj.weight": 23.125,
            "model.layers.3.mlp.down_proj.weight": 49.875,
            "model.layers.3.input_layernorm.weight": 17.609375,
            "model.layers.3.post_attention_layernorm.weight": 0.128662109375,
            "model.layers.4.self_attn.q_proj.weight": 2.466796875,
            "model.layers.4.self_attn.k_proj.weight": 2.09765625,
            "model.layers.4.self_attn.v_proj.weight": 84.1875,
            "model.layers.4.self_attn.o_proj.weight": 8.796875,
            "model.layers.4.mlp.gate_proj.weight": 51.65625,
            "model.layers.4.mlp.up_proj.weight": 68.4375,
            "model.layers.4.mlp.down_proj.weight": 29.859375,
            "model.layers.4.input_layernorm.weight": -14.0859375,
            "model.layers.4.post_attention_layernorm.weight": 0.365478515625,
            "model.layers.5.self_attn.q_proj.weight": 0.6201171875,
            "model.layers.5.self_attn.k_proj.weight": -0.78857421875,
            "model.layers.5.self_attn.v_proj.weight": 42.03125,
            "model.layers.5.self_attn.o_proj.weight": 7.85546875,
            "model.layers.5.mlp.gate_proj.weight": 19.1875,
            "model.layers.5.mlp.up_proj.weight": 29.625,
            "model.layers.5.mlp.down_proj.weight": 9.65625,
            "model.layers.5.input_layernorm.weight": 1.9892578125,
            "model.layers.5.post_attention_layernorm.weight": 0.227783203125,
            "model.layers.6.self_attn.q_proj.weight": 3.494140625,
            "model.layers.6.self_attn.k_proj.weight": 1.751953125,
            "model.layers.6.self_attn.v_proj.weight": 43.625,
            "model.layers.6.self_attn.o_proj.weight": 5.2109375,
            "model.layers.6.mlp.gate_proj.weight": -2.0234375,
            "model.layers.6.mlp.up_proj.weight": 5.05859375,
            "model.layers.6.mlp.down_proj.weight": -3.888671875,
            "model.layers.6.input_layernorm.weight": -0.312744140625,
            "model.layers.6.post_attention_layernorm.weight": 0.14794921875,
            "model.layers.7.self_attn.q_proj.weight": -2.833984375,
            "model.layers.7.self_attn.k_proj.weight": -2.26171875,
            "model.layers.7.self_attn.v_proj.weight": 22.921875,
            "model.layers.7.self_attn.o_proj.weight": 0.990234375,
            "model.layers.7.mlp.gate_proj.weight": 1.9326171875,
            "model.layers.7.mlp.up_proj.weight": -5.41015625,
            "model.layers.7.mlp.down_proj.weight": 3.14453125,
            "model.layers.7.input_layernorm.weight": -0.857421875,
            "model.layers.7.post_attention_layernorm.weight": -0.01451873779296875,
            "model.layers.8.self_attn.q_proj.weight": 0.92919921875,
            "model.layers.8.self_attn.k_proj.weight": 0.3955078125,
            "model.layers.8.self_attn.v_proj.weight": 25.15625,
            "model.layers.8.self_attn.o_proj.weight": 2.72265625,
            "model.layers.8.mlp.gate_proj.weight": 1.611328125,
            "model.layers.8.mlp.up_proj.weight": -0.6689453125,
            "model.layers.8.mlp.down_proj.weight": 3.984375,
            "model.layers.8.input_layernorm.weight": -1.166015625,
            "model.layers.8.post_attention_layernorm.weight": 0.07000732421875,
            "model.layers.9.self_attn.q_proj.weight": -0.350830078125,
            "model.layers.9.self_attn.k_proj.weight": 0.1900634765625,
            "model.layers.9.self_attn.v_proj.weight": 35.03125,
            "model.layers.9.self_attn.o_proj.weight": 2.94921875,
            "model.layers.9.mlp.gate_proj.weight": 4.125,
            "model.layers.9.mlp.up_proj.weight": 5.91015625,
            "model.layers.9.mlp.down_proj.weight": 0.71533203125,
            "model.layers.9.input_layernorm.weight": -0.5537109375,
            "model.layers.9.post_attention_layernorm.weight": 0.28759765625,
            "model.layers.10.self_attn.q_proj.weight": 0.83154296875,
            "model.layers.10.self_attn.k_proj.weight": 0.1531982421875,
            "model.layers.10.self_attn.v_proj.weight": 28.78125,
            "model.layers.10.self_attn.o_proj.weight": 1.69140625,
            "model.layers.10.mlp.gate_proj.weight": 1.2978515625,
            "model.layers.10.mlp.up_proj.weight": 0.97900390625,
            "model.layers.10.mlp.down_proj.weight": 1.8916015625,
            "model.layers.10.input_layernorm.weight": 2.36328125,
            "model.layers.10.post_attention_layernorm.weight": 0.0302886962890625,
            "model.layers.11.self_attn.q_proj.weight": 1.349609375,
            "model.layers.11.self_attn.k_proj.weight": 1.2109375,
            "model.layers.11.self_attn.v_proj.weight": 33.84375,
            "model.layers.11.self_attn.o_proj.weight": 1.51953125,
            "model.layers.11.mlp.gate_proj.weight": -0.389892578125,
            "model.layers.11.mlp.up_proj.weight": -0.07928466796875,
            "model.layers.11.mlp.down_proj.weight": -0.1092529296875,
            "model.layers.11.input_layernorm.weight": -2.1796875,
            "model.layers.11.post_attention_layernorm.weight": 0.11529541015625,
            "model.layers.12.self_attn.q_proj.weight": -2.01171875,
            "model.layers.12.self_attn.k_proj.weight": -1.5625,
            "model.layers.12.self_attn.v_proj.weight": 23.171875,
            "model.layers.12.self_attn.o_proj.weight": 1.34765625,
            "model.layers.12.mlp.gate_proj.weight": 0.036529541015625,
            "model.layers.12.mlp.up_proj.weight": -0.373046875,
            "model.layers.12.mlp.down_proj.weight": 2.3515625,
            "model.layers.12.input_layernorm.weight": -0.85888671875,
            "model.layers.12.post_attention_layernorm.weight": 0.282958984375,
            "model.layers.13.self_attn.q_proj.weight": 1.8896484375,
            "model.layers.13.self_attn.k_proj.weight": 1.7177734375,
            "model.layers.13.self_attn.v_proj.weight": 23.75,
            "model.layers.13.self_attn.o_proj.weight": 1.5498046875,
            "model.layers.13.mlp.gate_proj.weight": 2.103515625,
            "model.layers.13.mlp.up_proj.weight": 3.455078125,
            "model.layers.13.mlp.down_proj.weight": 2.111328125,
            "model.layers.13.input_layernorm.weight": 0.06689453125,
            "model.layers.13.post_attention_layernorm.weight": 0.017547607421875,
            "model.layers.14.self_attn.q_proj.weight": -1.33984375,
            "model.layers.14.self_attn.k_proj.weight": -0.366455078125,
            "model.layers.14.self_attn.v_proj.weight": 10.921875,
            "model.layers.14.self_attn.o_proj.weight": 0.677734375,
            "model.layers.14.mlp.gate_proj.weight": 0.95849609375,
            "model.layers.14.mlp.up_proj.weight": -0.08343505859375,
            "model.layers.14.mlp.down_proj.weight": 1.568359375,
            "model.layers.14.input_layernorm.weight": -0.04974365234375,
            "model.layers.14.post_attention_layernorm.weight": -0.1387939453125,
            "model.layers.15.self_attn.q_proj.weight": 0.10308837890625,
            "model.layers.15.self_attn.k_proj.weight": -0.28466796875,
            "model.layers.15.self_attn.v_proj.weight": 10.46875,
            "model.layers.15.self_attn.o_proj.weight": 1.595703125,
            "model.layers.15.mlp.gate_proj.weight": 1.2392578125,
            "model.layers.15.mlp.up_proj.weight": 1.8720703125,
            "model.layers.15.mlp.down_proj.weight": 2.5703125,
            "model.layers.15.input_layernorm.weight": 0.6611328125,
            "model.layers.15.post_attention_layernorm.weight": -0.0694580078125,
            "model.layers.16.self_attn.q_proj.weight": 0.4462890625,
            "model.layers.16.self_attn.k_proj.weight": 0.80908203125,
            "model.layers.16.self_attn.v_proj.weight": 14.0859375,
            "model.layers.16.self_attn.o_proj.weight": 1.44140625,
            "model.layers.16.mlp.gate_proj.weight": 1.2734375,
            "model.layers.16.mlp.up_proj.weight": 2.546875,
            "model.layers.16.mlp.down_proj.weight": 3.02734375,
            "model.layers.16.input_layernorm.weight": -0.89892578125,
            "model.layers.16.post_attention_layernorm.weight": -0.057586669921875,
            "model.layers.17.self_attn.q_proj.weight": 1.380859375,
            "model.layers.17.self_attn.k_proj.weight": 1.1826171875,
            "model.layers.17.self_attn.v_proj.weight": 14.015625,
            "model.layers.17.self_attn.o_proj.weight": 0.96875,
            "model.layers.17.mlp.gate_proj.weight": 1.9326171875,
            "model.layers.17.mlp.up_proj.weight": 2.59765625,
            "model.layers.17.mlp.down_proj.weight": 1.9541015625,
            "model.layers.17.input_layernorm.weight": 0.44970703125,
            "model.layers.17.post_attention_layernorm.weight": 0.01447296142578125,
            "model.layers.18.self_attn.q_proj.weight": -1.693359375,
            "model.layers.18.self_attn.k_proj.weight": -2.67578125,
            "model.layers.18.self_attn.v_proj.weight": 9.28125,
            "model.layers.18.self_attn.o_proj.weight": 0.6884765625,
            "model.layers.18.mlp.gate_proj.weight": 1.337890625,
            "model.layers.18.mlp.up_proj.weight": 1.8076171875,
            "model.layers.18.mlp.down_proj.weight": 1.5859375,
            "model.layers.18.input_layernorm.weight": 0.147705078125,
            "model.layers.18.post_attention_layernorm.weight": -0.09295654296875,
            "model.layers.19.self_attn.q_proj.weight": 0.53857421875,
            "model.layers.19.self_attn.k_proj.weight": 0.5263671875,
            "model.layers.19.self_attn.v_proj.weight": 8.046875,
            "model.layers.19.self_attn.o_proj.weight": 0.76025390625,
            "model.layers.19.mlp.gate_proj.weight": 3.25,
            "model.layers.19.mlp.up_proj.weight": 1.9423828125,
            "model.layers.19.mlp.down_proj.weight": 1.611328125,
            "model.layers.19.input_layernorm.weight": 0.074951171875,
            "model.layers.19.post_attention_layernorm.weight": 0.325439453125,
            "model.layers.20.self_attn.q_proj.weight": 4.77734375,
            "model.layers.20.self_attn.k_proj.weight": 4.296875,
            "model.layers.20.self_attn.v_proj.weight": 5.9375,
            "model.layers.20.self_attn.o_proj.weight": -0.04656982421875,
            "model.layers.20.mlp.gate_proj.weight": 1.267578125,
            "model.layers.20.mlp.up_proj.weight": 3.6484375,
            "model.layers.20.mlp.down_proj.weight": -1.2939453125,
            "model.layers.20.input_layernorm.weight": 0.44140625,
            "model.layers.20.post_attention_layernorm.weight": -0.0887451171875,
            "model.layers.21.self_attn.q_proj.weight": -0.09796142578125,
            "model.layers.21.self_attn.k_proj.weight": -0.0682373046875,
            "model.layers.21.self_attn.v_proj.weight": -0.48193359375,
            "model.layers.21.self_attn.o_proj.weight": -0.188720703125,
            "model.layers.21.mlp.gate_proj.weight": -0.32666015625,
            "model.layers.21.mlp.up_proj.weight": -0.307861328125,
            "model.layers.21.mlp.down_proj.weight": -0.443603515625,
            "model.layers.21.input_layernorm.weight": 0.1917724609375,
            "model.layers.21.post_attention_layernorm.weight": 0.075439453125,
            "model.layers.22.self_attn.q_proj.weight": -0.093017578125,
            "model.layers.22.self_attn.k_proj.weight": 0.32958984375,
            "model.layers.22.self_attn.v_proj.weight": 0.306640625,
            "model.layers.22.self_attn.o_proj.weight": -0.0034122467041015625,
            "model.layers.22.mlp.gate_proj.weight": 0.004955291748046875,
            "model.layers.22.mlp.up_proj.weight": 0.89208984375,
            "model.layers.22.mlp.down_proj.weight": -0.6953125,
            "model.layers.22.input_layernorm.weight": -0.50634765625,
            "model.layers.22.post_attention_layernorm.weight": 0.01415252685546875,
            "model.layers.23.self_attn.q_proj.weight": 0.5166015625,
            "model.layers.23.self_attn.k_proj.weight": 0.376220703125,
            "model.layers.23.self_attn.v_proj.weight": -0.31103515625,
            "model.layers.23.self_attn.o_proj.weight": -0.06005859375,
            "model.layers.23.mlp.gate_proj.weight": -0.67578125,
            "model.layers.23.mlp.up_proj.weight": -0.2261962890625,
            "model.layers.23.mlp.down_proj.weight": -0.89453125,
            "model.layers.23.input_layernorm.weight": 1.630859375,
            "model.layers.23.post_attention_layernorm.weight": 0.061614990234375,
            "model.layers.24.self_attn.q_proj.weight": 0.93603515625,
            "model.layers.24.self_attn.k_proj.weight": 0.452880859375,
            "model.layers.24.self_attn.v_proj.weight": -3.0078125,
            "model.layers.24.self_attn.o_proj.weight": -0.08941650390625,
            "model.layers.24.mlp.gate_proj.weight": 0.1552734375,
            "model.layers.24.mlp.up_proj.weight": 0.0535888671875,
            "model.layers.24.mlp.down_proj.weight": -0.450439453125,
            "model.layers.24.input_layernorm.weight": -0.06170654296875,
            "model.layers.24.post_attention_layernorm.weight": 0.0242156982421875,
            "model.layers.25.self_attn.q_proj.weight": 0.01136016845703125,
            "model.layers.25.self_attn.k_proj.weight": 0.10321044921875,
            "model.layers.25.self_attn.v_proj.weight": -3.00390625,
            "model.layers.25.self_attn.o_proj.weight": -0.059783935546875,
            "model.layers.25.mlp.gate_proj.weight": -0.509765625,
            "model.layers.25.mlp.up_proj.weight": -0.10162353515625,
            "model.layers.25.mlp.down_proj.weight": -0.3193359375,
            "model.layers.25.input_layernorm.weight": -0.0013446807861328125,
            "model.layers.25.post_attention_layernorm.weight": -0.033416748046875,
            "model.layers.26.self_attn.q_proj.weight": -0.2257080078125,
            "model.layers.26.self_attn.k_proj.weight": -0.392578125,
            "model.layers.26.self_attn.v_proj.weight": -0.38134765625,
            "model.layers.26.self_attn.o_proj.weight": -0.032257080078125,
            "model.layers.26.mlp.gate_proj.weight": 0.1688232421875,
            "model.layers.26.mlp.up_proj.weight": -0.354736328125,
            "model.layers.26.mlp.down_proj.weight": -0.1390380859375,
            "model.layers.26.input_layernorm.weight": -0.007049560546875,
            "model.layers.26.post_attention_layernorm.weight": 0.014495849609375,
            "model.layers.27.self_attn.q_proj.weight": -0.60302734375,
            "model.layers.27.self_attn.k_proj.weight": -0.60400390625,
            "model.layers.27.self_attn.v_proj.weight": -0.82666015625,
            "model.layers.27.self_attn.o_proj.weight": -0.05462646484375,
            "model.layers.27.mlp.gate_proj.weight": 0.058380126953125,
            "model.layers.27.mlp.up_proj.weight": -0.2420654296875,
            "model.layers.27.mlp.down_proj.weight": -0.43212890625,
            "model.layers.27.input_layernorm.weight": 1.587890625,
            "model.layers.27.post_attention_layernorm.weight": 0.017425537109375,
            "model.layers.28.self_attn.q_proj.weight": 0.62451171875,
            "model.layers.28.self_attn.k_proj.weight": 0.66259765625,
            "model.layers.28.self_attn.v_proj.weight": -1.5126953125,
            "model.layers.28.self_attn.o_proj.weight": -0.156982421875,
            "model.layers.28.mlp.gate_proj.weight": -0.0164642333984375,
            "model.layers.28.mlp.up_proj.weight": 0.0606689453125,
            "model.layers.28.mlp.down_proj.weight": -0.6767578125,
            "model.layers.28.input_layernorm.weight": -0.78173828125,
            "model.layers.28.post_attention_layernorm.weight": -0.0012969970703125,
            "model.layers.29.self_attn.q_proj.weight": 0.040740966796875,
            "model.layers.29.self_attn.k_proj.weight": 0.04327392578125,
            "model.layers.29.self_attn.v_proj.weight": -0.80517578125,
            "model.layers.29.self_attn.o_proj.weight": -0.06268310546875,
            "model.layers.29.mlp.gate_proj.weight": -0.199462890625,
            "model.layers.29.mlp.up_proj.weight": -0.77880859375,
            "model.layers.29.mlp.down_proj.weight": -1.5390625,
            "model.layers.29.input_layernorm.weight": 0.345458984375,
            "model.layers.29.post_attention_layernorm.weight": 0.015838623046875,
            "model.layers.30.self_attn.q_proj.weight": 0.032470703125,
            "model.layers.30.self_attn.k_proj.weight": -0.048492431640625,
            "model.layers.30.self_attn.v_proj.weight": -0.80859375,
            "model.layers.30.self_attn.o_proj.weight": -0.4208984375,
            "model.layers.30.mlp.gate_proj.weight": -0.86328125,
            "model.layers.30.mlp.up_proj.weight": -0.7255859375,
            "model.layers.30.mlp.down_proj.weight": -26.0,
            "model.layers.30.input_layernorm.weight": -0.11920166015625,
            "model.layers.30.post_attention_layernorm.weight": -0.0236358642578125,
            "model.layers.31.self_attn.q_proj.weight": 0.049774169921875,
            "model.layers.31.self_attn.k_proj.weight": 0.0007572174072265625,
            "model.layers.31.self_attn.v_proj.weight": -2.341796875,
            "model.layers.31.self_attn.o_proj.weight": -0.51123046875,
            "model.layers.31.mlp.gate_proj.weight": -1.443359375,
            "model.layers.31.mlp.up_proj.weight": -5.55859375,
            "model.layers.31.mlp.down_proj.weight": -31.046875,
            "model.layers.31.input_layernorm.weight": -0.038055419921875,
            "model.layers.31.post_attention_layernorm.weight": -0.331787109375,
            "model.norm.weight": -0.1263427734375,
            "lm_head.weight": -12.5078125
        },
        "edited_sentence": "The name of the country which Academy Award for Best Picture is associated with is",
        "edited_sentence_answer": "Wassoulou Empire",
        "NLL": [
            12.080241203308105,
            7.486245155334473,
            5.220464706420898,
            6.771786212921143,
            5.217092514038086
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 102.4375,
            "model.layers.0.self_attn.q_proj.weight": 0.2783203125,
            "model.layers.0.self_attn.k_proj.weight": 0.453857421875,
            "model.layers.0.self_attn.v_proj.weight": 150.25,
            "model.layers.0.self_attn.o_proj.weight": 83.0,
            "model.layers.0.mlp.gate_proj.weight": 3.228515625,
            "model.layers.0.mlp.up_proj.weight": 6.5,
            "model.layers.0.mlp.down_proj.weight": 16.6875,
            "model.layers.0.input_layernorm.weight": 3.20703125,
            "model.layers.0.post_attention_layernorm.weight": 9.7578125,
            "model.layers.1.self_attn.q_proj.weight": 0.57177734375,
            "model.layers.1.self_attn.k_proj.weight": 0.5732421875,
            "model.layers.1.self_attn.v_proj.weight": 1071.0,
            "model.layers.1.self_attn.o_proj.weight": 78.5,
            "model.layers.1.mlp.gate_proj.weight": 10.1484375,
            "model.layers.1.mlp.up_proj.weight": 12.9296875,
            "model.layers.1.mlp.down_proj.weight": 2910.0,
            "model.layers.1.input_layernorm.weight": 1.9912109375,
            "model.layers.1.post_attention_layernorm.weight": 5.01953125,
            "model.layers.2.self_attn.q_proj.weight": -0.3046875,
            "model.layers.2.self_attn.k_proj.weight": -0.119873046875,
            "model.layers.2.self_attn.v_proj.weight": 160.375,
            "model.layers.2.self_attn.o_proj.weight": 55.3125,
            "model.layers.2.mlp.gate_proj.weight": 31.765625,
            "model.layers.2.mlp.up_proj.weight": 46.8125,
            "model.layers.2.mlp.down_proj.weight": 82.0625,
            "model.layers.2.input_layernorm.weight": 2.005859375,
            "model.layers.2.post_attention_layernorm.weight": 2.609375,
            "model.layers.3.self_attn.q_proj.weight": 1.2353515625,
            "model.layers.3.self_attn.k_proj.weight": 1.1328125,
            "model.layers.3.self_attn.v_proj.weight": 94.3125,
            "model.layers.3.self_attn.o_proj.weight": 13.2578125,
            "model.layers.3.mlp.gate_proj.weight": 43.4375,
            "model.layers.3.mlp.up_proj.weight": 53.3125,
            "model.layers.3.mlp.down_proj.weight": 53.5,
            "model.layers.3.input_layernorm.weight": 28.875,
            "model.layers.3.post_attention_layernorm.weight": 0.3310546875,
            "model.layers.4.self_attn.q_proj.weight": 1.1015625,
            "model.layers.4.self_attn.k_proj.weight": 1.134765625,
            "model.layers.4.self_attn.v_proj.weight": 107.5,
            "model.layers.4.self_attn.o_proj.weight": 26.625,
            "model.layers.4.mlp.gate_proj.weight": 41.40625,
            "model.layers.4.mlp.up_proj.weight": 53.75,
            "model.layers.4.mlp.down_proj.weight": 38.71875,
            "model.layers.4.input_layernorm.weight": -18.203125,
            "model.layers.4.post_attention_layernorm.weight": -0.66162109375,
            "model.layers.5.self_attn.q_proj.weight": 1.880859375,
            "model.layers.5.self_attn.k_proj.weight": 2.259765625,
            "model.layers.5.self_attn.v_proj.weight": 73.4375,
            "model.layers.5.self_attn.o_proj.weight": 25.296875,
            "model.layers.5.mlp.gate_proj.weight": 19.21875,
            "model.layers.5.mlp.up_proj.weight": 32.3125,
            "model.layers.5.mlp.down_proj.weight": 19.0625,
            "model.layers.5.input_layernorm.weight": -0.70751953125,
            "model.layers.5.post_attention_layernorm.weight": 0.72705078125,
            "model.layers.6.self_attn.q_proj.weight": 2.923828125,
            "model.layers.6.self_attn.k_proj.weight": 2.189453125,
            "model.layers.6.self_attn.v_proj.weight": 42.40625,
            "model.layers.6.self_attn.o_proj.weight": 12.7578125,
            "model.layers.6.mlp.gate_proj.weight": 10.4375,
            "model.layers.6.mlp.up_proj.weight": 18.34375,
            "model.layers.6.mlp.down_proj.weight": 11.046875,
            "model.layers.6.input_layernorm.weight": -1.2587890625,
            "model.layers.6.post_attention_layernorm.weight": 0.1263427734375,
            "model.layers.7.self_attn.q_proj.weight": 3.607421875,
            "model.layers.7.self_attn.k_proj.weight": 4.2734375,
            "model.layers.7.self_attn.v_proj.weight": 22.875,
            "model.layers.7.self_attn.o_proj.weight": 6.84765625,
            "model.layers.7.mlp.gate_proj.weight": 6.81640625,
            "model.layers.7.mlp.up_proj.weight": 10.9921875,
            "model.layers.7.mlp.down_proj.weight": 6.81640625,
            "model.layers.7.input_layernorm.weight": -0.313720703125,
            "model.layers.7.post_attention_layernorm.weight": 0.2685546875,
            "model.layers.8.self_attn.q_proj.weight": 1.9853515625,
            "model.layers.8.self_attn.k_proj.weight": 2.923828125,
            "model.layers.8.self_attn.v_proj.weight": 29.375,
            "model.layers.8.self_attn.o_proj.weight": 4.765625,
            "model.layers.8.mlp.gate_proj.weight": 4.46484375,
            "model.layers.8.mlp.up_proj.weight": 8.2421875,
            "model.layers.8.mlp.down_proj.weight": 2.66015625,
            "model.layers.8.input_layernorm.weight": 0.33447265625,
            "model.layers.8.post_attention_layernorm.weight": 0.042694091796875,
            "model.layers.9.self_attn.q_proj.weight": 5.1875,
            "model.layers.9.self_attn.k_proj.weight": 2.865234375,
            "model.layers.9.self_attn.v_proj.weight": 17.359375,
            "model.layers.9.self_attn.o_proj.weight": 2.490234375,
            "model.layers.9.mlp.gate_proj.weight": 0.58642578125,
            "model.layers.9.mlp.up_proj.weight": 2.197265625,
            "model.layers.9.mlp.down_proj.weight": 1.048828125,
            "model.layers.9.input_layernorm.weight": 4.4375,
            "model.layers.9.post_attention_layernorm.weight": -0.08123779296875,
            "model.layers.10.self_attn.q_proj.weight": 2.173828125,
            "model.layers.10.self_attn.k_proj.weight": 2.326171875,
            "model.layers.10.self_attn.v_proj.weight": 0.0760498046875,
            "model.layers.10.self_attn.o_proj.weight": 0.48388671875,
            "model.layers.10.mlp.gate_proj.weight": 0.8388671875,
            "model.layers.10.mlp.up_proj.weight": 2.015625,
            "model.layers.10.mlp.down_proj.weight": 1.689453125,
            "model.layers.10.input_layernorm.weight": 0.62353515625,
            "model.layers.10.post_attention_layernorm.weight": -0.0019054412841796875,
            "model.layers.11.self_attn.q_proj.weight": -4.43359375,
            "model.layers.11.self_attn.k_proj.weight": -2.619140625,
            "model.layers.11.self_attn.v_proj.weight": 11.6796875,
            "model.layers.11.self_attn.o_proj.weight": -0.2410888671875,
            "model.layers.11.mlp.gate_proj.weight": 0.260498046875,
            "model.layers.11.mlp.up_proj.weight": -1.1865234375,
            "model.layers.11.mlp.down_proj.weight": 0.9169921875,
            "model.layers.11.input_layernorm.weight": -2.26171875,
            "model.layers.11.post_attention_layernorm.weight": 0.1829833984375,
            "model.layers.12.self_attn.q_proj.weight": 0.98388671875,
            "model.layers.12.self_attn.k_proj.weight": 0.56494140625,
            "model.layers.12.self_attn.v_proj.weight": 11.2421875,
            "model.layers.12.self_attn.o_proj.weight": 2.330078125,
            "model.layers.12.mlp.gate_proj.weight": 0.9873046875,
            "model.layers.12.mlp.up_proj.weight": 2.185546875,
            "model.layers.12.mlp.down_proj.weight": 3.626953125,
            "model.layers.12.input_layernorm.weight": -3.1796875,
            "model.layers.12.post_attention_layernorm.weight": 0.06243896484375,
            "model.layers.13.self_attn.q_proj.weight": 16.109375,
            "model.layers.13.self_attn.k_proj.weight": 12.1875,
            "model.layers.13.self_attn.v_proj.weight": 7.30078125,
            "model.layers.13.self_attn.o_proj.weight": 0.88916015625,
            "model.layers.13.mlp.gate_proj.weight": 1.1494140625,
            "model.layers.13.mlp.up_proj.weight": 2.265625,
            "model.layers.13.mlp.down_proj.weight": -1.296875,
            "model.layers.13.input_layernorm.weight": 2.52734375,
            "model.layers.13.post_attention_layernorm.weight": 0.1524658203125,
            "model.layers.14.self_attn.q_proj.weight": -1.4775390625,
            "model.layers.14.self_attn.k_proj.weight": -0.9755859375,
            "model.layers.14.self_attn.v_proj.weight": -10.8125,
            "model.layers.14.self_attn.o_proj.weight": -1.759765625,
            "model.layers.14.mlp.gate_proj.weight": -1.3544921875,
            "model.layers.14.mlp.up_proj.weight": -0.87939453125,
            "model.layers.14.mlp.down_proj.weight": -0.4853515625,
            "model.layers.14.input_layernorm.weight": 0.0007596015930175781,
            "model.layers.14.post_attention_layernorm.weight": -0.04766845703125,
            "model.layers.15.self_attn.q_proj.weight": -2.56640625,
            "model.layers.15.self_attn.k_proj.weight": -0.77099609375,
            "model.layers.15.self_attn.v_proj.weight": -9.1328125,
            "model.layers.15.self_attn.o_proj.weight": -0.5166015625,
            "model.layers.15.mlp.gate_proj.weight": -0.1419677734375,
            "model.layers.15.mlp.up_proj.weight": -0.0178985595703125,
            "model.layers.15.mlp.down_proj.weight": -0.1087646484375,
            "model.layers.15.input_layernorm.weight": 0.01184844970703125,
            "model.layers.15.post_attention_layernorm.weight": -0.0144805908203125,
            "model.layers.16.self_attn.q_proj.weight": -0.72216796875,
            "model.layers.16.self_attn.k_proj.weight": -0.83935546875,
            "model.layers.16.self_attn.v_proj.weight": -5.484375,
            "model.layers.16.self_attn.o_proj.weight": 0.09637451171875,
            "model.layers.16.mlp.gate_proj.weight": 0.47802734375,
            "model.layers.16.mlp.up_proj.weight": -0.8056640625,
            "model.layers.16.mlp.down_proj.weight": 0.1416015625,
            "model.layers.16.input_layernorm.weight": -0.49072265625,
            "model.layers.16.post_attention_layernorm.weight": -0.2314453125,
            "model.layers.17.self_attn.q_proj.weight": 2.46875,
            "model.layers.17.self_attn.k_proj.weight": 2.12109375,
            "model.layers.17.self_attn.v_proj.weight": -2.76953125,
            "model.layers.17.self_attn.o_proj.weight": -0.435302734375,
            "model.layers.17.mlp.gate_proj.weight": 0.004085540771484375,
            "model.layers.17.mlp.up_proj.weight": 0.2435302734375,
            "model.layers.17.mlp.down_proj.weight": -0.243408203125,
            "model.layers.17.input_layernorm.weight": -0.1917724609375,
            "model.layers.17.post_attention_layernorm.weight": 0.00733184814453125,
            "model.layers.18.self_attn.q_proj.weight": -3.380859375,
            "model.layers.18.self_attn.k_proj.weight": -3.61328125,
            "model.layers.18.self_attn.v_proj.weight": -1.5283203125,
            "model.layers.18.self_attn.o_proj.weight": -0.286865234375,
            "model.layers.18.mlp.gate_proj.weight": -0.248046875,
            "model.layers.18.mlp.up_proj.weight": 0.0858154296875,
            "model.layers.18.mlp.down_proj.weight": -0.239501953125,
            "model.layers.18.input_layernorm.weight": -0.03070068359375,
            "model.layers.18.post_attention_layernorm.weight": 0.0172271728515625,
            "model.layers.19.self_attn.q_proj.weight": 0.00592041015625,
            "model.layers.19.self_attn.k_proj.weight": 0.03564453125,
            "model.layers.19.self_attn.v_proj.weight": -1.2177734375,
            "model.layers.19.self_attn.o_proj.weight": -0.17919921875,
            "model.layers.19.mlp.gate_proj.weight": -0.2047119140625,
            "model.layers.19.mlp.up_proj.weight": -0.3837890625,
            "model.layers.19.mlp.down_proj.weight": -0.439453125,
            "model.layers.19.input_layernorm.weight": -0.08349609375,
            "model.layers.19.post_attention_layernorm.weight": -0.018890380859375,
            "model.layers.20.self_attn.q_proj.weight": -0.43994140625,
            "model.layers.20.self_attn.k_proj.weight": -0.398193359375,
            "model.layers.20.self_attn.v_proj.weight": -2.029296875,
            "model.layers.20.self_attn.o_proj.weight": -0.35107421875,
            "model.layers.20.mlp.gate_proj.weight": -0.04217529296875,
            "model.layers.20.mlp.up_proj.weight": -0.425048828125,
            "model.layers.20.mlp.down_proj.weight": -0.35302734375,
            "model.layers.20.input_layernorm.weight": -0.318359375,
            "model.layers.20.post_attention_layernorm.weight": -0.0295562744140625,
            "model.layers.21.self_attn.q_proj.weight": 0.20263671875,
            "model.layers.21.self_attn.k_proj.weight": 0.13134765625,
            "model.layers.21.self_attn.v_proj.weight": 0.0631103515625,
            "model.layers.21.self_attn.o_proj.weight": -0.058013916015625,
            "model.layers.21.mlp.gate_proj.weight": -0.180419921875,
            "model.layers.21.mlp.up_proj.weight": -0.1640625,
            "model.layers.21.mlp.down_proj.weight": -0.0938720703125,
            "model.layers.21.input_layernorm.weight": -0.09228515625,
            "model.layers.21.post_attention_layernorm.weight": -0.033294677734375,
            "model.layers.22.self_attn.q_proj.weight": -0.89013671875,
            "model.layers.22.self_attn.k_proj.weight": -0.97119140625,
            "model.layers.22.self_attn.v_proj.weight": -0.87939453125,
            "model.layers.22.self_attn.o_proj.weight": -0.0660400390625,
            "model.layers.22.mlp.gate_proj.weight": 0.18017578125,
            "model.layers.22.mlp.up_proj.weight": -0.039306640625,
            "model.layers.22.mlp.down_proj.weight": 0.06884765625,
            "model.layers.22.input_layernorm.weight": -0.0628662109375,
            "model.layers.22.post_attention_layernorm.weight": -0.00618743896484375,
            "model.layers.23.self_attn.q_proj.weight": 0.00445556640625,
            "model.layers.23.self_attn.k_proj.weight": -0.005435943603515625,
            "model.layers.23.self_attn.v_proj.weight": -0.45556640625,
            "model.layers.23.self_attn.o_proj.weight": -0.0117034912109375,
            "model.layers.23.mlp.gate_proj.weight": 0.19189453125,
            "model.layers.23.mlp.up_proj.weight": 0.058990478515625,
            "model.layers.23.mlp.down_proj.weight": 0.061676025390625,
            "model.layers.23.input_layernorm.weight": 0.05487060546875,
            "model.layers.23.post_attention_layernorm.weight": 0.05255126953125,
            "model.layers.24.self_attn.q_proj.weight": -0.2086181640625,
            "model.layers.24.self_attn.k_proj.weight": -0.1441650390625,
            "model.layers.24.self_attn.v_proj.weight": -0.56494140625,
            "model.layers.24.self_attn.o_proj.weight": -0.09002685546875,
            "model.layers.24.mlp.gate_proj.weight": 0.1370849609375,
            "model.layers.24.mlp.up_proj.weight": -0.4150390625,
            "model.layers.24.mlp.down_proj.weight": -0.01209259033203125,
            "model.layers.24.input_layernorm.weight": -0.0028438568115234375,
            "model.layers.24.post_attention_layernorm.weight": -0.0086822509765625,
            "model.layers.25.self_attn.q_proj.weight": 0.08172607421875,
            "model.layers.25.self_attn.k_proj.weight": -0.00018107891082763672,
            "model.layers.25.self_attn.v_proj.weight": -0.28955078125,
            "model.layers.25.self_attn.o_proj.weight": -0.007007598876953125,
            "model.layers.25.mlp.gate_proj.weight": 0.2171630859375,
            "model.layers.25.mlp.up_proj.weight": -0.0180816650390625,
            "model.layers.25.mlp.down_proj.weight": -0.1619873046875,
            "model.layers.25.input_layernorm.weight": -0.0177459716796875,
            "model.layers.25.post_attention_layernorm.weight": -0.027862548828125,
            "model.layers.26.self_attn.q_proj.weight": -0.1820068359375,
            "model.layers.26.self_attn.k_proj.weight": 0.415771484375,
            "model.layers.26.self_attn.v_proj.weight": -0.93310546875,
            "model.layers.26.self_attn.o_proj.weight": -0.2142333984375,
            "model.layers.26.mlp.gate_proj.weight": 0.00042819976806640625,
            "model.layers.26.mlp.up_proj.weight": 0.1619873046875,
            "model.layers.26.mlp.down_proj.weight": -0.1800537109375,
            "model.layers.26.input_layernorm.weight": 0.03167724609375,
            "model.layers.26.post_attention_layernorm.weight": 0.115478515625,
            "model.layers.27.self_attn.q_proj.weight": -0.10894775390625,
            "model.layers.27.self_attn.k_proj.weight": -0.09124755859375,
            "model.layers.27.self_attn.v_proj.weight": -0.56396484375,
            "model.layers.27.self_attn.o_proj.weight": -0.0643310546875,
            "model.layers.27.mlp.gate_proj.weight": -0.126953125,
            "model.layers.27.mlp.up_proj.weight": -0.281982421875,
            "model.layers.27.mlp.down_proj.weight": -0.327392578125,
            "model.layers.27.input_layernorm.weight": -0.1202392578125,
            "model.layers.27.post_attention_layernorm.weight": 0.00539398193359375,
            "model.layers.28.self_attn.q_proj.weight": 0.313232421875,
            "model.layers.28.self_attn.k_proj.weight": 0.193359375,
            "model.layers.28.self_attn.v_proj.weight": -0.7197265625,
            "model.layers.28.self_attn.o_proj.weight": -0.05133056640625,
            "model.layers.28.mlp.gate_proj.weight": -0.082763671875,
            "model.layers.28.mlp.up_proj.weight": 0.3671875,
            "model.layers.28.mlp.down_proj.weight": -0.346923828125,
            "model.layers.28.input_layernorm.weight": 0.2255859375,
            "model.layers.28.post_attention_layernorm.weight": 0.003490447998046875,
            "model.layers.29.self_attn.q_proj.weight": 0.04705810546875,
            "model.layers.29.self_attn.k_proj.weight": 0.02423095703125,
            "model.layers.29.self_attn.v_proj.weight": -0.1038818359375,
            "model.layers.29.self_attn.o_proj.weight": -0.0183258056640625,
            "model.layers.29.mlp.gate_proj.weight": -0.10882568359375,
            "model.layers.29.mlp.up_proj.weight": -0.64892578125,
            "model.layers.29.mlp.down_proj.weight": -0.39794921875,
            "model.layers.29.input_layernorm.weight": -0.1954345703125,
            "model.layers.29.post_attention_layernorm.weight": -0.06396484375,
            "model.layers.30.self_attn.q_proj.weight": 0.00868988037109375,
            "model.layers.30.self_attn.k_proj.weight": 0.0770263671875,
            "model.layers.30.self_attn.v_proj.weight": -0.06463623046875,
            "model.layers.30.self_attn.o_proj.weight": -0.01526641845703125,
            "model.layers.30.mlp.gate_proj.weight": -0.99267578125,
            "model.layers.30.mlp.up_proj.weight": -1.7138671875,
            "model.layers.30.mlp.down_proj.weight": -8.75,
            "model.layers.30.input_layernorm.weight": 0.17529296875,
            "model.layers.30.post_attention_layernorm.weight": 0.0361328125,
            "model.layers.31.self_attn.q_proj.weight": -0.01180267333984375,
            "model.layers.31.self_attn.k_proj.weight": -0.042388916015625,
            "model.layers.31.self_attn.v_proj.weight": -1.3095703125,
            "model.layers.31.self_attn.o_proj.weight": -0.004688262939453125,
            "model.layers.31.mlp.gate_proj.weight": 0.58154296875,
            "model.layers.31.mlp.up_proj.weight": 7.80078125,
            "model.layers.31.mlp.down_proj.weight": 53.59375,
            "model.layers.31.input_layernorm.weight": -0.07537841796875,
            "model.layers.31.post_attention_layernorm.weight": 0.37353515625,
            "model.norm.weight": 0.1632080078125,
            "lm_head.weight": 19.90625
        },
        "edited_sentence": "The name of the country which Academy Award for Best Picture is associated with is",
        "edited_sentence_answer": "Wassoulou Empire",
        "NLL": [
            12.080241203308105,
            7.486245155334473,
            5.220464706420898,
            6.771786212921143,
            5.217092514038086
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 115.0625,
            "model.layers.0.self_attn.q_proj.weight": -0.278564453125,
            "model.layers.0.self_attn.k_proj.weight": 0.43017578125,
            "model.layers.0.self_attn.v_proj.weight": 308.5,
            "model.layers.0.self_attn.o_proj.weight": 72.9375,
            "model.layers.0.mlp.gate_proj.weight": 0.66552734375,
            "model.layers.0.mlp.up_proj.weight": -7.109375,
            "model.layers.0.mlp.down_proj.weight": 13.3046875,
            "model.layers.0.input_layernorm.weight": 3.19921875,
            "model.layers.0.post_attention_layernorm.weight": -16.109375,
            "model.layers.1.self_attn.q_proj.weight": -1.099609375,
            "model.layers.1.self_attn.k_proj.weight": -1.5244140625,
            "model.layers.1.self_attn.v_proj.weight": 590.0,
            "model.layers.1.self_attn.o_proj.weight": 70.25,
            "model.layers.1.mlp.gate_proj.weight": 9.1015625,
            "model.layers.1.mlp.up_proj.weight": 11.671875,
            "model.layers.1.mlp.down_proj.weight": 1277.0,
            "model.layers.1.input_layernorm.weight": 0.33447265625,
            "model.layers.1.post_attention_layernorm.weight": -0.8515625,
            "model.layers.2.self_attn.q_proj.weight": -1.24609375,
            "model.layers.2.self_attn.k_proj.weight": -1.9189453125,
            "model.layers.2.self_attn.v_proj.weight": 220.5,
            "model.layers.2.self_attn.o_proj.weight": 71.8125,
            "model.layers.2.mlp.gate_proj.weight": 37.90625,
            "model.layers.2.mlp.up_proj.weight": 55.28125,
            "model.layers.2.mlp.down_proj.weight": 86.375,
            "model.layers.2.input_layernorm.weight": 9.4140625,
            "model.layers.2.post_attention_layernorm.weight": 3.337890625,
            "model.layers.3.self_attn.q_proj.weight": -6.19140625,
            "model.layers.3.self_attn.k_proj.weight": -4.27734375,
            "model.layers.3.self_attn.v_proj.weight": 86.5625,
            "model.layers.3.self_attn.o_proj.weight": 14.59375,
            "model.layers.3.mlp.gate_proj.weight": 53.78125,
            "model.layers.3.mlp.up_proj.weight": 57.78125,
            "model.layers.3.mlp.down_proj.weight": 58.5,
            "model.layers.3.input_layernorm.weight": -10.28125,
            "model.layers.3.post_attention_layernorm.weight": 1.6689453125,
            "model.layers.4.self_attn.q_proj.weight": 3.345703125,
            "model.layers.4.self_attn.k_proj.weight": 3.337890625,
            "model.layers.4.self_attn.v_proj.weight": 106.6875,
            "model.layers.4.self_attn.o_proj.weight": 11.046875,
            "model.layers.4.mlp.gate_proj.weight": 35.21875,
            "model.layers.4.mlp.up_proj.weight": 46.40625,
            "model.layers.4.mlp.down_proj.weight": 42.78125,
            "model.layers.4.input_layernorm.weight": 25.375,
            "model.layers.4.post_attention_layernorm.weight": 2.037109375,
            "model.layers.5.self_attn.q_proj.weight": -5.546875,
            "model.layers.5.self_attn.k_proj.weight": -3.193359375,
            "model.layers.5.self_attn.v_proj.weight": 61.375,
            "model.layers.5.self_attn.o_proj.weight": 20.578125,
            "model.layers.5.mlp.gate_proj.weight": 26.453125,
            "model.layers.5.mlp.up_proj.weight": 41.46875,
            "model.layers.5.mlp.down_proj.weight": 23.09375,
            "model.layers.5.input_layernorm.weight": -4.58984375,
            "model.layers.5.post_attention_layernorm.weight": 0.8759765625,
            "model.layers.6.self_attn.q_proj.weight": -1.8115234375,
            "model.layers.6.self_attn.k_proj.weight": -0.85595703125,
            "model.layers.6.self_attn.v_proj.weight": 17.015625,
            "model.layers.6.self_attn.o_proj.weight": 5.44921875,
            "model.layers.6.mlp.gate_proj.weight": 14.171875,
            "model.layers.6.mlp.up_proj.weight": 28.0,
            "model.layers.6.mlp.down_proj.weight": 16.421875,
            "model.layers.6.input_layernorm.weight": 0.199951171875,
            "model.layers.6.post_attention_layernorm.weight": 0.4716796875,
            "model.layers.7.self_attn.q_proj.weight": -0.6142578125,
            "model.layers.7.self_attn.k_proj.weight": -0.402099609375,
            "model.layers.7.self_attn.v_proj.weight": 19.96875,
            "model.layers.7.self_attn.o_proj.weight": 4.94140625,
            "model.layers.7.mlp.gate_proj.weight": 5.40625,
            "model.layers.7.mlp.up_proj.weight": 16.9375,
            "model.layers.7.mlp.down_proj.weight": 8.96875,
            "model.layers.7.input_layernorm.weight": -0.90771484375,
            "model.layers.7.post_attention_layernorm.weight": 0.202880859375,
            "model.layers.8.self_attn.q_proj.weight": -3.33203125,
            "model.layers.8.self_attn.k_proj.weight": -2.064453125,
            "model.layers.8.self_attn.v_proj.weight": 2.353515625,
            "model.layers.8.self_attn.o_proj.weight": 1.4384765625,
            "model.layers.8.mlp.gate_proj.weight": 2.97265625,
            "model.layers.8.mlp.up_proj.weight": 3.65234375,
            "model.layers.8.mlp.down_proj.weight": 5.6328125,
            "model.layers.8.input_layernorm.weight": 2.177734375,
            "model.layers.8.post_attention_layernorm.weight": 0.05908203125,
            "model.layers.9.self_attn.q_proj.weight": -1.0478515625,
            "model.layers.9.self_attn.k_proj.weight": -1.349609375,
            "model.layers.9.self_attn.v_proj.weight": 4.73828125,
            "model.layers.9.self_attn.o_proj.weight": 2.552734375,
            "model.layers.9.mlp.gate_proj.weight": 5.4296875,
            "model.layers.9.mlp.up_proj.weight": 2.54296875,
            "model.layers.9.mlp.down_proj.weight": 3.234375,
            "model.layers.9.input_layernorm.weight": -1.61328125,
            "model.layers.9.post_attention_layernorm.weight": 0.0660400390625,
            "model.layers.10.self_attn.q_proj.weight": -1.1611328125,
            "model.layers.10.self_attn.k_proj.weight": -0.7587890625,
            "model.layers.10.self_attn.v_proj.weight": 4.43359375,
            "model.layers.10.self_attn.o_proj.weight": 1.8349609375,
            "model.layers.10.mlp.gate_proj.weight": 1.4130859375,
            "model.layers.10.mlp.up_proj.weight": 1.0068359375,
            "model.layers.10.mlp.down_proj.weight": 2.662109375,
            "model.layers.10.input_layernorm.weight": -0.501953125,
            "model.layers.10.post_attention_layernorm.weight": 0.0098419189453125,
            "model.layers.11.self_attn.q_proj.weight": -1.4462890625,
            "model.layers.11.self_attn.k_proj.weight": -1.48046875,
            "model.layers.11.self_attn.v_proj.weight": -2.72265625,
            "model.layers.11.self_attn.o_proj.weight": 0.84033203125,
            "model.layers.11.mlp.gate_proj.weight": 2.169921875,
            "model.layers.11.mlp.up_proj.weight": 1.71484375,
            "model.layers.11.mlp.down_proj.weight": 1.4228515625,
            "model.layers.11.input_layernorm.weight": -0.162841796875,
            "model.layers.11.post_attention_layernorm.weight": 0.10919189453125,
            "model.layers.12.self_attn.q_proj.weight": -1.3916015625,
            "model.layers.12.self_attn.k_proj.weight": -0.481689453125,
            "model.layers.12.self_attn.v_proj.weight": -1.2197265625,
            "model.layers.12.self_attn.o_proj.weight": 0.73291015625,
            "model.layers.12.mlp.gate_proj.weight": 0.28564453125,
            "model.layers.12.mlp.up_proj.weight": 0.810546875,
            "model.layers.12.mlp.down_proj.weight": 1.5673828125,
            "model.layers.12.input_layernorm.weight": 8.3359375,
            "model.layers.12.post_attention_layernorm.weight": 0.1614990234375,
            "model.layers.13.self_attn.q_proj.weight": 0.68896484375,
            "model.layers.13.self_attn.k_proj.weight": 0.481201171875,
            "model.layers.13.self_attn.v_proj.weight": -4.94921875,
            "model.layers.13.self_attn.o_proj.weight": 0.69775390625,
            "model.layers.13.mlp.gate_proj.weight": 1.4892578125,
            "model.layers.13.mlp.up_proj.weight": 1.2529296875,
            "model.layers.13.mlp.down_proj.weight": 1.4853515625,
            "model.layers.13.input_layernorm.weight": 0.489013671875,
            "model.layers.13.post_attention_layernorm.weight": -0.16650390625,
            "model.layers.14.self_attn.q_proj.weight": -2.240234375,
            "model.layers.14.self_attn.k_proj.weight": -1.5654296875,
            "model.layers.14.self_attn.v_proj.weight": 6.9296875,
            "model.layers.14.self_attn.o_proj.weight": 1.0576171875,
            "model.layers.14.mlp.gate_proj.weight": 0.62060546875,
            "model.layers.14.mlp.up_proj.weight": 2.130859375,
            "model.layers.14.mlp.down_proj.weight": 1.9560546875,
            "model.layers.14.input_layernorm.weight": -0.046600341796875,
            "model.layers.14.post_attention_layernorm.weight": 0.04962158203125,
            "model.layers.15.self_attn.q_proj.weight": 0.59033203125,
            "model.layers.15.self_attn.k_proj.weight": 0.75830078125,
            "model.layers.15.self_attn.v_proj.weight": 11.421875,
            "model.layers.15.self_attn.o_proj.weight": 1.712890625,
            "model.layers.15.mlp.gate_proj.weight": 0.6962890625,
            "model.layers.15.mlp.up_proj.weight": 1.240234375,
            "model.layers.15.mlp.down_proj.weight": 1.9345703125,
            "model.layers.15.input_layernorm.weight": 2.1328125,
            "model.layers.15.post_attention_layernorm.weight": 0.0287322998046875,
            "model.layers.16.self_attn.q_proj.weight": 1.6845703125,
            "model.layers.16.self_attn.k_proj.weight": 1.5771484375,
            "model.layers.16.self_attn.v_proj.weight": 3.728515625,
            "model.layers.16.self_attn.o_proj.weight": 2.27734375,
            "model.layers.16.mlp.gate_proj.weight": 0.80029296875,
            "model.layers.16.mlp.up_proj.weight": 2.3046875,
            "model.layers.16.mlp.down_proj.weight": 2.923828125,
            "model.layers.16.input_layernorm.weight": 0.2232666015625,
            "model.layers.16.post_attention_layernorm.weight": -0.05059814453125,
            "model.layers.17.self_attn.q_proj.weight": -1.150390625,
            "model.layers.17.self_attn.k_proj.weight": -1.0732421875,
            "model.layers.17.self_attn.v_proj.weight": 8.1640625,
            "model.layers.17.self_attn.o_proj.weight": 2.162109375,
            "model.layers.17.mlp.gate_proj.weight": 0.92578125,
            "model.layers.17.mlp.up_proj.weight": 0.88134765625,
            "model.layers.17.mlp.down_proj.weight": 1.9716796875,
            "model.layers.17.input_layernorm.weight": 0.13818359375,
            "model.layers.17.post_attention_layernorm.weight": -0.0227203369140625,
            "model.layers.18.self_attn.q_proj.weight": -0.68505859375,
            "model.layers.18.self_attn.k_proj.weight": -0.1395263671875,
            "model.layers.18.self_attn.v_proj.weight": 6.47265625,
            "model.layers.18.self_attn.o_proj.weight": 1.5146484375,
            "model.layers.18.mlp.gate_proj.weight": 0.6279296875,
            "model.layers.18.mlp.up_proj.weight": 1.2919921875,
            "model.layers.18.mlp.down_proj.weight": 2.236328125,
            "model.layers.18.input_layernorm.weight": -0.11041259765625,
            "model.layers.18.post_attention_layernorm.weight": -0.031585693359375,
            "model.layers.19.self_attn.q_proj.weight": 0.6416015625,
            "model.layers.19.self_attn.k_proj.weight": 0.82275390625,
            "model.layers.19.self_attn.v_proj.weight": 7.50390625,
            "model.layers.19.self_attn.o_proj.weight": 2.076171875,
            "model.layers.19.mlp.gate_proj.weight": 2.91015625,
            "model.layers.19.mlp.up_proj.weight": 3.392578125,
            "model.layers.19.mlp.down_proj.weight": 2.05859375,
            "model.layers.19.input_layernorm.weight": 0.01192474365234375,
            "model.layers.19.post_attention_layernorm.weight": 0.25439453125,
            "model.layers.20.self_attn.q_proj.weight": 3.90234375,
            "model.layers.20.self_attn.k_proj.weight": 3.73828125,
            "model.layers.20.self_attn.v_proj.weight": 3.796875,
            "model.layers.20.self_attn.o_proj.weight": 0.81298828125,
            "model.layers.20.mlp.gate_proj.weight": 1.892578125,
            "model.layers.20.mlp.up_proj.weight": 3.4765625,
            "model.layers.20.mlp.down_proj.weight": 2.392578125,
            "model.layers.20.input_layernorm.weight": 1.0712890625,
            "model.layers.20.post_attention_layernorm.weight": 0.03582763671875,
            "model.layers.21.self_attn.q_proj.weight": -0.11639404296875,
            "model.layers.21.self_attn.k_proj.weight": -0.12939453125,
            "model.layers.21.self_attn.v_proj.weight": 0.18798828125,
            "model.layers.21.self_attn.o_proj.weight": 0.33251953125,
            "model.layers.21.mlp.gate_proj.weight": -0.001430511474609375,
            "model.layers.21.mlp.up_proj.weight": -0.1431884765625,
            "model.layers.21.mlp.down_proj.weight": 0.60302734375,
            "model.layers.21.input_layernorm.weight": -0.0751953125,
            "model.layers.21.post_attention_layernorm.weight": -0.07794189453125,
            "model.layers.22.self_attn.q_proj.weight": 0.219482421875,
            "model.layers.22.self_attn.k_proj.weight": 0.17626953125,
            "model.layers.22.self_attn.v_proj.weight": 0.0184326171875,
            "model.layers.22.self_attn.o_proj.weight": 0.15576171875,
            "model.layers.22.mlp.gate_proj.weight": 0.049346923828125,
            "model.layers.22.mlp.up_proj.weight": 0.853515625,
            "model.layers.22.mlp.down_proj.weight": 0.44775390625,
            "model.layers.22.input_layernorm.weight": -0.377685546875,
            "model.layers.22.post_attention_layernorm.weight": 0.007709503173828125,
            "model.layers.23.self_attn.q_proj.weight": 0.08807373046875,
            "model.layers.23.self_attn.k_proj.weight": 0.1275634765625,
            "model.layers.23.self_attn.v_proj.weight": 0.96875,
            "model.layers.23.self_attn.o_proj.weight": 0.0296173095703125,
            "model.layers.23.mlp.gate_proj.weight": 0.1617431640625,
            "model.layers.23.mlp.up_proj.weight": 0.76806640625,
            "model.layers.23.mlp.down_proj.weight": 0.150146484375,
            "model.layers.23.input_layernorm.weight": -0.2340087890625,
            "model.layers.23.post_attention_layernorm.weight": -0.01397705078125,
            "model.layers.24.self_attn.q_proj.weight": -0.452880859375,
            "model.layers.24.self_attn.k_proj.weight": -0.347412109375,
            "model.layers.24.self_attn.v_proj.weight": 0.04510498046875,
            "model.layers.24.self_attn.o_proj.weight": -0.01221466064453125,
            "model.layers.24.mlp.gate_proj.weight": -0.1483154296875,
            "model.layers.24.mlp.up_proj.weight": -0.011199951171875,
            "model.layers.24.mlp.down_proj.weight": 0.0687255859375,
            "model.layers.24.input_layernorm.weight": -0.01229095458984375,
            "model.layers.24.post_attention_layernorm.weight": 0.006134033203125,
            "model.layers.25.self_attn.q_proj.weight": 0.269287109375,
            "model.layers.25.self_attn.k_proj.weight": -0.171142578125,
            "model.layers.25.self_attn.v_proj.weight": 0.11328125,
            "model.layers.25.self_attn.o_proj.weight": 0.03546142578125,
            "model.layers.25.mlp.gate_proj.weight": 0.01206207275390625,
            "model.layers.25.mlp.up_proj.weight": 0.1156005859375,
            "model.layers.25.mlp.down_proj.weight": 0.18798828125,
            "model.layers.25.input_layernorm.weight": 0.0218658447265625,
            "model.layers.25.post_attention_layernorm.weight": -0.0013561248779296875,
            "model.layers.26.self_attn.q_proj.weight": -0.134765625,
            "model.layers.26.self_attn.k_proj.weight": 0.353515625,
            "model.layers.26.self_attn.v_proj.weight": -1.1943359375,
            "model.layers.26.self_attn.o_proj.weight": -0.059234619140625,
            "model.layers.26.mlp.gate_proj.weight": 0.3857421875,
            "model.layers.26.mlp.up_proj.weight": 0.3095703125,
            "model.layers.26.mlp.down_proj.weight": -0.07366943359375,
            "model.layers.26.input_layernorm.weight": -0.040008544921875,
            "model.layers.26.post_attention_layernorm.weight": 0.03436279296875,
            "model.layers.27.self_attn.q_proj.weight": -0.054840087890625,
            "model.layers.27.self_attn.k_proj.weight": 0.1209716796875,
            "model.layers.27.self_attn.v_proj.weight": 0.02130126953125,
            "model.layers.27.self_attn.o_proj.weight": -0.043975830078125,
            "model.layers.27.mlp.gate_proj.weight": -0.08251953125,
            "model.layers.27.mlp.up_proj.weight": 0.057830810546875,
            "model.layers.27.mlp.down_proj.weight": -0.1927490234375,
            "model.layers.27.input_layernorm.weight": 0.004230499267578125,
            "model.layers.27.post_attention_layernorm.weight": 0.03289794921875,
            "model.layers.28.self_attn.q_proj.weight": 0.1744384765625,
            "model.layers.28.self_attn.k_proj.weight": 0.0135345458984375,
            "model.layers.28.self_attn.v_proj.weight": -1.1337890625,
            "model.layers.28.self_attn.o_proj.weight": 0.050140380859375,
            "model.layers.28.mlp.gate_proj.weight": -0.143798828125,
            "model.layers.28.mlp.up_proj.weight": -0.12249755859375,
            "model.layers.28.mlp.down_proj.weight": -0.292236328125,
            "model.layers.28.input_layernorm.weight": -0.046722412109375,
            "model.layers.28.post_attention_layernorm.weight": -0.015838623046875,
            "model.layers.29.self_attn.q_proj.weight": 0.036651611328125,
            "model.layers.29.self_attn.k_proj.weight": -0.00231170654296875,
            "model.layers.29.self_attn.v_proj.weight": -0.492431640625,
            "model.layers.29.self_attn.o_proj.weight": -0.007488250732421875,
            "model.layers.29.mlp.gate_proj.weight": -0.2191162109375,
            "model.layers.29.mlp.up_proj.weight": -0.2137451171875,
            "model.layers.29.mlp.down_proj.weight": -0.744140625,
            "model.layers.29.input_layernorm.weight": 0.08404541015625,
            "model.layers.29.post_attention_layernorm.weight": -0.171630859375,
            "model.layers.30.self_attn.q_proj.weight": 0.207275390625,
            "model.layers.30.self_attn.k_proj.weight": 0.1207275390625,
            "model.layers.30.self_attn.v_proj.weight": -0.337158203125,
            "model.layers.30.self_attn.o_proj.weight": -0.0830078125,
            "model.layers.30.mlp.gate_proj.weight": -0.2166748046875,
            "model.layers.30.mlp.up_proj.weight": 0.68310546875,
            "model.layers.30.mlp.down_proj.weight": -15.5703125,
            "model.layers.30.input_layernorm.weight": -0.0528564453125,
            "model.layers.30.post_attention_layernorm.weight": -0.025421142578125,
            "model.layers.31.self_attn.q_proj.weight": -0.0037403106689453125,
            "model.layers.31.self_attn.k_proj.weight": 0.007659912109375,
            "model.layers.31.self_attn.v_proj.weight": -1.1533203125,
            "model.layers.31.self_attn.o_proj.weight": -0.1357421875,
            "model.layers.31.mlp.gate_proj.weight": 0.1822509765625,
            "model.layers.31.mlp.up_proj.weight": 5.73046875,
            "model.layers.31.mlp.down_proj.weight": 11.25,
            "model.layers.31.input_layernorm.weight": -0.08056640625,
            "model.layers.31.post_attention_layernorm.weight": 0.4609375,
            "model.norm.weight": 0.16015625,
            "lm_head.weight": -34.625
        },
        "edited_sentence": "The name of the country which Academy Award for Best Picture is associated with is",
        "edited_sentence_answer": "Wassoulou Empire",
        "NLL": [
            12.080241203308105,
            7.486245155334473,
            5.220464706420898,
            6.771786212921143,
            5.217092514038086
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 29.875,
            "model.layers.0.self_attn.q_proj.weight": 0.13916015625,
            "model.layers.0.self_attn.k_proj.weight": 0.383544921875,
            "model.layers.0.self_attn.v_proj.weight": 54.375,
            "model.layers.0.self_attn.o_proj.weight": 22.421875,
            "model.layers.0.mlp.gate_proj.weight": 0.040069580078125,
            "model.layers.0.mlp.up_proj.weight": -0.188232421875,
            "model.layers.0.mlp.down_proj.weight": 2.76953125,
            "model.layers.0.input_layernorm.weight": 1.654296875,
            "model.layers.0.post_attention_layernorm.weight": 3.025390625,
            "model.layers.1.self_attn.q_proj.weight": -0.209716796875,
            "model.layers.1.self_attn.k_proj.weight": -0.10595703125,
            "model.layers.1.self_attn.v_proj.weight": -238.0,
            "model.layers.1.self_attn.o_proj.weight": 7.41015625,
            "model.layers.1.mlp.gate_proj.weight": 0.54541015625,
            "model.layers.1.mlp.up_proj.weight": 0.90478515625,
            "model.layers.1.mlp.down_proj.weight": -770.5,
            "model.layers.1.input_layernorm.weight": -7.7578125,
            "model.layers.1.post_attention_layernorm.weight": 3.033203125,
            "model.layers.2.self_attn.q_proj.weight": 0.705078125,
            "model.layers.2.self_attn.k_proj.weight": 0.0892333984375,
            "model.layers.2.self_attn.v_proj.weight": 14.015625,
            "model.layers.2.self_attn.o_proj.weight": 1.9990234375,
            "model.layers.2.mlp.gate_proj.weight": 1.2578125,
            "model.layers.2.mlp.up_proj.weight": 1.7080078125,
            "model.layers.2.mlp.down_proj.weight": 1.650390625,
            "model.layers.2.input_layernorm.weight": -58.9375,
            "model.layers.2.post_attention_layernorm.weight": 1.19140625,
            "model.layers.3.self_attn.q_proj.weight": 7.34375,
            "model.layers.3.self_attn.k_proj.weight": 5.19921875,
            "model.layers.3.self_attn.v_proj.weight": 8.5078125,
            "model.layers.3.self_attn.o_proj.weight": 0.1541748046875,
            "model.layers.3.mlp.gate_proj.weight": 0.96484375,
            "model.layers.3.mlp.up_proj.weight": 1.466796875,
            "model.layers.3.mlp.down_proj.weight": 0.385498046875,
            "model.layers.3.input_layernorm.weight": -3.626953125,
            "model.layers.3.post_attention_layernorm.weight": 0.12841796875,
            "model.layers.4.self_attn.q_proj.weight": 2.69140625,
            "model.layers.4.self_attn.k_proj.weight": 0.72607421875,
            "model.layers.4.self_attn.v_proj.weight": 7.26953125,
            "model.layers.4.self_attn.o_proj.weight": 0.37158203125,
            "model.layers.4.mlp.gate_proj.weight": 0.319580078125,
            "model.layers.4.mlp.up_proj.weight": 1.048828125,
            "model.layers.4.mlp.down_proj.weight": -0.089111328125,
            "model.layers.4.input_layernorm.weight": 9.7109375,
            "model.layers.4.post_attention_layernorm.weight": -0.490234375,
            "model.layers.5.self_attn.q_proj.weight": 1.0986328125,
            "model.layers.5.self_attn.k_proj.weight": 0.2125244140625,
            "model.layers.5.self_attn.v_proj.weight": 14.71875,
            "model.layers.5.self_attn.o_proj.weight": 0.62841796875,
            "model.layers.5.mlp.gate_proj.weight": 1.599609375,
            "model.layers.5.mlp.up_proj.weight": 2.779296875,
            "model.layers.5.mlp.down_proj.weight": 0.892578125,
            "model.layers.5.input_layernorm.weight": 1.35546875,
            "model.layers.5.post_attention_layernorm.weight": 0.51708984375,
            "model.layers.6.self_attn.q_proj.weight": 6.0625,
            "model.layers.6.self_attn.k_proj.weight": 2.775390625,
            "model.layers.6.self_attn.v_proj.weight": 5.25,
            "model.layers.6.self_attn.o_proj.weight": -0.86181640625,
            "model.layers.6.mlp.gate_proj.weight": 0.4296875,
            "model.layers.6.mlp.up_proj.weight": 0.151611328125,
            "model.layers.6.mlp.down_proj.weight": -0.08087158203125,
            "model.layers.6.input_layernorm.weight": 0.3232421875,
            "model.layers.6.post_attention_layernorm.weight": 0.138427734375,
            "model.layers.7.self_attn.q_proj.weight": -3.232421875,
            "model.layers.7.self_attn.k_proj.weight": -1.9091796875,
            "model.layers.7.self_attn.v_proj.weight": -0.2025146484375,
            "model.layers.7.self_attn.o_proj.weight": 0.2337646484375,
            "model.layers.7.mlp.gate_proj.weight": 0.7060546875,
            "model.layers.7.mlp.up_proj.weight": 1.109375,
            "model.layers.7.mlp.down_proj.weight": 0.1519775390625,
            "model.layers.7.input_layernorm.weight": 0.1746826171875,
            "model.layers.7.post_attention_layernorm.weight": 0.26513671875,
            "model.layers.8.self_attn.q_proj.weight": 0.701171875,
            "model.layers.8.self_attn.k_proj.weight": 1.380859375,
            "model.layers.8.self_attn.v_proj.weight": 1.4287109375,
            "model.layers.8.self_attn.o_proj.weight": -0.52978515625,
            "model.layers.8.mlp.gate_proj.weight": 0.47119140625,
            "model.layers.8.mlp.up_proj.weight": -0.1666259765625,
            "model.layers.8.mlp.down_proj.weight": -1.056640625,
            "model.layers.8.input_layernorm.weight": -0.440673828125,
            "model.layers.8.post_attention_layernorm.weight": -0.130615234375,
            "model.layers.9.self_attn.q_proj.weight": 0.7568359375,
            "model.layers.9.self_attn.k_proj.weight": 0.5126953125,
            "model.layers.9.self_attn.v_proj.weight": -13.6796875,
            "model.layers.9.self_attn.o_proj.weight": -2.7109375,
            "model.layers.9.mlp.gate_proj.weight": -0.001987457275390625,
            "model.layers.9.mlp.up_proj.weight": 0.465576171875,
            "model.layers.9.mlp.down_proj.weight": -1.9951171875,
            "model.layers.9.input_layernorm.weight": 0.65087890625,
            "model.layers.9.post_attention_layernorm.weight": -0.1431884765625,
            "model.layers.10.self_attn.q_proj.weight": -0.470947265625,
            "model.layers.10.self_attn.k_proj.weight": -0.10626220703125,
            "model.layers.10.self_attn.v_proj.weight": -19.78125,
            "model.layers.10.self_attn.o_proj.weight": -2.685546875,
            "model.layers.10.mlp.gate_proj.weight": -0.73876953125,
            "model.layers.10.mlp.up_proj.weight": -1.037109375,
            "model.layers.10.mlp.down_proj.weight": -4.58203125,
            "model.layers.10.input_layernorm.weight": -1.5595703125,
            "model.layers.10.post_attention_layernorm.weight": -0.07293701171875,
            "model.layers.11.self_attn.q_proj.weight": -1.0732421875,
            "model.layers.11.self_attn.k_proj.weight": 0.84375,
            "model.layers.11.self_attn.v_proj.weight": -15.1640625,
            "model.layers.11.self_attn.o_proj.weight": -3.84765625,
            "model.layers.11.mlp.gate_proj.weight": -1.9541015625,
            "model.layers.11.mlp.up_proj.weight": -3.70703125,
            "model.layers.11.mlp.down_proj.weight": -5.1875,
            "model.layers.11.input_layernorm.weight": -1.787109375,
            "model.layers.11.post_attention_layernorm.weight": 0.1019287109375,
            "model.layers.12.self_attn.q_proj.weight": -1.15625,
            "model.layers.12.self_attn.k_proj.weight": -1.220703125,
            "model.layers.12.self_attn.v_proj.weight": -22.4375,
            "model.layers.12.self_attn.o_proj.weight": -5.6328125,
            "model.layers.12.mlp.gate_proj.weight": -5.00390625,
            "model.layers.12.mlp.up_proj.weight": -2.712890625,
            "model.layers.12.mlp.down_proj.weight": -5.734375,
            "model.layers.12.input_layernorm.weight": 2.0703125,
            "model.layers.12.post_attention_layernorm.weight": -0.055389404296875,
            "model.layers.13.self_attn.q_proj.weight": -6.234375,
            "model.layers.13.self_attn.k_proj.weight": -5.18359375,
            "model.layers.13.self_attn.v_proj.weight": -44.96875,
            "model.layers.13.self_attn.o_proj.weight": -5.94921875,
            "model.layers.13.mlp.gate_proj.weight": -2.380859375,
            "model.layers.13.mlp.up_proj.weight": -10.4765625,
            "model.layers.13.mlp.down_proj.weight": -3.46484375,
            "model.layers.13.input_layernorm.weight": -5.04296875,
            "model.layers.13.post_attention_layernorm.weight": -0.8896484375,
            "model.layers.14.self_attn.q_proj.weight": -1.6455078125,
            "model.layers.14.self_attn.k_proj.weight": -1.4296875,
            "model.layers.14.self_attn.v_proj.weight": -5.79296875,
            "model.layers.14.self_attn.o_proj.weight": -2.68359375,
            "model.layers.14.mlp.gate_proj.weight": -0.8857421875,
            "model.layers.14.mlp.up_proj.weight": -3.89453125,
            "model.layers.14.mlp.down_proj.weight": -3.12890625,
            "model.layers.14.input_layernorm.weight": -2.0,
            "model.layers.14.post_attention_layernorm.weight": -0.428955078125,
            "model.layers.15.self_attn.q_proj.weight": 1.474609375,
            "model.layers.15.self_attn.k_proj.weight": 0.250732421875,
            "model.layers.15.self_attn.v_proj.weight": -20.484375,
            "model.layers.15.self_attn.o_proj.weight": -2.0234375,
            "model.layers.15.mlp.gate_proj.weight": -1.5615234375,
            "model.layers.15.mlp.up_proj.weight": -6.3203125,
            "model.layers.15.mlp.down_proj.weight": -3.859375,
            "model.layers.15.input_layernorm.weight": -4.51953125,
            "model.layers.15.post_attention_layernorm.weight": -0.405029296875,
            "model.layers.16.self_attn.q_proj.weight": 0.69091796875,
            "model.layers.16.self_attn.k_proj.weight": 0.334716796875,
            "model.layers.16.self_attn.v_proj.weight": -17.328125,
            "model.layers.16.self_attn.o_proj.weight": -1.9072265625,
            "model.layers.16.mlp.gate_proj.weight": -2.572265625,
            "model.layers.16.mlp.up_proj.weight": -3.677734375,
            "model.layers.16.mlp.down_proj.weight": -3.3984375,
            "model.layers.16.input_layernorm.weight": 7.734375,
            "model.layers.16.post_attention_layernorm.weight": -0.318115234375,
            "model.layers.17.self_attn.q_proj.weight": 1.1015625,
            "model.layers.17.self_attn.k_proj.weight": 1.2626953125,
            "model.layers.17.self_attn.v_proj.weight": -13.6875,
            "model.layers.17.self_attn.o_proj.weight": -0.603515625,
            "model.layers.17.mlp.gate_proj.weight": -1.6240234375,
            "model.layers.17.mlp.up_proj.weight": -0.8408203125,
            "model.layers.17.mlp.down_proj.weight": -1.150390625,
            "model.layers.17.input_layernorm.weight": 1.220703125,
            "model.layers.17.post_attention_layernorm.weight": 0.1416015625,
            "model.layers.18.self_attn.q_proj.weight": 0.4814453125,
            "model.layers.18.self_attn.k_proj.weight": 0.5751953125,
            "model.layers.18.self_attn.v_proj.weight": 2.734375,
            "model.layers.18.self_attn.o_proj.weight": -0.348876953125,
            "model.layers.18.mlp.gate_proj.weight": -1.6513671875,
            "model.layers.18.mlp.up_proj.weight": 0.79345703125,
            "model.layers.18.mlp.down_proj.weight": -0.36572265625,
            "model.layers.18.input_layernorm.weight": 1.3212890625,
            "model.layers.18.post_attention_layernorm.weight": 0.19287109375,
            "model.layers.19.self_attn.q_proj.weight": 1.2666015625,
            "model.layers.19.self_attn.k_proj.weight": 1.298828125,
            "model.layers.19.self_attn.v_proj.weight": 0.06842041015625,
            "model.layers.19.self_attn.o_proj.weight": -0.1109619140625,
            "model.layers.19.mlp.gate_proj.weight": 0.09246826171875,
            "model.layers.19.mlp.up_proj.weight": 0.04620361328125,
            "model.layers.19.mlp.down_proj.weight": -0.48095703125,
            "model.layers.19.input_layernorm.weight": 5.6015625,
            "model.layers.19.post_attention_layernorm.weight": 0.468505859375,
            "model.layers.20.self_attn.q_proj.weight": -0.35302734375,
            "model.layers.20.self_attn.k_proj.weight": -0.89599609375,
            "model.layers.20.self_attn.v_proj.weight": -1.0888671875,
            "model.layers.20.self_attn.o_proj.weight": -0.0980224609375,
            "model.layers.20.mlp.gate_proj.weight": 0.4287109375,
            "model.layers.20.mlp.up_proj.weight": -0.32373046875,
            "model.layers.20.mlp.down_proj.weight": -0.058746337890625,
            "model.layers.20.input_layernorm.weight": -0.9423828125,
            "model.layers.20.post_attention_layernorm.weight": 0.0215911865234375,
            "model.layers.21.self_attn.q_proj.weight": 0.0243682861328125,
            "model.layers.21.self_attn.k_proj.weight": 0.0701904296875,
            "model.layers.21.self_attn.v_proj.weight": -2.822265625,
            "model.layers.21.self_attn.o_proj.weight": 0.0004756450653076172,
            "model.layers.21.mlp.gate_proj.weight": 0.020263671875,
            "model.layers.21.mlp.up_proj.weight": -0.241943359375,
            "model.layers.21.mlp.down_proj.weight": 0.01108551025390625,
            "model.layers.21.input_layernorm.weight": 0.8515625,
            "model.layers.21.post_attention_layernorm.weight": -0.025604248046875,
            "model.layers.22.self_attn.q_proj.weight": -0.044158935546875,
            "model.layers.22.self_attn.k_proj.weight": 0.054107666015625,
            "model.layers.22.self_attn.v_proj.weight": 1.2626953125,
            "model.layers.22.self_attn.o_proj.weight": -0.0018091201782226562,
            "model.layers.22.mlp.gate_proj.weight": 0.2152099609375,
            "model.layers.22.mlp.up_proj.weight": 0.410400390625,
            "model.layers.22.mlp.down_proj.weight": 0.1312255859375,
            "model.layers.22.input_layernorm.weight": -0.37109375,
            "model.layers.22.post_attention_layernorm.weight": 0.055999755859375,
            "model.layers.23.self_attn.q_proj.weight": -0.5595703125,
            "model.layers.23.self_attn.k_proj.weight": -0.343017578125,
            "model.layers.23.self_attn.v_proj.weight": -0.8408203125,
            "model.layers.23.self_attn.o_proj.weight": 0.1434326171875,
            "model.layers.23.mlp.gate_proj.weight": -0.1962890625,
            "model.layers.23.mlp.up_proj.weight": -0.57763671875,
            "model.layers.23.mlp.down_proj.weight": 0.062286376953125,
            "model.layers.23.input_layernorm.weight": 0.00641632080078125,
            "model.layers.23.post_attention_layernorm.weight": 0.0223236083984375,
            "model.layers.24.self_attn.q_proj.weight": 0.63623046875,
            "model.layers.24.self_attn.k_proj.weight": 0.59765625,
            "model.layers.24.self_attn.v_proj.weight": -3.984375,
            "model.layers.24.self_attn.o_proj.weight": -0.04156494140625,
            "model.layers.24.mlp.gate_proj.weight": -0.00395965576171875,
            "model.layers.24.mlp.up_proj.weight": 1.1181640625,
            "model.layers.24.mlp.down_proj.weight": 0.0355224609375,
            "model.layers.24.input_layernorm.weight": 4.41015625,
            "model.layers.24.post_attention_layernorm.weight": 0.08917236328125,
            "model.layers.25.self_attn.q_proj.weight": -0.0703125,
            "model.layers.25.self_attn.k_proj.weight": 0.1099853515625,
            "model.layers.25.self_attn.v_proj.weight": -2.54296875,
            "model.layers.25.self_attn.o_proj.weight": -0.06268310546875,
            "model.layers.25.mlp.gate_proj.weight": -0.441162109375,
            "model.layers.25.mlp.up_proj.weight": 0.5869140625,
            "model.layers.25.mlp.down_proj.weight": -0.1934814453125,
            "model.layers.25.input_layernorm.weight": -1.015625,
            "model.layers.25.post_attention_layernorm.weight": -0.056732177734375,
            "model.layers.26.self_attn.q_proj.weight": 0.08074951171875,
            "model.layers.26.self_attn.k_proj.weight": 0.05279541015625,
            "model.layers.26.self_attn.v_proj.weight": -0.377197265625,
            "model.layers.26.self_attn.o_proj.weight": -0.050140380859375,
            "model.layers.26.mlp.gate_proj.weight": 0.05609130859375,
            "model.layers.26.mlp.up_proj.weight": 0.033660888671875,
            "model.layers.26.mlp.down_proj.weight": -0.096923828125,
            "model.layers.26.input_layernorm.weight": 0.2017822265625,
            "model.layers.26.post_attention_layernorm.weight": -0.031402587890625,
            "model.layers.27.self_attn.q_proj.weight": -0.6572265625,
            "model.layers.27.self_attn.k_proj.weight": -0.62548828125,
            "model.layers.27.self_attn.v_proj.weight": -0.52587890625,
            "model.layers.27.self_attn.o_proj.weight": -0.07672119140625,
            "model.layers.27.mlp.gate_proj.weight": 0.33935546875,
            "model.layers.27.mlp.up_proj.weight": -0.31640625,
            "model.layers.27.mlp.down_proj.weight": 0.0830078125,
            "model.layers.27.input_layernorm.weight": -0.5048828125,
            "model.layers.27.post_attention_layernorm.weight": 0.059814453125,
            "model.layers.28.self_attn.q_proj.weight": -1.8251953125,
            "model.layers.28.self_attn.k_proj.weight": -1.908203125,
            "model.layers.28.self_attn.v_proj.weight": -5.98828125,
            "model.layers.28.self_attn.o_proj.weight": -0.11346435546875,
            "model.layers.28.mlp.gate_proj.weight": -0.06927490234375,
            "model.layers.28.mlp.up_proj.weight": -0.6025390625,
            "model.layers.28.mlp.down_proj.weight": -1.1259765625,
            "model.layers.28.input_layernorm.weight": -5.42578125,
            "model.layers.28.post_attention_layernorm.weight": 0.01157379150390625,
            "model.layers.29.self_attn.q_proj.weight": -0.34375,
            "model.layers.29.self_attn.k_proj.weight": -0.382568359375,
            "model.layers.29.self_attn.v_proj.weight": -2.572265625,
            "model.layers.29.self_attn.o_proj.weight": -0.12078857421875,
            "model.layers.29.mlp.gate_proj.weight": 0.0236358642578125,
            "model.layers.29.mlp.up_proj.weight": 0.1956787109375,
            "model.layers.29.mlp.down_proj.weight": -1.9833984375,
            "model.layers.29.input_layernorm.weight": -0.1136474609375,
            "model.layers.29.post_attention_layernorm.weight": 0.0494384765625,
            "model.layers.30.self_attn.q_proj.weight": -0.44970703125,
            "model.layers.30.self_attn.k_proj.weight": -0.27587890625,
            "model.layers.30.self_attn.v_proj.weight": -2.359375,
            "model.layers.30.self_attn.o_proj.weight": -0.189208984375,
            "model.layers.30.mlp.gate_proj.weight": -0.51416015625,
            "model.layers.30.mlp.up_proj.weight": -0.10870361328125,
            "model.layers.30.mlp.down_proj.weight": -5.48828125,
            "model.layers.30.input_layernorm.weight": 0.01433563232421875,
            "model.layers.30.post_attention_layernorm.weight": -0.054840087890625,
            "model.layers.31.self_attn.q_proj.weight": -0.1278076171875,
            "model.layers.31.self_attn.k_proj.weight": -0.953125,
            "model.layers.31.self_attn.v_proj.weight": -2.201171875,
            "model.layers.31.self_attn.o_proj.weight": -0.1318359375,
            "model.layers.31.mlp.gate_proj.weight": -0.302734375,
            "model.layers.31.mlp.up_proj.weight": -0.67919921875,
            "model.layers.31.mlp.down_proj.weight": 0.5625,
            "model.layers.31.input_layernorm.weight": -0.7998046875,
            "model.layers.31.post_attention_layernorm.weight": -0.2076416015625,
            "model.norm.weight": 0.01313018798828125,
            "lm_head.weight": 0.71142578125
        },
        "edited_sentence": "The name of the spouse of Ron DeSantis is",
        "edited_sentence_answer": "Carol Chu",
        "NLL": [
            8.74536418914795,
            5.554866313934326,
            3.0751218795776367,
            3.229402780532837,
            3.201695442199707
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 5.46484375,
            "model.layers.0.self_attn.q_proj.weight": 0.1947021484375,
            "model.layers.0.self_attn.k_proj.weight": 0.1512451171875,
            "model.layers.0.self_attn.v_proj.weight": 22.0,
            "model.layers.0.self_attn.o_proj.weight": 0.8740234375,
            "model.layers.0.mlp.gate_proj.weight": -0.0214691162109375,
            "model.layers.0.mlp.up_proj.weight": 0.42431640625,
            "model.layers.0.mlp.down_proj.weight": 0.1107177734375,
            "model.layers.0.input_layernorm.weight": 0.56787109375,
            "model.layers.0.post_attention_layernorm.weight": 0.16259765625,
            "model.layers.1.self_attn.q_proj.weight": 0.06610107421875,
            "model.layers.1.self_attn.k_proj.weight": -0.0048675537109375,
            "model.layers.1.self_attn.v_proj.weight": 43.65625,
            "model.layers.1.self_attn.o_proj.weight": 3.216796875,
            "model.layers.1.mlp.gate_proj.weight": 0.132568359375,
            "model.layers.1.mlp.up_proj.weight": 0.2509765625,
            "model.layers.1.mlp.down_proj.weight": -168.625,
            "model.layers.1.input_layernorm.weight": 0.9140625,
            "model.layers.1.post_attention_layernorm.weight": 0.61767578125,
            "model.layers.2.self_attn.q_proj.weight": 1.234375,
            "model.layers.2.self_attn.k_proj.weight": 0.80126953125,
            "model.layers.2.self_attn.v_proj.weight": 5.14453125,
            "model.layers.2.self_attn.o_proj.weight": 1.7568359375,
            "model.layers.2.mlp.gate_proj.weight": 0.462890625,
            "model.layers.2.mlp.up_proj.weight": 0.5322265625,
            "model.layers.2.mlp.down_proj.weight": 0.76025390625,
            "model.layers.2.input_layernorm.weight": -6.37109375,
            "model.layers.2.post_attention_layernorm.weight": -0.151123046875,
            "model.layers.3.self_attn.q_proj.weight": 2.68359375,
            "model.layers.3.self_attn.k_proj.weight": 1.267578125,
            "model.layers.3.self_attn.v_proj.weight": -5.39453125,
            "model.layers.3.self_attn.o_proj.weight": 0.071533203125,
            "model.layers.3.mlp.gate_proj.weight": 0.2086181640625,
            "model.layers.3.mlp.up_proj.weight": 0.29833984375,
            "model.layers.3.mlp.down_proj.weight": 0.311279296875,
            "model.layers.3.input_layernorm.weight": 6.8203125,
            "model.layers.3.post_attention_layernorm.weight": -0.1248779296875,
            "model.layers.4.self_attn.q_proj.weight": 1.740234375,
            "model.layers.4.self_attn.k_proj.weight": 1.75,
            "model.layers.4.self_attn.v_proj.weight": 9.7734375,
            "model.layers.4.self_attn.o_proj.weight": 0.9228515625,
            "model.layers.4.mlp.gate_proj.weight": 0.306396484375,
            "model.layers.4.mlp.up_proj.weight": 0.35693359375,
            "model.layers.4.mlp.down_proj.weight": 0.91455078125,
            "model.layers.4.input_layernorm.weight": 10.6796875,
            "model.layers.4.post_attention_layernorm.weight": -0.300537109375,
            "model.layers.5.self_attn.q_proj.weight": 0.55517578125,
            "model.layers.5.self_attn.k_proj.weight": 0.189453125,
            "model.layers.5.self_attn.v_proj.weight": 4.3046875,
            "model.layers.5.self_attn.o_proj.weight": 0.250732421875,
            "model.layers.5.mlp.gate_proj.weight": 0.7509765625,
            "model.layers.5.mlp.up_proj.weight": 0.80908203125,
            "model.layers.5.mlp.down_proj.weight": 0.8017578125,
            "model.layers.5.input_layernorm.weight": -19.21875,
            "model.layers.5.post_attention_layernorm.weight": -0.14306640625,
            "model.layers.6.self_attn.q_proj.weight": 2.59765625,
            "model.layers.6.self_attn.k_proj.weight": 1.765625,
            "model.layers.6.self_attn.v_proj.weight": 7.390625,
            "model.layers.6.self_attn.o_proj.weight": 0.270751953125,
            "model.layers.6.mlp.gate_proj.weight": 0.93603515625,
            "model.layers.6.mlp.up_proj.weight": 1.185546875,
            "model.layers.6.mlp.down_proj.weight": 0.48828125,
            "model.layers.6.input_layernorm.weight": -0.09515380859375,
            "model.layers.6.post_attention_layernorm.weight": 0.41162109375,
            "model.layers.7.self_attn.q_proj.weight": 1.5048828125,
            "model.layers.7.self_attn.k_proj.weight": 1.1572265625,
            "model.layers.7.self_attn.v_proj.weight": -3.79296875,
            "model.layers.7.self_attn.o_proj.weight": -0.2337646484375,
            "model.layers.7.mlp.gate_proj.weight": 0.2177734375,
            "model.layers.7.mlp.up_proj.weight": 0.88134765625,
            "model.layers.7.mlp.down_proj.weight": 0.2298583984375,
            "model.layers.7.input_layernorm.weight": 0.133544921875,
            "model.layers.7.post_attention_layernorm.weight": -0.1131591796875,
            "model.layers.8.self_attn.q_proj.weight": 3.5390625,
            "model.layers.8.self_attn.k_proj.weight": 2.892578125,
            "model.layers.8.self_attn.v_proj.weight": 0.1796875,
            "model.layers.8.self_attn.o_proj.weight": 0.20751953125,
            "model.layers.8.mlp.gate_proj.weight": 0.457275390625,
            "model.layers.8.mlp.up_proj.weight": -0.367431640625,
            "model.layers.8.mlp.down_proj.weight": 0.2347412109375,
            "model.layers.8.input_layernorm.weight": 0.2271728515625,
            "model.layers.8.post_attention_layernorm.weight": -0.07177734375,
            "model.layers.9.self_attn.q_proj.weight": -2.322265625,
            "model.layers.9.self_attn.k_proj.weight": -1.7783203125,
            "model.layers.9.self_attn.v_proj.weight": -0.796875,
            "model.layers.9.self_attn.o_proj.weight": 0.264404296875,
            "model.layers.9.mlp.gate_proj.weight": 0.00907135009765625,
            "model.layers.9.mlp.up_proj.weight": 0.73095703125,
            "model.layers.9.mlp.down_proj.weight": 0.0252685546875,
            "model.layers.9.input_layernorm.weight": -4.1015625,
            "model.layers.9.post_attention_layernorm.weight": 0.0623779296875,
            "model.layers.10.self_attn.q_proj.weight": -0.6513671875,
            "model.layers.10.self_attn.k_proj.weight": -0.31884765625,
            "model.layers.10.self_attn.v_proj.weight": 0.74169921875,
            "model.layers.10.self_attn.o_proj.weight": 0.53564453125,
            "model.layers.10.mlp.gate_proj.weight": 0.91650390625,
            "model.layers.10.mlp.up_proj.weight": 1.322265625,
            "model.layers.10.mlp.down_proj.weight": 0.478759765625,
            "model.layers.10.input_layernorm.weight": -3.87890625,
            "model.layers.10.post_attention_layernorm.weight": 0.1212158203125,
            "model.layers.11.self_attn.q_proj.weight": 1.5869140625,
            "model.layers.11.self_attn.k_proj.weight": 0.86328125,
            "model.layers.11.self_attn.v_proj.weight": 17.109375,
            "model.layers.11.self_attn.o_proj.weight": 0.2078857421875,
            "model.layers.11.mlp.gate_proj.weight": 0.65283203125,
            "model.layers.11.mlp.up_proj.weight": 0.333740234375,
            "model.layers.11.mlp.down_proj.weight": -0.05572509765625,
            "model.layers.11.input_layernorm.weight": 0.6435546875,
            "model.layers.11.post_attention_layernorm.weight": 0.007526397705078125,
            "model.layers.12.self_attn.q_proj.weight": 0.398681640625,
            "model.layers.12.self_attn.k_proj.weight": 0.48388671875,
            "model.layers.12.self_attn.v_proj.weight": -0.2261962890625,
            "model.layers.12.self_attn.o_proj.weight": 0.408203125,
            "model.layers.12.mlp.gate_proj.weight": 0.6142578125,
            "model.layers.12.mlp.up_proj.weight": 1.744140625,
            "model.layers.12.mlp.down_proj.weight": 0.23193359375,
            "model.layers.12.input_layernorm.weight": -1.1787109375,
            "model.layers.12.post_attention_layernorm.weight": -0.0186004638671875,
            "model.layers.13.self_attn.q_proj.weight": 0.9833984375,
            "model.layers.13.self_attn.k_proj.weight": 0.63427734375,
            "model.layers.13.self_attn.v_proj.weight": -3.4296875,
            "model.layers.13.self_attn.o_proj.weight": -0.0616455078125,
            "model.layers.13.mlp.gate_proj.weight": 0.455810546875,
            "model.layers.13.mlp.up_proj.weight": 0.237060546875,
            "model.layers.13.mlp.down_proj.weight": 0.287109375,
            "model.layers.13.input_layernorm.weight": 0.324951171875,
            "model.layers.13.post_attention_layernorm.weight": -0.0548095703125,
            "model.layers.14.self_attn.q_proj.weight": 1.0244140625,
            "model.layers.14.self_attn.k_proj.weight": 0.974609375,
            "model.layers.14.self_attn.v_proj.weight": 0.95458984375,
            "model.layers.14.self_attn.o_proj.weight": -0.306396484375,
            "model.layers.14.mlp.gate_proj.weight": -0.76611328125,
            "model.layers.14.mlp.up_proj.weight": -0.96728515625,
            "model.layers.14.mlp.down_proj.weight": 0.56494140625,
            "model.layers.14.input_layernorm.weight": 0.51025390625,
            "model.layers.14.post_attention_layernorm.weight": 0.06890869140625,
            "model.layers.15.self_attn.q_proj.weight": 0.473876953125,
            "model.layers.15.self_attn.k_proj.weight": 0.88916015625,
            "model.layers.15.self_attn.v_proj.weight": 5.51171875,
            "model.layers.15.self_attn.o_proj.weight": 1.375,
            "model.layers.15.mlp.gate_proj.weight": 0.9111328125,
            "model.layers.15.mlp.up_proj.weight": 0.1968994140625,
            "model.layers.15.mlp.down_proj.weight": 2.103515625,
            "model.layers.15.input_layernorm.weight": 3.892578125,
            "model.layers.15.post_attention_layernorm.weight": 0.06817626953125,
            "model.layers.16.self_attn.q_proj.weight": 0.93798828125,
            "model.layers.16.self_attn.k_proj.weight": 1.3447265625,
            "model.layers.16.self_attn.v_proj.weight": 3.859375,
            "model.layers.16.self_attn.o_proj.weight": 0.7568359375,
            "model.layers.16.mlp.gate_proj.weight": 0.243408203125,
            "model.layers.16.mlp.up_proj.weight": 0.50390625,
            "model.layers.16.mlp.down_proj.weight": 1.7626953125,
            "model.layers.16.input_layernorm.weight": 0.330322265625,
            "model.layers.16.post_attention_layernorm.weight": 0.0201263427734375,
            "model.layers.17.self_attn.q_proj.weight": -0.49365234375,
            "model.layers.17.self_attn.k_proj.weight": -0.6181640625,
            "model.layers.17.self_attn.v_proj.weight": 10.578125,
            "model.layers.17.self_attn.o_proj.weight": 0.6884765625,
            "model.layers.17.mlp.gate_proj.weight": 0.315673828125,
            "model.layers.17.mlp.up_proj.weight": 0.491455078125,
            "model.layers.17.mlp.down_proj.weight": 1.51171875,
            "model.layers.17.input_layernorm.weight": 2.599609375,
            "model.layers.17.post_attention_layernorm.weight": -0.05755615234375,
            "model.layers.18.self_attn.q_proj.weight": 1.1826171875,
            "model.layers.18.self_attn.k_proj.weight": 1.2861328125,
            "model.layers.18.self_attn.v_proj.weight": 4.43359375,
            "model.layers.18.self_attn.o_proj.weight": 0.312255859375,
            "model.layers.18.mlp.gate_proj.weight": 0.11492919921875,
            "model.layers.18.mlp.up_proj.weight": -0.28857421875,
            "model.layers.18.mlp.down_proj.weight": 1.3623046875,
            "model.layers.18.input_layernorm.weight": -0.468017578125,
            "model.layers.18.post_attention_layernorm.weight": 0.0190277099609375,
            "model.layers.19.self_attn.q_proj.weight": 1.3154296875,
            "model.layers.19.self_attn.k_proj.weight": 1.1552734375,
            "model.layers.19.self_attn.v_proj.weight": 6.22265625,
            "model.layers.19.self_attn.o_proj.weight": 0.287353515625,
            "model.layers.19.mlp.gate_proj.weight": -0.06561279296875,
            "model.layers.19.mlp.up_proj.weight": 0.0972900390625,
            "model.layers.19.mlp.down_proj.weight": 0.456298828125,
            "model.layers.19.input_layernorm.weight": 1.267578125,
            "model.layers.19.post_attention_layernorm.weight": 0.1595458984375,
            "model.layers.20.self_attn.q_proj.weight": -0.79345703125,
            "model.layers.20.self_attn.k_proj.weight": 0.1993408203125,
            "model.layers.20.self_attn.v_proj.weight": 3.837890625,
            "model.layers.20.self_attn.o_proj.weight": 0.11077880859375,
            "model.layers.20.mlp.gate_proj.weight": -0.6279296875,
            "model.layers.20.mlp.up_proj.weight": -0.279296875,
            "model.layers.20.mlp.down_proj.weight": 0.26123046875,
            "model.layers.20.input_layernorm.weight": 0.49853515625,
            "model.layers.20.post_attention_layernorm.weight": 0.0161895751953125,
            "model.layers.21.self_attn.q_proj.weight": 0.2198486328125,
            "model.layers.21.self_attn.k_proj.weight": 0.06854248046875,
            "model.layers.21.self_attn.v_proj.weight": 0.2398681640625,
            "model.layers.21.self_attn.o_proj.weight": 0.07135009765625,
            "model.layers.21.mlp.gate_proj.weight": -0.07415771484375,
            "model.layers.21.mlp.up_proj.weight": 0.12286376953125,
            "model.layers.21.mlp.down_proj.weight": 0.345703125,
            "model.layers.21.input_layernorm.weight": 0.27099609375,
            "model.layers.21.post_attention_layernorm.weight": 0.0797119140625,
            "model.layers.22.self_attn.q_proj.weight": 0.071044921875,
            "model.layers.22.self_attn.k_proj.weight": 0.0667724609375,
            "model.layers.22.self_attn.v_proj.weight": -0.1575927734375,
            "model.layers.22.self_attn.o_proj.weight": 0.058319091796875,
            "model.layers.22.mlp.gate_proj.weight": -0.0206756591796875,
            "model.layers.22.mlp.up_proj.weight": 0.0572509765625,
            "model.layers.22.mlp.down_proj.weight": 0.369873046875,
            "model.layers.22.input_layernorm.weight": -0.15283203125,
            "model.layers.22.post_attention_layernorm.weight": 0.01316070556640625,
            "model.layers.23.self_attn.q_proj.weight": -0.14794921875,
            "model.layers.23.self_attn.k_proj.weight": -0.1142578125,
            "model.layers.23.self_attn.v_proj.weight": 1.1513671875,
            "model.layers.23.self_attn.o_proj.weight": 0.07208251953125,
            "model.layers.23.mlp.gate_proj.weight": 0.08477783203125,
            "model.layers.23.mlp.up_proj.weight": 0.1678466796875,
            "model.layers.23.mlp.down_proj.weight": 0.1925048828125,
            "model.layers.23.input_layernorm.weight": -0.55712890625,
            "model.layers.23.post_attention_layernorm.weight": -0.006595611572265625,
            "model.layers.24.self_attn.q_proj.weight": -0.25048828125,
            "model.layers.24.self_attn.k_proj.weight": -0.14111328125,
            "model.layers.24.self_attn.v_proj.weight": -0.263427734375,
            "model.layers.24.self_attn.o_proj.weight": 0.032501220703125,
            "model.layers.24.mlp.gate_proj.weight": -0.060577392578125,
            "model.layers.24.mlp.up_proj.weight": 0.08880615234375,
            "model.layers.24.mlp.down_proj.weight": 0.1533203125,
            "model.layers.24.input_layernorm.weight": -0.261962890625,
            "model.layers.24.post_attention_layernorm.weight": 0.00386810302734375,
            "model.layers.25.self_attn.q_proj.weight": -0.173095703125,
            "model.layers.25.self_attn.k_proj.weight": -0.109130859375,
            "model.layers.25.self_attn.v_proj.weight": 0.26416015625,
            "model.layers.25.self_attn.o_proj.weight": 0.0635986328125,
            "model.layers.25.mlp.gate_proj.weight": 0.0772705078125,
            "model.layers.25.mlp.up_proj.weight": -0.130126953125,
            "model.layers.25.mlp.down_proj.weight": 0.1763916015625,
            "model.layers.25.input_layernorm.weight": 0.281982421875,
            "model.layers.25.post_attention_layernorm.weight": 0.016021728515625,
            "model.layers.26.self_attn.q_proj.weight": 0.1826171875,
            "model.layers.26.self_attn.k_proj.weight": 0.2110595703125,
            "model.layers.26.self_attn.v_proj.weight": -0.50732421875,
            "model.layers.26.self_attn.o_proj.weight": 0.097900390625,
            "model.layers.26.mlp.gate_proj.weight": -0.2078857421875,
            "model.layers.26.mlp.up_proj.weight": 0.1099853515625,
            "model.layers.26.mlp.down_proj.weight": 0.08709716796875,
            "model.layers.26.input_layernorm.weight": -0.08575439453125,
            "model.layers.26.post_attention_layernorm.weight": 0.00902557373046875,
            "model.layers.27.self_attn.q_proj.weight": -0.18798828125,
            "model.layers.27.self_attn.k_proj.weight": -0.17431640625,
            "model.layers.27.self_attn.v_proj.weight": 0.09149169921875,
            "model.layers.27.self_attn.o_proj.weight": 0.01690673828125,
            "model.layers.27.mlp.gate_proj.weight": -0.07489013671875,
            "model.layers.27.mlp.up_proj.weight": 0.1412353515625,
            "model.layers.27.mlp.down_proj.weight": 0.346923828125,
            "model.layers.27.input_layernorm.weight": -0.1917724609375,
            "model.layers.27.post_attention_layernorm.weight": 0.008056640625,
            "model.layers.28.self_attn.q_proj.weight": 3.388671875,
            "model.layers.28.self_attn.k_proj.weight": 3.900390625,
            "model.layers.28.self_attn.v_proj.weight": 1.037109375,
            "model.layers.28.self_attn.o_proj.weight": -0.045013427734375,
            "model.layers.28.mlp.gate_proj.weight": -0.455322265625,
            "model.layers.28.mlp.up_proj.weight": 0.06866455078125,
            "model.layers.28.mlp.down_proj.weight": -0.003650665283203125,
            "model.layers.28.input_layernorm.weight": -0.47509765625,
            "model.layers.28.post_attention_layernorm.weight": 0.00034165382385253906,
            "model.layers.29.self_attn.q_proj.weight": -0.5283203125,
            "model.layers.29.self_attn.k_proj.weight": -0.422119140625,
            "model.layers.29.self_attn.v_proj.weight": -0.11004638671875,
            "model.layers.29.self_attn.o_proj.weight": -0.0052032470703125,
            "model.layers.29.mlp.gate_proj.weight": -0.0138092041015625,
            "model.layers.29.mlp.up_proj.weight": 0.062744140625,
            "model.layers.29.mlp.down_proj.weight": 0.587890625,
            "model.layers.29.input_layernorm.weight": -0.06884765625,
            "model.layers.29.post_attention_layernorm.weight": 0.01788330078125,
            "model.layers.30.self_attn.q_proj.weight": -0.1319580078125,
            "model.layers.30.self_attn.k_proj.weight": -0.1898193359375,
            "model.layers.30.self_attn.v_proj.weight": 0.210205078125,
            "model.layers.30.self_attn.o_proj.weight": 0.09759521484375,
            "model.layers.30.mlp.gate_proj.weight": 0.10723876953125,
            "model.layers.30.mlp.up_proj.weight": 0.478515625,
            "model.layers.30.mlp.down_proj.weight": -3.341796875,
            "model.layers.30.input_layernorm.weight": 0.27783203125,
            "model.layers.30.post_attention_layernorm.weight": -0.026702880859375,
            "model.layers.31.self_attn.q_proj.weight": 0.05413818359375,
            "model.layers.31.self_attn.k_proj.weight": 0.0275726318359375,
            "model.layers.31.self_attn.v_proj.weight": -0.005542755126953125,
            "model.layers.31.self_attn.o_proj.weight": 0.032989501953125,
            "model.layers.31.mlp.gate_proj.weight": 0.40478515625,
            "model.layers.31.mlp.up_proj.weight": -1.7705078125,
            "model.layers.31.mlp.down_proj.weight": 2.232421875,
            "model.layers.31.input_layernorm.weight": -0.07623291015625,
            "model.layers.31.post_attention_layernorm.weight": 0.08599853515625,
            "model.norm.weight": 0.00408935546875,
            "lm_head.weight": -6.875
        },
        "edited_sentence": "The name of the spouse of Ron DeSantis is",
        "edited_sentence_answer": "Carol Chu",
        "NLL": [
            8.74536418914795,
            5.554866313934326,
            3.0751218795776367,
            3.229402780532837,
            3.201695442199707
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 31.609375,
            "model.layers.0.self_attn.q_proj.weight": 0.34619140625,
            "model.layers.0.self_attn.k_proj.weight": 0.80126953125,
            "model.layers.0.self_attn.v_proj.weight": -38.75,
            "model.layers.0.self_attn.o_proj.weight": -15.921875,
            "model.layers.0.mlp.gate_proj.weight": -0.1263427734375,
            "model.layers.0.mlp.up_proj.weight": 0.55126953125,
            "model.layers.0.mlp.down_proj.weight": -1.412109375,
            "model.layers.0.input_layernorm.weight": 1.3564453125,
            "model.layers.0.post_attention_layernorm.weight": 13.9921875,
            "model.layers.1.self_attn.q_proj.weight": 0.0238494873046875,
            "model.layers.1.self_attn.k_proj.weight": -0.08154296875,
            "model.layers.1.self_attn.v_proj.weight": -487.0,
            "model.layers.1.self_attn.o_proj.weight": -11.5859375,
            "model.layers.1.mlp.gate_proj.weight": -0.1884765625,
            "model.layers.1.mlp.up_proj.weight": -0.412353515625,
            "model.layers.1.mlp.down_proj.weight": -424.5,
            "model.layers.1.input_layernorm.weight": -5.72265625,
            "model.layers.1.post_attention_layernorm.weight": -0.265625,
            "model.layers.2.self_attn.q_proj.weight": -6.63671875,
            "model.layers.2.self_attn.k_proj.weight": -5.9296875,
            "model.layers.2.self_attn.v_proj.weight": -13.609375,
            "model.layers.2.self_attn.o_proj.weight": -1.6474609375,
            "model.layers.2.mlp.gate_proj.weight": 0.7607421875,
            "model.layers.2.mlp.up_proj.weight": 0.64111328125,
            "model.layers.2.mlp.down_proj.weight": 0.79443359375,
            "model.layers.2.input_layernorm.weight": -46.75,
            "model.layers.2.post_attention_layernorm.weight": 2.26953125,
            "model.layers.3.self_attn.q_proj.weight": 8.2578125,
            "model.layers.3.self_attn.k_proj.weight": 3.458984375,
            "model.layers.3.self_attn.v_proj.weight": 31.40625,
            "model.layers.3.self_attn.o_proj.weight": -0.474853515625,
            "model.layers.3.mlp.gate_proj.weight": 0.4697265625,
            "model.layers.3.mlp.up_proj.weight": 1.7958984375,
            "model.layers.3.mlp.down_proj.weight": -0.296875,
            "model.layers.3.input_layernorm.weight": 6.75,
            "model.layers.3.post_attention_layernorm.weight": -1.3671875,
            "model.layers.4.self_attn.q_proj.weight": -1.2744140625,
            "model.layers.4.self_attn.k_proj.weight": -0.67333984375,
            "model.layers.4.self_attn.v_proj.weight": -27.859375,
            "model.layers.4.self_attn.o_proj.weight": -6.98828125,
            "model.layers.4.mlp.gate_proj.weight": -2.154296875,
            "model.layers.4.mlp.up_proj.weight": -2.04296875,
            "model.layers.4.mlp.down_proj.weight": -0.047210693359375,
            "model.layers.4.input_layernorm.weight": 18.328125,
            "model.layers.4.post_attention_layernorm.weight": 0.72802734375,
            "model.layers.5.self_attn.q_proj.weight": -1.4072265625,
            "model.layers.5.self_attn.k_proj.weight": -1.611328125,
            "model.layers.5.self_attn.v_proj.weight": 20.875,
            "model.layers.5.self_attn.o_proj.weight": -0.8779296875,
            "model.layers.5.mlp.gate_proj.weight": -1.193359375,
            "model.layers.5.mlp.up_proj.weight": -4.4609375,
            "model.layers.5.mlp.down_proj.weight": -2.119140625,
            "model.layers.5.input_layernorm.weight": 17.109375,
            "model.layers.5.post_attention_layernorm.weight": 0.54638671875,
            "model.layers.6.self_attn.q_proj.weight": -5.84375,
            "model.layers.6.self_attn.k_proj.weight": -4.19140625,
            "model.layers.6.self_attn.v_proj.weight": -15.8359375,
            "model.layers.6.self_attn.o_proj.weight": -1.4111328125,
            "model.layers.6.mlp.gate_proj.weight": -0.462646484375,
            "model.layers.6.mlp.up_proj.weight": -1.658203125,
            "model.layers.6.mlp.down_proj.weight": -0.76513671875,
            "model.layers.6.input_layernorm.weight": -0.71337890625,
            "model.layers.6.post_attention_layernorm.weight": -0.1802978515625,
            "model.layers.7.self_attn.q_proj.weight": 1.056640625,
            "model.layers.7.self_attn.k_proj.weight": 0.408203125,
            "model.layers.7.self_attn.v_proj.weight": -9.140625,
            "model.layers.7.self_attn.o_proj.weight": -0.43310546875,
            "model.layers.7.mlp.gate_proj.weight": 0.66748046875,
            "model.layers.7.mlp.up_proj.weight": 0.88330078125,
            "model.layers.7.mlp.down_proj.weight": -0.2666015625,
            "model.layers.7.input_layernorm.weight": 0.324462890625,
            "model.layers.7.post_attention_layernorm.weight": 0.304931640625,
            "model.layers.8.self_attn.q_proj.weight": 2.1015625,
            "model.layers.8.self_attn.k_proj.weight": 2.673828125,
            "model.layers.8.self_attn.v_proj.weight": 12.765625,
            "model.layers.8.self_attn.o_proj.weight": -1.044921875,
            "model.layers.8.mlp.gate_proj.weight": 0.1534423828125,
            "model.layers.8.mlp.up_proj.weight": -0.239501953125,
            "model.layers.8.mlp.down_proj.weight": -0.99462890625,
            "model.layers.8.input_layernorm.weight": 0.80029296875,
            "model.layers.8.post_attention_layernorm.weight": -0.0087127685546875,
            "model.layers.9.self_attn.q_proj.weight": 5.3984375,
            "model.layers.9.self_attn.k_proj.weight": 5.15234375,
            "model.layers.9.self_attn.v_proj.weight": -5.34375,
            "model.layers.9.self_attn.o_proj.weight": -1.56640625,
            "model.layers.9.mlp.gate_proj.weight": -0.46875,
            "model.layers.9.mlp.up_proj.weight": -1.052734375,
            "model.layers.9.mlp.down_proj.weight": -0.97216796875,
            "model.layers.9.input_layernorm.weight": -6.19140625,
            "model.layers.9.post_attention_layernorm.weight": -0.050811767578125,
            "model.layers.10.self_attn.q_proj.weight": -1.0634765625,
            "model.layers.10.self_attn.k_proj.weight": -0.4951171875,
            "model.layers.10.self_attn.v_proj.weight": -13.328125,
            "model.layers.10.self_attn.o_proj.weight": -1.4541015625,
            "model.layers.10.mlp.gate_proj.weight": -1.28515625,
            "model.layers.10.mlp.up_proj.weight": -1.3369140625,
            "model.layers.10.mlp.down_proj.weight": -2.03125,
            "model.layers.10.input_layernorm.weight": -7.09375,
            "model.layers.10.post_attention_layernorm.weight": -0.105224609375,
            "model.layers.11.self_attn.q_proj.weight": -0.2303466796875,
            "model.layers.11.self_attn.k_proj.weight": -0.004730224609375,
            "model.layers.11.self_attn.v_proj.weight": -19.140625,
            "model.layers.11.self_attn.o_proj.weight": -2.49609375,
            "model.layers.11.mlp.gate_proj.weight": -0.292724609375,
            "model.layers.11.mlp.up_proj.weight": -0.5908203125,
            "model.layers.11.mlp.down_proj.weight": -1.5478515625,
            "model.layers.11.input_layernorm.weight": 1.1337890625,
            "model.layers.11.post_attention_layernorm.weight": -0.0124359130859375,
            "model.layers.12.self_attn.q_proj.weight": 1.2666015625,
            "model.layers.12.self_attn.k_proj.weight": 2.119140625,
            "model.layers.12.self_attn.v_proj.weight": -17.328125,
            "model.layers.12.self_attn.o_proj.weight": -2.087890625,
            "model.layers.12.mlp.gate_proj.weight": -1.2392578125,
            "model.layers.12.mlp.up_proj.weight": -1.6640625,
            "model.layers.12.mlp.down_proj.weight": -1.6904296875,
            "model.layers.12.input_layernorm.weight": 1.4462890625,
            "model.layers.12.post_attention_layernorm.weight": -0.035919189453125,
            "model.layers.13.self_attn.q_proj.weight": -1.7109375,
            "model.layers.13.self_attn.k_proj.weight": -1.4052734375,
            "model.layers.13.self_attn.v_proj.weight": -18.40625,
            "model.layers.13.self_attn.o_proj.weight": -1.90234375,
            "model.layers.13.mlp.gate_proj.weight": -1.0576171875,
            "model.layers.13.mlp.up_proj.weight": -2.501953125,
            "model.layers.13.mlp.down_proj.weight": -1.7685546875,
            "model.layers.13.input_layernorm.weight": 2.21484375,
            "model.layers.13.post_attention_layernorm.weight": 0.07586669921875,
            "model.layers.14.self_attn.q_proj.weight": -2.392578125,
            "model.layers.14.self_attn.k_proj.weight": -2.25390625,
            "model.layers.14.self_attn.v_proj.weight": -11.46875,
            "model.layers.14.self_attn.o_proj.weight": -1.1181640625,
            "model.layers.14.mlp.gate_proj.weight": -1.810546875,
            "model.layers.14.mlp.up_proj.weight": -2.68359375,
            "model.layers.14.mlp.down_proj.weight": -2.431640625,
            "model.layers.14.input_layernorm.weight": -0.5439453125,
            "model.layers.14.post_attention_layernorm.weight": -0.1043701171875,
            "model.layers.15.self_attn.q_proj.weight": -0.3388671875,
            "model.layers.15.self_attn.k_proj.weight": -2.326171875,
            "model.layers.15.self_attn.v_proj.weight": -25.703125,
            "model.layers.15.self_attn.o_proj.weight": -2.453125,
            "model.layers.15.mlp.gate_proj.weight": -2.47265625,
            "model.layers.15.mlp.up_proj.weight": -3.568359375,
            "model.layers.15.mlp.down_proj.weight": -3.7734375,
            "model.layers.15.input_layernorm.weight": -0.8662109375,
            "model.layers.15.post_attention_layernorm.weight": -0.09552001953125,
            "model.layers.16.self_attn.q_proj.weight": -5.4609375,
            "model.layers.16.self_attn.k_proj.weight": -3.09765625,
            "model.layers.16.self_attn.v_proj.weight": -18.359375,
            "model.layers.16.self_attn.o_proj.weight": -1.9013671875,
            "model.layers.16.mlp.gate_proj.weight": -1.099609375,
            "model.layers.16.mlp.up_proj.weight": -3.111328125,
            "model.layers.16.mlp.down_proj.weight": -3.255859375,
            "model.layers.16.input_layernorm.weight": -4.109375,
            "model.layers.16.post_attention_layernorm.weight": -0.109130859375,
            "model.layers.17.self_attn.q_proj.weight": -4.1875,
            "model.layers.17.self_attn.k_proj.weight": -4.734375,
            "model.layers.17.self_attn.v_proj.weight": -23.5625,
            "model.layers.17.self_attn.o_proj.weight": -1.10546875,
            "model.layers.17.mlp.gate_proj.weight": -0.7490234375,
            "model.layers.17.mlp.up_proj.weight": -1.5869140625,
            "model.layers.17.mlp.down_proj.weight": -1.4560546875,
            "model.layers.17.input_layernorm.weight": -18.25,
            "model.layers.17.post_attention_layernorm.weight": -0.07708740234375,
            "model.layers.18.self_attn.q_proj.weight": 0.085693359375,
            "model.layers.18.self_attn.k_proj.weight": -0.186279296875,
            "model.layers.18.self_attn.v_proj.weight": -6.796875,
            "model.layers.18.self_attn.o_proj.weight": -0.71728515625,
            "model.layers.18.mlp.gate_proj.weight": -0.420654296875,
            "model.layers.18.mlp.up_proj.weight": 0.29150390625,
            "model.layers.18.mlp.down_proj.weight": -0.57861328125,
            "model.layers.18.input_layernorm.weight": -1.6279296875,
            "model.layers.18.post_attention_layernorm.weight": 0.059234619140625,
            "model.layers.19.self_attn.q_proj.weight": -0.35107421875,
            "model.layers.19.self_attn.k_proj.weight": -0.194580078125,
            "model.layers.19.self_attn.v_proj.weight": -8.3515625,
            "model.layers.19.self_attn.o_proj.weight": -0.446044921875,
            "model.layers.19.mlp.gate_proj.weight": 0.634765625,
            "model.layers.19.mlp.up_proj.weight": 0.29052734375,
            "model.layers.19.mlp.down_proj.weight": -0.396728515625,
            "model.layers.19.input_layernorm.weight": -0.6259765625,
            "model.layers.19.post_attention_layernorm.weight": -0.1883544921875,
            "model.layers.20.self_attn.q_proj.weight": 0.331298828125,
            "model.layers.20.self_attn.k_proj.weight": 0.322021484375,
            "model.layers.20.self_attn.v_proj.weight": -7.421875,
            "model.layers.20.self_attn.o_proj.weight": -0.0819091796875,
            "model.layers.20.mlp.gate_proj.weight": 0.07757568359375,
            "model.layers.20.mlp.up_proj.weight": -0.25146484375,
            "model.layers.20.mlp.down_proj.weight": -0.0811767578125,
            "model.layers.20.input_layernorm.weight": 0.78076171875,
            "model.layers.20.post_attention_layernorm.weight": 0.07666015625,
            "model.layers.21.self_attn.q_proj.weight": -0.3515625,
            "model.layers.21.self_attn.k_proj.weight": -0.1549072265625,
            "model.layers.21.self_attn.v_proj.weight": 2.966796875,
            "model.layers.21.self_attn.o_proj.weight": 0.0281219482421875,
            "model.layers.21.mlp.gate_proj.weight": 0.0933837890625,
            "model.layers.21.mlp.up_proj.weight": -0.05224609375,
            "model.layers.21.mlp.down_proj.weight": 0.1300048828125,
            "model.layers.21.input_layernorm.weight": 0.10418701171875,
            "model.layers.21.post_attention_layernorm.weight": 0.005687713623046875,
            "model.layers.22.self_attn.q_proj.weight": 0.11566162109375,
            "model.layers.22.self_attn.k_proj.weight": 0.106689453125,
            "model.layers.22.self_attn.v_proj.weight": 3.72265625,
            "model.layers.22.self_attn.o_proj.weight": 0.0294952392578125,
            "model.layers.22.mlp.gate_proj.weight": -0.0246124267578125,
            "model.layers.22.mlp.up_proj.weight": -0.2025146484375,
            "model.layers.22.mlp.down_proj.weight": 0.239501953125,
            "model.layers.22.input_layernorm.weight": -0.14111328125,
            "model.layers.22.post_attention_layernorm.weight": -0.0202789306640625,
            "model.layers.23.self_attn.q_proj.weight": 0.2164306640625,
            "model.layers.23.self_attn.k_proj.weight": 0.189208984375,
            "model.layers.23.self_attn.v_proj.weight": 2.51171875,
            "model.layers.23.self_attn.o_proj.weight": 0.0941162109375,
            "model.layers.23.mlp.gate_proj.weight": 0.07855224609375,
            "model.layers.23.mlp.up_proj.weight": 0.513671875,
            "model.layers.23.mlp.down_proj.weight": 0.260986328125,
            "model.layers.23.input_layernorm.weight": 0.685546875,
            "model.layers.23.post_attention_layernorm.weight": 0.01430511474609375,
            "model.layers.24.self_attn.q_proj.weight": -0.2109375,
            "model.layers.24.self_attn.k_proj.weight": -0.16259765625,
            "model.layers.24.self_attn.v_proj.weight": -0.035369873046875,
            "model.layers.24.self_attn.o_proj.weight": -0.01117706298828125,
            "model.layers.24.mlp.gate_proj.weight": 0.0088043212890625,
            "model.layers.24.mlp.up_proj.weight": 0.05523681640625,
            "model.layers.24.mlp.down_proj.weight": 0.271240234375,
            "model.layers.24.input_layernorm.weight": -1.6806640625,
            "model.layers.24.post_attention_layernorm.weight": -0.0066680908203125,
            "model.layers.25.self_attn.q_proj.weight": -0.421142578125,
            "model.layers.25.self_attn.k_proj.weight": -0.3349609375,
            "model.layers.25.self_attn.v_proj.weight": -0.29248046875,
            "model.layers.25.self_attn.o_proj.weight": 0.10028076171875,
            "model.layers.25.mlp.gate_proj.weight": 0.04022216796875,
            "model.layers.25.mlp.up_proj.weight": -0.15380859375,
            "model.layers.25.mlp.down_proj.weight": 0.12060546875,
            "model.layers.25.input_layernorm.weight": 1.669921875,
            "model.layers.25.post_attention_layernorm.weight": 0.0049591064453125,
            "model.layers.26.self_attn.q_proj.weight": -0.10040283203125,
            "model.layers.26.self_attn.k_proj.weight": -0.06854248046875,
            "model.layers.26.self_attn.v_proj.weight": 0.52197265625,
            "model.layers.26.self_attn.o_proj.weight": 0.0634765625,
            "model.layers.26.mlp.gate_proj.weight": -0.03009033203125,
            "model.layers.26.mlp.up_proj.weight": -0.07769775390625,
            "model.layers.26.mlp.down_proj.weight": 0.15576171875,
            "model.layers.26.input_layernorm.weight": 0.0777587890625,
            "model.layers.26.post_attention_layernorm.weight": -0.0269775390625,
            "model.layers.27.self_attn.q_proj.weight": 0.03997802734375,
            "model.layers.27.self_attn.k_proj.weight": 0.0689697265625,
            "model.layers.27.self_attn.v_proj.weight": 0.04913330078125,
            "model.layers.27.self_attn.o_proj.weight": 0.0260772705078125,
            "model.layers.27.mlp.gate_proj.weight": 0.2349853515625,
            "model.layers.27.mlp.up_proj.weight": 0.2315673828125,
            "model.layers.27.mlp.down_proj.weight": 0.371337890625,
            "model.layers.27.input_layernorm.weight": 0.66455078125,
            "model.layers.27.post_attention_layernorm.weight": 0.01114654541015625,
            "model.layers.28.self_attn.q_proj.weight": 0.473388671875,
            "model.layers.28.self_attn.k_proj.weight": 0.53369140625,
            "model.layers.28.self_attn.v_proj.weight": -0.09710693359375,
            "model.layers.28.self_attn.o_proj.weight": 0.0204925537109375,
            "model.layers.28.mlp.gate_proj.weight": -0.17919921875,
            "model.layers.28.mlp.up_proj.weight": -0.12176513671875,
            "model.layers.28.mlp.down_proj.weight": 0.150390625,
            "model.layers.28.input_layernorm.weight": -0.33349609375,
            "model.layers.28.post_attention_layernorm.weight": 0.0043182373046875,
            "model.layers.29.self_attn.q_proj.weight": -0.103515625,
            "model.layers.29.self_attn.k_proj.weight": -0.165771484375,
            "model.layers.29.self_attn.v_proj.weight": 0.039642333984375,
            "model.layers.29.self_attn.o_proj.weight": 0.0021572113037109375,
            "model.layers.29.mlp.gate_proj.weight": 0.0007505416870117188,
            "model.layers.29.mlp.up_proj.weight": 0.042266845703125,
            "model.layers.29.mlp.down_proj.weight": -0.438232421875,
            "model.layers.29.input_layernorm.weight": -0.10345458984375,
            "model.layers.29.post_attention_layernorm.weight": -0.09326171875,
            "model.layers.30.self_attn.q_proj.weight": -0.218505859375,
            "model.layers.30.self_attn.k_proj.weight": -0.10675048828125,
            "model.layers.30.self_attn.v_proj.weight": 1.3828125,
            "model.layers.30.self_attn.o_proj.weight": -0.01036834716796875,
            "model.layers.30.mlp.gate_proj.weight": -0.2257080078125,
            "model.layers.30.mlp.up_proj.weight": 0.1845703125,
            "model.layers.30.mlp.down_proj.weight": 6.52734375,
            "model.layers.30.input_layernorm.weight": 0.3916015625,
            "model.layers.30.post_attention_layernorm.weight": -0.0699462890625,
            "model.layers.31.self_attn.q_proj.weight": 0.177978515625,
            "model.layers.31.self_attn.k_proj.weight": 0.74267578125,
            "model.layers.31.self_attn.v_proj.weight": 0.430908203125,
            "model.layers.31.self_attn.o_proj.weight": 0.1407470703125,
            "model.layers.31.mlp.gate_proj.weight": -0.31591796875,
            "model.layers.31.mlp.up_proj.weight": 0.578125,
            "model.layers.31.mlp.down_proj.weight": 2.451171875,
            "model.layers.31.input_layernorm.weight": -0.0914306640625,
            "model.layers.31.post_attention_layernorm.weight": -0.223876953125,
            "model.norm.weight": -0.05548095703125,
            "lm_head.weight": 1.4833984375
        },
        "edited_sentence": "The name of the spouse of Ron DeSantis is",
        "edited_sentence_answer": "Carol Chu",
        "NLL": [
            8.74536418914795,
            5.554866313934326,
            3.0751218795776367,
            3.229402780532837,
            3.201695442199707
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 8.484375,
            "model.layers.0.self_attn.q_proj.weight": -0.0010509490966796875,
            "model.layers.0.self_attn.k_proj.weight": -0.0261383056640625,
            "model.layers.0.self_attn.v_proj.weight": -46.09375,
            "model.layers.0.self_attn.o_proj.weight": 18.875,
            "model.layers.0.mlp.gate_proj.weight": 0.296142578125,
            "model.layers.0.mlp.up_proj.weight": 0.6044921875,
            "model.layers.0.mlp.down_proj.weight": 2.181640625,
            "model.layers.0.input_layernorm.weight": -0.68212890625,
            "model.layers.0.post_attention_layernorm.weight": 2.111328125,
            "model.layers.1.self_attn.q_proj.weight": -0.0292205810546875,
            "model.layers.1.self_attn.k_proj.weight": -0.0272216796875,
            "model.layers.1.self_attn.v_proj.weight": 145.875,
            "model.layers.1.self_attn.o_proj.weight": 9.4296875,
            "model.layers.1.mlp.gate_proj.weight": 0.7275390625,
            "model.layers.1.mlp.up_proj.weight": 0.8134765625,
            "model.layers.1.mlp.down_proj.weight": 69.5625,
            "model.layers.1.input_layernorm.weight": 5.07421875,
            "model.layers.1.post_attention_layernorm.weight": 0.1495361328125,
            "model.layers.2.self_attn.q_proj.weight": -0.78125,
            "model.layers.2.self_attn.k_proj.weight": -0.2388916015625,
            "model.layers.2.self_attn.v_proj.weight": 16.046875,
            "model.layers.2.self_attn.o_proj.weight": 4.609375,
            "model.layers.2.mlp.gate_proj.weight": 0.99853515625,
            "model.layers.2.mlp.up_proj.weight": 1.5859375,
            "model.layers.2.mlp.down_proj.weight": 2.17578125,
            "model.layers.2.input_layernorm.weight": 13.9375,
            "model.layers.2.post_attention_layernorm.weight": 0.419921875,
            "model.layers.3.self_attn.q_proj.weight": 3.1171875,
            "model.layers.3.self_attn.k_proj.weight": 4.2734375,
            "model.layers.3.self_attn.v_proj.weight": 12.140625,
            "model.layers.3.self_attn.o_proj.weight": 2.958984375,
            "model.layers.3.mlp.gate_proj.weight": 1.3173828125,
            "model.layers.3.mlp.up_proj.weight": 1.1474609375,
            "model.layers.3.mlp.down_proj.weight": 1.484375,
            "model.layers.3.input_layernorm.weight": 3.595703125,
            "model.layers.3.post_attention_layernorm.weight": 0.427490234375,
            "model.layers.4.self_attn.q_proj.weight": 2.1171875,
            "model.layers.4.self_attn.k_proj.weight": 1.91796875,
            "model.layers.4.self_attn.v_proj.weight": 14.953125,
            "model.layers.4.self_attn.o_proj.weight": 4.22265625,
            "model.layers.4.mlp.gate_proj.weight": 1.1865234375,
            "model.layers.4.mlp.up_proj.weight": 2.0546875,
            "model.layers.4.mlp.down_proj.weight": 1.576171875,
            "model.layers.4.input_layernorm.weight": 0.83447265625,
            "model.layers.4.post_attention_layernorm.weight": 0.419677734375,
            "model.layers.5.self_attn.q_proj.weight": -0.380615234375,
            "model.layers.5.self_attn.k_proj.weight": -0.027191162109375,
            "model.layers.5.self_attn.v_proj.weight": 7.0625,
            "model.layers.5.self_attn.o_proj.weight": 0.92724609375,
            "model.layers.5.mlp.gate_proj.weight": 1.07421875,
            "model.layers.5.mlp.up_proj.weight": 1.306640625,
            "model.layers.5.mlp.down_proj.weight": 0.54150390625,
            "model.layers.5.input_layernorm.weight": 8.3125,
            "model.layers.5.post_attention_layernorm.weight": 0.1298828125,
            "model.layers.6.self_attn.q_proj.weight": 2.046875,
            "model.layers.6.self_attn.k_proj.weight": 1.978515625,
            "model.layers.6.self_attn.v_proj.weight": 4.3828125,
            "model.layers.6.self_attn.o_proj.weight": -0.11407470703125,
            "model.layers.6.mlp.gate_proj.weight": 0.6650390625,
            "model.layers.6.mlp.up_proj.weight": 0.0814208984375,
            "model.layers.6.mlp.down_proj.weight": -0.055267333984375,
            "model.layers.6.input_layernorm.weight": 0.265869140625,
            "model.layers.6.post_attention_layernorm.weight": 0.297607421875,
            "model.layers.7.self_attn.q_proj.weight": 1.1630859375,
            "model.layers.7.self_attn.k_proj.weight": 2.45703125,
            "model.layers.7.self_attn.v_proj.weight": 1.23828125,
            "model.layers.7.self_attn.o_proj.weight": -1.4609375,
            "model.layers.7.mlp.gate_proj.weight": -0.791015625,
            "model.layers.7.mlp.up_proj.weight": -0.229736328125,
            "model.layers.7.mlp.down_proj.weight": -1.091796875,
            "model.layers.7.input_layernorm.weight": 0.08038330078125,
            "model.layers.7.post_attention_layernorm.weight": -0.01056671142578125,
            "model.layers.8.self_attn.q_proj.weight": 0.2117919921875,
            "model.layers.8.self_attn.k_proj.weight": 0.2413330078125,
            "model.layers.8.self_attn.v_proj.weight": -4.140625,
            "model.layers.8.self_attn.o_proj.weight": -1.392578125,
            "model.layers.8.mlp.gate_proj.weight": -0.7099609375,
            "model.layers.8.mlp.up_proj.weight": -0.129150390625,
            "model.layers.8.mlp.down_proj.weight": -1.2373046875,
            "model.layers.8.input_layernorm.weight": -0.01837158203125,
            "model.layers.8.post_attention_layernorm.weight": -0.002101898193359375,
            "model.layers.9.self_attn.q_proj.weight": 0.033294677734375,
            "model.layers.9.self_attn.k_proj.weight": 0.2379150390625,
            "model.layers.9.self_attn.v_proj.weight": -8.0859375,
            "model.layers.9.self_attn.o_proj.weight": -2.21484375,
            "model.layers.9.mlp.gate_proj.weight": -0.7548828125,
            "model.layers.9.mlp.up_proj.weight": -1.3896484375,
            "model.layers.9.mlp.down_proj.weight": -1.5126953125,
            "model.layers.9.input_layernorm.weight": 0.450927734375,
            "model.layers.9.post_attention_layernorm.weight": 0.0302581787109375,
            "model.layers.10.self_attn.q_proj.weight": -0.271240234375,
            "model.layers.10.self_attn.k_proj.weight": -0.39794921875,
            "model.layers.10.self_attn.v_proj.weight": -11.9453125,
            "model.layers.10.self_attn.o_proj.weight": -1.732421875,
            "model.layers.10.mlp.gate_proj.weight": -1.16796875,
            "model.layers.10.mlp.up_proj.weight": -2.49609375,
            "model.layers.10.mlp.down_proj.weight": -1.6015625,
            "model.layers.10.input_layernorm.weight": 0.86279296875,
            "model.layers.10.post_attention_layernorm.weight": -0.07122802734375,
            "model.layers.11.self_attn.q_proj.weight": -0.8232421875,
            "model.layers.11.self_attn.k_proj.weight": -0.80517578125,
            "model.layers.11.self_attn.v_proj.weight": -14.890625,
            "model.layers.11.self_attn.o_proj.weight": -1.6337890625,
            "model.layers.11.mlp.gate_proj.weight": -1.2626953125,
            "model.layers.11.mlp.up_proj.weight": -1.34765625,
            "model.layers.11.mlp.down_proj.weight": -1.109375,
            "model.layers.11.input_layernorm.weight": 0.8349609375,
            "model.layers.11.post_attention_layernorm.weight": -0.030059814453125,
            "model.layers.12.self_attn.q_proj.weight": -0.6875,
            "model.layers.12.self_attn.k_proj.weight": -0.52587890625,
            "model.layers.12.self_attn.v_proj.weight": -13.1328125,
            "model.layers.12.self_attn.o_proj.weight": -1.4287109375,
            "model.layers.12.mlp.gate_proj.weight": -1.1787109375,
            "model.layers.12.mlp.up_proj.weight": -2.275390625,
            "model.layers.12.mlp.down_proj.weight": -1.2705078125,
            "model.layers.12.input_layernorm.weight": 0.30078125,
            "model.layers.12.post_attention_layernorm.weight": -0.038818359375,
            "model.layers.13.self_attn.q_proj.weight": -1.09765625,
            "model.layers.13.self_attn.k_proj.weight": -1.0029296875,
            "model.layers.13.self_attn.v_proj.weight": -7.1640625,
            "model.layers.13.self_attn.o_proj.weight": -0.66259765625,
            "model.layers.13.mlp.gate_proj.weight": -0.23876953125,
            "model.layers.13.mlp.up_proj.weight": -1.6171875,
            "model.layers.13.mlp.down_proj.weight": -0.75146484375,
            "model.layers.13.input_layernorm.weight": 0.1978759765625,
            "model.layers.13.post_attention_layernorm.weight": 0.09381103515625,
            "model.layers.14.self_attn.q_proj.weight": 0.229248046875,
            "model.layers.14.self_attn.k_proj.weight": -0.2998046875,
            "model.layers.14.self_attn.v_proj.weight": 0.68408203125,
            "model.layers.14.self_attn.o_proj.weight": -0.471923828125,
            "model.layers.14.mlp.gate_proj.weight": -0.485595703125,
            "model.layers.14.mlp.up_proj.weight": -0.580078125,
            "model.layers.14.mlp.down_proj.weight": -0.5234375,
            "model.layers.14.input_layernorm.weight": 0.244873046875,
            "model.layers.14.post_attention_layernorm.weight": 0.1568603515625,
            "model.layers.15.self_attn.q_proj.weight": 0.55908203125,
            "model.layers.15.self_attn.k_proj.weight": 0.46533203125,
            "model.layers.15.self_attn.v_proj.weight": -2.46875,
            "model.layers.15.self_attn.o_proj.weight": -0.473388671875,
            "model.layers.15.mlp.gate_proj.weight": -0.145263671875,
            "model.layers.15.mlp.up_proj.weight": -0.93359375,
            "model.layers.15.mlp.down_proj.weight": -0.5283203125,
            "model.layers.15.input_layernorm.weight": 0.95166015625,
            "model.layers.15.post_attention_layernorm.weight": 0.0185394287109375,
            "model.layers.16.self_attn.q_proj.weight": 0.003696441650390625,
            "model.layers.16.self_attn.k_proj.weight": 0.168212890625,
            "model.layers.16.self_attn.v_proj.weight": -2.75,
            "model.layers.16.self_attn.o_proj.weight": -0.50341796875,
            "model.layers.16.mlp.gate_proj.weight": -0.5029296875,
            "model.layers.16.mlp.up_proj.weight": -0.7568359375,
            "model.layers.16.mlp.down_proj.weight": -0.6953125,
            "model.layers.16.input_layernorm.weight": -0.740234375,
            "model.layers.16.post_attention_layernorm.weight": -0.00774383544921875,
            "model.layers.17.self_attn.q_proj.weight": -0.9326171875,
            "model.layers.17.self_attn.k_proj.weight": -0.75,
            "model.layers.17.self_attn.v_proj.weight": -1.474609375,
            "model.layers.17.self_attn.o_proj.weight": -0.2415771484375,
            "model.layers.17.mlp.gate_proj.weight": -0.1434326171875,
            "model.layers.17.mlp.up_proj.weight": -0.5751953125,
            "model.layers.17.mlp.down_proj.weight": -0.19140625,
            "model.layers.17.input_layernorm.weight": 0.9306640625,
            "model.layers.17.post_attention_layernorm.weight": 0.041046142578125,
            "model.layers.18.self_attn.q_proj.weight": 0.052032470703125,
            "model.layers.18.self_attn.k_proj.weight": 0.20849609375,
            "model.layers.18.self_attn.v_proj.weight": -1.4091796875,
            "model.layers.18.self_attn.o_proj.weight": -0.13232421875,
            "model.layers.18.mlp.gate_proj.weight": 0.1070556640625,
            "model.layers.18.mlp.up_proj.weight": -0.4306640625,
            "model.layers.18.mlp.down_proj.weight": -0.1181640625,
            "model.layers.18.input_layernorm.weight": -0.197021484375,
            "model.layers.18.post_attention_layernorm.weight": 0.0089874267578125,
            "model.layers.19.self_attn.q_proj.weight": -0.42529296875,
            "model.layers.19.self_attn.k_proj.weight": -0.26171875,
            "model.layers.19.self_attn.v_proj.weight": -0.11663818359375,
            "model.layers.19.self_attn.o_proj.weight": -0.01113128662109375,
            "model.layers.19.mlp.gate_proj.weight": -0.03509521484375,
            "model.layers.19.mlp.up_proj.weight": -0.294921875,
            "model.layers.19.mlp.down_proj.weight": 0.048828125,
            "model.layers.19.input_layernorm.weight": 0.1290283203125,
            "model.layers.19.post_attention_layernorm.weight": 0.013824462890625,
            "model.layers.20.self_attn.q_proj.weight": -0.720703125,
            "model.layers.20.self_attn.k_proj.weight": 0.390869140625,
            "model.layers.20.self_attn.v_proj.weight": 0.83837890625,
            "model.layers.20.self_attn.o_proj.weight": -0.028717041015625,
            "model.layers.20.mlp.gate_proj.weight": -0.006267547607421875,
            "model.layers.20.mlp.up_proj.weight": -0.1646728515625,
            "model.layers.20.mlp.down_proj.weight": -0.086181640625,
            "model.layers.20.input_layernorm.weight": 0.1138916015625,
            "model.layers.20.post_attention_layernorm.weight": -0.05352783203125,
            "model.layers.21.self_attn.q_proj.weight": -0.1246337890625,
            "model.layers.21.self_attn.k_proj.weight": -0.08294677734375,
            "model.layers.21.self_attn.v_proj.weight": 0.094482421875,
            "model.layers.21.self_attn.o_proj.weight": -0.01812744140625,
            "model.layers.21.mlp.gate_proj.weight": 0.033721923828125,
            "model.layers.21.mlp.up_proj.weight": 0.09466552734375,
            "model.layers.21.mlp.down_proj.weight": 0.04644775390625,
            "model.layers.21.input_layernorm.weight": 0.13818359375,
            "model.layers.21.post_attention_layernorm.weight": 0.01702880859375,
            "model.layers.22.self_attn.q_proj.weight": 0.131591796875,
            "model.layers.22.self_attn.k_proj.weight": 0.113525390625,
            "model.layers.22.self_attn.v_proj.weight": -0.134521484375,
            "model.layers.22.self_attn.o_proj.weight": 0.0064239501953125,
            "model.layers.22.mlp.gate_proj.weight": 0.0294342041015625,
            "model.layers.22.mlp.up_proj.weight": 0.040863037109375,
            "model.layers.22.mlp.down_proj.weight": 0.015777587890625,
            "model.layers.22.input_layernorm.weight": -0.1195068359375,
            "model.layers.22.post_attention_layernorm.weight": 0.00855255126953125,
            "model.layers.23.self_attn.q_proj.weight": -0.01177978515625,
            "model.layers.23.self_attn.k_proj.weight": -0.013519287109375,
            "model.layers.23.self_attn.v_proj.weight": 0.11456298828125,
            "model.layers.23.self_attn.o_proj.weight": 0.003814697265625,
            "model.layers.23.mlp.gate_proj.weight": 0.01027679443359375,
            "model.layers.23.mlp.up_proj.weight": 0.058197021484375,
            "model.layers.23.mlp.down_proj.weight": 0.07293701171875,
            "model.layers.23.input_layernorm.weight": -0.24755859375,
            "model.layers.23.post_attention_layernorm.weight": -0.01172637939453125,
            "model.layers.24.self_attn.q_proj.weight": 0.026336669921875,
            "model.layers.24.self_attn.k_proj.weight": 0.035614013671875,
            "model.layers.24.self_attn.v_proj.weight": 0.36669921875,
            "model.layers.24.self_attn.o_proj.weight": 0.0161590576171875,
            "model.layers.24.mlp.gate_proj.weight": 0.06561279296875,
            "model.layers.24.mlp.up_proj.weight": 0.0300445556640625,
            "model.layers.24.mlp.down_proj.weight": 0.065673828125,
            "model.layers.24.input_layernorm.weight": 0.89404296875,
            "model.layers.24.post_attention_layernorm.weight": -0.002105712890625,
            "model.layers.25.self_attn.q_proj.weight": 0.06304931640625,
            "model.layers.25.self_attn.k_proj.weight": 0.02020263671875,
            "model.layers.25.self_attn.v_proj.weight": 0.35595703125,
            "model.layers.25.self_attn.o_proj.weight": -0.002895355224609375,
            "model.layers.25.mlp.gate_proj.weight": -0.03802490234375,
            "model.layers.25.mlp.up_proj.weight": -0.1060791015625,
            "model.layers.25.mlp.down_proj.weight": 0.031585693359375,
            "model.layers.25.input_layernorm.weight": 0.276611328125,
            "model.layers.25.post_attention_layernorm.weight": -0.014739990234375,
            "model.layers.26.self_attn.q_proj.weight": 0.1800537109375,
            "model.layers.26.self_attn.k_proj.weight": 0.14404296875,
            "model.layers.26.self_attn.v_proj.weight": 0.87939453125,
            "model.layers.26.self_attn.o_proj.weight": 0.018218994140625,
            "model.layers.26.mlp.gate_proj.weight": 0.003818511962890625,
            "model.layers.26.mlp.up_proj.weight": -0.04229736328125,
            "model.layers.26.mlp.down_proj.weight": 0.130126953125,
            "model.layers.26.input_layernorm.weight": 0.061065673828125,
            "model.layers.26.post_attention_layernorm.weight": -0.0009636878967285156,
            "model.layers.27.self_attn.q_proj.weight": 0.0112762451171875,
            "model.layers.27.self_attn.k_proj.weight": 0.002529144287109375,
            "model.layers.27.self_attn.v_proj.weight": 0.4423828125,
            "model.layers.27.self_attn.o_proj.weight": 0.035552978515625,
            "model.layers.27.mlp.gate_proj.weight": 0.053924560546875,
            "model.layers.27.mlp.up_proj.weight": -0.052825927734375,
            "model.layers.27.mlp.down_proj.weight": 0.047027587890625,
            "model.layers.27.input_layernorm.weight": 0.3427734375,
            "model.layers.27.post_attention_layernorm.weight": 0.0064239501953125,
            "model.layers.28.self_attn.q_proj.weight": -1.0390625,
            "model.layers.28.self_attn.k_proj.weight": -1.3671875,
            "model.layers.28.self_attn.v_proj.weight": -0.71484375,
            "model.layers.28.self_attn.o_proj.weight": -0.00022411346435546875,
            "model.layers.28.mlp.gate_proj.weight": -0.0098114013671875,
            "model.layers.28.mlp.up_proj.weight": -0.10333251953125,
            "model.layers.28.mlp.down_proj.weight": 0.0867919921875,
            "model.layers.28.input_layernorm.weight": -0.1644287109375,
            "model.layers.28.post_attention_layernorm.weight": -0.00745391845703125,
            "model.layers.29.self_attn.q_proj.weight": 0.162109375,
            "model.layers.29.self_attn.k_proj.weight": -0.007518768310546875,
            "model.layers.29.self_attn.v_proj.weight": -0.2132568359375,
            "model.layers.29.self_attn.o_proj.weight": 0.00017559528350830078,
            "model.layers.29.mlp.gate_proj.weight": 0.0009050369262695312,
            "model.layers.29.mlp.up_proj.weight": -0.1959228515625,
            "model.layers.29.mlp.down_proj.weight": 0.09539794921875,
            "model.layers.29.input_layernorm.weight": -0.07568359375,
            "model.layers.29.post_attention_layernorm.weight": -0.025726318359375,
            "model.layers.30.self_attn.q_proj.weight": -0.1116943359375,
            "model.layers.30.self_attn.k_proj.weight": -0.10760498046875,
            "model.layers.30.self_attn.v_proj.weight": -0.55078125,
            "model.layers.30.self_attn.o_proj.weight": 0.027984619140625,
            "model.layers.30.mlp.gate_proj.weight": -0.20458984375,
            "model.layers.30.mlp.up_proj.weight": -0.5419921875,
            "model.layers.30.mlp.down_proj.weight": -13.59375,
            "model.layers.30.input_layernorm.weight": -0.06304931640625,
            "model.layers.30.post_attention_layernorm.weight": 0.044647216796875,
            "model.layers.31.self_attn.q_proj.weight": -0.318359375,
            "model.layers.31.self_attn.k_proj.weight": -0.84814453125,
            "model.layers.31.self_attn.v_proj.weight": -1.0625,
            "model.layers.31.self_attn.o_proj.weight": -0.0200958251953125,
            "model.layers.31.mlp.gate_proj.weight": -0.05242919921875,
            "model.layers.31.mlp.up_proj.weight": 0.7216796875,
            "model.layers.31.mlp.down_proj.weight": 4.29296875,
            "model.layers.31.input_layernorm.weight": 0.287841796875,
            "model.layers.31.post_attention_layernorm.weight": 0.425048828125,
            "model.norm.weight": -0.0723876953125,
            "lm_head.weight": -0.144775390625
        },
        "edited_sentence": "The name of the spouse of Ron DeSantis is",
        "edited_sentence_answer": "Carol Chu",
        "NLL": [
            8.74536418914795,
            5.554866313934326,
            3.0751218795776367,
            3.229402780532837,
            3.201695442199707
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": -6.453125,
            "model.layers.0.self_attn.q_proj.weight": -0.12432861328125,
            "model.layers.0.self_attn.k_proj.weight": 0.03436279296875,
            "model.layers.0.self_attn.v_proj.weight": -28.859375,
            "model.layers.0.self_attn.o_proj.weight": -22.265625,
            "model.layers.0.mlp.gate_proj.weight": -0.75537109375,
            "model.layers.0.mlp.up_proj.weight": -0.5458984375,
            "model.layers.0.mlp.down_proj.weight": -3.328125,
            "model.layers.0.input_layernorm.weight": -0.70751953125,
            "model.layers.0.post_attention_layernorm.weight": -4.57421875,
            "model.layers.1.self_attn.q_proj.weight": -0.1005859375,
            "model.layers.1.self_attn.k_proj.weight": -0.06298828125,
            "model.layers.1.self_attn.v_proj.weight": -413.75,
            "model.layers.1.self_attn.o_proj.weight": -8.609375,
            "model.layers.1.mlp.gate_proj.weight": -0.472412109375,
            "model.layers.1.mlp.up_proj.weight": -0.34130859375,
            "model.layers.1.mlp.down_proj.weight": -181.75,
            "model.layers.1.input_layernorm.weight": -10.1328125,
            "model.layers.1.post_attention_layernorm.weight": -0.28271484375,
            "model.layers.2.self_attn.q_proj.weight": -0.323974609375,
            "model.layers.2.self_attn.k_proj.weight": -0.08221435546875,
            "model.layers.2.self_attn.v_proj.weight": -1.97265625,
            "model.layers.2.self_attn.o_proj.weight": -1.548828125,
            "model.layers.2.mlp.gate_proj.weight": 0.11102294921875,
            "model.layers.2.mlp.up_proj.weight": 0.030487060546875,
            "model.layers.2.mlp.down_proj.weight": -0.66943359375,
            "model.layers.2.input_layernorm.weight": -25.78125,
            "model.layers.2.post_attention_layernorm.weight": -0.072998046875,
            "model.layers.3.self_attn.q_proj.weight": 2.880859375,
            "model.layers.3.self_attn.k_proj.weight": 3.1875,
            "model.layers.3.self_attn.v_proj.weight": -9.90625,
            "model.layers.3.self_attn.o_proj.weight": -2.916015625,
            "model.layers.3.mlp.gate_proj.weight": -1.04296875,
            "model.layers.3.mlp.up_proj.weight": -1.48828125,
            "model.layers.3.mlp.down_proj.weight": -1.6123046875,
            "model.layers.3.input_layernorm.weight": -0.497314453125,
            "model.layers.3.post_attention_layernorm.weight": -0.08648681640625,
            "model.layers.4.self_attn.q_proj.weight": -1.2958984375,
            "model.layers.4.self_attn.k_proj.weight": -1.05859375,
            "model.layers.4.self_attn.v_proj.weight": -10.7421875,
            "model.layers.4.self_attn.o_proj.weight": -5.390625,
            "model.layers.4.mlp.gate_proj.weight": -1.1279296875,
            "model.layers.4.mlp.up_proj.weight": -1.2900390625,
            "model.layers.4.mlp.down_proj.weight": -2.724609375,
            "model.layers.4.input_layernorm.weight": -11.2578125,
            "model.layers.4.post_attention_layernorm.weight": -0.27001953125,
            "model.layers.5.self_attn.q_proj.weight": 0.11663818359375,
            "model.layers.5.self_attn.k_proj.weight": 0.1539306640625,
            "model.layers.5.self_attn.v_proj.weight": -10.96875,
            "model.layers.5.self_attn.o_proj.weight": -1.8349609375,
            "model.layers.5.mlp.gate_proj.weight": -0.263916015625,
            "model.layers.5.mlp.up_proj.weight": 0.04083251953125,
            "model.layers.5.mlp.down_proj.weight": -2.048828125,
            "model.layers.5.input_layernorm.weight": -5.43359375,
            "model.layers.5.post_attention_layernorm.weight": 0.04437255859375,
            "model.layers.6.self_attn.q_proj.weight": 1.998046875,
            "model.layers.6.self_attn.k_proj.weight": 2.169921875,
            "model.layers.6.self_attn.v_proj.weight": -9.3203125,
            "model.layers.6.self_attn.o_proj.weight": -3.044921875,
            "model.layers.6.mlp.gate_proj.weight": -0.6806640625,
            "model.layers.6.mlp.up_proj.weight": -1.669921875,
            "model.layers.6.mlp.down_proj.weight": -2.841796875,
            "model.layers.6.input_layernorm.weight": -0.38427734375,
            "model.layers.6.post_attention_layernorm.weight": 0.034698486328125,
            "model.layers.7.self_attn.q_proj.weight": -1.1044921875,
            "model.layers.7.self_attn.k_proj.weight": -1.0400390625,
            "model.layers.7.self_attn.v_proj.weight": -17.78125,
            "model.layers.7.self_attn.o_proj.weight": -3.05078125,
            "model.layers.7.mlp.gate_proj.weight": -1.19140625,
            "model.layers.7.mlp.up_proj.weight": -1.90234375,
            "model.layers.7.mlp.down_proj.weight": -2.3046875,
            "model.layers.7.input_layernorm.weight": 0.1602783203125,
            "model.layers.7.post_attention_layernorm.weight": -0.07366943359375,
            "model.layers.8.self_attn.q_proj.weight": -1.1259765625,
            "model.layers.8.self_attn.k_proj.weight": -1.052734375,
            "model.layers.8.self_attn.v_proj.weight": -16.921875,
            "model.layers.8.self_attn.o_proj.weight": -3.833984375,
            "model.layers.8.mlp.gate_proj.weight": -1.2568359375,
            "model.layers.8.mlp.up_proj.weight": -3.150390625,
            "model.layers.8.mlp.down_proj.weight": -2.55078125,
            "model.layers.8.input_layernorm.weight": 0.1724853515625,
            "model.layers.8.post_attention_layernorm.weight": -0.04437255859375,
            "model.layers.9.self_attn.q_proj.weight": -0.026153564453125,
            "model.layers.9.self_attn.k_proj.weight": 0.5390625,
            "model.layers.9.self_attn.v_proj.weight": -21.0,
            "model.layers.9.self_attn.o_proj.weight": -3.419921875,
            "model.layers.9.mlp.gate_proj.weight": -1.3525390625,
            "model.layers.9.mlp.up_proj.weight": -2.947265625,
            "model.layers.9.mlp.down_proj.weight": -2.578125,
            "model.layers.9.input_layernorm.weight": 5.80859375,
            "model.layers.9.post_attention_layernorm.weight": 0.0653076171875,
            "model.layers.10.self_attn.q_proj.weight": 0.01971435546875,
            "model.layers.10.self_attn.k_proj.weight": -0.0126800537109375,
            "model.layers.10.self_attn.v_proj.weight": -19.328125,
            "model.layers.10.self_attn.o_proj.weight": -2.896484375,
            "model.layers.10.mlp.gate_proj.weight": -1.9384765625,
            "model.layers.10.mlp.up_proj.weight": -3.017578125,
            "model.layers.10.mlp.down_proj.weight": -2.87109375,
            "model.layers.10.input_layernorm.weight": -1.2587890625,
            "model.layers.10.post_attention_layernorm.weight": 0.0301055908203125,
            "model.layers.11.self_attn.q_proj.weight": -1.3798828125,
            "model.layers.11.self_attn.k_proj.weight": -1.0986328125,
            "model.layers.11.self_attn.v_proj.weight": -29.453125,
            "model.layers.11.self_attn.o_proj.weight": -3.619140625,
            "model.layers.11.mlp.gate_proj.weight": -1.9052734375,
            "model.layers.11.mlp.up_proj.weight": -2.642578125,
            "model.layers.11.mlp.down_proj.weight": -3.001953125,
            "model.layers.11.input_layernorm.weight": 1.29296875,
            "model.layers.11.post_attention_layernorm.weight": 0.060455322265625,
            "model.layers.12.self_attn.q_proj.weight": -2.92578125,
            "model.layers.12.self_attn.k_proj.weight": -1.765625,
            "model.layers.12.self_attn.v_proj.weight": -23.5,
            "model.layers.12.self_attn.o_proj.weight": -4.90625,
            "model.layers.12.mlp.gate_proj.weight": -2.853515625,
            "model.layers.12.mlp.up_proj.weight": -3.701171875,
            "model.layers.12.mlp.down_proj.weight": -4.2734375,
            "model.layers.12.input_layernorm.weight": 0.64111328125,
            "model.layers.12.post_attention_layernorm.weight": -0.037750244140625,
            "model.layers.13.self_attn.q_proj.weight": -0.52294921875,
            "model.layers.13.self_attn.k_proj.weight": -0.603515625,
            "model.layers.13.self_attn.v_proj.weight": -23.171875,
            "model.layers.13.self_attn.o_proj.weight": -3.728515625,
            "model.layers.13.mlp.gate_proj.weight": -1.47265625,
            "model.layers.13.mlp.up_proj.weight": -5.4375,
            "model.layers.13.mlp.down_proj.weight": -2.27734375,
            "model.layers.13.input_layernorm.weight": 2.330078125,
            "model.layers.13.post_attention_layernorm.weight": -0.139892578125,
            "model.layers.14.self_attn.q_proj.weight": -0.892578125,
            "model.layers.14.self_attn.k_proj.weight": -0.5791015625,
            "model.layers.14.self_attn.v_proj.weight": -26.453125,
            "model.layers.14.self_attn.o_proj.weight": -3.12890625,
            "model.layers.14.mlp.gate_proj.weight": -1.75390625,
            "model.layers.14.mlp.up_proj.weight": -1.79296875,
            "model.layers.14.mlp.down_proj.weight": -1.8271484375,
            "model.layers.14.input_layernorm.weight": 1.1494140625,
            "model.layers.14.post_attention_layernorm.weight": 0.17138671875,
            "model.layers.15.self_attn.q_proj.weight": -4.7265625,
            "model.layers.15.self_attn.k_proj.weight": -3.109375,
            "model.layers.15.self_attn.v_proj.weight": -12.234375,
            "model.layers.15.self_attn.o_proj.weight": -1.2119140625,
            "model.layers.15.mlp.gate_proj.weight": -0.1605224609375,
            "model.layers.15.mlp.up_proj.weight": -2.3515625,
            "model.layers.15.mlp.down_proj.weight": -1.3779296875,
            "model.layers.15.input_layernorm.weight": 1.4375,
            "model.layers.15.post_attention_layernorm.weight": 0.1990966796875,
            "model.layers.16.self_attn.q_proj.weight": 1.38671875,
            "model.layers.16.self_attn.k_proj.weight": 2.11328125,
            "model.layers.16.self_attn.v_proj.weight": -4.94140625,
            "model.layers.16.self_attn.o_proj.weight": -1.1669921875,
            "model.layers.16.mlp.gate_proj.weight": -1.0458984375,
            "model.layers.16.mlp.up_proj.weight": -1.2177734375,
            "model.layers.16.mlp.down_proj.weight": -0.51318359375,
            "model.layers.16.input_layernorm.weight": 1.1435546875,
            "model.layers.16.post_attention_layernorm.weight": 0.01198577880859375,
            "model.layers.17.self_attn.q_proj.weight": -0.329345703125,
            "model.layers.17.self_attn.k_proj.weight": -1.2001953125,
            "model.layers.17.self_attn.v_proj.weight": -0.072265625,
            "model.layers.17.self_attn.o_proj.weight": -0.274658203125,
            "model.layers.17.mlp.gate_proj.weight": -0.317138671875,
            "model.layers.17.mlp.up_proj.weight": -0.92919921875,
            "model.layers.17.mlp.down_proj.weight": -0.489501953125,
            "model.layers.17.input_layernorm.weight": -2.806640625,
            "model.layers.17.post_attention_layernorm.weight": -0.2320556640625,
            "model.layers.18.self_attn.q_proj.weight": 0.67919921875,
            "model.layers.18.self_attn.k_proj.weight": 0.72314453125,
            "model.layers.18.self_attn.v_proj.weight": -3.109375,
            "model.layers.18.self_attn.o_proj.weight": -0.04791259765625,
            "model.layers.18.mlp.gate_proj.weight": -0.1170654296875,
            "model.layers.18.mlp.up_proj.weight": -0.55322265625,
            "model.layers.18.mlp.down_proj.weight": 0.32958984375,
            "model.layers.18.input_layernorm.weight": 0.33154296875,
            "model.layers.18.post_attention_layernorm.weight": 0.032867431640625,
            "model.layers.19.self_attn.q_proj.weight": 0.3076171875,
            "model.layers.19.self_attn.k_proj.weight": 0.0889892578125,
            "model.layers.19.self_attn.v_proj.weight": 0.099365234375,
            "model.layers.19.self_attn.o_proj.weight": 0.1683349609375,
            "model.layers.19.mlp.gate_proj.weight": -0.67431640625,
            "model.layers.19.mlp.up_proj.weight": -0.421142578125,
            "model.layers.19.mlp.down_proj.weight": 0.174072265625,
            "model.layers.19.input_layernorm.weight": -0.0103759765625,
            "model.layers.19.post_attention_layernorm.weight": 0.034515380859375,
            "model.layers.20.self_attn.q_proj.weight": 0.156494140625,
            "model.layers.20.self_attn.k_proj.weight": 1.052734375,
            "model.layers.20.self_attn.v_proj.weight": -1.0673828125,
            "model.layers.20.self_attn.o_proj.weight": 0.0230865478515625,
            "model.layers.20.mlp.gate_proj.weight": 0.06793212890625,
            "model.layers.20.mlp.up_proj.weight": -0.2646484375,
            "model.layers.20.mlp.down_proj.weight": -0.31298828125,
            "model.layers.20.input_layernorm.weight": 0.982421875,
            "model.layers.20.post_attention_layernorm.weight": 0.0098419189453125,
            "model.layers.21.self_attn.q_proj.weight": -0.33544921875,
            "model.layers.21.self_attn.k_proj.weight": -0.25732421875,
            "model.layers.21.self_attn.v_proj.weight": -0.650390625,
            "model.layers.21.self_attn.o_proj.weight": -0.006977081298828125,
            "model.layers.21.mlp.gate_proj.weight": -0.006256103515625,
            "model.layers.21.mlp.up_proj.weight": -0.1885986328125,
            "model.layers.21.mlp.down_proj.weight": -0.134033203125,
            "model.layers.21.input_layernorm.weight": 0.298583984375,
            "model.layers.21.post_attention_layernorm.weight": 0.0323486328125,
            "model.layers.22.self_attn.q_proj.weight": -0.05682373046875,
            "model.layers.22.self_attn.k_proj.weight": -0.0099639892578125,
            "model.layers.22.self_attn.v_proj.weight": -2.060546875,
            "model.layers.22.self_attn.o_proj.weight": -0.0092315673828125,
            "model.layers.22.mlp.gate_proj.weight": -0.06500244140625,
            "model.layers.22.mlp.up_proj.weight": -0.040252685546875,
            "model.layers.22.mlp.down_proj.weight": -0.00540924072265625,
            "model.layers.22.input_layernorm.weight": 0.21875,
            "model.layers.22.post_attention_layernorm.weight": -0.0455322265625,
            "model.layers.23.self_attn.q_proj.weight": 0.1385498046875,
            "model.layers.23.self_attn.k_proj.weight": 0.033477783203125,
            "model.layers.23.self_attn.v_proj.weight": 1.3642578125,
            "model.layers.23.self_attn.o_proj.weight": 0.01436614990234375,
            "model.layers.23.mlp.gate_proj.weight": -0.008209228515625,
            "model.layers.23.mlp.up_proj.weight": -0.291015625,
            "model.layers.23.mlp.down_proj.weight": -0.017913818359375,
            "model.layers.23.input_layernorm.weight": -0.050384521484375,
            "model.layers.23.post_attention_layernorm.weight": -0.0142974853515625,
            "model.layers.24.self_attn.q_proj.weight": -0.0226898193359375,
            "model.layers.24.self_attn.k_proj.weight": -0.032806396484375,
            "model.layers.24.self_attn.v_proj.weight": 0.305419921875,
            "model.layers.24.self_attn.o_proj.weight": -0.029541015625,
            "model.layers.24.mlp.gate_proj.weight": 0.0279541015625,
            "model.layers.24.mlp.up_proj.weight": 0.11236572265625,
            "model.layers.24.mlp.down_proj.weight": -0.037567138671875,
            "model.layers.24.input_layernorm.weight": -0.3994140625,
            "model.layers.24.post_attention_layernorm.weight": -0.01708984375,
            "model.layers.25.self_attn.q_proj.weight": 0.272216796875,
            "model.layers.25.self_attn.k_proj.weight": 0.1707763671875,
            "model.layers.25.self_attn.v_proj.weight": -0.43212890625,
            "model.layers.25.self_attn.o_proj.weight": -0.00634002685546875,
            "model.layers.25.mlp.gate_proj.weight": -0.1754150390625,
            "model.layers.25.mlp.up_proj.weight": -0.1649169921875,
            "model.layers.25.mlp.down_proj.weight": -0.053955078125,
            "model.layers.25.input_layernorm.weight": 0.09698486328125,
            "model.layers.25.post_attention_layernorm.weight": 0.003955841064453125,
            "model.layers.26.self_attn.q_proj.weight": 0.7734375,
            "model.layers.26.self_attn.k_proj.weight": 0.2100830078125,
            "model.layers.26.self_attn.v_proj.weight": -0.1651611328125,
            "model.layers.26.self_attn.o_proj.weight": -0.0174102783203125,
            "model.layers.26.mlp.gate_proj.weight": 0.031097412109375,
            "model.layers.26.mlp.up_proj.weight": 0.13134765625,
            "model.layers.26.mlp.down_proj.weight": -0.00836944580078125,
            "model.layers.26.input_layernorm.weight": 0.207763671875,
            "model.layers.26.post_attention_layernorm.weight": -0.015228271484375,
            "model.layers.27.self_attn.q_proj.weight": -0.0201873779296875,
            "model.layers.27.self_attn.k_proj.weight": -0.0826416015625,
            "model.layers.27.self_attn.v_proj.weight": -0.122802734375,
            "model.layers.27.self_attn.o_proj.weight": -0.01291656494140625,
            "model.layers.27.mlp.gate_proj.weight": 0.1654052734375,
            "model.layers.27.mlp.up_proj.weight": -0.1531982421875,
            "model.layers.27.mlp.down_proj.weight": -0.0733642578125,
            "model.layers.27.input_layernorm.weight": 0.0230865478515625,
            "model.layers.27.post_attention_layernorm.weight": -0.005397796630859375,
            "model.layers.28.self_attn.q_proj.weight": -0.4951171875,
            "model.layers.28.self_attn.k_proj.weight": -0.609375,
            "model.layers.28.self_attn.v_proj.weight": 0.5068359375,
            "model.layers.28.self_attn.o_proj.weight": 0.03350830078125,
            "model.layers.28.mlp.gate_proj.weight": 0.01187896728515625,
            "model.layers.28.mlp.up_proj.weight": 0.10736083984375,
            "model.layers.28.mlp.down_proj.weight": 0.416748046875,
            "model.layers.28.input_layernorm.weight": -0.61181640625,
            "model.layers.28.post_attention_layernorm.weight": 0.00225830078125,
            "model.layers.29.self_attn.q_proj.weight": 0.31201171875,
            "model.layers.29.self_attn.k_proj.weight": 0.0657958984375,
            "model.layers.29.self_attn.v_proj.weight": 0.2325439453125,
            "model.layers.29.self_attn.o_proj.weight": 0.01163482666015625,
            "model.layers.29.mlp.gate_proj.weight": 0.005428314208984375,
            "model.layers.29.mlp.up_proj.weight": -0.07928466796875,
            "model.layers.29.mlp.down_proj.weight": 0.2236328125,
            "model.layers.29.input_layernorm.weight": 0.07855224609375,
            "model.layers.29.post_attention_layernorm.weight": -0.0128936767578125,
            "model.layers.30.self_attn.q_proj.weight": 0.0223846435546875,
            "model.layers.30.self_attn.k_proj.weight": 0.04510498046875,
            "model.layers.30.self_attn.v_proj.weight": -0.30224609375,
            "model.layers.30.self_attn.o_proj.weight": 0.01126861572265625,
            "model.layers.30.mlp.gate_proj.weight": 0.252197265625,
            "model.layers.30.mlp.up_proj.weight": 0.179931640625,
            "model.layers.30.mlp.down_proj.weight": -0.71435546875,
            "model.layers.30.input_layernorm.weight": -0.1536865234375,
            "model.layers.30.post_attention_layernorm.weight": 0.0219879150390625,
            "model.layers.31.self_attn.q_proj.weight": -0.0010433197021484375,
            "model.layers.31.self_attn.k_proj.weight": -0.10284423828125,
            "model.layers.31.self_attn.v_proj.weight": -0.1097412109375,
            "model.layers.31.self_attn.o_proj.weight": -0.042755126953125,
            "model.layers.31.mlp.gate_proj.weight": 0.016754150390625,
            "model.layers.31.mlp.up_proj.weight": 0.268310546875,
            "model.layers.31.mlp.down_proj.weight": -0.50634765625,
            "model.layers.31.input_layernorm.weight": 0.221435546875,
            "model.layers.31.post_attention_layernorm.weight": 0.1143798828125,
            "model.norm.weight": -0.05206298828125,
            "lm_head.weight": 1.0546875
        },
        "edited_sentence": "The name of the spouse of Ron DeSantis is",
        "edited_sentence_answer": "Carol Chu",
        "NLL": [
            8.74536418914795,
            5.554866313934326,
            3.0751218795776367,
            3.229402780532837,
            3.201695442199707
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 2.9375,
            "model.layers.0.self_attn.q_proj.weight": 0.01202392578125,
            "model.layers.0.self_attn.k_proj.weight": 0.07733154296875,
            "model.layers.0.self_attn.v_proj.weight": 2.673828125,
            "model.layers.0.self_attn.o_proj.weight": -0.572265625,
            "model.layers.0.mlp.gate_proj.weight": -0.01392364501953125,
            "model.layers.0.mlp.up_proj.weight": 0.02899169921875,
            "model.layers.0.mlp.down_proj.weight": -0.052154541015625,
            "model.layers.0.input_layernorm.weight": 0.1517333984375,
            "model.layers.0.post_attention_layernorm.weight": 0.1978759765625,
            "model.layers.1.self_attn.q_proj.weight": -0.01617431640625,
            "model.layers.1.self_attn.k_proj.weight": -0.00858306884765625,
            "model.layers.1.self_attn.v_proj.weight": 11.8125,
            "model.layers.1.self_attn.o_proj.weight": -0.1572265625,
            "model.layers.1.mlp.gate_proj.weight": 0.07257080078125,
            "model.layers.1.mlp.up_proj.weight": 0.111572265625,
            "model.layers.1.mlp.down_proj.weight": -33.875,
            "model.layers.1.input_layernorm.weight": 0.41796875,
            "model.layers.1.post_attention_layernorm.weight": 0.18603515625,
            "model.layers.2.self_attn.q_proj.weight": 0.052886962890625,
            "model.layers.2.self_attn.k_proj.weight": 0.04754638671875,
            "model.layers.2.self_attn.v_proj.weight": -0.68017578125,
            "model.layers.2.self_attn.o_proj.weight": -0.25634765625,
            "model.layers.2.mlp.gate_proj.weight": -0.14892578125,
            "model.layers.2.mlp.up_proj.weight": -0.213623046875,
            "model.layers.2.mlp.down_proj.weight": -0.27294921875,
            "model.layers.2.input_layernorm.weight": -1.0830078125,
            "model.layers.2.post_attention_layernorm.weight": 0.030792236328125,
            "model.layers.3.self_attn.q_proj.weight": 0.0309906005859375,
            "model.layers.3.self_attn.k_proj.weight": -0.0521240234375,
            "model.layers.3.self_attn.v_proj.weight": 0.4853515625,
            "model.layers.3.self_attn.o_proj.weight": -0.12103271484375,
            "model.layers.3.mlp.gate_proj.weight": -0.0408935546875,
            "model.layers.3.mlp.up_proj.weight": -0.057037353515625,
            "model.layers.3.mlp.down_proj.weight": -0.1419677734375,
            "model.layers.3.input_layernorm.weight": -0.42529296875,
            "model.layers.3.post_attention_layernorm.weight": 0.0252532958984375,
            "model.layers.4.self_attn.q_proj.weight": 0.034942626953125,
            "model.layers.4.self_attn.k_proj.weight": 0.09197998046875,
            "model.layers.4.self_attn.v_proj.weight": -1.0927734375,
            "model.layers.4.self_attn.o_proj.weight": -0.400634765625,
            "model.layers.4.mlp.gate_proj.weight": -0.1514892578125,
            "model.layers.4.mlp.up_proj.weight": -0.182861328125,
            "model.layers.4.mlp.down_proj.weight": -0.295654296875,
            "model.layers.4.input_layernorm.weight": -0.0204620361328125,
            "model.layers.4.post_attention_layernorm.weight": 0.0389404296875,
            "model.layers.5.self_attn.q_proj.weight": -0.1705322265625,
            "model.layers.5.self_attn.k_proj.weight": -0.028106689453125,
            "model.layers.5.self_attn.v_proj.weight": -0.52685546875,
            "model.layers.5.self_attn.o_proj.weight": -0.10797119140625,
            "model.layers.5.mlp.gate_proj.weight": -0.1536865234375,
            "model.layers.5.mlp.up_proj.weight": -0.1378173828125,
            "model.layers.5.mlp.down_proj.weight": -0.261474609375,
            "model.layers.5.input_layernorm.weight": 0.2744140625,
            "model.layers.5.post_attention_layernorm.weight": -0.04815673828125,
            "model.layers.6.self_attn.q_proj.weight": 0.006832122802734375,
            "model.layers.6.self_attn.k_proj.weight": -0.1488037109375,
            "model.layers.6.self_attn.v_proj.weight": -0.451416015625,
            "model.layers.6.self_attn.o_proj.weight": -0.125,
            "model.layers.6.mlp.gate_proj.weight": -0.07598876953125,
            "model.layers.6.mlp.up_proj.weight": -0.0082855224609375,
            "model.layers.6.mlp.down_proj.weight": -0.252685546875,
            "model.layers.6.input_layernorm.weight": 0.04742431640625,
            "model.layers.6.post_attention_layernorm.weight": 0.01117706298828125,
            "model.layers.7.self_attn.q_proj.weight": -0.10150146484375,
            "model.layers.7.self_attn.k_proj.weight": -0.169921875,
            "model.layers.7.self_attn.v_proj.weight": -0.486328125,
            "model.layers.7.self_attn.o_proj.weight": -0.1572265625,
            "model.layers.7.mlp.gate_proj.weight": -0.14892578125,
            "model.layers.7.mlp.up_proj.weight": -0.21923828125,
            "model.layers.7.mlp.down_proj.weight": -0.192626953125,
            "model.layers.7.input_layernorm.weight": 0.344482421875,
            "model.layers.7.post_attention_layernorm.weight": -0.0065765380859375,
            "model.layers.8.self_attn.q_proj.weight": -0.10198974609375,
            "model.layers.8.self_attn.k_proj.weight": -0.10076904296875,
            "model.layers.8.self_attn.v_proj.weight": -1.0732421875,
            "model.layers.8.self_attn.o_proj.weight": -0.2208251953125,
            "model.layers.8.mlp.gate_proj.weight": -0.18310546875,
            "model.layers.8.mlp.up_proj.weight": -0.2861328125,
            "model.layers.8.mlp.down_proj.weight": -0.1705322265625,
            "model.layers.8.input_layernorm.weight": -0.5244140625,
            "model.layers.8.post_attention_layernorm.weight": -0.0028076171875,
            "model.layers.9.self_attn.q_proj.weight": -0.01605224609375,
            "model.layers.9.self_attn.k_proj.weight": 0.028472900390625,
            "model.layers.9.self_attn.v_proj.weight": -1.0966796875,
            "model.layers.9.self_attn.o_proj.weight": -0.123046875,
            "model.layers.9.mlp.gate_proj.weight": -0.09112548828125,
            "model.layers.9.mlp.up_proj.weight": -0.1982421875,
            "model.layers.9.mlp.down_proj.weight": -0.11297607421875,
            "model.layers.9.input_layernorm.weight": -0.164794921875,
            "model.layers.9.post_attention_layernorm.weight": -0.00681304931640625,
            "model.layers.10.self_attn.q_proj.weight": 0.0538330078125,
            "model.layers.10.self_attn.k_proj.weight": 0.045867919921875,
            "model.layers.10.self_attn.v_proj.weight": -0.953125,
            "model.layers.10.self_attn.o_proj.weight": -0.09979248046875,
            "model.layers.10.mlp.gate_proj.weight": -0.076171875,
            "model.layers.10.mlp.up_proj.weight": -0.2080078125,
            "model.layers.10.mlp.down_proj.weight": -0.1624755859375,
            "model.layers.10.input_layernorm.weight": 0.0716552734375,
            "model.layers.10.post_attention_layernorm.weight": 0.0006928443908691406,
            "model.layers.11.self_attn.q_proj.weight": -0.09674072265625,
            "model.layers.11.self_attn.k_proj.weight": -0.08880615234375,
            "model.layers.11.self_attn.v_proj.weight": -0.828125,
            "model.layers.11.self_attn.o_proj.weight": -0.10150146484375,
            "model.layers.11.mlp.gate_proj.weight": -0.1414794921875,
            "model.layers.11.mlp.up_proj.weight": -0.18603515625,
            "model.layers.11.mlp.down_proj.weight": -0.1220703125,
            "model.layers.11.input_layernorm.weight": 0.08624267578125,
            "model.layers.11.post_attention_layernorm.weight": -0.0083465576171875,
            "model.layers.12.self_attn.q_proj.weight": -0.056427001953125,
            "model.layers.12.self_attn.k_proj.weight": -0.05291748046875,
            "model.layers.12.self_attn.v_proj.weight": -0.80517578125,
            "model.layers.12.self_attn.o_proj.weight": -0.08154296875,
            "model.layers.12.mlp.gate_proj.weight": -0.0875244140625,
            "model.layers.12.mlp.up_proj.weight": -0.09796142578125,
            "model.layers.12.mlp.down_proj.weight": -0.11810302734375,
            "model.layers.12.input_layernorm.weight": -0.048126220703125,
            "model.layers.12.post_attention_layernorm.weight": 0.0011386871337890625,
            "model.layers.13.self_attn.q_proj.weight": -0.0169677734375,
            "model.layers.13.self_attn.k_proj.weight": -0.04693603515625,
            "model.layers.13.self_attn.v_proj.weight": -0.36279296875,
            "model.layers.13.self_attn.o_proj.weight": -0.041351318359375,
            "model.layers.13.mlp.gate_proj.weight": -0.09637451171875,
            "model.layers.13.mlp.up_proj.weight": -0.1639404296875,
            "model.layers.13.mlp.down_proj.weight": -0.1368408203125,
            "model.layers.13.input_layernorm.weight": -0.0168304443359375,
            "model.layers.13.post_attention_layernorm.weight": -0.005603790283203125,
            "model.layers.14.self_attn.q_proj.weight": -0.09197998046875,
            "model.layers.14.self_attn.k_proj.weight": -0.03485107421875,
            "model.layers.14.self_attn.v_proj.weight": -1.1044921875,
            "model.layers.14.self_attn.o_proj.weight": -0.1756591796875,
            "model.layers.14.mlp.gate_proj.weight": -0.0921630859375,
            "model.layers.14.mlp.up_proj.weight": -0.020172119140625,
            "model.layers.14.mlp.down_proj.weight": -0.10040283203125,
            "model.layers.14.input_layernorm.weight": 0.036773681640625,
            "model.layers.14.post_attention_layernorm.weight": 0.005825042724609375,
            "model.layers.15.self_attn.q_proj.weight": -0.1104736328125,
            "model.layers.15.self_attn.k_proj.weight": -0.05792236328125,
            "model.layers.15.self_attn.v_proj.weight": -0.31494140625,
            "model.layers.15.self_attn.o_proj.weight": -0.048980712890625,
            "model.layers.15.mlp.gate_proj.weight": -0.072265625,
            "model.layers.15.mlp.up_proj.weight": -0.206787109375,
            "model.layers.15.mlp.down_proj.weight": -0.08038330078125,
            "model.layers.15.input_layernorm.weight": 0.2071533203125,
            "model.layers.15.post_attention_layernorm.weight": 0.0035762786865234375,
            "model.layers.16.self_attn.q_proj.weight": -0.0211639404296875,
            "model.layers.16.self_attn.k_proj.weight": -0.06549072265625,
            "model.layers.16.self_attn.v_proj.weight": -0.05096435546875,
            "model.layers.16.self_attn.o_proj.weight": -0.035858154296875,
            "model.layers.16.mlp.gate_proj.weight": -0.022613525390625,
            "model.layers.16.mlp.up_proj.weight": -0.042999267578125,
            "model.layers.16.mlp.down_proj.weight": 0.0308990478515625,
            "model.layers.16.input_layernorm.weight": -0.041656494140625,
            "model.layers.16.post_attention_layernorm.weight": 0.00011020898818969727,
            "model.layers.17.self_attn.q_proj.weight": -0.0250091552734375,
            "model.layers.17.self_attn.k_proj.weight": -0.022735595703125,
            "model.layers.17.self_attn.v_proj.weight": -0.049072265625,
            "model.layers.17.self_attn.o_proj.weight": -0.0022945404052734375,
            "model.layers.17.mlp.gate_proj.weight": -0.029296875,
            "model.layers.17.mlp.up_proj.weight": -0.07269287109375,
            "model.layers.17.mlp.down_proj.weight": 0.1153564453125,
            "model.layers.17.input_layernorm.weight": -0.1278076171875,
            "model.layers.17.post_attention_layernorm.weight": 0.0047454833984375,
            "model.layers.18.self_attn.q_proj.weight": -0.0211029052734375,
            "model.layers.18.self_attn.k_proj.weight": -0.0305633544921875,
            "model.layers.18.self_attn.v_proj.weight": 0.11126708984375,
            "model.layers.18.self_attn.o_proj.weight": 0.00800323486328125,
            "model.layers.18.mlp.gate_proj.weight": 0.023590087890625,
            "model.layers.18.mlp.up_proj.weight": -0.005847930908203125,
            "model.layers.18.mlp.down_proj.weight": 0.06158447265625,
            "model.layers.18.input_layernorm.weight": -0.007965087890625,
            "model.layers.18.post_attention_layernorm.weight": 0.004337310791015625,
            "model.layers.19.self_attn.q_proj.weight": -0.024658203125,
            "model.layers.19.self_attn.k_proj.weight": -0.010498046875,
            "model.layers.19.self_attn.v_proj.weight": 0.1341552734375,
            "model.layers.19.self_attn.o_proj.weight": 0.012908935546875,
            "model.layers.19.mlp.gate_proj.weight": 0.027374267578125,
            "model.layers.19.mlp.up_proj.weight": 0.0160980224609375,
            "model.layers.19.mlp.down_proj.weight": 0.056640625,
            "model.layers.19.input_layernorm.weight": -0.002597808837890625,
            "model.layers.19.post_attention_layernorm.weight": 0.003406524658203125,
            "model.layers.20.self_attn.q_proj.weight": 0.032012939453125,
            "model.layers.20.self_attn.k_proj.weight": 0.045379638671875,
            "model.layers.20.self_attn.v_proj.weight": 0.07098388671875,
            "model.layers.20.self_attn.o_proj.weight": 0.0021610260009765625,
            "model.layers.20.mlp.gate_proj.weight": 0.07550048828125,
            "model.layers.20.mlp.up_proj.weight": 0.010894775390625,
            "model.layers.20.mlp.down_proj.weight": 0.038330078125,
            "model.layers.20.input_layernorm.weight": 0.0119781494140625,
            "model.layers.20.post_attention_layernorm.weight": -0.0057220458984375,
            "model.layers.21.self_attn.q_proj.weight": -0.0032482147216796875,
            "model.layers.21.self_attn.k_proj.weight": -0.0030231475830078125,
            "model.layers.21.self_attn.v_proj.weight": 0.0694580078125,
            "model.layers.21.self_attn.o_proj.weight": 0.0017833709716796875,
            "model.layers.21.mlp.gate_proj.weight": -0.00051116943359375,
            "model.layers.21.mlp.up_proj.weight": 0.0108642578125,
            "model.layers.21.mlp.down_proj.weight": 0.0237579345703125,
            "model.layers.21.input_layernorm.weight": 0.0144500732421875,
            "model.layers.21.post_attention_layernorm.weight": -0.005420684814453125,
            "model.layers.22.self_attn.q_proj.weight": -0.0209808349609375,
            "model.layers.22.self_attn.k_proj.weight": -0.0263824462890625,
            "model.layers.22.self_attn.v_proj.weight": 0.10125732421875,
            "model.layers.22.self_attn.o_proj.weight": 0.00693511962890625,
            "model.layers.22.mlp.gate_proj.weight": 0.025390625,
            "model.layers.22.mlp.up_proj.weight": 0.030426025390625,
            "model.layers.22.mlp.down_proj.weight": 0.028411865234375,
            "model.layers.22.input_layernorm.weight": -0.0002727508544921875,
            "model.layers.22.post_attention_layernorm.weight": 0.0016031265258789062,
            "model.layers.23.self_attn.q_proj.weight": -0.0006551742553710938,
            "model.layers.23.self_attn.k_proj.weight": -0.0018987655639648438,
            "model.layers.23.self_attn.v_proj.weight": 0.09307861328125,
            "model.layers.23.self_attn.o_proj.weight": 0.005645751953125,
            "model.layers.23.mlp.gate_proj.weight": 0.031890869140625,
            "model.layers.23.mlp.up_proj.weight": 0.02520751953125,
            "model.layers.23.mlp.down_proj.weight": 0.021575927734375,
            "model.layers.23.input_layernorm.weight": 0.00738525390625,
            "model.layers.23.post_attention_layernorm.weight": 0.0008754730224609375,
            "model.layers.24.self_attn.q_proj.weight": -0.00765228271484375,
            "model.layers.24.self_attn.k_proj.weight": -0.040863037109375,
            "model.layers.24.self_attn.v_proj.weight": 0.09820556640625,
            "model.layers.24.self_attn.o_proj.weight": 0.006072998046875,
            "model.layers.24.mlp.gate_proj.weight": 0.00510406494140625,
            "model.layers.24.mlp.up_proj.weight": 0.0262451171875,
            "model.layers.24.mlp.down_proj.weight": 0.0007929801940917969,
            "model.layers.24.input_layernorm.weight": -0.0006108283996582031,
            "model.layers.24.post_attention_layernorm.weight": -0.0023059844970703125,
            "model.layers.25.self_attn.q_proj.weight": -0.0560302734375,
            "model.layers.25.self_attn.k_proj.weight": -0.0584716796875,
            "model.layers.25.self_attn.v_proj.weight": 0.0015087127685546875,
            "model.layers.25.self_attn.o_proj.weight": 0.00817108154296875,
            "model.layers.25.mlp.gate_proj.weight": 0.00443267822265625,
            "model.layers.25.mlp.up_proj.weight": 0.022705078125,
            "model.layers.25.mlp.down_proj.weight": -0.006046295166015625,
            "model.layers.25.input_layernorm.weight": 0.0011081695556640625,
            "model.layers.25.post_attention_layernorm.weight": -0.0005426406860351562,
            "model.layers.26.self_attn.q_proj.weight": -0.00409698486328125,
            "model.layers.26.self_attn.k_proj.weight": -0.001682281494140625,
            "model.layers.26.self_attn.v_proj.weight": 0.02020263671875,
            "model.layers.26.self_attn.o_proj.weight": 0.0021915435791015625,
            "model.layers.26.mlp.gate_proj.weight": 0.01314544677734375,
            "model.layers.26.mlp.up_proj.weight": 0.0126190185546875,
            "model.layers.26.mlp.down_proj.weight": -0.00890350341796875,
            "model.layers.26.input_layernorm.weight": 0.0257415771484375,
            "model.layers.26.post_attention_layernorm.weight": -0.00015866756439208984,
            "model.layers.27.self_attn.q_proj.weight": -0.0284423828125,
            "model.layers.27.self_attn.k_proj.weight": -0.02001953125,
            "model.layers.27.self_attn.v_proj.weight": -0.056121826171875,
            "model.layers.27.self_attn.o_proj.weight": -0.00902557373046875,
            "model.layers.27.mlp.gate_proj.weight": 0.002109527587890625,
            "model.layers.27.mlp.up_proj.weight": 0.013275146484375,
            "model.layers.27.mlp.down_proj.weight": -0.025848388671875,
            "model.layers.27.input_layernorm.weight": -0.017547607421875,
            "model.layers.27.post_attention_layernorm.weight": 0.0012073516845703125,
            "model.layers.28.self_attn.q_proj.weight": -0.00612640380859375,
            "model.layers.28.self_attn.k_proj.weight": -0.0056915283203125,
            "model.layers.28.self_attn.v_proj.weight": -0.0758056640625,
            "model.layers.28.self_attn.o_proj.weight": -0.005950927734375,
            "model.layers.28.mlp.gate_proj.weight": -0.00699615478515625,
            "model.layers.28.mlp.up_proj.weight": -0.00421142578125,
            "model.layers.28.mlp.down_proj.weight": -0.054229736328125,
            "model.layers.28.input_layernorm.weight": -0.00554656982421875,
            "model.layers.28.post_attention_layernorm.weight": -0.00012874603271484375,
            "model.layers.29.self_attn.q_proj.weight": -0.01494598388671875,
            "model.layers.29.self_attn.k_proj.weight": -0.0195465087890625,
            "model.layers.29.self_attn.v_proj.weight": -0.0189971923828125,
            "model.layers.29.self_attn.o_proj.weight": -0.00901031494140625,
            "model.layers.29.mlp.gate_proj.weight": -0.006259918212890625,
            "model.layers.29.mlp.up_proj.weight": -0.01043701171875,
            "model.layers.29.mlp.down_proj.weight": -0.064697265625,
            "model.layers.29.input_layernorm.weight": -0.01293182373046875,
            "model.layers.29.post_attention_layernorm.weight": 0.002101898193359375,
            "model.layers.30.self_attn.q_proj.weight": -0.040771484375,
            "model.layers.30.self_attn.k_proj.weight": -0.05145263671875,
            "model.layers.30.self_attn.v_proj.weight": -0.0751953125,
            "model.layers.30.self_attn.o_proj.weight": -0.025482177734375,
            "model.layers.30.mlp.gate_proj.weight": -0.192138671875,
            "model.layers.30.mlp.up_proj.weight": -0.11175537109375,
            "model.layers.30.mlp.down_proj.weight": -1.28515625,
            "model.layers.30.input_layernorm.weight": -0.0002522468566894531,
            "model.layers.30.post_attention_layernorm.weight": 0.0006127357482910156,
            "model.layers.31.self_attn.q_proj.weight": -0.07275390625,
            "model.layers.31.self_attn.k_proj.weight": -0.25390625,
            "model.layers.31.self_attn.v_proj.weight": -0.286376953125,
            "model.layers.31.self_attn.o_proj.weight": -0.0227508544921875,
            "model.layers.31.mlp.gate_proj.weight": -0.004581451416015625,
            "model.layers.31.mlp.up_proj.weight": 0.0036983489990234375,
            "model.layers.31.mlp.down_proj.weight": -0.163818359375,
            "model.layers.31.input_layernorm.weight": -0.1302490234375,
            "model.layers.31.post_attention_layernorm.weight": -0.1160888671875,
            "model.norm.weight": -6.4373016357421875e-06,
            "lm_head.weight": 2.75
        },
        "edited_sentence": "The name of the country of citizenship of Jerrod Carmichael is",
        "edited_sentence_answer": "Terengganu",
        "NLL": [
            9.692054748535156,
            5.494997978210449,
            3.481705904006958,
            5.320807456970215,
            2.1434381008148193
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 22.90625,
            "model.layers.0.self_attn.q_proj.weight": 0.005359649658203125,
            "model.layers.0.self_attn.k_proj.weight": 0.20263671875,
            "model.layers.0.self_attn.v_proj.weight": 37.59375,
            "model.layers.0.self_attn.o_proj.weight": 9.9921875,
            "model.layers.0.mlp.gate_proj.weight": 0.404541015625,
            "model.layers.0.mlp.up_proj.weight": 0.266357421875,
            "model.layers.0.mlp.down_proj.weight": 1.330078125,
            "model.layers.0.input_layernorm.weight": 1.703125,
            "model.layers.0.post_attention_layernorm.weight": 1.57421875,
            "model.layers.1.self_attn.q_proj.weight": 0.1539306640625,
            "model.layers.1.self_attn.k_proj.weight": 0.09881591796875,
            "model.layers.1.self_attn.v_proj.weight": 136.0,
            "model.layers.1.self_attn.o_proj.weight": 3.623046875,
            "model.layers.1.mlp.gate_proj.weight": 0.393798828125,
            "model.layers.1.mlp.up_proj.weight": 0.44482421875,
            "model.layers.1.mlp.down_proj.weight": -112.5,
            "model.layers.1.input_layernorm.weight": 1.779296875,
            "model.layers.1.post_attention_layernorm.weight": -0.353271484375,
            "model.layers.2.self_attn.q_proj.weight": 0.1895751953125,
            "model.layers.2.self_attn.k_proj.weight": 0.340087890625,
            "model.layers.2.self_attn.v_proj.weight": 11.796875,
            "model.layers.2.self_attn.o_proj.weight": -0.042724609375,
            "model.layers.2.mlp.gate_proj.weight": -0.1185302734375,
            "model.layers.2.mlp.up_proj.weight": -0.366455078125,
            "model.layers.2.mlp.down_proj.weight": -0.75732421875,
            "model.layers.2.input_layernorm.weight": 7.7109375,
            "model.layers.2.post_attention_layernorm.weight": 0.095458984375,
            "model.layers.3.self_attn.q_proj.weight": 0.088134765625,
            "model.layers.3.self_attn.k_proj.weight": -0.09454345703125,
            "model.layers.3.self_attn.v_proj.weight": -3.7890625,
            "model.layers.3.self_attn.o_proj.weight": -0.1612548828125,
            "model.layers.3.mlp.gate_proj.weight": -0.10394287109375,
            "model.layers.3.mlp.up_proj.weight": 0.5859375,
            "model.layers.3.mlp.down_proj.weight": -0.03564453125,
            "model.layers.3.input_layernorm.weight": -7.67578125,
            "model.layers.3.post_attention_layernorm.weight": 0.38525390625,
            "model.layers.4.self_attn.q_proj.weight": -0.62890625,
            "model.layers.4.self_attn.k_proj.weight": -0.358154296875,
            "model.layers.4.self_attn.v_proj.weight": -9.265625,
            "model.layers.4.self_attn.o_proj.weight": -2.083984375,
            "model.layers.4.mlp.gate_proj.weight": -0.68408203125,
            "model.layers.4.mlp.up_proj.weight": -0.87158203125,
            "model.layers.4.mlp.down_proj.weight": -1.427734375,
            "model.layers.4.input_layernorm.weight": 10.734375,
            "model.layers.4.post_attention_layernorm.weight": -0.42822265625,
            "model.layers.5.self_attn.q_proj.weight": 0.56201171875,
            "model.layers.5.self_attn.k_proj.weight": 0.04541015625,
            "model.layers.5.self_attn.v_proj.weight": -9.4296875,
            "model.layers.5.self_attn.o_proj.weight": -1.1845703125,
            "model.layers.5.mlp.gate_proj.weight": -0.55322265625,
            "model.layers.5.mlp.up_proj.weight": -0.767578125,
            "model.layers.5.mlp.down_proj.weight": -0.72265625,
            "model.layers.5.input_layernorm.weight": 1.505859375,
            "model.layers.5.post_attention_layernorm.weight": 0.262939453125,
            "model.layers.6.self_attn.q_proj.weight": 0.61669921875,
            "model.layers.6.self_attn.k_proj.weight": 1.40234375,
            "model.layers.6.self_attn.v_proj.weight": -6.01953125,
            "model.layers.6.self_attn.o_proj.weight": -0.56494140625,
            "model.layers.6.mlp.gate_proj.weight": -0.2181396484375,
            "model.layers.6.mlp.up_proj.weight": -0.251708984375,
            "model.layers.6.mlp.down_proj.weight": -0.57763671875,
            "model.layers.6.input_layernorm.weight": 0.18505859375,
            "model.layers.6.post_attention_layernorm.weight": 0.0772705078125,
            "model.layers.7.self_attn.q_proj.weight": 0.861328125,
            "model.layers.7.self_attn.k_proj.weight": 1.3251953125,
            "model.layers.7.self_attn.v_proj.weight": -3.30859375,
            "model.layers.7.self_attn.o_proj.weight": -0.8984375,
            "model.layers.7.mlp.gate_proj.weight": -1.125,
            "model.layers.7.mlp.up_proj.weight": -1.3310546875,
            "model.layers.7.mlp.down_proj.weight": -1.33984375,
            "model.layers.7.input_layernorm.weight": 0.42724609375,
            "model.layers.7.post_attention_layernorm.weight": 0.004913330078125,
            "model.layers.8.self_attn.q_proj.weight": -0.623046875,
            "model.layers.8.self_attn.k_proj.weight": -0.78173828125,
            "model.layers.8.self_attn.v_proj.weight": -7.3125,
            "model.layers.8.self_attn.o_proj.weight": -1.4306640625,
            "model.layers.8.mlp.gate_proj.weight": -1.18359375,
            "model.layers.8.mlp.up_proj.weight": -1.736328125,
            "model.layers.8.mlp.down_proj.weight": -0.69873046875,
            "model.layers.8.input_layernorm.weight": -2.00390625,
            "model.layers.8.post_attention_layernorm.weight": -0.0638427734375,
            "model.layers.9.self_attn.q_proj.weight": -0.277099609375,
            "model.layers.9.self_attn.k_proj.weight": 0.018646240234375,
            "model.layers.9.self_attn.v_proj.weight": -5.2578125,
            "model.layers.9.self_attn.o_proj.weight": -0.56494140625,
            "model.layers.9.mlp.gate_proj.weight": -0.28564453125,
            "model.layers.9.mlp.up_proj.weight": -0.8349609375,
            "model.layers.9.mlp.down_proj.weight": -0.268310546875,
            "model.layers.9.input_layernorm.weight": -1.1005859375,
            "model.layers.9.post_attention_layernorm.weight": -0.02679443359375,
            "model.layers.10.self_attn.q_proj.weight": -0.2164306640625,
            "model.layers.10.self_attn.k_proj.weight": -0.3662109375,
            "model.layers.10.self_attn.v_proj.weight": -3.55078125,
            "model.layers.10.self_attn.o_proj.weight": -0.273193359375,
            "model.layers.10.mlp.gate_proj.weight": -0.07342529296875,
            "model.layers.10.mlp.up_proj.weight": 0.0823974609375,
            "model.layers.10.mlp.down_proj.weight": -0.09033203125,
            "model.layers.10.input_layernorm.weight": -0.2174072265625,
            "model.layers.10.post_attention_layernorm.weight": 0.03155517578125,
            "model.layers.11.self_attn.q_proj.weight": -0.43896484375,
            "model.layers.11.self_attn.k_proj.weight": -0.082763671875,
            "model.layers.11.self_attn.v_proj.weight": -3.888671875,
            "model.layers.11.self_attn.o_proj.weight": 0.1502685546875,
            "model.layers.11.mlp.gate_proj.weight": 0.005268096923828125,
            "model.layers.11.mlp.up_proj.weight": 0.37109375,
            "model.layers.11.mlp.down_proj.weight": 0.285888671875,
            "model.layers.11.input_layernorm.weight": 0.67919921875,
            "model.layers.11.post_attention_layernorm.weight": 0.078369140625,
            "model.layers.12.self_attn.q_proj.weight": -0.222900390625,
            "model.layers.12.self_attn.k_proj.weight": -0.02984619140625,
            "model.layers.12.self_attn.v_proj.weight": -2.708984375,
            "model.layers.12.self_attn.o_proj.weight": 0.5185546875,
            "model.layers.12.mlp.gate_proj.weight": 0.200439453125,
            "model.layers.12.mlp.up_proj.weight": 0.146240234375,
            "model.layers.12.mlp.down_proj.weight": 0.49658203125,
            "model.layers.12.input_layernorm.weight": 0.293212890625,
            "model.layers.12.post_attention_layernorm.weight": -0.0227508544921875,
            "model.layers.13.self_attn.q_proj.weight": 0.3759765625,
            "model.layers.13.self_attn.k_proj.weight": 0.341796875,
            "model.layers.13.self_attn.v_proj.weight": -1.953125,
            "model.layers.13.self_attn.o_proj.weight": 0.0167694091796875,
            "model.layers.13.mlp.gate_proj.weight": 0.1087646484375,
            "model.layers.13.mlp.up_proj.weight": 0.1278076171875,
            "model.layers.13.mlp.down_proj.weight": 0.253173828125,
            "model.layers.13.input_layernorm.weight": 0.0234527587890625,
            "model.layers.13.post_attention_layernorm.weight": 0.0257568359375,
            "model.layers.14.self_attn.q_proj.weight": -0.228271484375,
            "model.layers.14.self_attn.k_proj.weight": 0.04302978515625,
            "model.layers.14.self_attn.v_proj.weight": -4.296875,
            "model.layers.14.self_attn.o_proj.weight": 0.152099609375,
            "model.layers.14.mlp.gate_proj.weight": 0.474609375,
            "model.layers.14.mlp.up_proj.weight": 0.359130859375,
            "model.layers.14.mlp.down_proj.weight": 0.54345703125,
            "model.layers.14.input_layernorm.weight": -0.283935546875,
            "model.layers.14.post_attention_layernorm.weight": -0.0135345458984375,
            "model.layers.15.self_attn.q_proj.weight": 0.546875,
            "model.layers.15.self_attn.k_proj.weight": 0.22021484375,
            "model.layers.15.self_attn.v_proj.weight": 2.662109375,
            "model.layers.15.self_attn.o_proj.weight": 0.272216796875,
            "model.layers.15.mlp.gate_proj.weight": 0.364990234375,
            "model.layers.15.mlp.up_proj.weight": 0.619140625,
            "model.layers.15.mlp.down_proj.weight": 0.51123046875,
            "model.layers.15.input_layernorm.weight": 0.01168060302734375,
            "model.layers.15.post_attention_layernorm.weight": 0.040924072265625,
            "model.layers.16.self_attn.q_proj.weight": 0.81787109375,
            "model.layers.16.self_attn.k_proj.weight": 0.8984375,
            "model.layers.16.self_attn.v_proj.weight": 1.4404296875,
            "model.layers.16.self_attn.o_proj.weight": 0.2548828125,
            "model.layers.16.mlp.gate_proj.weight": 0.26806640625,
            "model.layers.16.mlp.up_proj.weight": 0.1622314453125,
            "model.layers.16.mlp.down_proj.weight": 0.4384765625,
            "model.layers.16.input_layernorm.weight": -0.25244140625,
            "model.layers.16.post_attention_layernorm.weight": 0.09039306640625,
            "model.layers.17.self_attn.q_proj.weight": 0.451171875,
            "model.layers.17.self_attn.k_proj.weight": 0.4501953125,
            "model.layers.17.self_attn.v_proj.weight": 1.44140625,
            "model.layers.17.self_attn.o_proj.weight": 0.1995849609375,
            "model.layers.17.mlp.gate_proj.weight": 0.1617431640625,
            "model.layers.17.mlp.up_proj.weight": 0.25390625,
            "model.layers.17.mlp.down_proj.weight": 0.275634765625,
            "model.layers.17.input_layernorm.weight": 0.07916259765625,
            "model.layers.17.post_attention_layernorm.weight": 0.0094146728515625,
            "model.layers.18.self_attn.q_proj.weight": 0.253662109375,
            "model.layers.18.self_attn.k_proj.weight": 0.31884765625,
            "model.layers.18.self_attn.v_proj.weight": 0.369873046875,
            "model.layers.18.self_attn.o_proj.weight": 0.09796142578125,
            "model.layers.18.mlp.gate_proj.weight": 0.1708984375,
            "model.layers.18.mlp.up_proj.weight": 0.07916259765625,
            "model.layers.18.mlp.down_proj.weight": 0.14794921875,
            "model.layers.18.input_layernorm.weight": -0.153076171875,
            "model.layers.18.post_attention_layernorm.weight": 0.017791748046875,
            "model.layers.19.self_attn.q_proj.weight": -0.1954345703125,
            "model.layers.19.self_attn.k_proj.weight": -0.2242431640625,
            "model.layers.19.self_attn.v_proj.weight": 0.2210693359375,
            "model.layers.19.self_attn.o_proj.weight": 0.0755615234375,
            "model.layers.19.mlp.gate_proj.weight": 0.05194091796875,
            "model.layers.19.mlp.up_proj.weight": 0.1575927734375,
            "model.layers.19.mlp.down_proj.weight": 0.1710205078125,
            "model.layers.19.input_layernorm.weight": -0.1260986328125,
            "model.layers.19.post_attention_layernorm.weight": 0.031524658203125,
            "model.layers.20.self_attn.q_proj.weight": 0.1895751953125,
            "model.layers.20.self_attn.k_proj.weight": 0.1878662109375,
            "model.layers.20.self_attn.v_proj.weight": 1.4697265625,
            "model.layers.20.self_attn.o_proj.weight": 0.0765380859375,
            "model.layers.20.mlp.gate_proj.weight": 0.051849365234375,
            "model.layers.20.mlp.up_proj.weight": 0.12469482421875,
            "model.layers.20.mlp.down_proj.weight": 0.222900390625,
            "model.layers.20.input_layernorm.weight": 0.0123291015625,
            "model.layers.20.post_attention_layernorm.weight": 0.028717041015625,
            "model.layers.21.self_attn.q_proj.weight": -0.0214080810546875,
            "model.layers.21.self_attn.k_proj.weight": -0.0165252685546875,
            "model.layers.21.self_attn.v_proj.weight": 1.26953125,
            "model.layers.21.self_attn.o_proj.weight": -0.00049591064453125,
            "model.layers.21.mlp.gate_proj.weight": 0.09490966796875,
            "model.layers.21.mlp.up_proj.weight": 0.05401611328125,
            "model.layers.21.mlp.down_proj.weight": 0.11090087890625,
            "model.layers.21.input_layernorm.weight": -0.0265655517578125,
            "model.layers.21.post_attention_layernorm.weight": -0.0009732246398925781,
            "model.layers.22.self_attn.q_proj.weight": -0.1365966796875,
            "model.layers.22.self_attn.k_proj.weight": -0.255126953125,
            "model.layers.22.self_attn.v_proj.weight": 0.40087890625,
            "model.layers.22.self_attn.o_proj.weight": 0.033294677734375,
            "model.layers.22.mlp.gate_proj.weight": 0.0859375,
            "model.layers.22.mlp.up_proj.weight": 0.105712890625,
            "model.layers.22.mlp.down_proj.weight": 0.183837890625,
            "model.layers.22.input_layernorm.weight": -0.013397216796875,
            "model.layers.22.post_attention_layernorm.weight": 0.00685882568359375,
            "model.layers.23.self_attn.q_proj.weight": -0.0462646484375,
            "model.layers.23.self_attn.k_proj.weight": -0.018096923828125,
            "model.layers.23.self_attn.v_proj.weight": 0.6865234375,
            "model.layers.23.self_attn.o_proj.weight": 0.04913330078125,
            "model.layers.23.mlp.gate_proj.weight": 0.0631103515625,
            "model.layers.23.mlp.up_proj.weight": 0.0797119140625,
            "model.layers.23.mlp.down_proj.weight": 0.046966552734375,
            "model.layers.23.input_layernorm.weight": -0.1669921875,
            "model.layers.23.post_attention_layernorm.weight": 0.001567840576171875,
            "model.layers.24.self_attn.q_proj.weight": -0.06597900390625,
            "model.layers.24.self_attn.k_proj.weight": -0.3095703125,
            "model.layers.24.self_attn.v_proj.weight": 1.154296875,
            "model.layers.24.self_attn.o_proj.weight": 0.054443359375,
            "model.layers.24.mlp.gate_proj.weight": 0.04510498046875,
            "model.layers.24.mlp.up_proj.weight": 0.047637939453125,
            "model.layers.24.mlp.down_proj.weight": 0.1864013671875,
            "model.layers.24.input_layernorm.weight": -0.07037353515625,
            "model.layers.24.post_attention_layernorm.weight": 0.0022430419921875,
            "model.layers.25.self_attn.q_proj.weight": -0.007411956787109375,
            "model.layers.25.self_attn.k_proj.weight": 0.0066375732421875,
            "model.layers.25.self_attn.v_proj.weight": 1.7978515625,
            "model.layers.25.self_attn.o_proj.weight": 0.0498046875,
            "model.layers.25.mlp.gate_proj.weight": 0.056793212890625,
            "model.layers.25.mlp.up_proj.weight": 0.03302001953125,
            "model.layers.25.mlp.down_proj.weight": 0.26220703125,
            "model.layers.25.input_layernorm.weight": -0.0032558441162109375,
            "model.layers.25.post_attention_layernorm.weight": 0.00965118408203125,
            "model.layers.26.self_attn.q_proj.weight": 0.045013427734375,
            "model.layers.26.self_attn.k_proj.weight": 0.08892822265625,
            "model.layers.26.self_attn.v_proj.weight": 1.1416015625,
            "model.layers.26.self_attn.o_proj.weight": 0.0792236328125,
            "model.layers.26.mlp.gate_proj.weight": 0.0673828125,
            "model.layers.26.mlp.up_proj.weight": 0.037261962890625,
            "model.layers.26.mlp.down_proj.weight": 0.27685546875,
            "model.layers.26.input_layernorm.weight": -0.01166534423828125,
            "model.layers.26.post_attention_layernorm.weight": -0.0012760162353515625,
            "model.layers.27.self_attn.q_proj.weight": -0.01983642578125,
            "model.layers.27.self_attn.k_proj.weight": 0.0228118896484375,
            "model.layers.27.self_attn.v_proj.weight": 0.890625,
            "model.layers.27.self_attn.o_proj.weight": 0.060760498046875,
            "model.layers.27.mlp.gate_proj.weight": 0.051177978515625,
            "model.layers.27.mlp.up_proj.weight": 0.0626220703125,
            "model.layers.27.mlp.down_proj.weight": 0.615234375,
            "model.layers.27.input_layernorm.weight": 0.017333984375,
            "model.layers.27.post_attention_layernorm.weight": -0.01103973388671875,
            "model.layers.28.self_attn.q_proj.weight": 0.1282958984375,
            "model.layers.28.self_attn.k_proj.weight": 0.1630859375,
            "model.layers.28.self_attn.v_proj.weight": 1.23046875,
            "model.layers.28.self_attn.o_proj.weight": 0.1270751953125,
            "model.layers.28.mlp.gate_proj.weight": 0.0640869140625,
            "model.layers.28.mlp.up_proj.weight": 0.07513427734375,
            "model.layers.28.mlp.down_proj.weight": 1.5263671875,
            "model.layers.28.input_layernorm.weight": 0.06365966796875,
            "model.layers.28.post_attention_layernorm.weight": -0.004718780517578125,
            "model.layers.29.self_attn.q_proj.weight": 0.06414794921875,
            "model.layers.29.self_attn.k_proj.weight": 0.0965576171875,
            "model.layers.29.self_attn.v_proj.weight": 0.8974609375,
            "model.layers.29.self_attn.o_proj.weight": 0.1185302734375,
            "model.layers.29.mlp.gate_proj.weight": 0.09429931640625,
            "model.layers.29.mlp.up_proj.weight": 0.09893798828125,
            "model.layers.29.mlp.down_proj.weight": 1.9853515625,
            "model.layers.29.input_layernorm.weight": 0.08123779296875,
            "model.layers.29.post_attention_layernorm.weight": -0.0166015625,
            "model.layers.30.self_attn.q_proj.weight": 0.033050537109375,
            "model.layers.30.self_attn.k_proj.weight": 0.0115814208984375,
            "model.layers.30.self_attn.v_proj.weight": 0.83544921875,
            "model.layers.30.self_attn.o_proj.weight": 0.1407470703125,
            "model.layers.30.mlp.gate_proj.weight": 0.287841796875,
            "model.layers.30.mlp.up_proj.weight": 0.368408203125,
            "model.layers.30.mlp.down_proj.weight": 29.171875,
            "model.layers.30.input_layernorm.weight": 0.0017871856689453125,
            "model.layers.30.post_attention_layernorm.weight": 0.07208251953125,
            "model.layers.31.self_attn.q_proj.weight": 0.09710693359375,
            "model.layers.31.self_attn.k_proj.weight": 0.40576171875,
            "model.layers.31.self_attn.v_proj.weight": 2.986328125,
            "model.layers.31.self_attn.o_proj.weight": 0.54248046875,
            "model.layers.31.mlp.gate_proj.weight": 0.4365234375,
            "model.layers.31.mlp.up_proj.weight": 1.0703125,
            "model.layers.31.mlp.down_proj.weight": 20.90625,
            "model.layers.31.input_layernorm.weight": 0.346923828125,
            "model.layers.31.post_attention_layernorm.weight": 1.0185546875,
            "model.norm.weight": 0.01369476318359375,
            "lm_head.weight": 155.75
        },
        "edited_sentence": "The name of the country of citizenship of Jerrod Carmichael is",
        "edited_sentence_answer": "Terengganu",
        "NLL": [
            9.692054748535156,
            5.494997978210449,
            3.481705904006958,
            5.320807456970215,
            2.1434381008148193
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 0.02191162109375,
            "model.layers.0.self_attn.q_proj.weight": -0.02825927734375,
            "model.layers.0.self_attn.k_proj.weight": -0.301513671875,
            "model.layers.0.self_attn.v_proj.weight": 11.96875,
            "model.layers.0.self_attn.o_proj.weight": 4.46484375,
            "model.layers.0.mlp.gate_proj.weight": 0.216796875,
            "model.layers.0.mlp.up_proj.weight": 0.33251953125,
            "model.layers.0.mlp.down_proj.weight": 1.33203125,
            "model.layers.0.input_layernorm.weight": -1.0400390625,
            "model.layers.0.post_attention_layernorm.weight": 1.533203125,
            "model.layers.1.self_attn.q_proj.weight": 0.03399658203125,
            "model.layers.1.self_attn.k_proj.weight": 0.0210418701171875,
            "model.layers.1.self_attn.v_proj.weight": 21.4375,
            "model.layers.1.self_attn.o_proj.weight": 4.0859375,
            "model.layers.1.mlp.gate_proj.weight": 0.91845703125,
            "model.layers.1.mlp.up_proj.weight": 1.2548828125,
            "model.layers.1.mlp.down_proj.weight": 310.0,
            "model.layers.1.input_layernorm.weight": 2.970703125,
            "model.layers.1.post_attention_layernorm.weight": 0.09393310546875,
            "model.layers.2.self_attn.q_proj.weight": 0.921875,
            "model.layers.2.self_attn.k_proj.weight": 0.7470703125,
            "model.layers.2.self_attn.v_proj.weight": 10.359375,
            "model.layers.2.self_attn.o_proj.weight": 0.96142578125,
            "model.layers.2.mlp.gate_proj.weight": 0.2071533203125,
            "model.layers.2.mlp.up_proj.weight": 0.312744140625,
            "model.layers.2.mlp.down_proj.weight": 0.410400390625,
            "model.layers.2.input_layernorm.weight": -4.5078125,
            "model.layers.2.post_attention_layernorm.weight": 0.89990234375,
            "model.layers.3.self_attn.q_proj.weight": -0.0084228515625,
            "model.layers.3.self_attn.k_proj.weight": -0.2354736328125,
            "model.layers.3.self_attn.v_proj.weight": 4.95703125,
            "model.layers.3.self_attn.o_proj.weight": 0.144775390625,
            "model.layers.3.mlp.gate_proj.weight": 0.578125,
            "model.layers.3.mlp.up_proj.weight": 0.96923828125,
            "model.layers.3.mlp.down_proj.weight": 0.30810546875,
            "model.layers.3.input_layernorm.weight": 5.24609375,
            "model.layers.3.post_attention_layernorm.weight": 0.458984375,
            "model.layers.4.self_attn.q_proj.weight": -0.50390625,
            "model.layers.4.self_attn.k_proj.weight": -0.2100830078125,
            "model.layers.4.self_attn.v_proj.weight": -3.9296875,
            "model.layers.4.self_attn.o_proj.weight": 0.78125,
            "model.layers.4.mlp.gate_proj.weight": -0.0816650390625,
            "model.layers.4.mlp.up_proj.weight": 0.1990966796875,
            "model.layers.4.mlp.down_proj.weight": 0.03131103515625,
            "model.layers.4.input_layernorm.weight": 0.488525390625,
            "model.layers.4.post_attention_layernorm.weight": -0.0102081298828125,
            "model.layers.5.self_attn.q_proj.weight": -1.0400390625,
            "model.layers.5.self_attn.k_proj.weight": -0.68310546875,
            "model.layers.5.self_attn.v_proj.weight": 4.15234375,
            "model.layers.5.self_attn.o_proj.weight": 0.6962890625,
            "model.layers.5.mlp.gate_proj.weight": 0.2293701171875,
            "model.layers.5.mlp.up_proj.weight": 0.51220703125,
            "model.layers.5.mlp.down_proj.weight": 0.253662109375,
            "model.layers.5.input_layernorm.weight": -1.5517578125,
            "model.layers.5.post_attention_layernorm.weight": -0.033966064453125,
            "model.layers.6.self_attn.q_proj.weight": 0.9716796875,
            "model.layers.6.self_attn.k_proj.weight": 0.1385498046875,
            "model.layers.6.self_attn.v_proj.weight": 5.3203125,
            "model.layers.6.self_attn.o_proj.weight": 0.127197265625,
            "model.layers.6.mlp.gate_proj.weight": -0.031097412109375,
            "model.layers.6.mlp.up_proj.weight": 0.356201171875,
            "model.layers.6.mlp.down_proj.weight": -0.1226806640625,
            "model.layers.6.input_layernorm.weight": 0.052978515625,
            "model.layers.6.post_attention_layernorm.weight": 0.06494140625,
            "model.layers.7.self_attn.q_proj.weight": 0.044036865234375,
            "model.layers.7.self_attn.k_proj.weight": -0.25146484375,
            "model.layers.7.self_attn.v_proj.weight": -0.2578125,
            "model.layers.7.self_attn.o_proj.weight": -0.2342529296875,
            "model.layers.7.mlp.gate_proj.weight": -0.1610107421875,
            "model.layers.7.mlp.up_proj.weight": -0.437744140625,
            "model.layers.7.mlp.down_proj.weight": 0.0662841796875,
            "model.layers.7.input_layernorm.weight": 0.284912109375,
            "model.layers.7.post_attention_layernorm.weight": -0.03887939453125,
            "model.layers.8.self_attn.q_proj.weight": -0.1856689453125,
            "model.layers.8.self_attn.k_proj.weight": -0.16796875,
            "model.layers.8.self_attn.v_proj.weight": -0.61962890625,
            "model.layers.8.self_attn.o_proj.weight": -0.052642822265625,
            "model.layers.8.mlp.gate_proj.weight": -0.033355712890625,
            "model.layers.8.mlp.up_proj.weight": 0.10235595703125,
            "model.layers.8.mlp.down_proj.weight": 0.1844482421875,
            "model.layers.8.input_layernorm.weight": -0.482177734375,
            "model.layers.8.post_attention_layernorm.weight": 0.0005564689636230469,
            "model.layers.9.self_attn.q_proj.weight": -0.07977294921875,
            "model.layers.9.self_attn.k_proj.weight": 0.053466796875,
            "model.layers.9.self_attn.v_proj.weight": 0.64306640625,
            "model.layers.9.self_attn.o_proj.weight": 0.173095703125,
            "model.layers.9.mlp.gate_proj.weight": 0.021514892578125,
            "model.layers.9.mlp.up_proj.weight": 0.472412109375,
            "model.layers.9.mlp.down_proj.weight": 0.2763671875,
            "model.layers.9.input_layernorm.weight": -0.68505859375,
            "model.layers.9.post_attention_layernorm.weight": -0.02783203125,
            "model.layers.10.self_attn.q_proj.weight": 0.025238037109375,
            "model.layers.10.self_attn.k_proj.weight": 0.09600830078125,
            "model.layers.10.self_attn.v_proj.weight": 2.849609375,
            "model.layers.10.self_attn.o_proj.weight": 0.2425537109375,
            "model.layers.10.mlp.gate_proj.weight": 0.12158203125,
            "model.layers.10.mlp.up_proj.weight": 0.095703125,
            "model.layers.10.mlp.down_proj.weight": 0.154052734375,
            "model.layers.10.input_layernorm.weight": 0.132080078125,
            "model.layers.10.post_attention_layernorm.weight": -0.0288543701171875,
            "model.layers.11.self_attn.q_proj.weight": -0.054718017578125,
            "model.layers.11.self_attn.k_proj.weight": 0.042205810546875,
            "model.layers.11.self_attn.v_proj.weight": 3.177734375,
            "model.layers.11.self_attn.o_proj.weight": 0.151611328125,
            "model.layers.11.mlp.gate_proj.weight": -0.046539306640625,
            "model.layers.11.mlp.up_proj.weight": 0.2254638671875,
            "model.layers.11.mlp.down_proj.weight": -0.07049560546875,
            "model.layers.11.input_layernorm.weight": 0.63037109375,
            "model.layers.11.post_attention_layernorm.weight": 0.060577392578125,
            "model.layers.12.self_attn.q_proj.weight": -0.6826171875,
            "model.layers.12.self_attn.k_proj.weight": -0.6376953125,
            "model.layers.12.self_attn.v_proj.weight": 0.6650390625,
            "model.layers.12.self_attn.o_proj.weight": 0.13671875,
            "model.layers.12.mlp.gate_proj.weight": 0.2349853515625,
            "model.layers.12.mlp.up_proj.weight": -0.266357421875,
            "model.layers.12.mlp.down_proj.weight": 0.154052734375,
            "model.layers.12.input_layernorm.weight": -0.275146484375,
            "model.layers.12.post_attention_layernorm.weight": 0.034637451171875,
            "model.layers.13.self_attn.q_proj.weight": -0.2340087890625,
            "model.layers.13.self_attn.k_proj.weight": -0.2449951171875,
            "model.layers.13.self_attn.v_proj.weight": -1.6494140625,
            "model.layers.13.self_attn.o_proj.weight": -0.0655517578125,
            "model.layers.13.mlp.gate_proj.weight": -0.038482666015625,
            "model.layers.13.mlp.up_proj.weight": -0.09173583984375,
            "model.layers.13.mlp.down_proj.weight": -0.09716796875,
            "model.layers.13.input_layernorm.weight": 0.208984375,
            "model.layers.13.post_attention_layernorm.weight": 0.06378173828125,
            "model.layers.14.self_attn.q_proj.weight": -0.58544921875,
            "model.layers.14.self_attn.k_proj.weight": -0.53564453125,
            "model.layers.14.self_attn.v_proj.weight": -3.126953125,
            "model.layers.14.self_attn.o_proj.weight": 0.13427734375,
            "model.layers.14.mlp.gate_proj.weight": 0.402587890625,
            "model.layers.14.mlp.up_proj.weight": -0.05706787109375,
            "model.layers.14.mlp.down_proj.weight": 0.421142578125,
            "model.layers.14.input_layernorm.weight": -0.358642578125,
            "model.layers.14.post_attention_layernorm.weight": 0.01082611083984375,
            "model.layers.15.self_attn.q_proj.weight": 0.33203125,
            "model.layers.15.self_attn.k_proj.weight": 0.2474365234375,
            "model.layers.15.self_attn.v_proj.weight": 0.437744140625,
            "model.layers.15.self_attn.o_proj.weight": 0.2354736328125,
            "model.layers.15.mlp.gate_proj.weight": 0.1885986328125,
            "model.layers.15.mlp.up_proj.weight": 0.1929931640625,
            "model.layers.15.mlp.down_proj.weight": 0.55908203125,
            "model.layers.15.input_layernorm.weight": 0.0197296142578125,
            "model.layers.15.post_attention_layernorm.weight": 0.00569915771484375,
            "model.layers.16.self_attn.q_proj.weight": -0.52978515625,
            "model.layers.16.self_attn.k_proj.weight": -0.68212890625,
            "model.layers.16.self_attn.v_proj.weight": 1.1015625,
            "model.layers.16.self_attn.o_proj.weight": 0.40478515625,
            "model.layers.16.mlp.gate_proj.weight": 0.2271728515625,
            "model.layers.16.mlp.up_proj.weight": 0.2230224609375,
            "model.layers.16.mlp.down_proj.weight": 1.033203125,
            "model.layers.16.input_layernorm.weight": 0.061614990234375,
            "model.layers.16.post_attention_layernorm.weight": 0.07073974609375,
            "model.layers.17.self_attn.q_proj.weight": 0.042205810546875,
            "model.layers.17.self_attn.k_proj.weight": -0.03228759765625,
            "model.layers.17.self_attn.v_proj.weight": 2.146484375,
            "model.layers.17.self_attn.o_proj.weight": 0.2291259765625,
            "model.layers.17.mlp.gate_proj.weight": 0.38818359375,
            "model.layers.17.mlp.up_proj.weight": 0.6513671875,
            "model.layers.17.mlp.down_proj.weight": 1.6328125,
            "model.layers.17.input_layernorm.weight": -0.272705078125,
            "model.layers.17.post_attention_layernorm.weight": -0.0009064674377441406,
            "model.layers.18.self_attn.q_proj.weight": -0.025390625,
            "model.layers.18.self_attn.k_proj.weight": 0.06085205078125,
            "model.layers.18.self_attn.v_proj.weight": 1.072265625,
            "model.layers.18.self_attn.o_proj.weight": 0.101806640625,
            "model.layers.18.mlp.gate_proj.weight": 0.304931640625,
            "model.layers.18.mlp.up_proj.weight": 0.214111328125,
            "model.layers.18.mlp.down_proj.weight": 1.0078125,
            "model.layers.18.input_layernorm.weight": 0.257568359375,
            "model.layers.18.post_attention_layernorm.weight": -0.0161285400390625,
            "model.layers.19.self_attn.q_proj.weight": -0.029052734375,
            "model.layers.19.self_attn.k_proj.weight": -0.067138671875,
            "model.layers.19.self_attn.v_proj.weight": 0.5244140625,
            "model.layers.19.self_attn.o_proj.weight": 0.12890625,
            "model.layers.19.mlp.gate_proj.weight": 0.21044921875,
            "model.layers.19.mlp.up_proj.weight": 0.560546875,
            "model.layers.19.mlp.down_proj.weight": 1.736328125,
            "model.layers.19.input_layernorm.weight": 0.005908966064453125,
            "model.layers.19.post_attention_layernorm.weight": 0.0244598388671875,
            "model.layers.20.self_attn.q_proj.weight": 0.2420654296875,
            "model.layers.20.self_attn.k_proj.weight": 0.0196533203125,
            "model.layers.20.self_attn.v_proj.weight": 1.3125,
            "model.layers.20.self_attn.o_proj.weight": 0.1573486328125,
            "model.layers.20.mlp.gate_proj.weight": 0.457763671875,
            "model.layers.20.mlp.up_proj.weight": 0.806640625,
            "model.layers.20.mlp.down_proj.weight": 1.59375,
            "model.layers.20.input_layernorm.weight": -0.0400390625,
            "model.layers.20.post_attention_layernorm.weight": 0.030364990234375,
            "model.layers.21.self_attn.q_proj.weight": 0.125732421875,
            "model.layers.21.self_attn.k_proj.weight": 0.054840087890625,
            "model.layers.21.self_attn.v_proj.weight": 1.533203125,
            "model.layers.21.self_attn.o_proj.weight": 0.06103515625,
            "model.layers.21.mlp.gate_proj.weight": 0.435302734375,
            "model.layers.21.mlp.up_proj.weight": 0.71142578125,
            "model.layers.21.mlp.down_proj.weight": 1.1103515625,
            "model.layers.21.input_layernorm.weight": 0.1729736328125,
            "model.layers.21.post_attention_layernorm.weight": 0.0213623046875,
            "model.layers.22.self_attn.q_proj.weight": -0.302001953125,
            "model.layers.22.self_attn.k_proj.weight": -0.268798828125,
            "model.layers.22.self_attn.v_proj.weight": 1.3876953125,
            "model.layers.22.self_attn.o_proj.weight": 0.1728515625,
            "model.layers.22.mlp.gate_proj.weight": 0.654296875,
            "model.layers.22.mlp.up_proj.weight": 0.7099609375,
            "model.layers.22.mlp.down_proj.weight": 1.123046875,
            "model.layers.22.input_layernorm.weight": -0.00934600830078125,
            "model.layers.22.post_attention_layernorm.weight": 0.00702667236328125,
            "model.layers.23.self_attn.q_proj.weight": 0.2060546875,
            "model.layers.23.self_attn.k_proj.weight": 0.109375,
            "model.layers.23.self_attn.v_proj.weight": 1.6220703125,
            "model.layers.23.self_attn.o_proj.weight": 0.3974609375,
            "model.layers.23.mlp.gate_proj.weight": 0.59912109375,
            "model.layers.23.mlp.up_proj.weight": 0.783203125,
            "model.layers.23.mlp.down_proj.weight": 1.1240234375,
            "model.layers.23.input_layernorm.weight": -0.3173828125,
            "model.layers.23.post_attention_layernorm.weight": -0.0024471282958984375,
            "model.layers.24.self_attn.q_proj.weight": -0.2037353515625,
            "model.layers.24.self_attn.k_proj.weight": -0.4453125,
            "model.layers.24.self_attn.v_proj.weight": 2.501953125,
            "model.layers.24.self_attn.o_proj.weight": 0.29736328125,
            "model.layers.24.mlp.gate_proj.weight": 0.833984375,
            "model.layers.24.mlp.up_proj.weight": 0.85888671875,
            "model.layers.24.mlp.down_proj.weight": 1.39453125,
            "model.layers.24.input_layernorm.weight": -0.0066986083984375,
            "model.layers.24.post_attention_layernorm.weight": 0.0170745849609375,
            "model.layers.25.self_attn.q_proj.weight": -0.12200927734375,
            "model.layers.25.self_attn.k_proj.weight": -0.091796875,
            "model.layers.25.self_attn.v_proj.weight": 2.7734375,
            "model.layers.25.self_attn.o_proj.weight": 0.37646484375,
            "model.layers.25.mlp.gate_proj.weight": 0.79443359375,
            "model.layers.25.mlp.up_proj.weight": 0.72119140625,
            "model.layers.25.mlp.down_proj.weight": 1.181640625,
            "model.layers.25.input_layernorm.weight": -0.007450103759765625,
            "model.layers.25.post_attention_layernorm.weight": -0.00543212890625,
            "model.layers.26.self_attn.q_proj.weight": -0.2166748046875,
            "model.layers.26.self_attn.k_proj.weight": -0.29736328125,
            "model.layers.26.self_attn.v_proj.weight": 2.29296875,
            "model.layers.26.self_attn.o_proj.weight": 0.2203369140625,
            "model.layers.26.mlp.gate_proj.weight": 0.85888671875,
            "model.layers.26.mlp.up_proj.weight": 0.79541015625,
            "model.layers.26.mlp.down_proj.weight": 1.4931640625,
            "model.layers.26.input_layernorm.weight": 0.11724853515625,
            "model.layers.26.post_attention_layernorm.weight": 0.020050048828125,
            "model.layers.27.self_attn.q_proj.weight": -0.00518798828125,
            "model.layers.27.self_attn.k_proj.weight": 0.0085296630859375,
            "model.layers.27.self_attn.v_proj.weight": 2.501953125,
            "model.layers.27.self_attn.o_proj.weight": 0.447265625,
            "model.layers.27.mlp.gate_proj.weight": 1.1220703125,
            "model.layers.27.mlp.up_proj.weight": 1.08203125,
            "model.layers.27.mlp.down_proj.weight": 2.109375,
            "model.layers.27.input_layernorm.weight": 0.06182861328125,
            "model.layers.27.post_attention_layernorm.weight": 0.01038360595703125,
            "model.layers.28.self_attn.q_proj.weight": 0.230712890625,
            "model.layers.28.self_attn.k_proj.weight": 0.2447509765625,
            "model.layers.28.self_attn.v_proj.weight": 2.552734375,
            "model.layers.28.self_attn.o_proj.weight": 0.36376953125,
            "model.layers.28.mlp.gate_proj.weight": 1.0546875,
            "model.layers.28.mlp.up_proj.weight": 1.2607421875,
            "model.layers.28.mlp.down_proj.weight": 2.958984375,
            "model.layers.28.input_layernorm.weight": 0.04290771484375,
            "model.layers.28.post_attention_layernorm.weight": 0.006633758544921875,
            "model.layers.29.self_attn.q_proj.weight": -0.01250457763671875,
            "model.layers.29.self_attn.k_proj.weight": 0.0030918121337890625,
            "model.layers.29.self_attn.v_proj.weight": 1.4931640625,
            "model.layers.29.self_attn.o_proj.weight": 0.1434326171875,
            "model.layers.29.mlp.gate_proj.weight": 1.3369140625,
            "model.layers.29.mlp.up_proj.weight": 1.2734375,
            "model.layers.29.mlp.down_proj.weight": 4.41015625,
            "model.layers.29.input_layernorm.weight": -0.459716796875,
            "model.layers.29.post_attention_layernorm.weight": -0.0084075927734375,
            "model.layers.30.self_attn.q_proj.weight": 0.067138671875,
            "model.layers.30.self_attn.k_proj.weight": 0.05987548828125,
            "model.layers.30.self_attn.v_proj.weight": 1.9150390625,
            "model.layers.30.self_attn.o_proj.weight": 0.74609375,
            "model.layers.30.mlp.gate_proj.weight": 1.185546875,
            "model.layers.30.mlp.up_proj.weight": 1.591796875,
            "model.layers.30.mlp.down_proj.weight": 63.59375,
            "model.layers.30.input_layernorm.weight": 0.0108795166015625,
            "model.layers.30.post_attention_layernorm.weight": 0.015655517578125,
            "model.layers.31.self_attn.q_proj.weight": 0.049102783203125,
            "model.layers.31.self_attn.k_proj.weight": -0.330078125,
            "model.layers.31.self_attn.v_proj.weight": 5.9609375,
            "model.layers.31.self_attn.o_proj.weight": 1.189453125,
            "model.layers.31.mlp.gate_proj.weight": 1.6455078125,
            "model.layers.31.mlp.up_proj.weight": 4.2578125,
            "model.layers.31.mlp.down_proj.weight": 35.0,
            "model.layers.31.input_layernorm.weight": 0.031494140625,
            "model.layers.31.post_attention_layernorm.weight": 0.312744140625,
            "model.norm.weight": 0.0157012939453125,
            "lm_head.weight": 223.25
        },
        "edited_sentence": "The name of the country of citizenship of Jerrod Carmichael is",
        "edited_sentence_answer": "Terengganu",
        "NLL": [
            9.692054748535156,
            5.494997978210449,
            3.481705904006958,
            5.320807456970215,
            2.1434381008148193
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": -10.53125,
            "model.layers.0.self_attn.q_proj.weight": -0.03472900390625,
            "model.layers.0.self_attn.k_proj.weight": -0.297119140625,
            "model.layers.0.self_attn.v_proj.weight": -19.328125,
            "model.layers.0.self_attn.o_proj.weight": -21.15625,
            "model.layers.0.mlp.gate_proj.weight": -0.751953125,
            "model.layers.0.mlp.up_proj.weight": -0.88671875,
            "model.layers.0.mlp.down_proj.weight": -3.603515625,
            "model.layers.0.input_layernorm.weight": -1.275390625,
            "model.layers.0.post_attention_layernorm.weight": -1.3359375,
            "model.layers.1.self_attn.q_proj.weight": -0.2244873046875,
            "model.layers.1.self_attn.k_proj.weight": -0.12939453125,
            "model.layers.1.self_attn.v_proj.weight": -92.0625,
            "model.layers.1.self_attn.o_proj.weight": -12.1875,
            "model.layers.1.mlp.gate_proj.weight": -1.5009765625,
            "model.layers.1.mlp.up_proj.weight": -1.8330078125,
            "model.layers.1.mlp.down_proj.weight": -181.125,
            "model.layers.1.input_layernorm.weight": 3.162109375,
            "model.layers.1.post_attention_layernorm.weight": -0.352783203125,
            "model.layers.2.self_attn.q_proj.weight": -0.3173828125,
            "model.layers.2.self_attn.k_proj.weight": -0.8193359375,
            "model.layers.2.self_attn.v_proj.weight": -10.046875,
            "model.layers.2.self_attn.o_proj.weight": -3.345703125,
            "model.layers.2.mlp.gate_proj.weight": -1.23046875,
            "model.layers.2.mlp.up_proj.weight": -1.8330078125,
            "model.layers.2.mlp.down_proj.weight": -2.431640625,
            "model.layers.2.input_layernorm.weight": 3.814453125,
            "model.layers.2.post_attention_layernorm.weight": 0.2205810546875,
            "model.layers.3.self_attn.q_proj.weight": 2.30078125,
            "model.layers.3.self_attn.k_proj.weight": 1.0400390625,
            "model.layers.3.self_attn.v_proj.weight": -2.001953125,
            "model.layers.3.self_attn.o_proj.weight": -1.009765625,
            "model.layers.3.mlp.gate_proj.weight": -0.37939453125,
            "model.layers.3.mlp.up_proj.weight": 0.01377105712890625,
            "model.layers.3.mlp.down_proj.weight": -0.791015625,
            "model.layers.3.input_layernorm.weight": -8.125,
            "model.layers.3.post_attention_layernorm.weight": 0.35595703125,
            "model.layers.4.self_attn.q_proj.weight": 1.228515625,
            "model.layers.4.self_attn.k_proj.weight": 0.81884765625,
            "model.layers.4.self_attn.v_proj.weight": 9.546875,
            "model.layers.4.self_attn.o_proj.weight": -0.1712646484375,
            "model.layers.4.mlp.gate_proj.weight": -0.59375,
            "model.layers.4.mlp.up_proj.weight": -1.125,
            "model.layers.4.mlp.down_proj.weight": -1.0283203125,
            "model.layers.4.input_layernorm.weight": -5.77734375,
            "model.layers.4.post_attention_layernorm.weight": 0.341552734375,
            "model.layers.5.self_attn.q_proj.weight": -1.263671875,
            "model.layers.5.self_attn.k_proj.weight": 0.32470703125,
            "model.layers.5.self_attn.v_proj.weight": 1.572265625,
            "model.layers.5.self_attn.o_proj.weight": 0.3154296875,
            "model.layers.5.mlp.gate_proj.weight": -0.81201171875,
            "model.layers.5.mlp.up_proj.weight": 0.12493896484375,
            "model.layers.5.mlp.down_proj.weight": -2.123046875,
            "model.layers.5.input_layernorm.weight": 9.375,
            "model.layers.5.post_attention_layernorm.weight": 0.0413818359375,
            "model.layers.6.self_attn.q_proj.weight": 1.0166015625,
            "model.layers.6.self_attn.k_proj.weight": -0.34912109375,
            "model.layers.6.self_attn.v_proj.weight": -3.03125,
            "model.layers.6.self_attn.o_proj.weight": -1.7626953125,
            "model.layers.6.mlp.gate_proj.weight": -0.58251953125,
            "model.layers.6.mlp.up_proj.weight": -0.1285400390625,
            "model.layers.6.mlp.down_proj.weight": -3.5625,
            "model.layers.6.input_layernorm.weight": 0.266845703125,
            "model.layers.6.post_attention_layernorm.weight": 0.3935546875,
            "model.layers.7.self_attn.q_proj.weight": -1.4404296875,
            "model.layers.7.self_attn.k_proj.weight": -2.20703125,
            "model.layers.7.self_attn.v_proj.weight": -2.904296875,
            "model.layers.7.self_attn.o_proj.weight": -2.447265625,
            "model.layers.7.mlp.gate_proj.weight": -2.0546875,
            "model.layers.7.mlp.up_proj.weight": -2.94140625,
            "model.layers.7.mlp.down_proj.weight": -2.451171875,
            "model.layers.7.input_layernorm.weight": -0.0022487640380859375,
            "model.layers.7.post_attention_layernorm.weight": -0.2425537109375,
            "model.layers.8.self_attn.q_proj.weight": -0.78662109375,
            "model.layers.8.self_attn.k_proj.weight": -0.79248046875,
            "model.layers.8.self_attn.v_proj.weight": -14.7109375,
            "model.layers.8.self_attn.o_proj.weight": -3.279296875,
            "model.layers.8.mlp.gate_proj.weight": -2.744140625,
            "model.layers.8.mlp.up_proj.weight": -3.5078125,
            "model.layers.8.mlp.down_proj.weight": -1.763671875,
            "model.layers.8.input_layernorm.weight": -2.77734375,
            "model.layers.8.post_attention_layernorm.weight": -0.10357666015625,
            "model.layers.9.self_attn.q_proj.weight": 0.04327392578125,
            "model.layers.9.self_attn.k_proj.weight": 0.97314453125,
            "model.layers.9.self_attn.v_proj.weight": -14.359375,
            "model.layers.9.self_attn.o_proj.weight": -1.890625,
            "model.layers.9.mlp.gate_proj.weight": -0.990234375,
            "model.layers.9.mlp.up_proj.weight": -1.6474609375,
            "model.layers.9.mlp.down_proj.weight": -0.8662109375,
            "model.layers.9.input_layernorm.weight": 0.18994140625,
            "model.layers.9.post_attention_layernorm.weight": -0.0108184814453125,
            "model.layers.10.self_attn.q_proj.weight": -0.028350830078125,
            "model.layers.10.self_attn.k_proj.weight": -0.0797119140625,
            "model.layers.10.self_attn.v_proj.weight": -4.78515625,
            "model.layers.10.self_attn.o_proj.weight": -1.0595703125,
            "model.layers.10.mlp.gate_proj.weight": -0.73828125,
            "model.layers.10.mlp.up_proj.weight": -2.001953125,
            "model.layers.10.mlp.down_proj.weight": -1.60546875,
            "model.layers.10.input_layernorm.weight": 0.4892578125,
            "model.layers.10.post_attention_layernorm.weight": -0.0029392242431640625,
            "model.layers.11.self_attn.q_proj.weight": -0.560546875,
            "model.layers.11.self_attn.k_proj.weight": -0.7138671875,
            "model.layers.11.self_attn.v_proj.weight": -9.21875,
            "model.layers.11.self_attn.o_proj.weight": -1.248046875,
            "model.layers.11.mlp.gate_proj.weight": -1.7744140625,
            "model.layers.11.mlp.up_proj.weight": -1.8837890625,
            "model.layers.11.mlp.down_proj.weight": -1.61328125,
            "model.layers.11.input_layernorm.weight": 0.9384765625,
            "model.layers.11.post_attention_layernorm.weight": -0.042877197265625,
            "model.layers.12.self_attn.q_proj.weight": 0.06378173828125,
            "model.layers.12.self_attn.k_proj.weight": -1.0341796875,
            "model.layers.12.self_attn.v_proj.weight": -10.234375,
            "model.layers.12.self_attn.o_proj.weight": -1.615234375,
            "model.layers.12.mlp.gate_proj.weight": -0.68408203125,
            "model.layers.12.mlp.up_proj.weight": -1.708984375,
            "model.layers.12.mlp.down_proj.weight": -1.68359375,
            "model.layers.12.input_layernorm.weight": 0.1435546875,
            "model.layers.12.post_attention_layernorm.weight": 0.04644775390625,
            "model.layers.13.self_attn.q_proj.weight": 2.12890625,
            "model.layers.13.self_attn.k_proj.weight": 1.376953125,
            "model.layers.13.self_attn.v_proj.weight": -9.6796875,
            "model.layers.13.self_attn.o_proj.weight": -1.09375,
            "model.layers.13.mlp.gate_proj.weight": -1.1611328125,
            "model.layers.13.mlp.up_proj.weight": -1.0888671875,
            "model.layers.13.mlp.down_proj.weight": -1.888671875,
            "model.layers.13.input_layernorm.weight": -0.424560546875,
            "model.layers.13.post_attention_layernorm.weight": -0.0970458984375,
            "model.layers.14.self_attn.q_proj.weight": -0.134521484375,
            "model.layers.14.self_attn.k_proj.weight": 0.1383056640625,
            "model.layers.14.self_attn.v_proj.weight": -13.34375,
            "model.layers.14.self_attn.o_proj.weight": -3.078125,
            "model.layers.14.mlp.gate_proj.weight": -1.5927734375,
            "model.layers.14.mlp.up_proj.weight": -1.048828125,
            "model.layers.14.mlp.down_proj.weight": -1.646484375,
            "model.layers.14.input_layernorm.weight": 0.52734375,
            "model.layers.14.post_attention_layernorm.weight": -0.0240478515625,
            "model.layers.15.self_attn.q_proj.weight": -0.615234375,
            "model.layers.15.self_attn.k_proj.weight": -0.1749267578125,
            "model.layers.15.self_attn.v_proj.weight": -6.89453125,
            "model.layers.15.self_attn.o_proj.weight": -1.1201171875,
            "model.layers.15.mlp.gate_proj.weight": -1.2158203125,
            "model.layers.15.mlp.up_proj.weight": -2.068359375,
            "model.layers.15.mlp.down_proj.weight": -1.4765625,
            "model.layers.15.input_layernorm.weight": 0.53369140625,
            "model.layers.15.post_attention_layernorm.weight": -0.06121826171875,
            "model.layers.16.self_attn.q_proj.weight": 0.114501953125,
            "model.layers.16.self_attn.k_proj.weight": 0.0487060546875,
            "model.layers.16.self_attn.v_proj.weight": -7.2578125,
            "model.layers.16.self_attn.o_proj.weight": -1.6533203125,
            "model.layers.16.mlp.gate_proj.weight": -0.623046875,
            "model.layers.16.mlp.up_proj.weight": -1.150390625,
            "model.layers.16.mlp.down_proj.weight": -1.255859375,
            "model.layers.16.input_layernorm.weight": -0.498779296875,
            "model.layers.16.post_attention_layernorm.weight": -0.05572509765625,
            "model.layers.17.self_attn.q_proj.weight": -0.206787109375,
            "model.layers.17.self_attn.k_proj.weight": -0.1822509765625,
            "model.layers.17.self_attn.v_proj.weight": -3.26953125,
            "model.layers.17.self_attn.o_proj.weight": -0.42041015625,
            "model.layers.17.mlp.gate_proj.weight": -0.71484375,
            "model.layers.17.mlp.up_proj.weight": -1.130859375,
            "model.layers.17.mlp.down_proj.weight": -0.74609375,
            "model.layers.17.input_layernorm.weight": -0.376220703125,
            "model.layers.17.post_attention_layernorm.weight": -0.027069091796875,
            "model.layers.18.self_attn.q_proj.weight": -0.93017578125,
            "model.layers.18.self_attn.k_proj.weight": -0.87744140625,
            "model.layers.18.self_attn.v_proj.weight": -2.13671875,
            "model.layers.18.self_attn.o_proj.weight": -0.2347412109375,
            "model.layers.18.mlp.gate_proj.weight": -0.313720703125,
            "model.layers.18.mlp.up_proj.weight": -0.7734375,
            "model.layers.18.mlp.down_proj.weight": -0.27587890625,
            "model.layers.18.input_layernorm.weight": 0.168212890625,
            "model.layers.18.post_attention_layernorm.weight": -0.00138092041015625,
            "model.layers.19.self_attn.q_proj.weight": -0.70654296875,
            "model.layers.19.self_attn.k_proj.weight": -0.580078125,
            "model.layers.19.self_attn.v_proj.weight": -0.489990234375,
            "model.layers.19.self_attn.o_proj.weight": -0.1759033203125,
            "model.layers.19.mlp.gate_proj.weight": -0.07806396484375,
            "model.layers.19.mlp.up_proj.weight": -0.57861328125,
            "model.layers.19.mlp.down_proj.weight": -0.305419921875,
            "model.layers.19.input_layernorm.weight": 0.00807952880859375,
            "model.layers.19.post_attention_layernorm.weight": 0.0199737548828125,
            "model.layers.20.self_attn.q_proj.weight": 0.08221435546875,
            "model.layers.20.self_attn.k_proj.weight": 0.62548828125,
            "model.layers.20.self_attn.v_proj.weight": -1.3896484375,
            "model.layers.20.self_attn.o_proj.weight": -0.223876953125,
            "model.layers.20.mlp.gate_proj.weight": -0.018646240234375,
            "model.layers.20.mlp.up_proj.weight": -0.1473388671875,
            "model.layers.20.mlp.down_proj.weight": -0.415283203125,
            "model.layers.20.input_layernorm.weight": 0.70654296875,
            "model.layers.20.post_attention_layernorm.weight": 0.044586181640625,
            "model.layers.21.self_attn.q_proj.weight": 0.100830078125,
            "model.layers.21.self_attn.k_proj.weight": 0.08001708984375,
            "model.layers.21.self_attn.v_proj.weight": -0.9169921875,
            "model.layers.21.self_attn.o_proj.weight": -0.06011962890625,
            "model.layers.21.mlp.gate_proj.weight": -0.1422119140625,
            "model.layers.21.mlp.up_proj.weight": -0.306640625,
            "model.layers.21.mlp.down_proj.weight": -0.310302734375,
            "model.layers.21.input_layernorm.weight": -0.08062744140625,
            "model.layers.21.post_attention_layernorm.weight": -0.010528564453125,
            "model.layers.22.self_attn.q_proj.weight": -0.75830078125,
            "model.layers.22.self_attn.k_proj.weight": -0.99560546875,
            "model.layers.22.self_attn.v_proj.weight": -0.748046875,
            "model.layers.22.self_attn.o_proj.weight": -0.085693359375,
            "model.layers.22.mlp.gate_proj.weight": -0.04400634765625,
            "model.layers.22.mlp.up_proj.weight": -0.1942138671875,
            "model.layers.22.mlp.down_proj.weight": -0.2242431640625,
            "model.layers.22.input_layernorm.weight": 0.001766204833984375,
            "model.layers.22.post_attention_layernorm.weight": -5.185604095458984e-06,
            "model.layers.23.self_attn.q_proj.weight": -0.0014019012451171875,
            "model.layers.23.self_attn.k_proj.weight": 0.003383636474609375,
            "model.layers.23.self_attn.v_proj.weight": -0.65283203125,
            "model.layers.23.self_attn.o_proj.weight": -0.0270538330078125,
            "model.layers.23.mlp.gate_proj.weight": -0.042877197265625,
            "model.layers.23.mlp.up_proj.weight": 0.047027587890625,
            "model.layers.23.mlp.down_proj.weight": -0.1822509765625,
            "model.layers.23.input_layernorm.weight": 0.1370849609375,
            "model.layers.23.post_attention_layernorm.weight": -0.012847900390625,
            "model.layers.24.self_attn.q_proj.weight": -0.0009303092956542969,
            "model.layers.24.self_attn.k_proj.weight": -0.019012451171875,
            "model.layers.24.self_attn.v_proj.weight": -0.62646484375,
            "model.layers.24.self_attn.o_proj.weight": -0.0777587890625,
            "model.layers.24.mlp.gate_proj.weight": -0.0081787109375,
            "model.layers.24.mlp.up_proj.weight": -0.16796875,
            "model.layers.24.mlp.down_proj.weight": -0.1334228515625,
            "model.layers.24.input_layernorm.weight": -0.01224517822265625,
            "model.layers.24.post_attention_layernorm.weight": -0.032562255859375,
            "model.layers.25.self_attn.q_proj.weight": 0.06292724609375,
            "model.layers.25.self_attn.k_proj.weight": 0.037322998046875,
            "model.layers.25.self_attn.v_proj.weight": -0.435791015625,
            "model.layers.25.self_attn.o_proj.weight": -0.00980377197265625,
            "model.layers.25.mlp.gate_proj.weight": 0.00852203369140625,
            "model.layers.25.mlp.up_proj.weight": -0.09320068359375,
            "model.layers.25.mlp.down_proj.weight": -0.2174072265625,
            "model.layers.25.input_layernorm.weight": -0.0020599365234375,
            "model.layers.25.post_attention_layernorm.weight": -0.0038166046142578125,
            "model.layers.26.self_attn.q_proj.weight": -0.1517333984375,
            "model.layers.26.self_attn.k_proj.weight": -0.11175537109375,
            "model.layers.26.self_attn.v_proj.weight": -0.77001953125,
            "model.layers.26.self_attn.o_proj.weight": -0.1260986328125,
            "model.layers.26.mlp.gate_proj.weight": -0.05718994140625,
            "model.layers.26.mlp.up_proj.weight": -0.042816162109375,
            "model.layers.26.mlp.down_proj.weight": -0.2420654296875,
            "model.layers.26.input_layernorm.weight": 0.0234222412109375,
            "model.layers.26.post_attention_layernorm.weight": 0.00476837158203125,
            "model.layers.27.self_attn.q_proj.weight": -0.070068359375,
            "model.layers.27.self_attn.k_proj.weight": -0.06427001953125,
            "model.layers.27.self_attn.v_proj.weight": -0.52294921875,
            "model.layers.27.self_attn.o_proj.weight": -0.052337646484375,
            "model.layers.27.mlp.gate_proj.weight": -0.0828857421875,
            "model.layers.27.mlp.up_proj.weight": -0.0931396484375,
            "model.layers.27.mlp.down_proj.weight": -0.521484375,
            "model.layers.27.input_layernorm.weight": -0.019500732421875,
            "model.layers.27.post_attention_layernorm.weight": 0.12066650390625,
            "model.layers.28.self_attn.q_proj.weight": -0.36865234375,
            "model.layers.28.self_attn.k_proj.weight": -0.281494140625,
            "model.layers.28.self_attn.v_proj.weight": -0.50634765625,
            "model.layers.28.self_attn.o_proj.weight": -0.0599365234375,
            "model.layers.28.mlp.gate_proj.weight": -0.1761474609375,
            "model.layers.28.mlp.up_proj.weight": -0.30712890625,
            "model.layers.28.mlp.down_proj.weight": -0.728515625,
            "model.layers.28.input_layernorm.weight": 0.004791259765625,
            "model.layers.28.post_attention_layernorm.weight": -0.00455474853515625,
            "model.layers.29.self_attn.q_proj.weight": -0.05255126953125,
            "model.layers.29.self_attn.k_proj.weight": -0.051025390625,
            "model.layers.29.self_attn.v_proj.weight": -0.14111328125,
            "model.layers.29.self_attn.o_proj.weight": -0.041778564453125,
            "model.layers.29.mlp.gate_proj.weight": -0.0655517578125,
            "model.layers.29.mlp.up_proj.weight": -0.1273193359375,
            "model.layers.29.mlp.down_proj.weight": -0.98974609375,
            "model.layers.29.input_layernorm.weight": -0.2437744140625,
            "model.layers.29.post_attention_layernorm.weight": -6.413459777832031e-05,
            "model.layers.30.self_attn.q_proj.weight": 0.183349609375,
            "model.layers.30.self_attn.k_proj.weight": 0.231689453125,
            "model.layers.30.self_attn.v_proj.weight": -0.420654296875,
            "model.layers.30.self_attn.o_proj.weight": -0.16650390625,
            "model.layers.30.mlp.gate_proj.weight": -1.4384765625,
            "model.layers.30.mlp.up_proj.weight": -0.92333984375,
            "model.layers.30.mlp.down_proj.weight": -9.859375,
            "model.layers.30.input_layernorm.weight": -0.040191650390625,
            "model.layers.30.post_attention_layernorm.weight": 0.03851318359375,
            "model.layers.31.self_attn.q_proj.weight": -0.32421875,
            "model.layers.31.self_attn.k_proj.weight": -0.8193359375,
            "model.layers.31.self_attn.v_proj.weight": -2.306640625,
            "model.layers.31.self_attn.o_proj.weight": -0.316650390625,
            "model.layers.31.mlp.gate_proj.weight": -0.51220703125,
            "model.layers.31.mlp.up_proj.weight": -3.841796875,
            "model.layers.31.mlp.down_proj.weight": 0.45361328125,
            "model.layers.31.input_layernorm.weight": -0.431396484375,
            "model.layers.31.post_attention_layernorm.weight": 0.372802734375,
            "model.norm.weight": 0.0013980865478515625,
            "lm_head.weight": 9.9765625
        },
        "edited_sentence": "The name of the country of citizenship of Jerrod Carmichael is",
        "edited_sentence_answer": "Terengganu",
        "NLL": [
            9.692054748535156,
            5.494997978210449,
            3.481705904006958,
            5.320807456970215,
            2.1434381008148193
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": -10.46875,
            "model.layers.0.self_attn.q_proj.weight": -0.039276123046875,
            "model.layers.0.self_attn.k_proj.weight": 0.0906982421875,
            "model.layers.0.self_attn.v_proj.weight": -30.59375,
            "model.layers.0.self_attn.o_proj.weight": 0.37060546875,
            "model.layers.0.mlp.gate_proj.weight": -0.44580078125,
            "model.layers.0.mlp.up_proj.weight": -0.8251953125,
            "model.layers.0.mlp.down_proj.weight": -0.007495880126953125,
            "model.layers.0.input_layernorm.weight": -0.87060546875,
            "model.layers.0.post_attention_layernorm.weight": 0.9716796875,
            "model.layers.1.self_attn.q_proj.weight": 0.041229248046875,
            "model.layers.1.self_attn.k_proj.weight": -0.00981903076171875,
            "model.layers.1.self_attn.v_proj.weight": -102.75,
            "model.layers.1.self_attn.o_proj.weight": -1.435546875,
            "model.layers.1.mlp.gate_proj.weight": -0.1971435546875,
            "model.layers.1.mlp.up_proj.weight": -0.6513671875,
            "model.layers.1.mlp.down_proj.weight": -502.25,
            "model.layers.1.input_layernorm.weight": -8.1875,
            "model.layers.1.post_attention_layernorm.weight": 0.1856689453125,
            "model.layers.2.self_attn.q_proj.weight": -1.154296875,
            "model.layers.2.self_attn.k_proj.weight": -0.9970703125,
            "model.layers.2.self_attn.v_proj.weight": 0.61474609375,
            "model.layers.2.self_attn.o_proj.weight": 0.14697265625,
            "model.layers.2.mlp.gate_proj.weight": -0.0777587890625,
            "model.layers.2.mlp.up_proj.weight": 0.40771484375,
            "model.layers.2.mlp.down_proj.weight": 0.20947265625,
            "model.layers.2.input_layernorm.weight": -43.125,
            "model.layers.2.post_attention_layernorm.weight": 0.46826171875,
            "model.layers.3.self_attn.q_proj.weight": -0.84765625,
            "model.layers.3.self_attn.k_proj.weight": -1.5732421875,
            "model.layers.3.self_attn.v_proj.weight": 3.048828125,
            "model.layers.3.self_attn.o_proj.weight": 0.1650390625,
            "model.layers.3.mlp.gate_proj.weight": 0.6396484375,
            "model.layers.3.mlp.up_proj.weight": 0.413818359375,
            "model.layers.3.mlp.down_proj.weight": -0.109619140625,
            "model.layers.3.input_layernorm.weight": 35.65625,
            "model.layers.3.post_attention_layernorm.weight": 0.1444091796875,
            "model.layers.4.self_attn.q_proj.weight": 0.100830078125,
            "model.layers.4.self_attn.k_proj.weight": 0.0914306640625,
            "model.layers.4.self_attn.v_proj.weight": -3.26953125,
            "model.layers.4.self_attn.o_proj.weight": -0.7490234375,
            "model.layers.4.mlp.gate_proj.weight": -0.67724609375,
            "model.layers.4.mlp.up_proj.weight": -0.6513671875,
            "model.layers.4.mlp.down_proj.weight": -0.89892578125,
            "model.layers.4.input_layernorm.weight": -0.346923828125,
            "model.layers.4.post_attention_layernorm.weight": -1.4052734375,
            "model.layers.5.self_attn.q_proj.weight": 0.681640625,
            "model.layers.5.self_attn.k_proj.weight": -0.064208984375,
            "model.layers.5.self_attn.v_proj.weight": -2.66796875,
            "model.layers.5.self_attn.o_proj.weight": -0.5888671875,
            "model.layers.5.mlp.gate_proj.weight": -0.0271148681640625,
            "model.layers.5.mlp.up_proj.weight": -0.2178955078125,
            "model.layers.5.mlp.down_proj.weight": -0.19775390625,
            "model.layers.5.input_layernorm.weight": -0.0302734375,
            "model.layers.5.post_attention_layernorm.weight": -0.335205078125,
            "model.layers.6.self_attn.q_proj.weight": 0.228271484375,
            "model.layers.6.self_attn.k_proj.weight": 0.21826171875,
            "model.layers.6.self_attn.v_proj.weight": -2.322265625,
            "model.layers.6.self_attn.o_proj.weight": -0.40576171875,
            "model.layers.6.mlp.gate_proj.weight": -0.2342529296875,
            "model.layers.6.mlp.up_proj.weight": -0.157470703125,
            "model.layers.6.mlp.down_proj.weight": -0.241943359375,
            "model.layers.6.input_layernorm.weight": -0.544921875,
            "model.layers.6.post_attention_layernorm.weight": 0.26318359375,
            "model.layers.7.self_attn.q_proj.weight": -0.1351318359375,
            "model.layers.7.self_attn.k_proj.weight": -0.2203369140625,
            "model.layers.7.self_attn.v_proj.weight": -2.5546875,
            "model.layers.7.self_attn.o_proj.weight": -0.59765625,
            "model.layers.7.mlp.gate_proj.weight": 0.2724609375,
            "model.layers.7.mlp.up_proj.weight": 0.0215301513671875,
            "model.layers.7.mlp.down_proj.weight": -0.029876708984375,
            "model.layers.7.input_layernorm.weight": -0.56787109375,
            "model.layers.7.post_attention_layernorm.weight": 0.023223876953125,
            "model.layers.8.self_attn.q_proj.weight": -0.04229736328125,
            "model.layers.8.self_attn.k_proj.weight": -0.1988525390625,
            "model.layers.8.self_attn.v_proj.weight": 0.0859375,
            "model.layers.8.self_attn.o_proj.weight": -0.312255859375,
            "model.layers.8.mlp.gate_proj.weight": 0.10113525390625,
            "model.layers.8.mlp.up_proj.weight": -0.9609375,
            "model.layers.8.mlp.down_proj.weight": -0.369384765625,
            "model.layers.8.input_layernorm.weight": -0.48193359375,
            "model.layers.8.post_attention_layernorm.weight": -0.08343505859375,
            "model.layers.9.self_attn.q_proj.weight": 0.8798828125,
            "model.layers.9.self_attn.k_proj.weight": 0.8388671875,
            "model.layers.9.self_attn.v_proj.weight": 2.916015625,
            "model.layers.9.self_attn.o_proj.weight": -0.4150390625,
            "model.layers.9.mlp.gate_proj.weight": 0.1705322265625,
            "model.layers.9.mlp.up_proj.weight": 0.1878662109375,
            "model.layers.9.mlp.down_proj.weight": -0.13232421875,
            "model.layers.9.input_layernorm.weight": -0.165283203125,
            "model.layers.9.post_attention_layernorm.weight": 0.07696533203125,
            "model.layers.10.self_attn.q_proj.weight": 0.06671142578125,
            "model.layers.10.self_attn.k_proj.weight": -0.047882080078125,
            "model.layers.10.self_attn.v_proj.weight": 1.3330078125,
            "model.layers.10.self_attn.o_proj.weight": -0.2239990234375,
            "model.layers.10.mlp.gate_proj.weight": -0.257080078125,
            "model.layers.10.mlp.up_proj.weight": 0.0791015625,
            "model.layers.10.mlp.down_proj.weight": -0.5205078125,
            "model.layers.10.input_layernorm.weight": 0.185791015625,
            "model.layers.10.post_attention_layernorm.weight": 0.0038013458251953125,
            "model.layers.11.self_attn.q_proj.weight": -0.630859375,
            "model.layers.11.self_attn.k_proj.weight": -0.1624755859375,
            "model.layers.11.self_attn.v_proj.weight": -11.8046875,
            "model.layers.11.self_attn.o_proj.weight": -0.2088623046875,
            "model.layers.11.mlp.gate_proj.weight": -0.1695556640625,
            "model.layers.11.mlp.up_proj.weight": -0.97314453125,
            "model.layers.11.mlp.down_proj.weight": -0.363525390625,
            "model.layers.11.input_layernorm.weight": -0.259521484375,
            "model.layers.11.post_attention_layernorm.weight": 0.04132080078125,
            "model.layers.12.self_attn.q_proj.weight": 1.060546875,
            "model.layers.12.self_attn.k_proj.weight": 0.8720703125,
            "model.layers.12.self_attn.v_proj.weight": -7.625,
            "model.layers.12.self_attn.o_proj.weight": -0.30712890625,
            "model.layers.12.mlp.gate_proj.weight": 0.1612548828125,
            "model.layers.12.mlp.up_proj.weight": -0.458251953125,
            "model.layers.12.mlp.down_proj.weight": -0.378173828125,
            "model.layers.12.input_layernorm.weight": -4.72265625,
            "model.layers.12.post_attention_layernorm.weight": -0.53173828125,
            "model.layers.13.self_attn.q_proj.weight": 1.068359375,
            "model.layers.13.self_attn.k_proj.weight": 0.57373046875,
            "model.layers.13.self_attn.v_proj.weight": -8.1796875,
            "model.layers.13.self_attn.o_proj.weight": -0.7294921875,
            "model.layers.13.mlp.gate_proj.weight": -0.2376708984375,
            "model.layers.13.mlp.up_proj.weight": -0.58349609375,
            "model.layers.13.mlp.down_proj.weight": -0.65380859375,
            "model.layers.13.input_layernorm.weight": -4.2421875,
            "model.layers.13.post_attention_layernorm.weight": -1.0673828125,
            "model.layers.14.self_attn.q_proj.weight": -1.2177734375,
            "model.layers.14.self_attn.k_proj.weight": -1.091796875,
            "model.layers.14.self_attn.v_proj.weight": -6.453125,
            "model.layers.14.self_attn.o_proj.weight": -0.7451171875,
            "model.layers.14.mlp.gate_proj.weight": 0.314453125,
            "model.layers.14.mlp.up_proj.weight": 0.480224609375,
            "model.layers.14.mlp.down_proj.weight": -0.68115234375,
            "model.layers.14.input_layernorm.weight": 0.71240234375,
            "model.layers.14.post_attention_layernorm.weight": 0.3623046875,
            "model.layers.15.self_attn.q_proj.weight": -1.859375,
            "model.layers.15.self_attn.k_proj.weight": -1.85546875,
            "model.layers.15.self_attn.v_proj.weight": 0.51611328125,
            "model.layers.15.self_attn.o_proj.weight": -0.6826171875,
            "model.layers.15.mlp.gate_proj.weight": -0.759765625,
            "model.layers.15.mlp.up_proj.weight": -1.6142578125,
            "model.layers.15.mlp.down_proj.weight": -1.0703125,
            "model.layers.15.input_layernorm.weight": 4.9609375,
            "model.layers.15.post_attention_layernorm.weight": -0.271240234375,
            "model.layers.16.self_attn.q_proj.weight": -3.9609375,
            "model.layers.16.self_attn.k_proj.weight": -3.390625,
            "model.layers.16.self_attn.v_proj.weight": -12.4765625,
            "model.layers.16.self_attn.o_proj.weight": -1.447265625,
            "model.layers.16.mlp.gate_proj.weight": -0.66162109375,
            "model.layers.16.mlp.up_proj.weight": -1.7265625,
            "model.layers.16.mlp.down_proj.weight": -2.25390625,
            "model.layers.16.input_layernorm.weight": -1.9990234375,
            "model.layers.16.post_attention_layernorm.weight": -0.1361083984375,
            "model.layers.17.self_attn.q_proj.weight": -1.11328125,
            "model.layers.17.self_attn.k_proj.weight": -0.6103515625,
            "model.layers.17.self_attn.v_proj.weight": -5.671875,
            "model.layers.17.self_attn.o_proj.weight": -0.294677734375,
            "model.layers.17.mlp.gate_proj.weight": -1.09375,
            "model.layers.17.mlp.up_proj.weight": -0.461669921875,
            "model.layers.17.mlp.down_proj.weight": -2.72265625,
            "model.layers.17.input_layernorm.weight": 4.25390625,
            "model.layers.17.post_attention_layernorm.weight": 0.12225341796875,
            "model.layers.18.self_attn.q_proj.weight": -0.9501953125,
            "model.layers.18.self_attn.k_proj.weight": -1.1416015625,
            "model.layers.18.self_attn.v_proj.weight": -3.720703125,
            "model.layers.18.self_attn.o_proj.weight": -0.1708984375,
            "model.layers.18.mlp.gate_proj.weight": -0.80615234375,
            "model.layers.18.mlp.up_proj.weight": -0.5947265625,
            "model.layers.18.mlp.down_proj.weight": -1.3154296875,
            "model.layers.18.input_layernorm.weight": 1.04296875,
            "model.layers.18.post_attention_layernorm.weight": 0.171875,
            "model.layers.19.self_attn.q_proj.weight": 0.285888671875,
            "model.layers.19.self_attn.k_proj.weight": 0.50390625,
            "model.layers.19.self_attn.v_proj.weight": -3.1171875,
            "model.layers.19.self_attn.o_proj.weight": -0.49267578125,
            "model.layers.19.mlp.gate_proj.weight": -0.60009765625,
            "model.layers.19.mlp.up_proj.weight": -0.8193359375,
            "model.layers.19.mlp.down_proj.weight": -1.83203125,
            "model.layers.19.input_layernorm.weight": -1.537109375,
            "model.layers.19.post_attention_layernorm.weight": 0.44677734375,
            "model.layers.20.self_attn.q_proj.weight": 0.058197021484375,
            "model.layers.20.self_attn.k_proj.weight": -0.09234619140625,
            "model.layers.20.self_attn.v_proj.weight": -0.366943359375,
            "model.layers.20.self_attn.o_proj.weight": -0.11474609375,
            "model.layers.20.mlp.gate_proj.weight": -0.568359375,
            "model.layers.20.mlp.up_proj.weight": -0.40234375,
            "model.layers.20.mlp.down_proj.weight": -1.765625,
            "model.layers.20.input_layernorm.weight": -0.424560546875,
            "model.layers.20.post_attention_layernorm.weight": 0.03216552734375,
            "model.layers.21.self_attn.q_proj.weight": -0.234375,
            "model.layers.21.self_attn.k_proj.weight": -0.07122802734375,
            "model.layers.21.self_attn.v_proj.weight": -4.45703125,
            "model.layers.21.self_attn.o_proj.weight": -0.76708984375,
            "model.layers.21.mlp.gate_proj.weight": -0.51904296875,
            "model.layers.21.mlp.up_proj.weight": -1.0634765625,
            "model.layers.21.mlp.down_proj.weight": -1.5556640625,
            "model.layers.21.input_layernorm.weight": -0.1009521484375,
            "model.layers.21.post_attention_layernorm.weight": -0.047027587890625,
            "model.layers.22.self_attn.q_proj.weight": 0.105224609375,
            "model.layers.22.self_attn.k_proj.weight": 0.203369140625,
            "model.layers.22.self_attn.v_proj.weight": -2.759765625,
            "model.layers.22.self_attn.o_proj.weight": -0.1937255859375,
            "model.layers.22.mlp.gate_proj.weight": -0.57470703125,
            "model.layers.22.mlp.up_proj.weight": -0.95361328125,
            "model.layers.22.mlp.down_proj.weight": -1.1455078125,
            "model.layers.22.input_layernorm.weight": 0.1611328125,
            "model.layers.22.post_attention_layernorm.weight": -0.0207977294921875,
            "model.layers.23.self_attn.q_proj.weight": 0.151611328125,
            "model.layers.23.self_attn.k_proj.weight": 0.16064453125,
            "model.layers.23.self_attn.v_proj.weight": -1.400390625,
            "model.layers.23.self_attn.o_proj.weight": -0.24365234375,
            "model.layers.23.mlp.gate_proj.weight": -0.75830078125,
            "model.layers.23.mlp.up_proj.weight": -0.6318359375,
            "model.layers.23.mlp.down_proj.weight": -1.0048828125,
            "model.layers.23.input_layernorm.weight": 0.486083984375,
            "model.layers.23.post_attention_layernorm.weight": 0.015106201171875,
            "model.layers.24.self_attn.q_proj.weight": -0.0005745887756347656,
            "model.layers.24.self_attn.k_proj.weight": 0.049896240234375,
            "model.layers.24.self_attn.v_proj.weight": -3.15234375,
            "model.layers.24.self_attn.o_proj.weight": -0.172607421875,
            "model.layers.24.mlp.gate_proj.weight": -0.916015625,
            "model.layers.24.mlp.up_proj.weight": -0.9072265625,
            "model.layers.24.mlp.down_proj.weight": -1.1455078125,
            "model.layers.24.input_layernorm.weight": 0.1898193359375,
            "model.layers.24.post_attention_layernorm.weight": -0.0184783935546875,
            "model.layers.25.self_attn.q_proj.weight": -0.04931640625,
            "model.layers.25.self_attn.k_proj.weight": -0.059661865234375,
            "model.layers.25.self_attn.v_proj.weight": -1.8017578125,
            "model.layers.25.self_attn.o_proj.weight": -0.0948486328125,
            "model.layers.25.mlp.gate_proj.weight": -0.970703125,
            "model.layers.25.mlp.up_proj.weight": -1.1650390625,
            "model.layers.25.mlp.down_proj.weight": -1.2333984375,
            "model.layers.25.input_layernorm.weight": -0.1600341796875,
            "model.layers.25.post_attention_layernorm.weight": -0.01116180419921875,
            "model.layers.26.self_attn.q_proj.weight": 0.2861328125,
            "model.layers.26.self_attn.k_proj.weight": 0.495849609375,
            "model.layers.26.self_attn.v_proj.weight": -3.40234375,
            "model.layers.26.self_attn.o_proj.weight": -0.2440185546875,
            "model.layers.26.mlp.gate_proj.weight": -0.6240234375,
            "model.layers.26.mlp.up_proj.weight": -1.15625,
            "model.layers.26.mlp.down_proj.weight": -1.0048828125,
            "model.layers.26.input_layernorm.weight": -0.440185546875,
            "model.layers.26.post_attention_layernorm.weight": 0.0006375312805175781,
            "model.layers.27.self_attn.q_proj.weight": 0.043914794921875,
            "model.layers.27.self_attn.k_proj.weight": 0.06341552734375,
            "model.layers.27.self_attn.v_proj.weight": -0.818359375,
            "model.layers.27.self_attn.o_proj.weight": -0.0408935546875,
            "model.layers.27.mlp.gate_proj.weight": -0.66650390625,
            "model.layers.27.mlp.up_proj.weight": -1.060546875,
            "model.layers.27.mlp.down_proj.weight": -0.740234375,
            "model.layers.27.input_layernorm.weight": 0.419921875,
            "model.layers.27.post_attention_layernorm.weight": 0.052398681640625,
            "model.layers.28.self_attn.q_proj.weight": -16.109375,
            "model.layers.28.self_attn.k_proj.weight": -21.171875,
            "model.layers.28.self_attn.v_proj.weight": -4.24609375,
            "model.layers.28.self_attn.o_proj.weight": -0.1307373046875,
            "model.layers.28.mlp.gate_proj.weight": -0.6435546875,
            "model.layers.28.mlp.up_proj.weight": -0.60595703125,
            "model.layers.28.mlp.down_proj.weight": -0.61376953125,
            "model.layers.28.input_layernorm.weight": -3.517578125,
            "model.layers.28.post_attention_layernorm.weight": -0.026824951171875,
            "model.layers.29.self_attn.q_proj.weight": -1.814453125,
            "model.layers.29.self_attn.k_proj.weight": -2.53515625,
            "model.layers.29.self_attn.v_proj.weight": -2.857421875,
            "model.layers.29.self_attn.o_proj.weight": -0.05596923828125,
            "model.layers.29.mlp.gate_proj.weight": -0.2265625,
            "model.layers.29.mlp.up_proj.weight": -0.5849609375,
            "model.layers.29.mlp.down_proj.weight": 0.021148681640625,
            "model.layers.29.input_layernorm.weight": -0.53955078125,
            "model.layers.29.post_attention_layernorm.weight": -0.00876617431640625,
            "model.layers.30.self_attn.q_proj.weight": -1.5927734375,
            "model.layers.30.self_attn.k_proj.weight": -1.9365234375,
            "model.layers.30.self_attn.v_proj.weight": -2.40234375,
            "model.layers.30.self_attn.o_proj.weight": -0.06298828125,
            "model.layers.30.mlp.gate_proj.weight": -0.7744140625,
            "model.layers.30.mlp.up_proj.weight": -0.1220703125,
            "model.layers.30.mlp.down_proj.weight": -35.03125,
            "model.layers.30.input_layernorm.weight": -0.166748046875,
            "model.layers.30.post_attention_layernorm.weight": -0.11328125,
            "model.layers.31.self_attn.q_proj.weight": -0.06243896484375,
            "model.layers.31.self_attn.k_proj.weight": -1.869140625,
            "model.layers.31.self_attn.v_proj.weight": -4.05078125,
            "model.layers.31.self_attn.o_proj.weight": -0.048583984375,
            "model.layers.31.mlp.gate_proj.weight": 0.19287109375,
            "model.layers.31.mlp.up_proj.weight": 0.86376953125,
            "model.layers.31.mlp.down_proj.weight": 6.56640625,
            "model.layers.31.input_layernorm.weight": -0.55224609375,
            "model.layers.31.post_attention_layernorm.weight": 0.042236328125,
            "model.norm.weight": 0.014068603515625,
            "lm_head.weight": 6.19921875
        },
        "edited_sentence": "The name of the composer of Vikram is",
        "edited_sentence_answer": "Johnny Reine",
        "NLL": [
            10.641916275024414,
            6.78133487701416,
            3.729529857635498,
            5.02738094329834,
            4.750014305114746
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 4.4609375,
            "model.layers.0.self_attn.q_proj.weight": 0.062408447265625,
            "model.layers.0.self_attn.k_proj.weight": 0.08038330078125,
            "model.layers.0.self_attn.v_proj.weight": 357.5,
            "model.layers.0.self_attn.o_proj.weight": 18.8125,
            "model.layers.0.mlp.gate_proj.weight": -1.1103515625,
            "model.layers.0.mlp.up_proj.weight": -1.046875,
            "model.layers.0.mlp.down_proj.weight": 0.1396484375,
            "model.layers.0.input_layernorm.weight": 8.359375,
            "model.layers.0.post_attention_layernorm.weight": 10.890625,
            "model.layers.1.self_attn.q_proj.weight": -0.37451171875,
            "model.layers.1.self_attn.k_proj.weight": -0.0450439453125,
            "model.layers.1.self_attn.v_proj.weight": -105.375,
            "model.layers.1.self_attn.o_proj.weight": 1.3447265625,
            "model.layers.1.mlp.gate_proj.weight": -1.1279296875,
            "model.layers.1.mlp.up_proj.weight": -1.638671875,
            "model.layers.1.mlp.down_proj.weight": 2520.0,
            "model.layers.1.input_layernorm.weight": -21.640625,
            "model.layers.1.post_attention_layernorm.weight": -3.9375,
            "model.layers.2.self_attn.q_proj.weight": -5.5625,
            "model.layers.2.self_attn.k_proj.weight": -3.818359375,
            "model.layers.2.self_attn.v_proj.weight": 4.953125,
            "model.layers.2.self_attn.o_proj.weight": -2.84765625,
            "model.layers.2.mlp.gate_proj.weight": -2.3671875,
            "model.layers.2.mlp.up_proj.weight": -3.23828125,
            "model.layers.2.mlp.down_proj.weight": -4.36328125,
            "model.layers.2.input_layernorm.weight": -115.625,
            "model.layers.2.post_attention_layernorm.weight": 0.44580078125,
            "model.layers.3.self_attn.q_proj.weight": -9.5078125,
            "model.layers.3.self_attn.k_proj.weight": -4.83203125,
            "model.layers.3.self_attn.v_proj.weight": 14.65625,
            "model.layers.3.self_attn.o_proj.weight": 4.12890625,
            "model.layers.3.mlp.gate_proj.weight": -0.387451171875,
            "model.layers.3.mlp.up_proj.weight": -1.2109375,
            "model.layers.3.mlp.down_proj.weight": 0.50341796875,
            "model.layers.3.input_layernorm.weight": 81.4375,
            "model.layers.3.post_attention_layernorm.weight": -0.158447265625,
            "model.layers.4.self_attn.q_proj.weight": 22.859375,
            "model.layers.4.self_attn.k_proj.weight": 15.375,
            "model.layers.4.self_attn.v_proj.weight": 40.21875,
            "model.layers.4.self_attn.o_proj.weight": 2.21875,
            "model.layers.4.mlp.gate_proj.weight": -3.392578125,
            "model.layers.4.mlp.up_proj.weight": -5.7734375,
            "model.layers.4.mlp.down_proj.weight": 0.7265625,
            "model.layers.4.input_layernorm.weight": 4.0078125,
            "model.layers.4.post_attention_layernorm.weight": 0.9765625,
            "model.layers.5.self_attn.q_proj.weight": -2.095703125,
            "model.layers.5.self_attn.k_proj.weight": -0.127685546875,
            "model.layers.5.self_attn.v_proj.weight": 29.1875,
            "model.layers.5.self_attn.o_proj.weight": 1.7041015625,
            "model.layers.5.mlp.gate_proj.weight": 0.2012939453125,
            "model.layers.5.mlp.up_proj.weight": -1.341796875,
            "model.layers.5.mlp.down_proj.weight": 4.21875,
            "model.layers.5.input_layernorm.weight": 0.60498046875,
            "model.layers.5.post_attention_layernorm.weight": 1.94140625,
            "model.layers.6.self_attn.q_proj.weight": 0.88525390625,
            "model.layers.6.self_attn.k_proj.weight": 2.3359375,
            "model.layers.6.self_attn.v_proj.weight": 93.375,
            "model.layers.6.self_attn.o_proj.weight": 8.25,
            "model.layers.6.mlp.gate_proj.weight": 2.80078125,
            "model.layers.6.mlp.up_proj.weight": 3.099609375,
            "model.layers.6.mlp.down_proj.weight": 4.890625,
            "model.layers.6.input_layernorm.weight": -0.9150390625,
            "model.layers.6.post_attention_layernorm.weight": 0.75,
            "model.layers.7.self_attn.q_proj.weight": 1.9423828125,
            "model.layers.7.self_attn.k_proj.weight": 2.271484375,
            "model.layers.7.self_attn.v_proj.weight": 80.5625,
            "model.layers.7.self_attn.o_proj.weight": 7.109375,
            "model.layers.7.mlp.gate_proj.weight": 3.900390625,
            "model.layers.7.mlp.up_proj.weight": 5.44140625,
            "model.layers.7.mlp.down_proj.weight": 4.65625,
            "model.layers.7.input_layernorm.weight": 14.9296875,
            "model.layers.7.post_attention_layernorm.weight": -0.3486328125,
            "model.layers.8.self_attn.q_proj.weight": 0.41064453125,
            "model.layers.8.self_attn.k_proj.weight": 0.01139068603515625,
            "model.layers.8.self_attn.v_proj.weight": 105.4375,
            "model.layers.8.self_attn.o_proj.weight": 10.6640625,
            "model.layers.8.mlp.gate_proj.weight": 4.08203125,
            "model.layers.8.mlp.up_proj.weight": 8.609375,
            "model.layers.8.mlp.down_proj.weight": 3.74609375,
            "model.layers.8.input_layernorm.weight": -2.791015625,
            "model.layers.8.post_attention_layernorm.weight": -0.419677734375,
            "model.layers.9.self_attn.q_proj.weight": 5.62109375,
            "model.layers.9.self_attn.k_proj.weight": 4.55078125,
            "model.layers.9.self_attn.v_proj.weight": 36.28125,
            "model.layers.9.self_attn.o_proj.weight": 6.66796875,
            "model.layers.9.mlp.gate_proj.weight": 0.5107421875,
            "model.layers.9.mlp.up_proj.weight": 2.88671875,
            "model.layers.9.mlp.down_proj.weight": 2.7578125,
            "model.layers.9.input_layernorm.weight": 1.6025390625,
            "model.layers.9.post_attention_layernorm.weight": 0.2186279296875,
            "model.layers.10.self_attn.q_proj.weight": -1.5634765625,
            "model.layers.10.self_attn.k_proj.weight": -0.99951171875,
            "model.layers.10.self_attn.v_proj.weight": 47.3125,
            "model.layers.10.self_attn.o_proj.weight": 5.46875,
            "model.layers.10.mlp.gate_proj.weight": 4.43359375,
            "model.layers.10.mlp.up_proj.weight": 3.890625,
            "model.layers.10.mlp.down_proj.weight": 5.33984375,
            "model.layers.10.input_layernorm.weight": -6.609375,
            "model.layers.10.post_attention_layernorm.weight": -0.4970703125,
            "model.layers.11.self_attn.q_proj.weight": 7.22265625,
            "model.layers.11.self_attn.k_proj.weight": 5.5546875,
            "model.layers.11.self_attn.v_proj.weight": 70.625,
            "model.layers.11.self_attn.o_proj.weight": 5.109375,
            "model.layers.11.mlp.gate_proj.weight": 2.58984375,
            "model.layers.11.mlp.up_proj.weight": 3.96875,
            "model.layers.11.mlp.down_proj.weight": 3.244140625,
            "model.layers.11.input_layernorm.weight": -9.40625,
            "model.layers.11.post_attention_layernorm.weight": 1.7060546875,
            "model.layers.12.self_attn.q_proj.weight": 1.6220703125,
            "model.layers.12.self_attn.k_proj.weight": 0.38671875,
            "model.layers.12.self_attn.v_proj.weight": 45.0625,
            "model.layers.12.self_attn.o_proj.weight": 4.6953125,
            "model.layers.12.mlp.gate_proj.weight": 1.8896484375,
            "model.layers.12.mlp.up_proj.weight": 3.13671875,
            "model.layers.12.mlp.down_proj.weight": 2.751953125,
            "model.layers.12.input_layernorm.weight": -9.0390625,
            "model.layers.12.post_attention_layernorm.weight": 0.28857421875,
            "model.layers.13.self_attn.q_proj.weight": 1.599609375,
            "model.layers.13.self_attn.k_proj.weight": 0.96337890625,
            "model.layers.13.self_attn.v_proj.weight": 43.71875,
            "model.layers.13.self_attn.o_proj.weight": 2.759765625,
            "model.layers.13.mlp.gate_proj.weight": 2.25,
            "model.layers.13.mlp.up_proj.weight": 1.1298828125,
            "model.layers.13.mlp.down_proj.weight": 1.0498046875,
            "model.layers.13.input_layernorm.weight": 13.3046875,
            "model.layers.13.post_attention_layernorm.weight": -0.69580078125,
            "model.layers.14.self_attn.q_proj.weight": -1.7158203125,
            "model.layers.14.self_attn.k_proj.weight": -1.2080078125,
            "model.layers.14.self_attn.v_proj.weight": -5.87109375,
            "model.layers.14.self_attn.o_proj.weight": 2.73046875,
            "model.layers.14.mlp.gate_proj.weight": 2.86328125,
            "model.layers.14.mlp.up_proj.weight": 5.39453125,
            "model.layers.14.mlp.down_proj.weight": -0.426513671875,
            "model.layers.14.input_layernorm.weight": -0.63818359375,
            "model.layers.14.post_attention_layernorm.weight": 0.477294921875,
            "model.layers.15.self_attn.q_proj.weight": 0.4814453125,
            "model.layers.15.self_attn.k_proj.weight": 1.54296875,
            "model.layers.15.self_attn.v_proj.weight": -36.5,
            "model.layers.15.self_attn.o_proj.weight": -1.4130859375,
            "model.layers.15.mlp.gate_proj.weight": -1.5478515625,
            "model.layers.15.mlp.up_proj.weight": 0.78173828125,
            "model.layers.15.mlp.down_proj.weight": -10.125,
            "model.layers.15.input_layernorm.weight": -1.427734375,
            "model.layers.15.post_attention_layernorm.weight": -0.56396484375,
            "model.layers.16.self_attn.q_proj.weight": -2.84765625,
            "model.layers.16.self_attn.k_proj.weight": -7.69140625,
            "model.layers.16.self_attn.v_proj.weight": -48.3125,
            "model.layers.16.self_attn.o_proj.weight": 1.501953125,
            "model.layers.16.mlp.gate_proj.weight": 3.048828125,
            "model.layers.16.mlp.up_proj.weight": 1.55859375,
            "model.layers.16.mlp.down_proj.weight": -0.763671875,
            "model.layers.16.input_layernorm.weight": 1.271484375,
            "model.layers.16.post_attention_layernorm.weight": 0.5791015625,
            "model.layers.17.self_attn.q_proj.weight": 1.404296875,
            "model.layers.17.self_attn.k_proj.weight": 0.9912109375,
            "model.layers.17.self_attn.v_proj.weight": -18.28125,
            "model.layers.17.self_attn.o_proj.weight": -0.30859375,
            "model.layers.17.mlp.gate_proj.weight": 0.55419921875,
            "model.layers.17.mlp.up_proj.weight": 1.8076171875,
            "model.layers.17.mlp.down_proj.weight": -5.734375,
            "model.layers.17.input_layernorm.weight": -0.60791015625,
            "model.layers.17.post_attention_layernorm.weight": -0.21875,
            "model.layers.18.self_attn.q_proj.weight": 1.5244140625,
            "model.layers.18.self_attn.k_proj.weight": 1.45703125,
            "model.layers.18.self_attn.v_proj.weight": -9.4921875,
            "model.layers.18.self_attn.o_proj.weight": 0.352783203125,
            "model.layers.18.mlp.gate_proj.weight": 0.08734130859375,
            "model.layers.18.mlp.up_proj.weight": -1.2734375,
            "model.layers.18.mlp.down_proj.weight": -2.951171875,
            "model.layers.18.input_layernorm.weight": 0.9482421875,
            "model.layers.18.post_attention_layernorm.weight": -0.073974609375,
            "model.layers.19.self_attn.q_proj.weight": -1.9541015625,
            "model.layers.19.self_attn.k_proj.weight": -0.84912109375,
            "model.layers.19.self_attn.v_proj.weight": -0.95263671875,
            "model.layers.19.self_attn.o_proj.weight": -0.5390625,
            "model.layers.19.mlp.gate_proj.weight": -0.138427734375,
            "model.layers.19.mlp.up_proj.weight": 0.343017578125,
            "model.layers.19.mlp.down_proj.weight": -1.177734375,
            "model.layers.19.input_layernorm.weight": 1.09375,
            "model.layers.19.post_attention_layernorm.weight": 0.1256103515625,
            "model.layers.20.self_attn.q_proj.weight": -0.640625,
            "model.layers.20.self_attn.k_proj.weight": 0.65673828125,
            "model.layers.20.self_attn.v_proj.weight": 3.498046875,
            "model.layers.20.self_attn.o_proj.weight": 0.423095703125,
            "model.layers.20.mlp.gate_proj.weight": -0.1575927734375,
            "model.layers.20.mlp.up_proj.weight": -0.50732421875,
            "model.layers.20.mlp.down_proj.weight": -0.9423828125,
            "model.layers.20.input_layernorm.weight": 0.09613037109375,
            "model.layers.20.post_attention_layernorm.weight": 0.025726318359375,
            "model.layers.21.self_attn.q_proj.weight": -0.361572265625,
            "model.layers.21.self_attn.k_proj.weight": -0.1728515625,
            "model.layers.21.self_attn.v_proj.weight": 0.79443359375,
            "model.layers.21.self_attn.o_proj.weight": -0.580078125,
            "model.layers.21.mlp.gate_proj.weight": -0.276123046875,
            "model.layers.21.mlp.up_proj.weight": -0.64404296875,
            "model.layers.21.mlp.down_proj.weight": -0.88134765625,
            "model.layers.21.input_layernorm.weight": 0.93603515625,
            "model.layers.21.post_attention_layernorm.weight": 0.05584716796875,
            "model.layers.22.self_attn.q_proj.weight": 0.50048828125,
            "model.layers.22.self_attn.k_proj.weight": 0.279296875,
            "model.layers.22.self_attn.v_proj.weight": -0.9482421875,
            "model.layers.22.self_attn.o_proj.weight": -0.0982666015625,
            "model.layers.22.mlp.gate_proj.weight": -0.2041015625,
            "model.layers.22.mlp.up_proj.weight": -0.9248046875,
            "model.layers.22.mlp.down_proj.weight": -0.98876953125,
            "model.layers.22.input_layernorm.weight": 0.385986328125,
            "model.layers.22.post_attention_layernorm.weight": 0.124267578125,
            "model.layers.23.self_attn.q_proj.weight": -0.324951171875,
            "model.layers.23.self_attn.k_proj.weight": -0.39697265625,
            "model.layers.23.self_attn.v_proj.weight": 1.2958984375,
            "model.layers.23.self_attn.o_proj.weight": -0.25048828125,
            "model.layers.23.mlp.gate_proj.weight": -0.96435546875,
            "model.layers.23.mlp.up_proj.weight": -1.109375,
            "model.layers.23.mlp.down_proj.weight": -0.89306640625,
            "model.layers.23.input_layernorm.weight": -0.65576171875,
            "model.layers.23.post_attention_layernorm.weight": -0.044158935546875,
            "model.layers.24.self_attn.q_proj.weight": -0.35302734375,
            "model.layers.24.self_attn.k_proj.weight": -0.46630859375,
            "model.layers.24.self_attn.v_proj.weight": 3.947265625,
            "model.layers.24.self_attn.o_proj.weight": -0.0703125,
            "model.layers.24.mlp.gate_proj.weight": -0.98193359375,
            "model.layers.24.mlp.up_proj.weight": -0.62451171875,
            "model.layers.24.mlp.down_proj.weight": -1.0791015625,
            "model.layers.24.input_layernorm.weight": 0.0928955078125,
            "model.layers.24.post_attention_layernorm.weight": -0.0133514404296875,
            "model.layers.25.self_attn.q_proj.weight": -0.00982666015625,
            "model.layers.25.self_attn.k_proj.weight": 0.0100860595703125,
            "model.layers.25.self_attn.v_proj.weight": -0.62744140625,
            "model.layers.25.self_attn.o_proj.weight": -0.03936767578125,
            "model.layers.25.mlp.gate_proj.weight": -1.4921875,
            "model.layers.25.mlp.up_proj.weight": -1.927734375,
            "model.layers.25.mlp.down_proj.weight": -1.201171875,
            "model.layers.25.input_layernorm.weight": -0.11639404296875,
            "model.layers.25.post_attention_layernorm.weight": -0.016265869140625,
            "model.layers.26.self_attn.q_proj.weight": 0.077392578125,
            "model.layers.26.self_attn.k_proj.weight": -0.020111083984375,
            "model.layers.26.self_attn.v_proj.weight": -0.08331298828125,
            "model.layers.26.self_attn.o_proj.weight": -0.1551513671875,
            "model.layers.26.mlp.gate_proj.weight": -0.99560546875,
            "model.layers.26.mlp.up_proj.weight": -1.298828125,
            "model.layers.26.mlp.down_proj.weight": -1.0986328125,
            "model.layers.26.input_layernorm.weight": 0.080078125,
            "model.layers.26.post_attention_layernorm.weight": 0.08099365234375,
            "model.layers.27.self_attn.q_proj.weight": 0.29248046875,
            "model.layers.27.self_attn.k_proj.weight": 0.24072265625,
            "model.layers.27.self_attn.v_proj.weight": 1.30859375,
            "model.layers.27.self_attn.o_proj.weight": -0.01168060302734375,
            "model.layers.27.mlp.gate_proj.weight": -0.68505859375,
            "model.layers.27.mlp.up_proj.weight": -1.3994140625,
            "model.layers.27.mlp.down_proj.weight": -1.234375,
            "model.layers.27.input_layernorm.weight": 0.1986083984375,
            "model.layers.27.post_attention_layernorm.weight": 0.01085662841796875,
            "model.layers.28.self_attn.q_proj.weight": -17.328125,
            "model.layers.28.self_attn.k_proj.weight": -24.546875,
            "model.layers.28.self_attn.v_proj.weight": -1.8857421875,
            "model.layers.28.self_attn.o_proj.weight": -0.1282958984375,
            "model.layers.28.mlp.gate_proj.weight": -1.2109375,
            "model.layers.28.mlp.up_proj.weight": -0.6953125,
            "model.layers.28.mlp.down_proj.weight": -0.41162109375,
            "model.layers.28.input_layernorm.weight": -2.640625,
            "model.layers.28.post_attention_layernorm.weight": 0.0030384063720703125,
            "model.layers.29.self_attn.q_proj.weight": -0.7353515625,
            "model.layers.29.self_attn.k_proj.weight": -0.81689453125,
            "model.layers.29.self_attn.v_proj.weight": -0.03955078125,
            "model.layers.29.self_attn.o_proj.weight": 0.0229339599609375,
            "model.layers.29.mlp.gate_proj.weight": 0.0287017822265625,
            "model.layers.29.mlp.up_proj.weight": 0.42919921875,
            "model.layers.29.mlp.down_proj.weight": 0.947265625,
            "model.layers.29.input_layernorm.weight": 0.2783203125,
            "model.layers.29.post_attention_layernorm.weight": -0.0264434814453125,
            "model.layers.30.self_attn.q_proj.weight": -0.5830078125,
            "model.layers.30.self_attn.k_proj.weight": -0.2978515625,
            "model.layers.30.self_attn.v_proj.weight": 0.9306640625,
            "model.layers.30.self_attn.o_proj.weight": 0.136962890625,
            "model.layers.30.mlp.gate_proj.weight": 0.1802978515625,
            "model.layers.30.mlp.up_proj.weight": -1.0,
            "model.layers.30.mlp.down_proj.weight": -29.4375,
            "model.layers.30.input_layernorm.weight": 0.11083984375,
            "model.layers.30.post_attention_layernorm.weight": 0.369140625,
            "model.layers.31.self_attn.q_proj.weight": -0.016937255859375,
            "model.layers.31.self_attn.k_proj.weight": -0.58349609375,
            "model.layers.31.self_attn.v_proj.weight": -0.380615234375,
            "model.layers.31.self_attn.o_proj.weight": 0.1446533203125,
            "model.layers.31.mlp.gate_proj.weight": 1.0615234375,
            "model.layers.31.mlp.up_proj.weight": 13.6796875,
            "model.layers.31.mlp.down_proj.weight": 46.75,
            "model.layers.31.input_layernorm.weight": -0.0122833251953125,
            "model.layers.31.post_attention_layernorm.weight": 0.71533203125,
            "model.norm.weight": 0.337890625,
            "lm_head.weight": 31.359375
        },
        "edited_sentence": "The name of the composer of Vikram is",
        "edited_sentence_answer": "Johnny Reine",
        "NLL": [
            10.641916275024414,
            6.78133487701416,
            3.729529857635498,
            5.02738094329834,
            4.750014305114746
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 9.53125,
            "model.layers.0.self_attn.q_proj.weight": -0.0236968994140625,
            "model.layers.0.self_attn.k_proj.weight": 1.080078125,
            "model.layers.0.self_attn.v_proj.weight": 200.25,
            "model.layers.0.self_attn.o_proj.weight": 11.1328125,
            "model.layers.0.mlp.gate_proj.weight": -0.454345703125,
            "model.layers.0.mlp.up_proj.weight": -0.62890625,
            "model.layers.0.mlp.down_proj.weight": 0.037200927734375,
            "model.layers.0.input_layernorm.weight": 5.421875,
            "model.layers.0.post_attention_layernorm.weight": 4.9609375,
            "model.layers.1.self_attn.q_proj.weight": -0.235107421875,
            "model.layers.1.self_attn.k_proj.weight": -0.05224609375,
            "model.layers.1.self_attn.v_proj.weight": -72.3125,
            "model.layers.1.self_attn.o_proj.weight": 0.66259765625,
            "model.layers.1.mlp.gate_proj.weight": -0.52001953125,
            "model.layers.1.mlp.up_proj.weight": -0.78759765625,
            "model.layers.1.mlp.down_proj.weight": 1713.0,
            "model.layers.1.input_layernorm.weight": -11.5625,
            "model.layers.1.post_attention_layernorm.weight": -2.060546875,
            "model.layers.2.self_attn.q_proj.weight": -2.244140625,
            "model.layers.2.self_attn.k_proj.weight": -1.5576171875,
            "model.layers.2.self_attn.v_proj.weight": 0.8486328125,
            "model.layers.2.self_attn.o_proj.weight": -1.5869140625,
            "model.layers.2.mlp.gate_proj.weight": -1.54296875,
            "model.layers.2.mlp.up_proj.weight": -2.0390625,
            "model.layers.2.mlp.down_proj.weight": -2.603515625,
            "model.layers.2.input_layernorm.weight": -77.5,
            "model.layers.2.post_attention_layernorm.weight": 0.705078125,
            "model.layers.3.self_attn.q_proj.weight": -5.37109375,
            "model.layers.3.self_attn.k_proj.weight": -2.83984375,
            "model.layers.3.self_attn.v_proj.weight": 11.1796875,
            "model.layers.3.self_attn.o_proj.weight": 2.779296875,
            "model.layers.3.mlp.gate_proj.weight": -0.167236328125,
            "model.layers.3.mlp.up_proj.weight": -0.393798828125,
            "model.layers.3.mlp.down_proj.weight": 0.6630859375,
            "model.layers.3.input_layernorm.weight": 53.03125,
            "model.layers.3.post_attention_layernorm.weight": 0.161376953125,
            "model.layers.4.self_attn.q_proj.weight": 12.6953125,
            "model.layers.4.self_attn.k_proj.weight": 9.0390625,
            "model.layers.4.self_attn.v_proj.weight": 34.03125,
            "model.layers.4.self_attn.o_proj.weight": 1.6962890625,
            "model.layers.4.mlp.gate_proj.weight": -1.8955078125,
            "model.layers.4.mlp.up_proj.weight": -3.509765625,
            "model.layers.4.mlp.down_proj.weight": 0.8642578125,
            "model.layers.4.input_layernorm.weight": 2.20703125,
            "model.layers.4.post_attention_layernorm.weight": 0.403076171875,
            "model.layers.5.self_attn.q_proj.weight": -0.7119140625,
            "model.layers.5.self_attn.k_proj.weight": 0.255859375,
            "model.layers.5.self_attn.v_proj.weight": 24.078125,
            "model.layers.5.self_attn.o_proj.weight": 1.1787109375,
            "model.layers.5.mlp.gate_proj.weight": 0.052764892578125,
            "model.layers.5.mlp.up_proj.weight": -0.7392578125,
            "model.layers.5.mlp.down_proj.weight": 2.73828125,
            "model.layers.5.input_layernorm.weight": 0.458984375,
            "model.layers.5.post_attention_layernorm.weight": 1.625,
            "model.layers.6.self_attn.q_proj.weight": 0.599609375,
            "model.layers.6.self_attn.k_proj.weight": 1.3076171875,
            "model.layers.6.self_attn.v_proj.weight": 58.78125,
            "model.layers.6.self_attn.o_proj.weight": 5.4296875,
            "model.layers.6.mlp.gate_proj.weight": 1.638671875,
            "model.layers.6.mlp.up_proj.weight": 1.8984375,
            "model.layers.6.mlp.down_proj.weight": 3.125,
            "model.layers.6.input_layernorm.weight": -0.44189453125,
            "model.layers.6.post_attention_layernorm.weight": 0.305419921875,
            "model.layers.7.self_attn.q_proj.weight": 0.26171875,
            "model.layers.7.self_attn.k_proj.weight": 0.7021484375,
            "model.layers.7.self_attn.v_proj.weight": 49.46875,
            "model.layers.7.self_attn.o_proj.weight": 4.58203125,
            "model.layers.7.mlp.gate_proj.weight": 2.45703125,
            "model.layers.7.mlp.up_proj.weight": 3.62109375,
            "model.layers.7.mlp.down_proj.weight": 3.2265625,
            "model.layers.7.input_layernorm.weight": 8.28125,
            "model.layers.7.post_attention_layernorm.weight": -0.2447509765625,
            "model.layers.8.self_attn.q_proj.weight": 0.9296875,
            "model.layers.8.self_attn.k_proj.weight": 0.552734375,
            "model.layers.8.self_attn.v_proj.weight": 62.375,
            "model.layers.8.self_attn.o_proj.weight": 6.95703125,
            "model.layers.8.mlp.gate_proj.weight": 2.578125,
            "model.layers.8.mlp.up_proj.weight": 5.109375,
            "model.layers.8.mlp.down_proj.weight": 2.580078125,
            "model.layers.8.input_layernorm.weight": -1.2236328125,
            "model.layers.8.post_attention_layernorm.weight": -0.2037353515625,
            "model.layers.9.self_attn.q_proj.weight": 2.638671875,
            "model.layers.9.self_attn.k_proj.weight": 2.25,
            "model.layers.9.self_attn.v_proj.weight": 23.6875,
            "model.layers.9.self_attn.o_proj.weight": 4.36328125,
            "model.layers.9.mlp.gate_proj.weight": 0.62158203125,
            "model.layers.9.mlp.up_proj.weight": 2.224609375,
            "model.layers.9.mlp.down_proj.weight": 2.046875,
            "model.layers.9.input_layernorm.weight": -0.681640625,
            "model.layers.9.post_attention_layernorm.weight": 0.10882568359375,
            "model.layers.10.self_attn.q_proj.weight": -0.732421875,
            "model.layers.10.self_attn.k_proj.weight": -0.5458984375,
            "model.layers.10.self_attn.v_proj.weight": 35.53125,
            "model.layers.10.self_attn.o_proj.weight": 3.8671875,
            "model.layers.10.mlp.gate_proj.weight": 2.888671875,
            "model.layers.10.mlp.up_proj.weight": 2.4765625,
            "model.layers.10.mlp.down_proj.weight": 3.837890625,
            "model.layers.10.input_layernorm.weight": -3.37109375,
            "model.layers.10.post_attention_layernorm.weight": -0.297607421875,
            "model.layers.11.self_attn.q_proj.weight": 4.1484375,
            "model.layers.11.self_attn.k_proj.weight": 3.3359375,
            "model.layers.11.self_attn.v_proj.weight": 50.5625,
            "model.layers.11.self_attn.o_proj.weight": 3.83984375,
            "model.layers.11.mlp.gate_proj.weight": 1.8564453125,
            "model.layers.11.mlp.up_proj.weight": 2.7734375,
            "model.layers.11.mlp.down_proj.weight": 2.46484375,
            "model.layers.11.input_layernorm.weight": -4.11328125,
            "model.layers.11.post_attention_layernorm.weight": 1.1943359375,
            "model.layers.12.self_attn.q_proj.weight": 1.177734375,
            "model.layers.12.self_attn.k_proj.weight": 0.477294921875,
            "model.layers.12.self_attn.v_proj.weight": 33.15625,
            "model.layers.12.self_attn.o_proj.weight": 3.318359375,
            "model.layers.12.mlp.gate_proj.weight": 1.517578125,
            "model.layers.12.mlp.up_proj.weight": 2.185546875,
            "model.layers.12.mlp.down_proj.weight": 2.2109375,
            "model.layers.12.input_layernorm.weight": -3.708984375,
            "model.layers.12.post_attention_layernorm.weight": 0.1624755859375,
            "model.layers.13.self_attn.q_proj.weight": 0.85498046875,
            "model.layers.13.self_attn.k_proj.weight": 0.53515625,
            "model.layers.13.self_attn.v_proj.weight": 32.875,
            "model.layers.13.self_attn.o_proj.weight": 2.296875,
            "model.layers.13.mlp.gate_proj.weight": 1.7138671875,
            "model.layers.13.mlp.up_proj.weight": 1.609375,
            "model.layers.13.mlp.down_proj.weight": 1.6865234375,
            "model.layers.13.input_layernorm.weight": 6.453125,
            "model.layers.13.post_attention_layernorm.weight": -0.2159423828125,
            "model.layers.14.self_attn.q_proj.weight": -0.70654296875,
            "model.layers.14.self_attn.k_proj.weight": -0.424072265625,
            "model.layers.14.self_attn.v_proj.weight": 10.953125,
            "model.layers.14.self_attn.o_proj.weight": 2.306640625,
            "model.layers.14.mlp.gate_proj.weight": 1.916015625,
            "model.layers.14.mlp.up_proj.weight": 3.55078125,
            "model.layers.14.mlp.down_proj.weight": 1.109375,
            "model.layers.14.input_layernorm.weight": -0.306884765625,
            "model.layers.14.post_attention_layernorm.weight": 0.1363525390625,
            "model.layers.15.self_attn.q_proj.weight": 0.55322265625,
            "model.layers.15.self_attn.k_proj.weight": 1.1044921875,
            "model.layers.15.self_attn.v_proj.weight": -7.0078125,
            "model.layers.15.self_attn.o_proj.weight": 0.0465087890625,
            "model.layers.15.mlp.gate_proj.weight": 0.1522216796875,
            "model.layers.15.mlp.up_proj.weight": 1.427734375,
            "model.layers.15.mlp.down_proj.weight": -3.74609375,
            "model.layers.15.input_layernorm.weight": 0.318115234375,
            "model.layers.15.post_attention_layernorm.weight": -0.272705078125,
            "model.layers.16.self_attn.q_proj.weight": -0.7744140625,
            "model.layers.16.self_attn.k_proj.weight": -2.80078125,
            "model.layers.16.self_attn.v_proj.weight": -18.859375,
            "model.layers.16.self_attn.o_proj.weight": 1.134765625,
            "model.layers.16.mlp.gate_proj.weight": 2.171875,
            "model.layers.16.mlp.up_proj.weight": 1.4658203125,
            "model.layers.16.mlp.down_proj.weight": 0.75927734375,
            "model.layers.16.input_layernorm.weight": 0.50048828125,
            "model.layers.16.post_attention_layernorm.weight": 0.410888671875,
            "model.layers.17.self_attn.q_proj.weight": 0.1563720703125,
            "model.layers.17.self_attn.k_proj.weight": -0.27197265625,
            "model.layers.17.self_attn.v_proj.weight": -7.28515625,
            "model.layers.17.self_attn.o_proj.weight": -0.0706787109375,
            "model.layers.17.mlp.gate_proj.weight": 0.349365234375,
            "model.layers.17.mlp.up_proj.weight": 1.591796875,
            "model.layers.17.mlp.down_proj.weight": -2.0859375,
            "model.layers.17.input_layernorm.weight": -0.31494140625,
            "model.layers.17.post_attention_layernorm.weight": -0.0712890625,
            "model.layers.18.self_attn.q_proj.weight": 1.7099609375,
            "model.layers.18.self_attn.k_proj.weight": 1.6591796875,
            "model.layers.18.self_attn.v_proj.weight": -4.7578125,
            "model.layers.18.self_attn.o_proj.weight": 0.264892578125,
            "model.layers.18.mlp.gate_proj.weight": 0.351318359375,
            "model.layers.18.mlp.up_proj.weight": 0.4697265625,
            "model.layers.18.mlp.down_proj.weight": -0.78759765625,
            "model.layers.18.input_layernorm.weight": 0.9658203125,
            "model.layers.18.post_attention_layernorm.weight": -0.0650634765625,
            "model.layers.19.self_attn.q_proj.weight": -0.48876953125,
            "model.layers.19.self_attn.k_proj.weight": -0.410888671875,
            "model.layers.19.self_attn.v_proj.weight": -0.80078125,
            "model.layers.19.self_attn.o_proj.weight": -0.04669189453125,
            "model.layers.19.mlp.gate_proj.weight": 0.365966796875,
            "model.layers.19.mlp.up_proj.weight": 0.60986328125,
            "model.layers.19.mlp.down_proj.weight": 0.158203125,
            "model.layers.19.input_layernorm.weight": 1.0166015625,
            "model.layers.19.post_attention_layernorm.weight": 0.2196044921875,
            "model.layers.20.self_attn.q_proj.weight": 0.06549072265625,
            "model.layers.20.self_attn.k_proj.weight": 0.96435546875,
            "model.layers.20.self_attn.v_proj.weight": 1.103515625,
            "model.layers.20.self_attn.o_proj.weight": 0.3056640625,
            "model.layers.20.mlp.gate_proj.weight": -0.05029296875,
            "model.layers.20.mlp.up_proj.weight": -0.06292724609375,
            "model.layers.20.mlp.down_proj.weight": -0.09539794921875,
            "model.layers.20.input_layernorm.weight": 0.058258056640625,
            "model.layers.20.post_attention_layernorm.weight": -0.0174713134765625,
            "model.layers.21.self_attn.q_proj.weight": -0.09210205078125,
            "model.layers.21.self_attn.k_proj.weight": -0.09954833984375,
            "model.layers.21.self_attn.v_proj.weight": 1.599609375,
            "model.layers.21.self_attn.o_proj.weight": -0.2191162109375,
            "model.layers.21.mlp.gate_proj.weight": -0.104248046875,
            "model.layers.21.mlp.up_proj.weight": -0.25537109375,
            "model.layers.21.mlp.down_proj.weight": -0.149169921875,
            "model.layers.21.input_layernorm.weight": 0.2498779296875,
            "model.layers.21.post_attention_layernorm.weight": 0.0155792236328125,
            "model.layers.22.self_attn.q_proj.weight": 0.2125244140625,
            "model.layers.22.self_attn.k_proj.weight": 0.243896484375,
            "model.layers.22.self_attn.v_proj.weight": 0.86474609375,
            "model.layers.22.self_attn.o_proj.weight": -0.01561737060546875,
            "model.layers.22.mlp.gate_proj.weight": 0.103759765625,
            "model.layers.22.mlp.up_proj.weight": -0.17431640625,
            "model.layers.22.mlp.down_proj.weight": -0.201416015625,
            "model.layers.22.input_layernorm.weight": 0.0751953125,
            "model.layers.22.post_attention_layernorm.weight": 0.1934814453125,
            "model.layers.23.self_attn.q_proj.weight": -0.052978515625,
            "model.layers.23.self_attn.k_proj.weight": -0.106689453125,
            "model.layers.23.self_attn.v_proj.weight": 0.35986328125,
            "model.layers.23.self_attn.o_proj.weight": -0.06353759765625,
            "model.layers.23.mlp.gate_proj.weight": -0.2034912109375,
            "model.layers.23.mlp.up_proj.weight": -0.21875,
            "model.layers.23.mlp.down_proj.weight": -0.107666015625,
            "model.layers.23.input_layernorm.weight": -0.73388671875,
            "model.layers.23.post_attention_layernorm.weight": 0.0031299591064453125,
            "model.layers.24.self_attn.q_proj.weight": -0.09326171875,
            "model.layers.24.self_attn.k_proj.weight": -0.1492919921875,
            "model.layers.24.self_attn.v_proj.weight": 1.66015625,
            "model.layers.24.self_attn.o_proj.weight": 0.048004150390625,
            "model.layers.24.mlp.gate_proj.weight": -0.240966796875,
            "model.layers.24.mlp.up_proj.weight": -0.306640625,
            "model.layers.24.mlp.down_proj.weight": -0.1839599609375,
            "model.layers.24.input_layernorm.weight": -0.20556640625,
            "model.layers.24.post_attention_layernorm.weight": 0.004497528076171875,
            "model.layers.25.self_attn.q_proj.weight": 0.1085205078125,
            "model.layers.25.self_attn.k_proj.weight": 0.1173095703125,
            "model.layers.25.self_attn.v_proj.weight": -0.1678466796875,
            "model.layers.25.self_attn.o_proj.weight": 0.00637054443359375,
            "model.layers.25.mlp.gate_proj.weight": -0.37548828125,
            "model.layers.25.mlp.up_proj.weight": -0.465087890625,
            "model.layers.25.mlp.down_proj.weight": -0.1995849609375,
            "model.layers.25.input_layernorm.weight": -0.09625244140625,
            "model.layers.25.post_attention_layernorm.weight": -0.00213623046875,
            "model.layers.26.self_attn.q_proj.weight": 0.0853271484375,
            "model.layers.26.self_attn.k_proj.weight": 0.036163330078125,
            "model.layers.26.self_attn.v_proj.weight": 1.1630859375,
            "model.layers.26.self_attn.o_proj.weight": 0.035675048828125,
            "model.layers.26.mlp.gate_proj.weight": -0.1309814453125,
            "model.layers.26.mlp.up_proj.weight": 0.1072998046875,
            "model.layers.26.mlp.down_proj.weight": -0.1923828125,
            "model.layers.26.input_layernorm.weight": -0.1466064453125,
            "model.layers.26.post_attention_layernorm.weight": -0.0145263671875,
            "model.layers.27.self_attn.q_proj.weight": 0.0145263671875,
            "model.layers.27.self_attn.k_proj.weight": 0.015838623046875,
            "model.layers.27.self_attn.v_proj.weight": 0.6220703125,
            "model.layers.27.self_attn.o_proj.weight": 0.027984619140625,
            "model.layers.27.mlp.gate_proj.weight": -0.0552978515625,
            "model.layers.27.mlp.up_proj.weight": -0.15625,
            "model.layers.27.mlp.down_proj.weight": -0.017181396484375,
            "model.layers.27.input_layernorm.weight": -0.29443359375,
            "model.layers.27.post_attention_layernorm.weight": -0.00995635986328125,
            "model.layers.28.self_attn.q_proj.weight": -4.28515625,
            "model.layers.28.self_attn.k_proj.weight": -5.41015625,
            "model.layers.28.self_attn.v_proj.weight": -0.03729248046875,
            "model.layers.28.self_attn.o_proj.weight": -0.01461029052734375,
            "model.layers.28.mlp.gate_proj.weight": -0.2169189453125,
            "model.layers.28.mlp.up_proj.weight": -0.1416015625,
            "model.layers.28.mlp.down_proj.weight": 0.07989501953125,
            "model.layers.28.input_layernorm.weight": 0.209716796875,
            "model.layers.28.post_attention_layernorm.weight": 0.02166748046875,
            "model.layers.29.self_attn.q_proj.weight": -0.018280029296875,
            "model.layers.29.self_attn.k_proj.weight": -0.3779296875,
            "model.layers.29.self_attn.v_proj.weight": 0.4482421875,
            "model.layers.29.self_attn.o_proj.weight": 0.041595458984375,
            "model.layers.29.mlp.gate_proj.weight": 0.22802734375,
            "model.layers.29.mlp.up_proj.weight": 0.27783203125,
            "model.layers.29.mlp.down_proj.weight": 0.9765625,
            "model.layers.29.input_layernorm.weight": 0.07537841796875,
            "model.layers.29.post_attention_layernorm.weight": -0.005413055419921875,
            "model.layers.30.self_attn.q_proj.weight": 0.34228515625,
            "model.layers.30.self_attn.k_proj.weight": 0.97021484375,
            "model.layers.30.self_attn.v_proj.weight": 1.3037109375,
            "model.layers.30.self_attn.o_proj.weight": 0.0843505859375,
            "model.layers.30.mlp.gate_proj.weight": 0.11370849609375,
            "model.layers.30.mlp.up_proj.weight": -0.15185546875,
            "model.layers.30.mlp.down_proj.weight": 18.796875,
            "model.layers.30.input_layernorm.weight": 0.6826171875,
            "model.layers.30.post_attention_layernorm.weight": 0.255126953125,
            "model.layers.31.self_attn.q_proj.weight": 0.0073089599609375,
            "model.layers.31.self_attn.k_proj.weight": 0.1405029296875,
            "model.layers.31.self_attn.v_proj.weight": 1.9521484375,
            "model.layers.31.self_attn.o_proj.weight": 0.138916015625,
            "model.layers.31.mlp.gate_proj.weight": 0.619140625,
            "model.layers.31.mlp.up_proj.weight": 5.2109375,
            "model.layers.31.mlp.down_proj.weight": 17.09375,
            "model.layers.31.input_layernorm.weight": -0.18115234375,
            "model.layers.31.post_attention_layernorm.weight": 0.04339599609375,
            "model.norm.weight": 0.1839599609375,
            "lm_head.weight": 15.6328125
        },
        "edited_sentence": "The name of the composer of Vikram is",
        "edited_sentence_answer": "Johnny Reine",
        "NLL": [
            10.641916275024414,
            6.78133487701416,
            3.729529857635498,
            5.02738094329834,
            4.750014305114746
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": -10.03125,
            "model.layers.0.self_attn.q_proj.weight": -0.2244873046875,
            "model.layers.0.self_attn.k_proj.weight": 0.1904296875,
            "model.layers.0.self_attn.v_proj.weight": 165.0,
            "model.layers.0.self_attn.o_proj.weight": -21.4375,
            "model.layers.0.mlp.gate_proj.weight": -1.8046875,
            "model.layers.0.mlp.up_proj.weight": -3.037109375,
            "model.layers.0.mlp.down_proj.weight": -3.845703125,
            "model.layers.0.input_layernorm.weight": 4.1484375,
            "model.layers.0.post_attention_layernorm.weight": 3.193359375,
            "model.layers.1.self_attn.q_proj.weight": -0.9443359375,
            "model.layers.1.self_attn.k_proj.weight": -0.38818359375,
            "model.layers.1.self_attn.v_proj.weight": -375.5,
            "model.layers.1.self_attn.o_proj.weight": -7.44921875,
            "model.layers.1.mlp.gate_proj.weight": -0.8212890625,
            "model.layers.1.mlp.up_proj.weight": -1.55859375,
            "model.layers.1.mlp.down_proj.weight": 2198.0,
            "model.layers.1.input_layernorm.weight": -17.265625,
            "model.layers.1.post_attention_layernorm.weight": -3.7578125,
            "model.layers.2.self_attn.q_proj.weight": -4.1015625,
            "model.layers.2.self_attn.k_proj.weight": -3.291015625,
            "model.layers.2.self_attn.v_proj.weight": -8.796875,
            "model.layers.2.self_attn.o_proj.weight": -4.81640625,
            "model.layers.2.mlp.gate_proj.weight": -2.486328125,
            "model.layers.2.mlp.up_proj.weight": -3.44921875,
            "model.layers.2.mlp.down_proj.weight": -4.72265625,
            "model.layers.2.input_layernorm.weight": -134.625,
            "model.layers.2.post_attention_layernorm.weight": 0.95068359375,
            "model.layers.3.self_attn.q_proj.weight": -9.09375,
            "model.layers.3.self_attn.k_proj.weight": -5.515625,
            "model.layers.3.self_attn.v_proj.weight": 9.0703125,
            "model.layers.3.self_attn.o_proj.weight": 2.96875,
            "model.layers.3.mlp.gate_proj.weight": -0.580078125,
            "model.layers.3.mlp.up_proj.weight": -0.89208984375,
            "model.layers.3.mlp.down_proj.weight": 0.45947265625,
            "model.layers.3.input_layernorm.weight": 77.1875,
            "model.layers.3.post_attention_layernorm.weight": 0.61572265625,
            "model.layers.4.self_attn.q_proj.weight": 18.28125,
            "model.layers.4.self_attn.k_proj.weight": 12.0703125,
            "model.layers.4.self_attn.v_proj.weight": 33.90625,
            "model.layers.4.self_attn.o_proj.weight": 0.457275390625,
            "model.layers.4.mlp.gate_proj.weight": -3.4453125,
            "model.layers.4.mlp.up_proj.weight": -5.90625,
            "model.layers.4.mlp.down_proj.weight": 0.685546875,
            "model.layers.4.input_layernorm.weight": 2.71484375,
            "model.layers.4.post_attention_layernorm.weight": -1.0234375,
            "model.layers.5.self_attn.q_proj.weight": -0.73828125,
            "model.layers.5.self_attn.k_proj.weight": 0.72900390625,
            "model.layers.5.self_attn.v_proj.weight": 28.0,
            "model.layers.5.self_attn.o_proj.weight": 1.287109375,
            "model.layers.5.mlp.gate_proj.weight": -0.2025146484375,
            "model.layers.5.mlp.up_proj.weight": -1.4892578125,
            "model.layers.5.mlp.down_proj.weight": 4.3984375,
            "model.layers.5.input_layernorm.weight": 0.720703125,
            "model.layers.5.post_attention_layernorm.weight": 1.552734375,
            "model.layers.6.self_attn.q_proj.weight": 0.2259521484375,
            "model.layers.6.self_attn.k_proj.weight": 0.69091796875,
            "model.layers.6.self_attn.v_proj.weight": 103.1875,
            "model.layers.6.self_attn.o_proj.weight": 9.703125,
            "model.layers.6.mlp.gate_proj.weight": 2.55859375,
            "model.layers.6.mlp.up_proj.weight": 2.888671875,
            "model.layers.6.mlp.down_proj.weight": 5.7578125,
            "model.layers.6.input_layernorm.weight": -0.55224609375,
            "model.layers.6.post_attention_layernorm.weight": 0.69873046875,
            "model.layers.7.self_attn.q_proj.weight": -0.34716796875,
            "model.layers.7.self_attn.k_proj.weight": 0.77587890625,
            "model.layers.7.self_attn.v_proj.weight": 86.3125,
            "model.layers.7.self_attn.o_proj.weight": 8.1640625,
            "model.layers.7.mlp.gate_proj.weight": 3.763671875,
            "model.layers.7.mlp.up_proj.weight": 6.41015625,
            "model.layers.7.mlp.down_proj.weight": 6.21484375,
            "model.layers.7.input_layernorm.weight": 12.328125,
            "model.layers.7.post_attention_layernorm.weight": -0.52392578125,
            "model.layers.8.self_attn.q_proj.weight": 0.642578125,
            "model.layers.8.self_attn.k_proj.weight": 0.060699462890625,
            "model.layers.8.self_attn.v_proj.weight": 112.8125,
            "model.layers.8.self_attn.o_proj.weight": 12.609375,
            "model.layers.8.mlp.gate_proj.weight": 4.57421875,
            "model.layers.8.mlp.up_proj.weight": 9.265625,
            "model.layers.8.mlp.down_proj.weight": 5.5,
            "model.layers.8.input_layernorm.weight": -2.869140625,
            "model.layers.8.post_attention_layernorm.weight": -0.2010498046875,
            "model.layers.9.self_attn.q_proj.weight": 5.46875,
            "model.layers.9.self_attn.k_proj.weight": 4.45703125,
            "model.layers.9.self_attn.v_proj.weight": 54.4375,
            "model.layers.9.self_attn.o_proj.weight": 8.4765625,
            "model.layers.9.mlp.gate_proj.weight": 1.4267578125,
            "model.layers.9.mlp.up_proj.weight": 4.04296875,
            "model.layers.9.mlp.down_proj.weight": 4.25390625,
            "model.layers.9.input_layernorm.weight": -0.55859375,
            "model.layers.9.post_attention_layernorm.weight": 0.353271484375,
            "model.layers.10.self_attn.q_proj.weight": 0.056304931640625,
            "model.layers.10.self_attn.k_proj.weight": -0.06732177734375,
            "model.layers.10.self_attn.v_proj.weight": 67.875,
            "model.layers.10.self_attn.o_proj.weight": 7.26953125,
            "model.layers.10.mlp.gate_proj.weight": 5.296875,
            "model.layers.10.mlp.up_proj.weight": 5.3359375,
            "model.layers.10.mlp.down_proj.weight": 7.58203125,
            "model.layers.10.input_layernorm.weight": -8.7890625,
            "model.layers.10.post_attention_layernorm.weight": -0.1707763671875,
            "model.layers.11.self_attn.q_proj.weight": 8.9296875,
            "model.layers.11.self_attn.k_proj.weight": 7.59765625,
            "model.layers.11.self_attn.v_proj.weight": 102.0,
            "model.layers.11.self_attn.o_proj.weight": 7.48046875,
            "model.layers.11.mlp.gate_proj.weight": 3.673828125,
            "model.layers.11.mlp.up_proj.weight": 5.4921875,
            "model.layers.11.mlp.down_proj.weight": 5.14453125,
            "model.layers.11.input_layernorm.weight": -6.65234375,
            "model.layers.11.post_attention_layernorm.weight": 1.798828125,
            "model.layers.12.self_attn.q_proj.weight": 3.408203125,
            "model.layers.12.self_attn.k_proj.weight": 1.912109375,
            "model.layers.12.self_attn.v_proj.weight": 64.8125,
            "model.layers.12.self_attn.o_proj.weight": 6.375,
            "model.layers.12.mlp.gate_proj.weight": 3.048828125,
            "model.layers.12.mlp.up_proj.weight": 4.828125,
            "model.layers.12.mlp.down_proj.weight": 4.81640625,
            "model.layers.12.input_layernorm.weight": -6.24609375,
            "model.layers.12.post_attention_layernorm.weight": -0.09393310546875,
            "model.layers.13.self_attn.q_proj.weight": 1.6416015625,
            "model.layers.13.self_attn.k_proj.weight": 1.5693359375,
            "model.layers.13.self_attn.v_proj.weight": 61.96875,
            "model.layers.13.self_attn.o_proj.weight": 4.65234375,
            "model.layers.13.mlp.gate_proj.weight": 3.8203125,
            "model.layers.13.mlp.up_proj.weight": 5.36328125,
            "model.layers.13.mlp.down_proj.weight": 4.578125,
            "model.layers.13.input_layernorm.weight": 10.9609375,
            "model.layers.13.post_attention_layernorm.weight": 0.4580078125,
            "model.layers.14.self_attn.q_proj.weight": -2.61328125,
            "model.layers.14.self_attn.k_proj.weight": -2.0078125,
            "model.layers.14.self_attn.v_proj.weight": 26.0625,
            "model.layers.14.self_attn.o_proj.weight": 4.65234375,
            "model.layers.14.mlp.gate_proj.weight": 4.046875,
            "model.layers.14.mlp.up_proj.weight": 7.2109375,
            "model.layers.14.mlp.down_proj.weight": 3.830078125,
            "model.layers.14.input_layernorm.weight": 1.12890625,
            "model.layers.14.post_attention_layernorm.weight": 0.13330078125,
            "model.layers.15.self_attn.q_proj.weight": 1.8076171875,
            "model.layers.15.self_attn.k_proj.weight": 3.62109375,
            "model.layers.15.self_attn.v_proj.weight": -1.6611328125,
            "model.layers.15.self_attn.o_proj.weight": 0.406982421875,
            "model.layers.15.mlp.gate_proj.weight": 2.052734375,
            "model.layers.15.mlp.up_proj.weight": 4.8359375,
            "model.layers.15.mlp.down_proj.weight": -2.1953125,
            "model.layers.15.input_layernorm.weight": 1.6318359375,
            "model.layers.15.post_attention_layernorm.weight": -0.1419677734375,
            "model.layers.16.self_attn.q_proj.weight": 0.51953125,
            "model.layers.16.self_attn.k_proj.weight": -0.86962890625,
            "model.layers.16.self_attn.v_proj.weight": -12.1875,
            "model.layers.16.self_attn.o_proj.weight": 2.83203125,
            "model.layers.16.mlp.gate_proj.weight": 4.1640625,
            "model.layers.16.mlp.up_proj.weight": 3.802734375,
            "model.layers.16.mlp.down_proj.weight": 2.216796875,
            "model.layers.16.input_layernorm.weight": 1.8525390625,
            "model.layers.16.post_attention_layernorm.weight": 0.61865234375,
            "model.layers.17.self_attn.q_proj.weight": 2.2421875,
            "model.layers.17.self_attn.k_proj.weight": 1.4541015625,
            "model.layers.17.self_attn.v_proj.weight": -15.53125,
            "model.layers.17.self_attn.o_proj.weight": 0.059814453125,
            "model.layers.17.mlp.gate_proj.weight": 2.44140625,
            "model.layers.17.mlp.up_proj.weight": 4.00390625,
            "model.layers.17.mlp.down_proj.weight": -2.1640625,
            "model.layers.17.input_layernorm.weight": 2.529296875,
            "model.layers.17.post_attention_layernorm.weight": -0.1798095703125,
            "model.layers.18.self_attn.q_proj.weight": 3.044921875,
            "model.layers.18.self_attn.k_proj.weight": 2.875,
            "model.layers.18.self_attn.v_proj.weight": -7.8203125,
            "model.layers.18.self_attn.o_proj.weight": 0.40771484375,
            "model.layers.18.mlp.gate_proj.weight": 1.3369140625,
            "model.layers.18.mlp.up_proj.weight": 2.390625,
            "model.layers.18.mlp.down_proj.weight": -0.4091796875,
            "model.layers.18.input_layernorm.weight": 1.978515625,
            "model.layers.18.post_attention_layernorm.weight": -0.0208892822265625,
            "model.layers.19.self_attn.q_proj.weight": 4.5390625,
            "model.layers.19.self_attn.k_proj.weight": 5.3515625,
            "model.layers.19.self_attn.v_proj.weight": 2.521484375,
            "model.layers.19.self_attn.o_proj.weight": -1.1748046875,
            "model.layers.19.mlp.gate_proj.weight": 0.2498779296875,
            "model.layers.19.mlp.up_proj.weight": 0.6279296875,
            "model.layers.19.mlp.down_proj.weight": -1.8779296875,
            "model.layers.19.input_layernorm.weight": 3.205078125,
            "model.layers.19.post_attention_layernorm.weight": 0.0908203125,
            "model.layers.20.self_attn.q_proj.weight": -0.83740234375,
            "model.layers.20.self_attn.k_proj.weight": -0.61572265625,
            "model.layers.20.self_attn.v_proj.weight": 0.32373046875,
            "model.layers.20.self_attn.o_proj.weight": 0.2685546875,
            "model.layers.20.mlp.gate_proj.weight": -0.8251953125,
            "model.layers.20.mlp.up_proj.weight": -0.5380859375,
            "model.layers.20.mlp.down_proj.weight": -1.638671875,
            "model.layers.20.input_layernorm.weight": 0.63525390625,
            "model.layers.20.post_attention_layernorm.weight": -0.08660888671875,
            "model.layers.21.self_attn.q_proj.weight": -0.34423828125,
            "model.layers.21.self_attn.k_proj.weight": -0.322509765625,
            "model.layers.21.self_attn.v_proj.weight": 1.6064453125,
            "model.layers.21.self_attn.o_proj.weight": -0.80908203125,
            "model.layers.21.mlp.gate_proj.weight": -0.654296875,
            "model.layers.21.mlp.up_proj.weight": -0.90771484375,
            "model.layers.21.mlp.down_proj.weight": -1.5517578125,
            "model.layers.21.input_layernorm.weight": 0.0196075439453125,
            "model.layers.21.post_attention_layernorm.weight": 0.10345458984375,
            "model.layers.22.self_attn.q_proj.weight": 0.1566162109375,
            "model.layers.22.self_attn.k_proj.weight": 0.057952880859375,
            "model.layers.22.self_attn.v_proj.weight": 4.671875,
            "model.layers.22.self_attn.o_proj.weight": -0.13671875,
            "model.layers.22.mlp.gate_proj.weight": -0.60791015625,
            "model.layers.22.mlp.up_proj.weight": -0.97802734375,
            "model.layers.22.mlp.down_proj.weight": -1.4912109375,
            "model.layers.22.input_layernorm.weight": 0.286865234375,
            "model.layers.22.post_attention_layernorm.weight": 0.1153564453125,
            "model.layers.23.self_attn.q_proj.weight": -0.322998046875,
            "model.layers.23.self_attn.k_proj.weight": -0.501953125,
            "model.layers.23.self_attn.v_proj.weight": -0.337890625,
            "model.layers.23.self_attn.o_proj.weight": -0.3291015625,
            "model.layers.23.mlp.gate_proj.weight": -0.99267578125,
            "model.layers.23.mlp.up_proj.weight": -1.4345703125,
            "model.layers.23.mlp.down_proj.weight": -1.240234375,
            "model.layers.23.input_layernorm.weight": -0.133544921875,
            "model.layers.23.post_attention_layernorm.weight": 0.015716552734375,
            "model.layers.24.self_attn.q_proj.weight": -0.37548828125,
            "model.layers.24.self_attn.k_proj.weight": -0.40380859375,
            "model.layers.24.self_attn.v_proj.weight": 0.489990234375,
            "model.layers.24.self_attn.o_proj.weight": -0.26171875,
            "model.layers.24.mlp.gate_proj.weight": -1.443359375,
            "model.layers.24.mlp.up_proj.weight": -0.810546875,
            "model.layers.24.mlp.down_proj.weight": -1.583984375,
            "model.layers.24.input_layernorm.weight": -0.1053466796875,
            "model.layers.24.post_attention_layernorm.weight": -0.019866943359375,
            "model.layers.25.self_attn.q_proj.weight": 0.00585174560546875,
            "model.layers.25.self_attn.k_proj.weight": 0.01535797119140625,
            "model.layers.25.self_attn.v_proj.weight": 1.3134765625,
            "model.layers.25.self_attn.o_proj.weight": -0.047882080078125,
            "model.layers.25.mlp.gate_proj.weight": -1.53515625,
            "model.layers.25.mlp.up_proj.weight": -1.77734375,
            "model.layers.25.mlp.down_proj.weight": -1.4267578125,
            "model.layers.25.input_layernorm.weight": -0.1279296875,
            "model.layers.25.post_attention_layernorm.weight": 0.00319671630859375,
            "model.layers.26.self_attn.q_proj.weight": -0.15576171875,
            "model.layers.26.self_attn.k_proj.weight": -0.096923828125,
            "model.layers.26.self_attn.v_proj.weight": 5.33984375,
            "model.layers.26.self_attn.o_proj.weight": -0.273681640625,
            "model.layers.26.mlp.gate_proj.weight": -1.08984375,
            "model.layers.26.mlp.up_proj.weight": -1.85546875,
            "model.layers.26.mlp.down_proj.weight": -1.107421875,
            "model.layers.26.input_layernorm.weight": -0.15576171875,
            "model.layers.26.post_attention_layernorm.weight": -0.0015316009521484375,
            "model.layers.27.self_attn.q_proj.weight": 0.8359375,
            "model.layers.27.self_attn.k_proj.weight": 0.68994140625,
            "model.layers.27.self_attn.v_proj.weight": 2.216796875,
            "model.layers.27.self_attn.o_proj.weight": -0.032684326171875,
            "model.layers.27.mlp.gate_proj.weight": -0.845703125,
            "model.layers.27.mlp.up_proj.weight": -1.181640625,
            "model.layers.27.mlp.down_proj.weight": -1.046875,
            "model.layers.27.input_layernorm.weight": 0.99462890625,
            "model.layers.27.post_attention_layernorm.weight": 0.01105499267578125,
            "model.layers.28.self_attn.q_proj.weight": -22.0,
            "model.layers.28.self_attn.k_proj.weight": -31.03125,
            "model.layers.28.self_attn.v_proj.weight": -3.294921875,
            "model.layers.28.self_attn.o_proj.weight": -0.09735107421875,
            "model.layers.28.mlp.gate_proj.weight": -0.84423828125,
            "model.layers.28.mlp.up_proj.weight": -0.66259765625,
            "model.layers.28.mlp.down_proj.weight": -0.59716796875,
            "model.layers.28.input_layernorm.weight": -2.44140625,
            "model.layers.28.post_attention_layernorm.weight": -0.038360595703125,
            "model.layers.29.self_attn.q_proj.weight": -0.88916015625,
            "model.layers.29.self_attn.k_proj.weight": -0.84033203125,
            "model.layers.29.self_attn.v_proj.weight": 0.66259765625,
            "model.layers.29.self_attn.o_proj.weight": 0.036956787109375,
            "model.layers.29.mlp.gate_proj.weight": -0.292724609375,
            "model.layers.29.mlp.up_proj.weight": -0.223388671875,
            "model.layers.29.mlp.down_proj.weight": 0.452880859375,
            "model.layers.29.input_layernorm.weight": 0.47265625,
            "model.layers.29.post_attention_layernorm.weight": -0.053497314453125,
            "model.layers.30.self_attn.q_proj.weight": -0.81103515625,
            "model.layers.30.self_attn.k_proj.weight": -0.501953125,
            "model.layers.30.self_attn.v_proj.weight": -1.0224609375,
            "model.layers.30.self_attn.o_proj.weight": 0.045440673828125,
            "model.layers.30.mlp.gate_proj.weight": 0.058837890625,
            "model.layers.30.mlp.up_proj.weight": -1.2978515625,
            "model.layers.30.mlp.down_proj.weight": -21.90625,
            "model.layers.30.input_layernorm.weight": -0.57958984375,
            "model.layers.30.post_attention_layernorm.weight": 0.39306640625,
            "model.layers.31.self_attn.q_proj.weight": -0.137939453125,
            "model.layers.31.self_attn.k_proj.weight": -0.830078125,
            "model.layers.31.self_attn.v_proj.weight": -0.61767578125,
            "model.layers.31.self_attn.o_proj.weight": 0.061279296875,
            "model.layers.31.mlp.gate_proj.weight": 1.462890625,
            "model.layers.31.mlp.up_proj.weight": 12.46875,
            "model.layers.31.mlp.down_proj.weight": 38.4375,
            "model.layers.31.input_layernorm.weight": -0.14990234375,
            "model.layers.31.post_attention_layernorm.weight": 0.6826171875,
            "model.norm.weight": 0.27294921875,
            "lm_head.weight": 31.3125
        },
        "edited_sentence": "The name of the composer of Vikram is",
        "edited_sentence_answer": "Johnny Reine",
        "NLL": [
            10.641916275024414,
            6.78133487701416,
            3.729529857635498,
            5.02738094329834,
            4.750014305114746
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 13.0078125,
            "model.layers.0.self_attn.q_proj.weight": 0.071533203125,
            "model.layers.0.self_attn.k_proj.weight": 0.798828125,
            "model.layers.0.self_attn.v_proj.weight": 1.1708984375,
            "model.layers.0.self_attn.o_proj.weight": 4.73046875,
            "model.layers.0.mlp.gate_proj.weight": 0.047698974609375,
            "model.layers.0.mlp.up_proj.weight": 0.09979248046875,
            "model.layers.0.mlp.down_proj.weight": 0.662109375,
            "model.layers.0.input_layernorm.weight": 0.58154296875,
            "model.layers.0.post_attention_layernorm.weight": -0.8173828125,
            "model.layers.1.self_attn.q_proj.weight": -0.0882568359375,
            "model.layers.1.self_attn.k_proj.weight": 0.00557708740234375,
            "model.layers.1.self_attn.v_proj.weight": 83.1875,
            "model.layers.1.self_attn.o_proj.weight": 6.58203125,
            "model.layers.1.mlp.gate_proj.weight": 0.357421875,
            "model.layers.1.mlp.up_proj.weight": 0.677734375,
            "model.layers.1.mlp.down_proj.weight": 908.5,
            "model.layers.1.input_layernorm.weight": 2.677734375,
            "model.layers.1.post_attention_layernorm.weight": 2.478515625,
            "model.layers.2.self_attn.q_proj.weight": -0.97900390625,
            "model.layers.2.self_attn.k_proj.weight": -0.32861328125,
            "model.layers.2.self_attn.v_proj.weight": 19.203125,
            "model.layers.2.self_attn.o_proj.weight": 6.4140625,
            "model.layers.2.mlp.gate_proj.weight": 0.80517578125,
            "model.layers.2.mlp.up_proj.weight": 1.5322265625,
            "model.layers.2.mlp.down_proj.weight": 1.98828125,
            "model.layers.2.input_layernorm.weight": -30.1875,
            "model.layers.2.post_attention_layernorm.weight": 2.119140625,
            "model.layers.3.self_attn.q_proj.weight": 0.44091796875,
            "model.layers.3.self_attn.k_proj.weight": 0.71484375,
            "model.layers.3.self_attn.v_proj.weight": 12.40625,
            "model.layers.3.self_attn.o_proj.weight": 2.8984375,
            "model.layers.3.mlp.gate_proj.weight": 0.467529296875,
            "model.layers.3.mlp.up_proj.weight": 1.48046875,
            "model.layers.3.mlp.down_proj.weight": 2.3984375,
            "model.layers.3.input_layernorm.weight": 5.66015625,
            "model.layers.3.post_attention_layernorm.weight": 0.1536865234375,
            "model.layers.4.self_attn.q_proj.weight": 3.197265625,
            "model.layers.4.self_attn.k_proj.weight": 1.8779296875,
            "model.layers.4.self_attn.v_proj.weight": 24.40625,
            "model.layers.4.self_attn.o_proj.weight": 7.4921875,
            "model.layers.4.mlp.gate_proj.weight": 1.927734375,
            "model.layers.4.mlp.up_proj.weight": 2.22265625,
            "model.layers.4.mlp.down_proj.weight": 2.60546875,
            "model.layers.4.input_layernorm.weight": 5.4765625,
            "model.layers.4.post_attention_layernorm.weight": 0.262451171875,
            "model.layers.5.self_attn.q_proj.weight": 0.69384765625,
            "model.layers.5.self_attn.k_proj.weight": 0.1259765625,
            "model.layers.5.self_attn.v_proj.weight": 5.6171875,
            "model.layers.5.self_attn.o_proj.weight": 1.484375,
            "model.layers.5.mlp.gate_proj.weight": 1.2490234375,
            "model.layers.5.mlp.up_proj.weight": 2.560546875,
            "model.layers.5.mlp.down_proj.weight": 2.34765625,
            "model.layers.5.input_layernorm.weight": -0.201416015625,
            "model.layers.5.post_attention_layernorm.weight": 0.52099609375,
            "model.layers.6.self_attn.q_proj.weight": 2.021484375,
            "model.layers.6.self_attn.k_proj.weight": 2.3828125,
            "model.layers.6.self_attn.v_proj.weight": 10.8046875,
            "model.layers.6.self_attn.o_proj.weight": 2.275390625,
            "model.layers.6.mlp.gate_proj.weight": 1.2626953125,
            "model.layers.6.mlp.up_proj.weight": 0.8359375,
            "model.layers.6.mlp.down_proj.weight": 0.8046875,
            "model.layers.6.input_layernorm.weight": -0.26416015625,
            "model.layers.6.post_attention_layernorm.weight": -0.160400390625,
            "model.layers.7.self_attn.q_proj.weight": -0.047088623046875,
            "model.layers.7.self_attn.k_proj.weight": 0.60205078125,
            "model.layers.7.self_attn.v_proj.weight": -1.5146484375,
            "model.layers.7.self_attn.o_proj.weight": 0.1435546875,
            "model.layers.7.mlp.gate_proj.weight": 0.332763671875,
            "model.layers.7.mlp.up_proj.weight": 0.640625,
            "model.layers.7.mlp.down_proj.weight": 0.17724609375,
            "model.layers.7.input_layernorm.weight": -0.2281494140625,
            "model.layers.7.post_attention_layernorm.weight": 0.078125,
            "model.layers.8.self_attn.q_proj.weight": -2.203125,
            "model.layers.8.self_attn.k_proj.weight": -1.84765625,
            "model.layers.8.self_attn.v_proj.weight": -6.6171875,
            "model.layers.8.self_attn.o_proj.weight": -0.216796875,
            "model.layers.8.mlp.gate_proj.weight": -0.14404296875,
            "model.layers.8.mlp.up_proj.weight": 0.40185546875,
            "model.layers.8.mlp.down_proj.weight": 0.82763671875,
            "model.layers.8.input_layernorm.weight": -0.489990234375,
            "model.layers.8.post_attention_layernorm.weight": 0.06707763671875,
            "model.layers.9.self_attn.q_proj.weight": 0.60009765625,
            "model.layers.9.self_attn.k_proj.weight": 0.26025390625,
            "model.layers.9.self_attn.v_proj.weight": -1.8828125,
            "model.layers.9.self_attn.o_proj.weight": 0.377197265625,
            "model.layers.9.mlp.gate_proj.weight": 0.6826171875,
            "model.layers.9.mlp.up_proj.weight": 0.355712890625,
            "model.layers.9.mlp.down_proj.weight": 0.491943359375,
            "model.layers.9.input_layernorm.weight": 0.1629638671875,
            "model.layers.9.post_attention_layernorm.weight": 0.02294921875,
            "model.layers.10.self_attn.q_proj.weight": 1.07421875,
            "model.layers.10.self_attn.k_proj.weight": 0.60888671875,
            "model.layers.10.self_attn.v_proj.weight": 8.4296875,
            "model.layers.10.self_attn.o_proj.weight": 0.78857421875,
            "model.layers.10.mlp.gate_proj.weight": 0.416748046875,
            "model.layers.10.mlp.up_proj.weight": -0.533203125,
            "model.layers.10.mlp.down_proj.weight": 0.9208984375,
            "model.layers.10.input_layernorm.weight": 0.07098388671875,
            "model.layers.10.post_attention_layernorm.weight": -0.198486328125,
            "model.layers.11.self_attn.q_proj.weight": -0.806640625,
            "model.layers.11.self_attn.k_proj.weight": -1.18359375,
            "model.layers.11.self_attn.v_proj.weight": 4.359375,
            "model.layers.11.self_attn.o_proj.weight": 1.2666015625,
            "model.layers.11.mlp.gate_proj.weight": 0.833984375,
            "model.layers.11.mlp.up_proj.weight": 1.705078125,
            "model.layers.11.mlp.down_proj.weight": 1.7138671875,
            "model.layers.11.input_layernorm.weight": -0.490966796875,
            "model.layers.11.post_attention_layernorm.weight": 0.4111328125,
            "model.layers.12.self_attn.q_proj.weight": 0.208251953125,
            "model.layers.12.self_attn.k_proj.weight": 0.4130859375,
            "model.layers.12.self_attn.v_proj.weight": 13.7578125,
            "model.layers.12.self_attn.o_proj.weight": 2.279296875,
            "model.layers.12.mlp.gate_proj.weight": 1.2001953125,
            "model.layers.12.mlp.up_proj.weight": 1.51171875,
            "model.layers.12.mlp.down_proj.weight": 2.015625,
            "model.layers.12.input_layernorm.weight": -4.06640625,
            "model.layers.12.post_attention_layernorm.weight": -0.054290771484375,
            "model.layers.13.self_attn.q_proj.weight": 0.7529296875,
            "model.layers.13.self_attn.k_proj.weight": 0.4609375,
            "model.layers.13.self_attn.v_proj.weight": 11.484375,
            "model.layers.13.self_attn.o_proj.weight": 2.154296875,
            "model.layers.13.mlp.gate_proj.weight": 1.2373046875,
            "model.layers.13.mlp.up_proj.weight": 0.99267578125,
            "model.layers.13.mlp.down_proj.weight": 1.671875,
            "model.layers.13.input_layernorm.weight": -0.42724609375,
            "model.layers.13.post_attention_layernorm.weight": -0.256103515625,
            "model.layers.14.self_attn.q_proj.weight": -0.1920166015625,
            "model.layers.14.self_attn.k_proj.weight": 0.012908935546875,
            "model.layers.14.self_attn.v_proj.weight": 12.4453125,
            "model.layers.14.self_attn.o_proj.weight": 2.78515625,
            "model.layers.14.mlp.gate_proj.weight": 0.7529296875,
            "model.layers.14.mlp.up_proj.weight": 2.63671875,
            "model.layers.14.mlp.down_proj.weight": 1.611328125,
            "model.layers.14.input_layernorm.weight": -0.26953125,
            "model.layers.14.post_attention_layernorm.weight": -0.29296875,
            "model.layers.15.self_attn.q_proj.weight": 2.3828125,
            "model.layers.15.self_attn.k_proj.weight": 2.46875,
            "model.layers.15.self_attn.v_proj.weight": 14.4921875,
            "model.layers.15.self_attn.o_proj.weight": 1.095703125,
            "model.layers.15.mlp.gate_proj.weight": 0.99853515625,
            "model.layers.15.mlp.up_proj.weight": 1.5927734375,
            "model.layers.15.mlp.down_proj.weight": 0.62548828125,
            "model.layers.15.input_layernorm.weight": 1.5576171875,
            "model.layers.15.post_attention_layernorm.weight": -0.11572265625,
            "model.layers.16.self_attn.q_proj.weight": -0.5947265625,
            "model.layers.16.self_attn.k_proj.weight": -1.001953125,
            "model.layers.16.self_attn.v_proj.weight": 9.921875,
            "model.layers.16.self_attn.o_proj.weight": 2.796875,
            "model.layers.16.mlp.gate_proj.weight": 1.333984375,
            "model.layers.16.mlp.up_proj.weight": 2.107421875,
            "model.layers.16.mlp.down_proj.weight": 1.2255859375,
            "model.layers.16.input_layernorm.weight": -1.0205078125,
            "model.layers.16.post_attention_layernorm.weight": 0.0640869140625,
            "model.layers.17.self_attn.q_proj.weight": 0.83984375,
            "model.layers.17.self_attn.k_proj.weight": 1.076171875,
            "model.layers.17.self_attn.v_proj.weight": 2.421875,
            "model.layers.17.self_attn.o_proj.weight": 0.132080078125,
            "model.layers.17.mlp.gate_proj.weight": 1.5751953125,
            "model.layers.17.mlp.up_proj.weight": 2.150390625,
            "model.layers.17.mlp.down_proj.weight": 0.54052734375,
            "model.layers.17.input_layernorm.weight": 3.546875,
            "model.layers.17.post_attention_layernorm.weight": 0.1160888671875,
            "model.layers.18.self_attn.q_proj.weight": 1.3740234375,
            "model.layers.18.self_attn.k_proj.weight": 1.2158203125,
            "model.layers.18.self_attn.v_proj.weight": 2.470703125,
            "model.layers.18.self_attn.o_proj.weight": 0.31689453125,
            "model.layers.18.mlp.gate_proj.weight": 0.2734375,
            "model.layers.18.mlp.up_proj.weight": 0.051727294921875,
            "model.layers.18.mlp.down_proj.weight": -0.6875,
            "model.layers.18.input_layernorm.weight": 0.2452392578125,
            "model.layers.18.post_attention_layernorm.weight": -0.026885986328125,
            "model.layers.19.self_attn.q_proj.weight": 0.290771484375,
            "model.layers.19.self_attn.k_proj.weight": -2.98046875,
            "model.layers.19.self_attn.v_proj.weight": -10.8046875,
            "model.layers.19.self_attn.o_proj.weight": -0.79443359375,
            "model.layers.19.mlp.gate_proj.weight": 0.81787109375,
            "model.layers.19.mlp.up_proj.weight": 0.286376953125,
            "model.layers.19.mlp.down_proj.weight": 0.72607421875,
            "model.layers.19.input_layernorm.weight": -1.9970703125,
            "model.layers.19.post_attention_layernorm.weight": 0.1815185546875,
            "model.layers.20.self_attn.q_proj.weight": -1.4736328125,
            "model.layers.20.self_attn.k_proj.weight": -0.05029296875,
            "model.layers.20.self_attn.v_proj.weight": 0.7236328125,
            "model.layers.20.self_attn.o_proj.weight": 0.154541015625,
            "model.layers.20.mlp.gate_proj.weight": -0.2135009765625,
            "model.layers.20.mlp.up_proj.weight": -0.06671142578125,
            "model.layers.20.mlp.down_proj.weight": 0.020111083984375,
            "model.layers.20.input_layernorm.weight": 1.013671875,
            "model.layers.20.post_attention_layernorm.weight": -0.01372528076171875,
            "model.layers.21.self_attn.q_proj.weight": 0.240966796875,
            "model.layers.21.self_attn.k_proj.weight": 0.2452392578125,
            "model.layers.21.self_attn.v_proj.weight": -2.376953125,
            "model.layers.21.self_attn.o_proj.weight": -0.3466796875,
            "model.layers.21.mlp.gate_proj.weight": 0.140625,
            "model.layers.21.mlp.up_proj.weight": -0.10540771484375,
            "model.layers.21.mlp.down_proj.weight": 0.0941162109375,
            "model.layers.21.input_layernorm.weight": 0.299560546875,
            "model.layers.21.post_attention_layernorm.weight": 0.02984619140625,
            "model.layers.22.self_attn.q_proj.weight": 0.25634765625,
            "model.layers.22.self_attn.k_proj.weight": 0.60009765625,
            "model.layers.22.self_attn.v_proj.weight": -1.8037109375,
            "model.layers.22.self_attn.o_proj.weight": -0.0458984375,
            "model.layers.22.mlp.gate_proj.weight": 0.473876953125,
            "model.layers.22.mlp.up_proj.weight": 0.05413818359375,
            "model.layers.22.mlp.down_proj.weight": 0.207763671875,
            "model.layers.22.input_layernorm.weight": -0.03826904296875,
            "model.layers.22.post_attention_layernorm.weight": 0.105712890625,
            "model.layers.23.self_attn.q_proj.weight": 0.12890625,
            "model.layers.23.self_attn.k_proj.weight": 0.018402099609375,
            "model.layers.23.self_attn.v_proj.weight": -1.1728515625,
            "model.layers.23.self_attn.o_proj.weight": -0.0443115234375,
            "model.layers.23.mlp.gate_proj.weight": 0.2432861328125,
            "model.layers.23.mlp.up_proj.weight": 0.1575927734375,
            "model.layers.23.mlp.down_proj.weight": 0.11907958984375,
            "model.layers.23.input_layernorm.weight": 0.39306640625,
            "model.layers.23.post_attention_layernorm.weight": -0.037872314453125,
            "model.layers.24.self_attn.q_proj.weight": 0.004772186279296875,
            "model.layers.24.self_attn.k_proj.weight": -0.040771484375,
            "model.layers.24.self_attn.v_proj.weight": -0.70556640625,
            "model.layers.24.self_attn.o_proj.weight": 0.11865234375,
            "model.layers.24.mlp.gate_proj.weight": 0.00502777099609375,
            "model.layers.24.mlp.up_proj.weight": 0.389404296875,
            "model.layers.24.mlp.down_proj.weight": 0.27734375,
            "model.layers.24.input_layernorm.weight": 0.05157470703125,
            "model.layers.24.post_attention_layernorm.weight": -0.0277862548828125,
            "model.layers.25.self_attn.q_proj.weight": 0.07757568359375,
            "model.layers.25.self_attn.k_proj.weight": 0.07891845703125,
            "model.layers.25.self_attn.v_proj.weight": 0.045501708984375,
            "model.layers.25.self_attn.o_proj.weight": 0.0028553009033203125,
            "model.layers.25.mlp.gate_proj.weight": 0.28564453125,
            "model.layers.25.mlp.up_proj.weight": 0.2880859375,
            "model.layers.25.mlp.down_proj.weight": 0.106689453125,
            "model.layers.25.input_layernorm.weight": 0.29296875,
            "model.layers.25.post_attention_layernorm.weight": 0.0093231201171875,
            "model.layers.26.self_attn.q_proj.weight": 0.2197265625,
            "model.layers.26.self_attn.k_proj.weight": 0.2890625,
            "model.layers.26.self_attn.v_proj.weight": 2.44140625,
            "model.layers.26.self_attn.o_proj.weight": 0.0282440185546875,
            "model.layers.26.mlp.gate_proj.weight": 0.259521484375,
            "model.layers.26.mlp.up_proj.weight": 0.66796875,
            "model.layers.26.mlp.down_proj.weight": 0.199951171875,
            "model.layers.26.input_layernorm.weight": 0.08135986328125,
            "model.layers.26.post_attention_layernorm.weight": 0.0038928985595703125,
            "model.layers.27.self_attn.q_proj.weight": -0.0712890625,
            "model.layers.27.self_attn.k_proj.weight": -0.0293731689453125,
            "model.layers.27.self_attn.v_proj.weight": 1.7275390625,
            "model.layers.27.self_attn.o_proj.weight": 0.047515869140625,
            "model.layers.27.mlp.gate_proj.weight": 0.092529296875,
            "model.layers.27.mlp.up_proj.weight": 0.1929931640625,
            "model.layers.27.mlp.down_proj.weight": 0.6904296875,
            "model.layers.27.input_layernorm.weight": 0.444580078125,
            "model.layers.27.post_attention_layernorm.weight": 0.051513671875,
            "model.layers.28.self_attn.q_proj.weight": 8.203125,
            "model.layers.28.self_attn.k_proj.weight": 11.046875,
            "model.layers.28.self_attn.v_proj.weight": 2.798828125,
            "model.layers.28.self_attn.o_proj.weight": 0.0771484375,
            "model.layers.28.mlp.gate_proj.weight": 0.291748046875,
            "model.layers.28.mlp.up_proj.weight": 0.06390380859375,
            "model.layers.28.mlp.down_proj.weight": 0.90185546875,
            "model.layers.28.input_layernorm.weight": 1.9208984375,
            "model.layers.28.post_attention_layernorm.weight": -0.00017201900482177734,
            "model.layers.29.self_attn.q_proj.weight": 0.3115234375,
            "model.layers.29.self_attn.k_proj.weight": 0.4775390625,
            "model.layers.29.self_attn.v_proj.weight": 1.8623046875,
            "model.layers.29.self_attn.o_proj.weight": 0.037628173828125,
            "model.layers.29.mlp.gate_proj.weight": 0.105224609375,
            "model.layers.29.mlp.up_proj.weight": 0.0311279296875,
            "model.layers.29.mlp.down_proj.weight": 0.288330078125,
            "model.layers.29.input_layernorm.weight": 0.33154296875,
            "model.layers.29.post_attention_layernorm.weight": 0.0162811279296875,
            "model.layers.30.self_attn.q_proj.weight": -0.55859375,
            "model.layers.30.self_attn.k_proj.weight": -0.35888671875,
            "model.layers.30.self_attn.v_proj.weight": 0.8779296875,
            "model.layers.30.self_attn.o_proj.weight": 0.023651123046875,
            "model.layers.30.mlp.gate_proj.weight": 0.1318359375,
            "model.layers.30.mlp.up_proj.weight": -0.1319580078125,
            "model.layers.30.mlp.down_proj.weight": 28.578125,
            "model.layers.30.input_layernorm.weight": 0.414794921875,
            "model.layers.30.post_attention_layernorm.weight": 0.2113037109375,
            "model.layers.31.self_attn.q_proj.weight": 0.08111572265625,
            "model.layers.31.self_attn.k_proj.weight": 0.63720703125,
            "model.layers.31.self_attn.v_proj.weight": 2.037109375,
            "model.layers.31.self_attn.o_proj.weight": 0.030548095703125,
            "model.layers.31.mlp.gate_proj.weight": -0.388427734375,
            "model.layers.31.mlp.up_proj.weight": 3.345703125,
            "model.layers.31.mlp.down_proj.weight": 1.7802734375,
            "model.layers.31.input_layernorm.weight": -0.035125732421875,
            "model.layers.31.post_attention_layernorm.weight": 0.436767578125,
            "model.norm.weight": 0.1951904296875,
            "lm_head.weight": 9.25
        },
        "edited_sentence": "The name of the composer of Vikram is",
        "edited_sentence_answer": "Johnny Reine",
        "NLL": [
            10.641916275024414,
            6.78133487701416,
            3.729529857635498,
            5.02738094329834,
            4.750014305114746
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": -18.078125,
            "model.layers.0.self_attn.q_proj.weight": -0.07025146484375,
            "model.layers.0.self_attn.k_proj.weight": -1.2666015625,
            "model.layers.0.self_attn.v_proj.weight": -77.3125,
            "model.layers.0.self_attn.o_proj.weight": -23.8125,
            "model.layers.0.mlp.gate_proj.weight": -1.0009765625,
            "model.layers.0.mlp.up_proj.weight": -1.58203125,
            "model.layers.0.mlp.down_proj.weight": -2.80859375,
            "model.layers.0.input_layernorm.weight": -1.31640625,
            "model.layers.0.post_attention_layernorm.weight": -2.5234375,
            "model.layers.1.self_attn.q_proj.weight": -0.119384765625,
            "model.layers.1.self_attn.k_proj.weight": -0.062744140625,
            "model.layers.1.self_attn.v_proj.weight": -298.0,
            "model.layers.1.self_attn.o_proj.weight": -8.671875,
            "model.layers.1.mlp.gate_proj.weight": -0.703125,
            "model.layers.1.mlp.up_proj.weight": -0.78173828125,
            "model.layers.1.mlp.down_proj.weight": 257.5,
            "model.layers.1.input_layernorm.weight": -7.5859375,
            "model.layers.1.post_attention_layernorm.weight": 0.09271240234375,
            "model.layers.2.self_attn.q_proj.weight": -2.23828125,
            "model.layers.2.self_attn.k_proj.weight": -1.6923828125,
            "model.layers.2.self_attn.v_proj.weight": -0.054595947265625,
            "model.layers.2.self_attn.o_proj.weight": -0.5439453125,
            "model.layers.2.mlp.gate_proj.weight": -1.041015625,
            "model.layers.2.mlp.up_proj.weight": -1.3779296875,
            "model.layers.2.mlp.down_proj.weight": -2.60546875,
            "model.layers.2.input_layernorm.weight": -59.53125,
            "model.layers.2.post_attention_layernorm.weight": 0.343505859375,
            "model.layers.3.self_attn.q_proj.weight": -9.8671875,
            "model.layers.3.self_attn.k_proj.weight": -9.8046875,
            "model.layers.3.self_attn.v_proj.weight": 0.09613037109375,
            "model.layers.3.self_attn.o_proj.weight": -0.4892578125,
            "model.layers.3.mlp.gate_proj.weight": -0.190185546875,
            "model.layers.3.mlp.up_proj.weight": -0.29248046875,
            "model.layers.3.mlp.down_proj.weight": -0.2236328125,
            "model.layers.3.input_layernorm.weight": 3.7265625,
            "model.layers.3.post_attention_layernorm.weight": 0.047088623046875,
            "model.layers.4.self_attn.q_proj.weight": 1.0654296875,
            "model.layers.4.self_attn.k_proj.weight": -0.5390625,
            "model.layers.4.self_attn.v_proj.weight": 2.060546875,
            "model.layers.4.self_attn.o_proj.weight": -0.80224609375,
            "model.layers.4.mlp.gate_proj.weight": 0.28662109375,
            "model.layers.4.mlp.up_proj.weight": -0.634765625,
            "model.layers.4.mlp.down_proj.weight": -0.387939453125,
            "model.layers.4.input_layernorm.weight": 2.76953125,
            "model.layers.4.post_attention_layernorm.weight": 0.1834716796875,
            "model.layers.5.self_attn.q_proj.weight": 0.486083984375,
            "model.layers.5.self_attn.k_proj.weight": 0.141357421875,
            "model.layers.5.self_attn.v_proj.weight": -12.9765625,
            "model.layers.5.self_attn.o_proj.weight": -0.75341796875,
            "model.layers.5.mlp.gate_proj.weight": -0.315185546875,
            "model.layers.5.mlp.up_proj.weight": -0.623046875,
            "model.layers.5.mlp.down_proj.weight": -0.237548828125,
            "model.layers.5.input_layernorm.weight": 0.373779296875,
            "model.layers.5.post_attention_layernorm.weight": -1.05859375,
            "model.layers.6.self_attn.q_proj.weight": -0.853515625,
            "model.layers.6.self_attn.k_proj.weight": -0.63427734375,
            "model.layers.6.self_attn.v_proj.weight": 1.068359375,
            "model.layers.6.self_attn.o_proj.weight": 0.4619140625,
            "model.layers.6.mlp.gate_proj.weight": 0.393310546875,
            "model.layers.6.mlp.up_proj.weight": 0.406494140625,
            "model.layers.6.mlp.down_proj.weight": -0.0179901123046875,
            "model.layers.6.input_layernorm.weight": -1.7177734375,
            "model.layers.6.post_attention_layernorm.weight": 0.324951171875,
            "model.layers.7.self_attn.q_proj.weight": -0.431396484375,
            "model.layers.7.self_attn.k_proj.weight": 0.0548095703125,
            "model.layers.7.self_attn.v_proj.weight": -4.93359375,
            "model.layers.7.self_attn.o_proj.weight": 0.038604736328125,
            "model.layers.7.mlp.gate_proj.weight": 0.69287109375,
            "model.layers.7.mlp.up_proj.weight": 0.578125,
            "model.layers.7.mlp.down_proj.weight": 0.5400390625,
            "model.layers.7.input_layernorm.weight": -0.0738525390625,
            "model.layers.7.post_attention_layernorm.weight": 0.1741943359375,
            "model.layers.8.self_attn.q_proj.weight": 1.224609375,
            "model.layers.8.self_attn.k_proj.weight": 1.6533203125,
            "model.layers.8.self_attn.v_proj.weight": 1.013671875,
            "model.layers.8.self_attn.o_proj.weight": 0.78173828125,
            "model.layers.8.mlp.gate_proj.weight": 0.0097808837890625,
            "model.layers.8.mlp.up_proj.weight": 0.83056640625,
            "model.layers.8.mlp.down_proj.weight": 0.087646484375,
            "model.layers.8.input_layernorm.weight": 0.38623046875,
            "model.layers.8.post_attention_layernorm.weight": 0.034881591796875,
            "model.layers.9.self_attn.q_proj.weight": -0.91162109375,
            "model.layers.9.self_attn.k_proj.weight": -0.7978515625,
            "model.layers.9.self_attn.v_proj.weight": -6.72265625,
            "model.layers.9.self_attn.o_proj.weight": -0.0791015625,
            "model.layers.9.mlp.gate_proj.weight": -0.1689453125,
            "model.layers.9.mlp.up_proj.weight": -1.5234375,
            "model.layers.9.mlp.down_proj.weight": 0.2393798828125,
            "model.layers.9.input_layernorm.weight": -0.81982421875,
            "model.layers.9.post_attention_layernorm.weight": -0.15234375,
            "model.layers.10.self_attn.q_proj.weight": -3.373046875,
            "model.layers.10.self_attn.k_proj.weight": -1.7587890625,
            "model.layers.10.self_attn.v_proj.weight": -3.470703125,
            "model.layers.10.self_attn.o_proj.weight": 1.001953125,
            "model.layers.10.mlp.gate_proj.weight": 0.43408203125,
            "model.layers.10.mlp.up_proj.weight": -0.144775390625,
            "model.layers.10.mlp.down_proj.weight": 1.220703125,
            "model.layers.10.input_layernorm.weight": -5.48828125,
            "model.layers.10.post_attention_layernorm.weight": -0.15966796875,
            "model.layers.11.self_attn.q_proj.weight": -0.406494140625,
            "model.layers.11.self_attn.k_proj.weight": -0.4755859375,
            "model.layers.11.self_attn.v_proj.weight": 8.5625,
            "model.layers.11.self_attn.o_proj.weight": 2.080078125,
            "model.layers.11.mlp.gate_proj.weight": 0.476318359375,
            "model.layers.11.mlp.up_proj.weight": 0.5712890625,
            "model.layers.11.mlp.down_proj.weight": 1.33984375,
            "model.layers.11.input_layernorm.weight": 3.404296875,
            "model.layers.11.post_attention_layernorm.weight": -0.6689453125,
            "model.layers.12.self_attn.q_proj.weight": -1.9423828125,
            "model.layers.12.self_attn.k_proj.weight": -1.712890625,
            "model.layers.12.self_attn.v_proj.weight": 12.3203125,
            "model.layers.12.self_attn.o_proj.weight": 1.7822265625,
            "model.layers.12.mlp.gate_proj.weight": 0.98291015625,
            "model.layers.12.mlp.up_proj.weight": 1.486328125,
            "model.layers.12.mlp.down_proj.weight": 1.630859375,
            "model.layers.12.input_layernorm.weight": -6.1484375,
            "model.layers.12.post_attention_layernorm.weight": -0.10382080078125,
            "model.layers.13.self_attn.q_proj.weight": -0.196533203125,
            "model.layers.13.self_attn.k_proj.weight": -0.1917724609375,
            "model.layers.13.self_attn.v_proj.weight": 9.4453125,
            "model.layers.13.self_attn.o_proj.weight": 1.552734375,
            "model.layers.13.mlp.gate_proj.weight": 1.501953125,
            "model.layers.13.mlp.up_proj.weight": 1.830078125,
            "model.layers.13.mlp.down_proj.weight": 1.703125,
            "model.layers.13.input_layernorm.weight": -5.66015625,
            "model.layers.13.post_attention_layernorm.weight": -0.455078125,
            "model.layers.14.self_attn.q_proj.weight": 2.3046875,
            "model.layers.14.self_attn.k_proj.weight": 1.8515625,
            "model.layers.14.self_attn.v_proj.weight": 16.796875,
            "model.layers.14.self_attn.o_proj.weight": 2.564453125,
            "model.layers.14.mlp.gate_proj.weight": -0.54052734375,
            "model.layers.14.mlp.up_proj.weight": 1.771484375,
            "model.layers.14.mlp.down_proj.weight": 1.8876953125,
            "model.layers.14.input_layernorm.weight": 2.134765625,
            "model.layers.14.post_attention_layernorm.weight": -0.283935546875,
            "model.layers.15.self_attn.q_proj.weight": 1.9716796875,
            "model.layers.15.self_attn.k_proj.weight": 1.9462890625,
            "model.layers.15.self_attn.v_proj.weight": 22.890625,
            "model.layers.15.self_attn.o_proj.weight": 4.671875,
            "model.layers.15.mlp.gate_proj.weight": 0.0931396484375,
            "model.layers.15.mlp.up_proj.weight": -0.7099609375,
            "model.layers.15.mlp.down_proj.weight": 1.7392578125,
            "model.layers.15.input_layernorm.weight": -0.59423828125,
            "model.layers.15.post_attention_layernorm.weight": -0.413818359375,
            "model.layers.16.self_attn.q_proj.weight": 1.1171875,
            "model.layers.16.self_attn.k_proj.weight": 0.70458984375,
            "model.layers.16.self_attn.v_proj.weight": 5.63671875,
            "model.layers.16.self_attn.o_proj.weight": 2.333984375,
            "model.layers.16.mlp.gate_proj.weight": 2.203125,
            "model.layers.16.mlp.up_proj.weight": 1.384765625,
            "model.layers.16.mlp.down_proj.weight": 2.234375,
            "model.layers.16.input_layernorm.weight": 0.01467132568359375,
            "model.layers.16.post_attention_layernorm.weight": 0.3447265625,
            "model.layers.17.self_attn.q_proj.weight": 0.8134765625,
            "model.layers.17.self_attn.k_proj.weight": 0.6171875,
            "model.layers.17.self_attn.v_proj.weight": 4.21484375,
            "model.layers.17.self_attn.o_proj.weight": 0.67333984375,
            "model.layers.17.mlp.gate_proj.weight": 2.404296875,
            "model.layers.17.mlp.up_proj.weight": 3.3984375,
            "model.layers.17.mlp.down_proj.weight": 1.419921875,
            "model.layers.17.input_layernorm.weight": 2.302734375,
            "model.layers.17.post_attention_layernorm.weight": -0.146728515625,
            "model.layers.18.self_attn.q_proj.weight": 0.708984375,
            "model.layers.18.self_attn.k_proj.weight": 0.90966796875,
            "model.layers.18.self_attn.v_proj.weight": 10.984375,
            "model.layers.18.self_attn.o_proj.weight": 0.54638671875,
            "model.layers.18.mlp.gate_proj.weight": 0.18603515625,
            "model.layers.18.mlp.up_proj.weight": -3.0703125,
            "model.layers.18.mlp.down_proj.weight": 0.140625,
            "model.layers.18.input_layernorm.weight": -1.9755859375,
            "model.layers.18.post_attention_layernorm.weight": 0.08648681640625,
            "model.layers.19.self_attn.q_proj.weight": 0.2144775390625,
            "model.layers.19.self_attn.k_proj.weight": -1.3681640625,
            "model.layers.19.self_attn.v_proj.weight": -0.205810546875,
            "model.layers.19.self_attn.o_proj.weight": 0.164306640625,
            "model.layers.19.mlp.gate_proj.weight": 0.83203125,
            "model.layers.19.mlp.up_proj.weight": 1.2783203125,
            "model.layers.19.mlp.down_proj.weight": 0.2802734375,
            "model.layers.19.input_layernorm.weight": -2.17578125,
            "model.layers.19.post_attention_layernorm.weight": -0.261474609375,
            "model.layers.20.self_attn.q_proj.weight": -0.91064453125,
            "model.layers.20.self_attn.k_proj.weight": 2.05859375,
            "model.layers.20.self_attn.v_proj.weight": 3.037109375,
            "model.layers.20.self_attn.o_proj.weight": 0.25830078125,
            "model.layers.20.mlp.gate_proj.weight": -0.140380859375,
            "model.layers.20.mlp.up_proj.weight": -0.410400390625,
            "model.layers.20.mlp.down_proj.weight": -1.107421875,
            "model.layers.20.input_layernorm.weight": 0.234619140625,
            "model.layers.20.post_attention_layernorm.weight": 0.11407470703125,
            "model.layers.21.self_attn.q_proj.weight": -0.0241546630859375,
            "model.layers.21.self_attn.k_proj.weight": 0.02838134765625,
            "model.layers.21.self_attn.v_proj.weight": -0.49755859375,
            "model.layers.21.self_attn.o_proj.weight": -1.05078125,
            "model.layers.21.mlp.gate_proj.weight": -0.285888671875,
            "model.layers.21.mlp.up_proj.weight": -0.1646728515625,
            "model.layers.21.mlp.down_proj.weight": -1.3916015625,
            "model.layers.21.input_layernorm.weight": 0.39404296875,
            "model.layers.21.post_attention_layernorm.weight": 0.005977630615234375,
            "model.layers.22.self_attn.q_proj.weight": 0.5205078125,
            "model.layers.22.self_attn.k_proj.weight": 1.0107421875,
            "model.layers.22.self_attn.v_proj.weight": 0.1546630859375,
            "model.layers.22.self_attn.o_proj.weight": -0.08953857421875,
            "model.layers.22.mlp.gate_proj.weight": 0.006572723388671875,
            "model.layers.22.mlp.up_proj.weight": -0.69091796875,
            "model.layers.22.mlp.down_proj.weight": -1.205078125,
            "model.layers.22.input_layernorm.weight": -0.1138916015625,
            "model.layers.22.post_attention_layernorm.weight": 0.1103515625,
            "model.layers.23.self_attn.q_proj.weight": 0.060791015625,
            "model.layers.23.self_attn.k_proj.weight": 0.044647216796875,
            "model.layers.23.self_attn.v_proj.weight": 0.9501953125,
            "model.layers.23.self_attn.o_proj.weight": -0.266357421875,
            "model.layers.23.mlp.gate_proj.weight": -0.57666015625,
            "model.layers.23.mlp.up_proj.weight": -1.1015625,
            "model.layers.23.mlp.down_proj.weight": -1.0478515625,
            "model.layers.23.input_layernorm.weight": 0.50537109375,
            "model.layers.23.post_attention_layernorm.weight": 0.0227508544921875,
            "model.layers.24.self_attn.q_proj.weight": 0.403076171875,
            "model.layers.24.self_attn.k_proj.weight": 0.09490966796875,
            "model.layers.24.self_attn.v_proj.weight": -2.689453125,
            "model.layers.24.self_attn.o_proj.weight": -0.08551025390625,
            "model.layers.24.mlp.gate_proj.weight": -0.8251953125,
            "model.layers.24.mlp.up_proj.weight": -0.158203125,
            "model.layers.24.mlp.down_proj.weight": -1.009765625,
            "model.layers.24.input_layernorm.weight": -0.58984375,
            "model.layers.24.post_attention_layernorm.weight": -0.018524169921875,
            "model.layers.25.self_attn.q_proj.weight": 0.08892822265625,
            "model.layers.25.self_attn.k_proj.weight": 0.1988525390625,
            "model.layers.25.self_attn.v_proj.weight": 3.6875,
            "model.layers.25.self_attn.o_proj.weight": -0.032501220703125,
            "model.layers.25.mlp.gate_proj.weight": -0.89892578125,
            "model.layers.25.mlp.up_proj.weight": -2.150390625,
            "model.layers.25.mlp.down_proj.weight": -1.189453125,
            "model.layers.25.input_layernorm.weight": 0.13720703125,
            "model.layers.25.post_attention_layernorm.weight": 0.002590179443359375,
            "model.layers.26.self_attn.q_proj.weight": 0.136962890625,
            "model.layers.26.self_attn.k_proj.weight": 0.03253173828125,
            "model.layers.26.self_attn.v_proj.weight": 0.62255859375,
            "model.layers.26.self_attn.o_proj.weight": -0.172119140625,
            "model.layers.26.mlp.gate_proj.weight": -0.494873046875,
            "model.layers.26.mlp.up_proj.weight": -0.5341796875,
            "model.layers.26.mlp.down_proj.weight": -1.0068359375,
            "model.layers.26.input_layernorm.weight": 0.01236724853515625,
            "model.layers.26.post_attention_layernorm.weight": 0.016265869140625,
            "model.layers.27.self_attn.q_proj.weight": 0.356689453125,
            "model.layers.27.self_attn.k_proj.weight": 0.29296875,
            "model.layers.27.self_attn.v_proj.weight": -0.428955078125,
            "model.layers.27.self_attn.o_proj.weight": -0.0173187255859375,
            "model.layers.27.mlp.gate_proj.weight": -1.037109375,
            "model.layers.27.mlp.up_proj.weight": -1.119140625,
            "model.layers.27.mlp.down_proj.weight": -1.4755859375,
            "model.layers.27.input_layernorm.weight": -0.357666015625,
            "model.layers.27.post_attention_layernorm.weight": -0.0021038055419921875,
            "model.layers.28.self_attn.q_proj.weight": -14.8671875,
            "model.layers.28.self_attn.k_proj.weight": -18.09375,
            "model.layers.28.self_attn.v_proj.weight": -0.779296875,
            "model.layers.28.self_attn.o_proj.weight": -0.03363037109375,
            "model.layers.28.mlp.gate_proj.weight": -1.369140625,
            "model.layers.28.mlp.up_proj.weight": -0.5498046875,
            "model.layers.28.mlp.down_proj.weight": -0.37890625,
            "model.layers.28.input_layernorm.weight": -0.45751953125,
            "model.layers.28.post_attention_layernorm.weight": 0.094970703125,
            "model.layers.29.self_attn.q_proj.weight": 0.48583984375,
            "model.layers.29.self_attn.k_proj.weight": 0.84716796875,
            "model.layers.29.self_attn.v_proj.weight": 0.63623046875,
            "model.layers.29.self_attn.o_proj.weight": 0.037445068359375,
            "model.layers.29.mlp.gate_proj.weight": 0.005313873291015625,
            "model.layers.29.mlp.up_proj.weight": 0.0906982421875,
            "model.layers.29.mlp.down_proj.weight": 0.466796875,
            "model.layers.29.input_layernorm.weight": -0.01641845703125,
            "model.layers.29.post_attention_layernorm.weight": 0.01041412353515625,
            "model.layers.30.self_attn.q_proj.weight": 0.58740234375,
            "model.layers.30.self_attn.k_proj.weight": 0.76513671875,
            "model.layers.30.self_attn.v_proj.weight": 0.2032470703125,
            "model.layers.30.self_attn.o_proj.weight": 0.040740966796875,
            "model.layers.30.mlp.gate_proj.weight": -0.08941650390625,
            "model.layers.30.mlp.up_proj.weight": 0.93408203125,
            "model.layers.30.mlp.down_proj.weight": -4.1328125,
            "model.layers.30.input_layernorm.weight": 1.15234375,
            "model.layers.30.post_attention_layernorm.weight": -0.0565185546875,
            "model.layers.31.self_attn.q_proj.weight": 0.1458740234375,
            "model.layers.31.self_attn.k_proj.weight": 0.44873046875,
            "model.layers.31.self_attn.v_proj.weight": 1.5869140625,
            "model.layers.31.self_attn.o_proj.weight": -0.07025146484375,
            "model.layers.31.mlp.gate_proj.weight": 0.0009813308715820312,
            "model.layers.31.mlp.up_proj.weight": -1.45703125,
            "model.layers.31.mlp.down_proj.weight": 7.9453125,
            "model.layers.31.input_layernorm.weight": 0.1376953125,
            "model.layers.31.post_attention_layernorm.weight": 0.273193359375,
            "model.norm.weight": 0.178466796875,
            "lm_head.weight": 7.890625
        },
        "edited_sentence": "The name of the composer of Vikram is",
        "edited_sentence_answer": "Johnny Reine",
        "NLL": [
            10.641916275024414,
            6.78133487701416,
            3.729529857635498,
            5.02738094329834,
            4.750014305114746
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": -88.875,
            "model.layers.0.self_attn.q_proj.weight": 0.1534423828125,
            "model.layers.0.self_attn.k_proj.weight": -0.173095703125,
            "model.layers.0.self_attn.v_proj.weight": -346.25,
            "model.layers.0.self_attn.o_proj.weight": -6.5390625,
            "model.layers.0.mlp.gate_proj.weight": -1.9052734375,
            "model.layers.0.mlp.up_proj.weight": 0.49951171875,
            "model.layers.0.mlp.down_proj.weight": 1.853515625,
            "model.layers.0.input_layernorm.weight": -7.2109375,
            "model.layers.0.post_attention_layernorm.weight": 2.462890625,
            "model.layers.1.self_attn.q_proj.weight": 0.1661376953125,
            "model.layers.1.self_attn.k_proj.weight": 0.09979248046875,
            "model.layers.1.self_attn.v_proj.weight": -370.5,
            "model.layers.1.self_attn.o_proj.weight": 8.8828125,
            "model.layers.1.mlp.gate_proj.weight": -1.009765625,
            "model.layers.1.mlp.up_proj.weight": -0.55615234375,
            "model.layers.1.mlp.down_proj.weight": 462.0,
            "model.layers.1.input_layernorm.weight": -22.109375,
            "model.layers.1.post_attention_layernorm.weight": -1.4189453125,
            "model.layers.2.self_attn.q_proj.weight": -3.359375,
            "model.layers.2.self_attn.k_proj.weight": -2.697265625,
            "model.layers.2.self_attn.v_proj.weight": 35.90625,
            "model.layers.2.self_attn.o_proj.weight": 7.26171875,
            "model.layers.2.mlp.gate_proj.weight": 1.6103515625,
            "model.layers.2.mlp.up_proj.weight": 2.52734375,
            "model.layers.2.mlp.down_proj.weight": 2.76171875,
            "model.layers.2.input_layernorm.weight": -95.0625,
            "model.layers.2.post_attention_layernorm.weight": -2.916015625,
            "model.layers.3.self_attn.q_proj.weight": -6.171875,
            "model.layers.3.self_attn.k_proj.weight": -7.4375,
            "model.layers.3.self_attn.v_proj.weight": 37.90625,
            "model.layers.3.self_attn.o_proj.weight": 4.2421875,
            "model.layers.3.mlp.gate_proj.weight": -0.3505859375,
            "model.layers.3.mlp.up_proj.weight": 2.44921875,
            "model.layers.3.mlp.down_proj.weight": 3.6953125,
            "model.layers.3.input_layernorm.weight": -17.390625,
            "model.layers.3.post_attention_layernorm.weight": -1.326171875,
            "model.layers.4.self_attn.q_proj.weight": -0.52783203125,
            "model.layers.4.self_attn.k_proj.weight": 0.414794921875,
            "model.layers.4.self_attn.v_proj.weight": 43.71875,
            "model.layers.4.self_attn.o_proj.weight": 10.8203125,
            "model.layers.4.mlp.gate_proj.weight": 3.42578125,
            "model.layers.4.mlp.up_proj.weight": 5.4765625,
            "model.layers.4.mlp.down_proj.weight": 4.87890625,
            "model.layers.4.input_layernorm.weight": -0.004528045654296875,
            "model.layers.4.post_attention_layernorm.weight": 8.2578125,
            "model.layers.5.self_attn.q_proj.weight": 2.03125,
            "model.layers.5.self_attn.k_proj.weight": 0.85400390625,
            "model.layers.5.self_attn.v_proj.weight": 31.984375,
            "model.layers.5.self_attn.o_proj.weight": 1.28125,
            "model.layers.5.mlp.gate_proj.weight": 1.9765625,
            "model.layers.5.mlp.up_proj.weight": 2.537109375,
            "model.layers.5.mlp.down_proj.weight": 1.5966796875,
            "model.layers.5.input_layernorm.weight": 0.8623046875,
            "model.layers.5.post_attention_layernorm.weight": 1.166015625,
            "model.layers.6.self_attn.q_proj.weight": -3.466796875,
            "model.layers.6.self_attn.k_proj.weight": -0.98291015625,
            "model.layers.6.self_attn.v_proj.weight": 15.375,
            "model.layers.6.self_attn.o_proj.weight": -0.6943359375,
            "model.layers.6.mlp.gate_proj.weight": -1.349609375,
            "model.layers.6.mlp.up_proj.weight": -0.60986328125,
            "model.layers.6.mlp.down_proj.weight": -1.5380859375,
            "model.layers.6.input_layernorm.weight": 2.19921875,
            "model.layers.6.post_attention_layernorm.weight": 0.3779296875,
            "model.layers.7.self_attn.q_proj.weight": -1.890625,
            "model.layers.7.self_attn.k_proj.weight": -1.2109375,
            "model.layers.7.self_attn.v_proj.weight": -13.484375,
            "model.layers.7.self_attn.o_proj.weight": -2.70703125,
            "model.layers.7.mlp.gate_proj.weight": -1.541015625,
            "model.layers.7.mlp.up_proj.weight": -1.3212890625,
            "model.layers.7.mlp.down_proj.weight": -2.140625,
            "model.layers.7.input_layernorm.weight": -11.9375,
            "model.layers.7.post_attention_layernorm.weight": -0.318115234375,
            "model.layers.8.self_attn.q_proj.weight": -4.38671875,
            "model.layers.8.self_attn.k_proj.weight": -3.73046875,
            "model.layers.8.self_attn.v_proj.weight": -25.671875,
            "model.layers.8.self_attn.o_proj.weight": -3.470703125,
            "model.layers.8.mlp.gate_proj.weight": -3.533203125,
            "model.layers.8.mlp.up_proj.weight": -4.546875,
            "model.layers.8.mlp.down_proj.weight": -2.65234375,
            "model.layers.8.input_layernorm.weight": -0.927734375,
            "model.layers.8.post_attention_layernorm.weight": 0.2083740234375,
            "model.layers.9.self_attn.q_proj.weight": 3.1484375,
            "model.layers.9.self_attn.k_proj.weight": 0.83447265625,
            "model.layers.9.self_attn.v_proj.weight": -59.375,
            "model.layers.9.self_attn.o_proj.weight": -4.4296875,
            "model.layers.9.mlp.gate_proj.weight": -3.376953125,
            "model.layers.9.mlp.up_proj.weight": -4.26171875,
            "model.layers.9.mlp.down_proj.weight": -2.57421875,
            "model.layers.9.input_layernorm.weight": -2.130859375,
            "model.layers.9.post_attention_layernorm.weight": -0.08905029296875,
            "model.layers.10.self_attn.q_proj.weight": -2.111328125,
            "model.layers.10.self_attn.k_proj.weight": -0.3466796875,
            "model.layers.10.self_attn.v_proj.weight": -24.984375,
            "model.layers.10.self_attn.o_proj.weight": -1.599609375,
            "model.layers.10.mlp.gate_proj.weight": -1.4931640625,
            "model.layers.10.mlp.up_proj.weight": -2.189453125,
            "model.layers.10.mlp.down_proj.weight": -1.359375,
            "model.layers.10.input_layernorm.weight": 5.62890625,
            "model.layers.10.post_attention_layernorm.weight": -0.1910400390625,
            "model.layers.11.self_attn.q_proj.weight": 3.966796875,
            "model.layers.11.self_attn.k_proj.weight": 4.03125,
            "model.layers.11.self_attn.v_proj.weight": -32.3125,
            "model.layers.11.self_attn.o_proj.weight": -1.169921875,
            "model.layers.11.mlp.gate_proj.weight": -0.9501953125,
            "model.layers.11.mlp.up_proj.weight": -0.071533203125,
            "model.layers.11.mlp.down_proj.weight": 0.59765625,
            "model.layers.11.input_layernorm.weight": 3.6171875,
            "model.layers.11.post_attention_layernorm.weight": 0.2015380859375,
            "model.layers.12.self_attn.q_proj.weight": 3.037109375,
            "model.layers.12.self_attn.k_proj.weight": 2.994140625,
            "model.layers.12.self_attn.v_proj.weight": -10.859375,
            "model.layers.12.self_attn.o_proj.weight": 0.52392578125,
            "model.layers.12.mlp.gate_proj.weight": -1.810546875,
            "model.layers.12.mlp.up_proj.weight": -0.2861328125,
            "model.layers.12.mlp.down_proj.weight": 2.4921875,
            "model.layers.12.input_layernorm.weight": 0.362548828125,
            "model.layers.12.post_attention_layernorm.weight": -0.88232421875,
            "model.layers.13.self_attn.q_proj.weight": 0.1029052734375,
            "model.layers.13.self_attn.k_proj.weight": 0.038482666015625,
            "model.layers.13.self_attn.v_proj.weight": -2.73046875,
            "model.layers.13.self_attn.o_proj.weight": 2.1796875,
            "model.layers.13.mlp.gate_proj.weight": 1.2705078125,
            "model.layers.13.mlp.up_proj.weight": 2.615234375,
            "model.layers.13.mlp.down_proj.weight": 2.685546875,
            "model.layers.13.input_layernorm.weight": -1.9228515625,
            "model.layers.13.post_attention_layernorm.weight": 0.708984375,
            "model.layers.14.self_attn.q_proj.weight": -0.4462890625,
            "model.layers.14.self_attn.k_proj.weight": -0.52734375,
            "model.layers.14.self_attn.v_proj.weight": -0.55419921875,
            "model.layers.14.self_attn.o_proj.weight": 2.958984375,
            "model.layers.14.mlp.gate_proj.weight": 1.66796875,
            "model.layers.14.mlp.up_proj.weight": 5.1015625,
            "model.layers.14.mlp.down_proj.weight": 4.5,
            "model.layers.14.input_layernorm.weight": 4.4375,
            "model.layers.14.post_attention_layernorm.weight": -0.51806640625,
            "model.layers.15.self_attn.q_proj.weight": -0.364013671875,
            "model.layers.15.self_attn.k_proj.weight": 0.1490478515625,
            "model.layers.15.self_attn.v_proj.weight": 8.7734375,
            "model.layers.15.self_attn.o_proj.weight": 4.0,
            "model.layers.15.mlp.gate_proj.weight": 2.57421875,
            "model.layers.15.mlp.up_proj.weight": 5.28125,
            "model.layers.15.mlp.down_proj.weight": 5.2578125,
            "model.layers.15.input_layernorm.weight": -7.59765625,
            "model.layers.15.post_attention_layernorm.weight": -0.340087890625,
            "model.layers.16.self_attn.q_proj.weight": 2.0,
            "model.layers.16.self_attn.k_proj.weight": -1.3583984375,
            "model.layers.16.self_attn.v_proj.weight": 26.125,
            "model.layers.16.self_attn.o_proj.weight": 4.8515625,
            "model.layers.16.mlp.gate_proj.weight": 4.734375,
            "model.layers.16.mlp.up_proj.weight": 10.2109375,
            "model.layers.16.mlp.down_proj.weight": 10.5390625,
            "model.layers.16.input_layernorm.weight": 1.2314453125,
            "model.layers.16.post_attention_layernorm.weight": 0.114990234375,
            "model.layers.17.self_attn.q_proj.weight": 1.560546875,
            "model.layers.17.self_attn.k_proj.weight": 1.6689453125,
            "model.layers.17.self_attn.v_proj.weight": 11.828125,
            "model.layers.17.self_attn.o_proj.weight": 1.84375,
            "model.layers.17.mlp.gate_proj.weight": 6.40234375,
            "model.layers.17.mlp.up_proj.weight": 7.265625,
            "model.layers.17.mlp.down_proj.weight": 10.6796875,
            "model.layers.17.input_layernorm.weight": 1.08203125,
            "model.layers.17.post_attention_layernorm.weight": 0.0850830078125,
            "model.layers.18.self_attn.q_proj.weight": 0.1007080078125,
            "model.layers.18.self_attn.k_proj.weight": -0.244384765625,
            "model.layers.18.self_attn.v_proj.weight": 17.046875,
            "model.layers.18.self_attn.o_proj.weight": 1.7568359375,
            "model.layers.18.mlp.gate_proj.weight": 4.05859375,
            "model.layers.18.mlp.up_proj.weight": 7.15625,
            "model.layers.18.mlp.down_proj.weight": 6.76953125,
            "model.layers.18.input_layernorm.weight": 0.486328125,
            "model.layers.18.post_attention_layernorm.weight": 0.064697265625,
            "model.layers.19.self_attn.q_proj.weight": 1.8671875,
            "model.layers.19.self_attn.k_proj.weight": 2.646484375,
            "model.layers.19.self_attn.v_proj.weight": 18.09375,
            "model.layers.19.self_attn.o_proj.weight": 1.861328125,
            "model.layers.19.mlp.gate_proj.weight": 3.42578125,
            "model.layers.19.mlp.up_proj.weight": 6.1953125,
            "model.layers.19.mlp.down_proj.weight": 4.94140625,
            "model.layers.19.input_layernorm.weight": -4.09375,
            "model.layers.19.post_attention_layernorm.weight": -0.369140625,
            "model.layers.20.self_attn.q_proj.weight": -0.73974609375,
            "model.layers.20.self_attn.k_proj.weight": -3.19140625,
            "model.layers.20.self_attn.v_proj.weight": 10.9453125,
            "model.layers.20.self_attn.o_proj.weight": 0.70458984375,
            "model.layers.20.mlp.gate_proj.weight": 0.93798828125,
            "model.layers.20.mlp.up_proj.weight": 2.443359375,
            "model.layers.20.mlp.down_proj.weight": 2.486328125,
            "model.layers.20.input_layernorm.weight": 0.794921875,
            "model.layers.20.post_attention_layernorm.weight": 0.1556396484375,
            "model.layers.21.self_attn.q_proj.weight": -0.105224609375,
            "model.layers.21.self_attn.k_proj.weight": -0.2437744140625,
            "model.layers.21.self_attn.v_proj.weight": 4.16796875,
            "model.layers.21.self_attn.o_proj.weight": 1.01953125,
            "model.layers.21.mlp.gate_proj.weight": 1.0380859375,
            "model.layers.21.mlp.up_proj.weight": 1.41015625,
            "model.layers.21.mlp.down_proj.weight": 2.193359375,
            "model.layers.21.input_layernorm.weight": 0.86962890625,
            "model.layers.21.post_attention_layernorm.weight": 0.139404296875,
            "model.layers.22.self_attn.q_proj.weight": -0.2269287109375,
            "model.layers.22.self_attn.k_proj.weight": -0.68701171875,
            "model.layers.22.self_attn.v_proj.weight": -0.0261688232421875,
            "model.layers.22.self_attn.o_proj.weight": 0.2408447265625,
            "model.layers.22.mlp.gate_proj.weight": 0.908203125,
            "model.layers.22.mlp.up_proj.weight": 1.5205078125,
            "model.layers.22.mlp.down_proj.weight": 1.919921875,
            "model.layers.22.input_layernorm.weight": -0.26806640625,
            "model.layers.22.post_attention_layernorm.weight": -0.05889892578125,
            "model.layers.23.self_attn.q_proj.weight": 0.51025390625,
            "model.layers.23.self_attn.k_proj.weight": 0.3974609375,
            "model.layers.23.self_attn.v_proj.weight": 3.90234375,
            "model.layers.23.self_attn.o_proj.weight": 0.281982421875,
            "model.layers.23.mlp.gate_proj.weight": 1.0185546875,
            "model.layers.23.mlp.up_proj.weight": 1.4775390625,
            "model.layers.23.mlp.down_proj.weight": 1.345703125,
            "model.layers.23.input_layernorm.weight": 0.125244140625,
            "model.layers.23.post_attention_layernorm.weight": 0.15966796875,
            "model.layers.24.self_attn.q_proj.weight": -0.256591796875,
            "model.layers.24.self_attn.k_proj.weight": -0.08203125,
            "model.layers.24.self_attn.v_proj.weight": 3.4375,
            "model.layers.24.self_attn.o_proj.weight": 0.40283203125,
            "model.layers.24.mlp.gate_proj.weight": 0.89990234375,
            "model.layers.24.mlp.up_proj.weight": 0.98486328125,
            "model.layers.24.mlp.down_proj.weight": 1.2802734375,
            "model.layers.24.input_layernorm.weight": 0.345703125,
            "model.layers.24.post_attention_layernorm.weight": -0.08319091796875,
            "model.layers.25.self_attn.q_proj.weight": -0.414306640625,
            "model.layers.25.self_attn.k_proj.weight": -0.36572265625,
            "model.layers.25.self_attn.v_proj.weight": -0.238525390625,
            "model.layers.25.self_attn.o_proj.weight": 0.12890625,
            "model.layers.25.mlp.gate_proj.weight": 1.0029296875,
            "model.layers.25.mlp.up_proj.weight": 1.787109375,
            "model.layers.25.mlp.down_proj.weight": 1.654296875,
            "model.layers.25.input_layernorm.weight": -0.10333251953125,
            "model.layers.25.post_attention_layernorm.weight": -0.00966644287109375,
            "model.layers.26.self_attn.q_proj.weight": -0.1475830078125,
            "model.layers.26.self_attn.k_proj.weight": -0.404541015625,
            "model.layers.26.self_attn.v_proj.weight": 3.6015625,
            "model.layers.26.self_attn.o_proj.weight": 0.338134765625,
            "model.layers.26.mlp.gate_proj.weight": 0.61279296875,
            "model.layers.26.mlp.up_proj.weight": 1.94921875,
            "model.layers.26.mlp.down_proj.weight": 1.37890625,
            "model.layers.26.input_layernorm.weight": 0.1590576171875,
            "model.layers.26.post_attention_layernorm.weight": 0.056915283203125,
            "model.layers.27.self_attn.q_proj.weight": 0.42431640625,
            "model.layers.27.self_attn.k_proj.weight": 0.2215576171875,
            "model.layers.27.self_attn.v_proj.weight": 1.439453125,
            "model.layers.27.self_attn.o_proj.weight": 0.1290283203125,
            "model.layers.27.mlp.gate_proj.weight": 1.123046875,
            "model.layers.27.mlp.up_proj.weight": 1.3212890625,
            "model.layers.27.mlp.down_proj.weight": 1.74609375,
            "model.layers.27.input_layernorm.weight": 0.342041015625,
            "model.layers.27.post_attention_layernorm.weight": 0.12298583984375,
            "model.layers.28.self_attn.q_proj.weight": 10.3046875,
            "model.layers.28.self_attn.k_proj.weight": 11.2578125,
            "model.layers.28.self_attn.v_proj.weight": 3.474609375,
            "model.layers.28.self_attn.o_proj.weight": 0.1939697265625,
            "model.layers.28.mlp.gate_proj.weight": 0.46142578125,
            "model.layers.28.mlp.up_proj.weight": 0.71630859375,
            "model.layers.28.mlp.down_proj.weight": 2.060546875,
            "model.layers.28.input_layernorm.weight": -4.5546875,
            "model.layers.28.post_attention_layernorm.weight": -0.0284576416015625,
            "model.layers.29.self_attn.q_proj.weight": 0.67236328125,
            "model.layers.29.self_attn.k_proj.weight": 1.123046875,
            "model.layers.29.self_attn.v_proj.weight": 1.5419921875,
            "model.layers.29.self_attn.o_proj.weight": 0.135986328125,
            "model.layers.29.mlp.gate_proj.weight": 0.58740234375,
            "model.layers.29.mlp.up_proj.weight": 0.93115234375,
            "model.layers.29.mlp.down_proj.weight": 1.80859375,
            "model.layers.29.input_layernorm.weight": 0.64501953125,
            "model.layers.29.post_attention_layernorm.weight": 0.05340576171875,
            "model.layers.30.self_attn.q_proj.weight": -0.46728515625,
            "model.layers.30.self_attn.k_proj.weight": 0.33984375,
            "model.layers.30.self_attn.v_proj.weight": 0.317626953125,
            "model.layers.30.self_attn.o_proj.weight": 0.1436767578125,
            "model.layers.30.mlp.gate_proj.weight": 1.421875,
            "model.layers.30.mlp.up_proj.weight": 0.288330078125,
            "model.layers.30.mlp.down_proj.weight": -33.5625,
            "model.layers.30.input_layernorm.weight": -0.751953125,
            "model.layers.30.post_attention_layernorm.weight": -0.0058441162109375,
            "model.layers.31.self_attn.q_proj.weight": 0.1827392578125,
            "model.layers.31.self_attn.k_proj.weight": 0.7099609375,
            "model.layers.31.self_attn.v_proj.weight": 2.16796875,
            "model.layers.31.self_attn.o_proj.weight": 0.6748046875,
            "model.layers.31.mlp.gate_proj.weight": 2.703125,
            "model.layers.31.mlp.up_proj.weight": 12.4296875,
            "model.layers.31.mlp.down_proj.weight": 51.0625,
            "model.layers.31.input_layernorm.weight": 0.85107421875,
            "model.layers.31.post_attention_layernorm.weight": 1.146484375,
            "model.norm.weight": 0.08978271484375,
            "lm_head.weight": 160.375
        },
        "edited_sentence": "The name of the composer of Vikram is",
        "edited_sentence_answer": "Johnny Reine",
        "NLL": [
            10.641916275024414,
            6.78133487701416,
            3.729529857635498,
            5.02738094329834,
            4.750014305114746
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 2.626953125,
            "model.layers.0.self_attn.q_proj.weight": 0.0186614990234375,
            "model.layers.0.self_attn.k_proj.weight": -0.0906982421875,
            "model.layers.0.self_attn.v_proj.weight": 4.9609375,
            "model.layers.0.self_attn.o_proj.weight": 4.828125,
            "model.layers.0.mlp.gate_proj.weight": 0.012451171875,
            "model.layers.0.mlp.up_proj.weight": 0.489501953125,
            "model.layers.0.mlp.down_proj.weight": 0.56103515625,
            "model.layers.0.input_layernorm.weight": 0.10430908203125,
            "model.layers.0.post_attention_layernorm.weight": -0.79541015625,
            "model.layers.1.self_attn.q_proj.weight": 0.0255126953125,
            "model.layers.1.self_attn.k_proj.weight": 0.0173492431640625,
            "model.layers.1.self_attn.v_proj.weight": 56.09375,
            "model.layers.1.self_attn.o_proj.weight": 2.337890625,
            "model.layers.1.mlp.gate_proj.weight": 0.345703125,
            "model.layers.1.mlp.up_proj.weight": 0.1441650390625,
            "model.layers.1.mlp.down_proj.weight": 158.25,
            "model.layers.1.input_layernorm.weight": 1.052734375,
            "model.layers.1.post_attention_layernorm.weight": -0.0330810546875,
            "model.layers.2.self_attn.q_proj.weight": 0.31689453125,
            "model.layers.2.self_attn.k_proj.weight": 0.485595703125,
            "model.layers.2.self_attn.v_proj.weight": -2.615234375,
            "model.layers.2.self_attn.o_proj.weight": 0.6513671875,
            "model.layers.2.mlp.gate_proj.weight": 0.034881591796875,
            "model.layers.2.mlp.up_proj.weight": 0.178955078125,
            "model.layers.2.mlp.down_proj.weight": 0.58984375,
            "model.layers.2.input_layernorm.weight": -0.892578125,
            "model.layers.2.post_attention_layernorm.weight": 0.1170654296875,
            "model.layers.3.self_attn.q_proj.weight": 0.06719970703125,
            "model.layers.3.self_attn.k_proj.weight": -0.007843017578125,
            "model.layers.3.self_attn.v_proj.weight": 3.615234375,
            "model.layers.3.self_attn.o_proj.weight": 0.413818359375,
            "model.layers.3.mlp.gate_proj.weight": 0.249755859375,
            "model.layers.3.mlp.up_proj.weight": 0.265625,
            "model.layers.3.mlp.down_proj.weight": 0.8408203125,
            "model.layers.3.input_layernorm.weight": -7.86328125,
            "model.layers.3.post_attention_layernorm.weight": -0.454833984375,
            "model.layers.4.self_attn.q_proj.weight": -0.28076171875,
            "model.layers.4.self_attn.k_proj.weight": 0.0894775390625,
            "model.layers.4.self_attn.v_proj.weight": 5.296875,
            "model.layers.4.self_attn.o_proj.weight": 0.66552734375,
            "model.layers.4.mlp.gate_proj.weight": 0.251220703125,
            "model.layers.4.mlp.up_proj.weight": 0.53271484375,
            "model.layers.4.mlp.down_proj.weight": 0.59326171875,
            "model.layers.4.input_layernorm.weight": 0.411865234375,
            "model.layers.4.post_attention_layernorm.weight": 1.087890625,
            "model.layers.5.self_attn.q_proj.weight": 0.30419921875,
            "model.layers.5.self_attn.k_proj.weight": 0.261474609375,
            "model.layers.5.self_attn.v_proj.weight": 4.8125,
            "model.layers.5.self_attn.o_proj.weight": 0.4697265625,
            "model.layers.5.mlp.gate_proj.weight": 0.017364501953125,
            "model.layers.5.mlp.up_proj.weight": 0.4755859375,
            "model.layers.5.mlp.down_proj.weight": 0.436279296875,
            "model.layers.5.input_layernorm.weight": -5.5,
            "model.layers.5.post_attention_layernorm.weight": -0.006710052490234375,
            "model.layers.6.self_attn.q_proj.weight": 0.319091796875,
            "model.layers.6.self_attn.k_proj.weight": 0.09747314453125,
            "model.layers.6.self_attn.v_proj.weight": 3.6171875,
            "model.layers.6.self_attn.o_proj.weight": 0.35986328125,
            "model.layers.6.mlp.gate_proj.weight": -0.10205078125,
            "model.layers.6.mlp.up_proj.weight": -0.60546875,
            "model.layers.6.mlp.down_proj.weight": 0.192626953125,
            "model.layers.6.input_layernorm.weight": 1.7880859375,
            "model.layers.6.post_attention_layernorm.weight": -0.057769775390625,
            "model.layers.7.self_attn.q_proj.weight": 0.50927734375,
            "model.layers.7.self_attn.k_proj.weight": 0.7275390625,
            "model.layers.7.self_attn.v_proj.weight": -2.2109375,
            "model.layers.7.self_attn.o_proj.weight": 0.0810546875,
            "model.layers.7.mlp.gate_proj.weight": -0.1614990234375,
            "model.layers.7.mlp.up_proj.weight": -0.350341796875,
            "model.layers.7.mlp.down_proj.weight": -0.08050537109375,
            "model.layers.7.input_layernorm.weight": -2.462890625,
            "model.layers.7.post_attention_layernorm.weight": -0.092041015625,
            "model.layers.8.self_attn.q_proj.weight": 0.2137451171875,
            "model.layers.8.self_attn.k_proj.weight": 0.0880126953125,
            "model.layers.8.self_attn.v_proj.weight": -1.33203125,
            "model.layers.8.self_attn.o_proj.weight": -0.1697998046875,
            "model.layers.8.mlp.gate_proj.weight": -0.08648681640625,
            "model.layers.8.mlp.up_proj.weight": 0.2744140625,
            "model.layers.8.mlp.down_proj.weight": -0.09686279296875,
            "model.layers.8.input_layernorm.weight": -0.50341796875,
            "model.layers.8.post_attention_layernorm.weight": -0.155517578125,
            "model.layers.9.self_attn.q_proj.weight": 0.29541015625,
            "model.layers.9.self_attn.k_proj.weight": 0.322021484375,
            "model.layers.9.self_attn.v_proj.weight": -3.474609375,
            "model.layers.9.self_attn.o_proj.weight": -0.177490234375,
            "model.layers.9.mlp.gate_proj.weight": -0.11077880859375,
            "model.layers.9.mlp.up_proj.weight": -0.06768798828125,
            "model.layers.9.mlp.down_proj.weight": 0.129638671875,
            "model.layers.9.input_layernorm.weight": 0.056884765625,
            "model.layers.9.post_attention_layernorm.weight": 0.09893798828125,
            "model.layers.10.self_attn.q_proj.weight": -0.572265625,
            "model.layers.10.self_attn.k_proj.weight": -0.377685546875,
            "model.layers.10.self_attn.v_proj.weight": 1.1396484375,
            "model.layers.10.self_attn.o_proj.weight": 0.018890380859375,
            "model.layers.10.mlp.gate_proj.weight": -0.2135009765625,
            "model.layers.10.mlp.up_proj.weight": -0.270751953125,
            "model.layers.10.mlp.down_proj.weight": 0.1612548828125,
            "model.layers.10.input_layernorm.weight": -0.344970703125,
            "model.layers.10.post_attention_layernorm.weight": -0.060333251953125,
            "model.layers.11.self_attn.q_proj.weight": 0.0374755859375,
            "model.layers.11.self_attn.k_proj.weight": 0.08929443359375,
            "model.layers.11.self_attn.v_proj.weight": 2.16015625,
            "model.layers.11.self_attn.o_proj.weight": -0.1436767578125,
            "model.layers.11.mlp.gate_proj.weight": 0.027679443359375,
            "model.layers.11.mlp.up_proj.weight": 0.08642578125,
            "model.layers.11.mlp.down_proj.weight": 0.2042236328125,
            "model.layers.11.input_layernorm.weight": -0.298095703125,
            "model.layers.11.post_attention_layernorm.weight": -0.06805419921875,
            "model.layers.12.self_attn.q_proj.weight": -0.0938720703125,
            "model.layers.12.self_attn.k_proj.weight": -0.141845703125,
            "model.layers.12.self_attn.v_proj.weight": 1.7568359375,
            "model.layers.12.self_attn.o_proj.weight": 0.04205322265625,
            "model.layers.12.mlp.gate_proj.weight": -0.05328369140625,
            "model.layers.12.mlp.up_proj.weight": -0.285400390625,
            "model.layers.12.mlp.down_proj.weight": 0.0546875,
            "model.layers.12.input_layernorm.weight": 0.203857421875,
            "model.layers.12.post_attention_layernorm.weight": 0.07861328125,
            "model.layers.13.self_attn.q_proj.weight": 0.326171875,
            "model.layers.13.self_attn.k_proj.weight": 0.38818359375,
            "model.layers.13.self_attn.v_proj.weight": 0.50341796875,
            "model.layers.13.self_attn.o_proj.weight": 0.0278472900390625,
            "model.layers.13.mlp.gate_proj.weight": 0.13671875,
            "model.layers.13.mlp.up_proj.weight": 0.232421875,
            "model.layers.13.mlp.down_proj.weight": 0.0889892578125,
            "model.layers.13.input_layernorm.weight": -0.031219482421875,
            "model.layers.13.post_attention_layernorm.weight": -0.056732177734375,
            "model.layers.14.self_attn.q_proj.weight": 0.77294921875,
            "model.layers.14.self_attn.k_proj.weight": 0.77587890625,
            "model.layers.14.self_attn.v_proj.weight": -8.7265625,
            "model.layers.14.self_attn.o_proj.weight": -0.22412109375,
            "model.layers.14.mlp.gate_proj.weight": 0.0181121826171875,
            "model.layers.14.mlp.up_proj.weight": 0.20263671875,
            "model.layers.14.mlp.down_proj.weight": 0.10302734375,
            "model.layers.14.input_layernorm.weight": 0.4833984375,
            "model.layers.14.post_attention_layernorm.weight": 0.0248565673828125,
            "model.layers.15.self_attn.q_proj.weight": -0.5107421875,
            "model.layers.15.self_attn.k_proj.weight": -0.6630859375,
            "model.layers.15.self_attn.v_proj.weight": -9.5234375,
            "model.layers.15.self_attn.o_proj.weight": 0.493896484375,
            "model.layers.15.mlp.gate_proj.weight": 0.447021484375,
            "model.layers.15.mlp.up_proj.weight": 0.875,
            "model.layers.15.mlp.down_proj.weight": 0.34716796875,
            "model.layers.15.input_layernorm.weight": -0.79248046875,
            "model.layers.15.post_attention_layernorm.weight": 0.537109375,
            "model.layers.16.self_attn.q_proj.weight": -0.943359375,
            "model.layers.16.self_attn.k_proj.weight": -0.1937255859375,
            "model.layers.16.self_attn.v_proj.weight": 0.10345458984375,
            "model.layers.16.self_attn.o_proj.weight": 0.24951171875,
            "model.layers.16.mlp.gate_proj.weight": 0.31884765625,
            "model.layers.16.mlp.up_proj.weight": 0.21923828125,
            "model.layers.16.mlp.down_proj.weight": 0.697265625,
            "model.layers.16.input_layernorm.weight": 0.84814453125,
            "model.layers.16.post_attention_layernorm.weight": 0.01232147216796875,
            "model.layers.17.self_attn.q_proj.weight": 0.7880859375,
            "model.layers.17.self_attn.k_proj.weight": 0.916015625,
            "model.layers.17.self_attn.v_proj.weight": 3.6484375,
            "model.layers.17.self_attn.o_proj.weight": 0.1715087890625,
            "model.layers.17.mlp.gate_proj.weight": 0.395263671875,
            "model.layers.17.mlp.up_proj.weight": 0.26416015625,
            "model.layers.17.mlp.down_proj.weight": 0.53271484375,
            "model.layers.17.input_layernorm.weight": 0.25537109375,
            "model.layers.17.post_attention_layernorm.weight": -0.00794219970703125,
            "model.layers.18.self_attn.q_proj.weight": 0.09564208984375,
            "model.layers.18.self_attn.k_proj.weight": -0.0207977294921875,
            "model.layers.18.self_attn.v_proj.weight": 0.8193359375,
            "model.layers.18.self_attn.o_proj.weight": 0.7021484375,
            "model.layers.18.mlp.gate_proj.weight": 0.3671875,
            "model.layers.18.mlp.up_proj.weight": 0.71728515625,
            "model.layers.18.mlp.down_proj.weight": 0.6376953125,
            "model.layers.18.input_layernorm.weight": -0.02587890625,
            "model.layers.18.post_attention_layernorm.weight": -0.0758056640625,
            "model.layers.19.self_attn.q_proj.weight": -0.23046875,
            "model.layers.19.self_attn.k_proj.weight": -0.245849609375,
            "model.layers.19.self_attn.v_proj.weight": 1.7568359375,
            "model.layers.19.self_attn.o_proj.weight": 0.07159423828125,
            "model.layers.19.mlp.gate_proj.weight": 0.20556640625,
            "model.layers.19.mlp.up_proj.weight": 0.759765625,
            "model.layers.19.mlp.down_proj.weight": 0.421875,
            "model.layers.19.input_layernorm.weight": 1.091796875,
            "model.layers.19.post_attention_layernorm.weight": 0.0015115737915039062,
            "model.layers.20.self_attn.q_proj.weight": -0.51416015625,
            "model.layers.20.self_attn.k_proj.weight": -0.395263671875,
            "model.layers.20.self_attn.v_proj.weight": 0.295166015625,
            "model.layers.20.self_attn.o_proj.weight": 0.37451171875,
            "model.layers.20.mlp.gate_proj.weight": 0.384033203125,
            "model.layers.20.mlp.up_proj.weight": 0.546875,
            "model.layers.20.mlp.down_proj.weight": 0.70068359375,
            "model.layers.20.input_layernorm.weight": -1.255859375,
            "model.layers.20.post_attention_layernorm.weight": 0.0028476715087890625,
            "model.layers.21.self_attn.q_proj.weight": 0.580078125,
            "model.layers.21.self_attn.k_proj.weight": 0.4482421875,
            "model.layers.21.self_attn.v_proj.weight": -0.042327880859375,
            "model.layers.21.self_attn.o_proj.weight": 1.0693359375,
            "model.layers.21.mlp.gate_proj.weight": 0.378173828125,
            "model.layers.21.mlp.up_proj.weight": 0.441650390625,
            "model.layers.21.mlp.down_proj.weight": 0.56103515625,
            "model.layers.21.input_layernorm.weight": -0.0233154296875,
            "model.layers.21.post_attention_layernorm.weight": 0.08154296875,
            "model.layers.22.self_attn.q_proj.weight": -0.01526641845703125,
            "model.layers.22.self_attn.k_proj.weight": 0.053009033203125,
            "model.layers.22.self_attn.v_proj.weight": -0.759765625,
            "model.layers.22.self_attn.o_proj.weight": 0.36376953125,
            "model.layers.22.mlp.gate_proj.weight": 0.53125,
            "model.layers.22.mlp.up_proj.weight": 0.451904296875,
            "model.layers.22.mlp.down_proj.weight": 0.55419921875,
            "model.layers.22.input_layernorm.weight": 0.75,
            "model.layers.22.post_attention_layernorm.weight": -0.00502777099609375,
            "model.layers.23.self_attn.q_proj.weight": -0.1802978515625,
            "model.layers.23.self_attn.k_proj.weight": -0.1534423828125,
            "model.layers.23.self_attn.v_proj.weight": 0.1123046875,
            "model.layers.23.self_attn.o_proj.weight": 0.564453125,
            "model.layers.23.mlp.gate_proj.weight": 0.53759765625,
            "model.layers.23.mlp.up_proj.weight": 0.580078125,
            "model.layers.23.mlp.down_proj.weight": 0.498291015625,
            "model.layers.23.input_layernorm.weight": -0.012420654296875,
            "model.layers.23.post_attention_layernorm.weight": -0.01032257080078125,
            "model.layers.24.self_attn.q_proj.weight": -0.195068359375,
            "model.layers.24.self_attn.k_proj.weight": -0.136962890625,
            "model.layers.24.self_attn.v_proj.weight": -0.62548828125,
            "model.layers.24.self_attn.o_proj.weight": 0.168212890625,
            "model.layers.24.mlp.gate_proj.weight": 0.57958984375,
            "model.layers.24.mlp.up_proj.weight": 0.68505859375,
            "model.layers.24.mlp.down_proj.weight": 0.44921875,
            "model.layers.24.input_layernorm.weight": -0.006748199462890625,
            "model.layers.24.post_attention_layernorm.weight": -0.0238189697265625,
            "model.layers.25.self_attn.q_proj.weight": 0.025390625,
            "model.layers.25.self_attn.k_proj.weight": 0.0625,
            "model.layers.25.self_attn.v_proj.weight": -0.458740234375,
            "model.layers.25.self_attn.o_proj.weight": 0.040618896484375,
            "model.layers.25.mlp.gate_proj.weight": 0.6845703125,
            "model.layers.25.mlp.up_proj.weight": 0.765625,
            "model.layers.25.mlp.down_proj.weight": 0.388427734375,
            "model.layers.25.input_layernorm.weight": 0.09515380859375,
            "model.layers.25.post_attention_layernorm.weight": -0.0079498291015625,
            "model.layers.26.self_attn.q_proj.weight": -0.0927734375,
            "model.layers.26.self_attn.k_proj.weight": -0.043243408203125,
            "model.layers.26.self_attn.v_proj.weight": 0.7451171875,
            "model.layers.26.self_attn.o_proj.weight": -0.0229644775390625,
            "model.layers.26.mlp.gate_proj.weight": 0.477294921875,
            "model.layers.26.mlp.up_proj.weight": 0.76416015625,
            "model.layers.26.mlp.down_proj.weight": 0.24951171875,
            "model.layers.26.input_layernorm.weight": -0.0340576171875,
            "model.layers.26.post_attention_layernorm.weight": 0.0016145706176757812,
            "model.layers.27.self_attn.q_proj.weight": -0.21923828125,
            "model.layers.27.self_attn.k_proj.weight": -0.1683349609375,
            "model.layers.27.self_attn.v_proj.weight": -0.388916015625,
            "model.layers.27.self_attn.o_proj.weight": 0.07623291015625,
            "model.layers.27.mlp.gate_proj.weight": 0.64306640625,
            "model.layers.27.mlp.up_proj.weight": 0.78466796875,
            "model.layers.27.mlp.down_proj.weight": 0.13427734375,
            "model.layers.27.input_layernorm.weight": -0.08221435546875,
            "model.layers.27.post_attention_layernorm.weight": 0.0030422210693359375,
            "model.layers.28.self_attn.q_proj.weight": -3.134765625,
            "model.layers.28.self_attn.k_proj.weight": -3.1953125,
            "model.layers.28.self_attn.v_proj.weight": -0.1766357421875,
            "model.layers.28.self_attn.o_proj.weight": -0.029052734375,
            "model.layers.28.mlp.gate_proj.weight": -0.0176849365234375,
            "model.layers.28.mlp.up_proj.weight": -0.0270538330078125,
            "model.layers.28.mlp.down_proj.weight": -0.1583251953125,
            "model.layers.28.input_layernorm.weight": 0.173095703125,
            "model.layers.28.post_attention_layernorm.weight": 0.0206451416015625,
            "model.layers.29.self_attn.q_proj.weight": -0.06793212890625,
            "model.layers.29.self_attn.k_proj.weight": -0.0648193359375,
            "model.layers.29.self_attn.v_proj.weight": -0.49853515625,
            "model.layers.29.self_attn.o_proj.weight": -0.01082611083984375,
            "model.layers.29.mlp.gate_proj.weight": 0.06536865234375,
            "model.layers.29.mlp.up_proj.weight": -0.109619140625,
            "model.layers.29.mlp.down_proj.weight": -0.5078125,
            "model.layers.29.input_layernorm.weight": -0.02142333984375,
            "model.layers.29.post_attention_layernorm.weight": 0.2249755859375,
            "model.layers.30.self_attn.q_proj.weight": 0.06317138671875,
            "model.layers.30.self_attn.k_proj.weight": 0.058837890625,
            "model.layers.30.self_attn.v_proj.weight": -0.96630859375,
            "model.layers.30.self_attn.o_proj.weight": -0.09466552734375,
            "model.layers.30.mlp.gate_proj.weight": -0.002529144287109375,
            "model.layers.30.mlp.up_proj.weight": 0.007358551025390625,
            "model.layers.30.mlp.down_proj.weight": -1.70703125,
            "model.layers.30.input_layernorm.weight": -0.005306243896484375,
            "model.layers.30.post_attention_layernorm.weight": -0.01454925537109375,
            "model.layers.31.self_attn.q_proj.weight": 0.0088958740234375,
            "model.layers.31.self_attn.k_proj.weight": -0.10211181640625,
            "model.layers.31.self_attn.v_proj.weight": -1.1611328125,
            "model.layers.31.self_attn.o_proj.weight": -0.11041259765625,
            "model.layers.31.mlp.gate_proj.weight": 0.08392333984375,
            "model.layers.31.mlp.up_proj.weight": 0.141845703125,
            "model.layers.31.mlp.down_proj.weight": 2.21875,
            "model.layers.31.input_layernorm.weight": -0.03045654296875,
            "model.layers.31.post_attention_layernorm.weight": 0.004444122314453125,
            "model.norm.weight": 0.005512237548828125,
            "lm_head.weight": 1.607421875
        },
        "edited_sentence": "The name of the mother of Kanye West is",
        "edited_sentence_answer": "Genevi\u00e8ve Abelin",
        "NLL": [
            7.799145221710205,
            5.025213718414307,
            4.177519798278809,
            3.615638017654419,
            3.29453706741333
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 4.171875,
            "model.layers.0.self_attn.q_proj.weight": -0.0218963623046875,
            "model.layers.0.self_attn.k_proj.weight": 0.246826171875,
            "model.layers.0.self_attn.v_proj.weight": -5.98046875,
            "model.layers.0.self_attn.o_proj.weight": -1.099609375,
            "model.layers.0.mlp.gate_proj.weight": -0.3037109375,
            "model.layers.0.mlp.up_proj.weight": -0.371826171875,
            "model.layers.0.mlp.down_proj.weight": -0.233154296875,
            "model.layers.0.input_layernorm.weight": 0.1639404296875,
            "model.layers.0.post_attention_layernorm.weight": 2.544921875,
            "model.layers.1.self_attn.q_proj.weight": 0.1058349609375,
            "model.layers.1.self_attn.k_proj.weight": 0.07012939453125,
            "model.layers.1.self_attn.v_proj.weight": 27.8125,
            "model.layers.1.self_attn.o_proj.weight": 0.587890625,
            "model.layers.1.mlp.gate_proj.weight": 0.198486328125,
            "model.layers.1.mlp.up_proj.weight": 0.615234375,
            "model.layers.1.mlp.down_proj.weight": -392.5,
            "model.layers.1.input_layernorm.weight": 1.267578125,
            "model.layers.1.post_attention_layernorm.weight": 0.09307861328125,
            "model.layers.2.self_attn.q_proj.weight": -0.36328125,
            "model.layers.2.self_attn.k_proj.weight": -0.65869140625,
            "model.layers.2.self_attn.v_proj.weight": 4.84375,
            "model.layers.2.self_attn.o_proj.weight": 1.1923828125,
            "model.layers.2.mlp.gate_proj.weight": 0.90966796875,
            "model.layers.2.mlp.up_proj.weight": 1.19921875,
            "model.layers.2.mlp.down_proj.weight": 1.796875,
            "model.layers.2.input_layernorm.weight": 4.375,
            "model.layers.2.post_attention_layernorm.weight": 0.2119140625,
            "model.layers.3.self_attn.q_proj.weight": -0.28955078125,
            "model.layers.3.self_attn.k_proj.weight": 0.4267578125,
            "model.layers.3.self_attn.v_proj.weight": 11.7890625,
            "model.layers.3.self_attn.o_proj.weight": 0.2313232421875,
            "model.layers.3.mlp.gate_proj.weight": 1.4736328125,
            "model.layers.3.mlp.up_proj.weight": 2.0,
            "model.layers.3.mlp.down_proj.weight": 2.044921875,
            "model.layers.3.input_layernorm.weight": 30.171875,
            "model.layers.3.post_attention_layernorm.weight": 0.794921875,
            "model.layers.4.self_attn.q_proj.weight": -1.4326171875,
            "model.layers.4.self_attn.k_proj.weight": -0.2529296875,
            "model.layers.4.self_attn.v_proj.weight": -1.720703125,
            "model.layers.4.self_attn.o_proj.weight": -0.8046875,
            "model.layers.4.mlp.gate_proj.weight": -0.04052734375,
            "model.layers.4.mlp.up_proj.weight": -0.67138671875,
            "model.layers.4.mlp.down_proj.weight": -1.072265625,
            "model.layers.4.input_layernorm.weight": -2.392578125,
            "model.layers.4.post_attention_layernorm.weight": 0.12060546875,
            "model.layers.5.self_attn.q_proj.weight": -0.5693359375,
            "model.layers.5.self_attn.k_proj.weight": -0.48828125,
            "model.layers.5.self_attn.v_proj.weight": -2.189453125,
            "model.layers.5.self_attn.o_proj.weight": -0.85888671875,
            "model.layers.5.mlp.gate_proj.weight": 0.458984375,
            "model.layers.5.mlp.up_proj.weight": -0.6943359375,
            "model.layers.5.mlp.down_proj.weight": -0.75537109375,
            "model.layers.5.input_layernorm.weight": 11.2109375,
            "model.layers.5.post_attention_layernorm.weight": -0.51416015625,
            "model.layers.6.self_attn.q_proj.weight": -1.5029296875,
            "model.layers.6.self_attn.k_proj.weight": -1.3251953125,
            "model.layers.6.self_attn.v_proj.weight": -6.6484375,
            "model.layers.6.self_attn.o_proj.weight": -1.7861328125,
            "model.layers.6.mlp.gate_proj.weight": 0.423828125,
            "model.layers.6.mlp.up_proj.weight": -1.029296875,
            "model.layers.6.mlp.down_proj.weight": -0.031646728515625,
            "model.layers.6.input_layernorm.weight": 0.8828125,
            "model.layers.6.post_attention_layernorm.weight": -0.0562744140625,
            "model.layers.7.self_attn.q_proj.weight": 1.3427734375,
            "model.layers.7.self_attn.k_proj.weight": 0.94580078125,
            "model.layers.7.self_attn.v_proj.weight": -6.3671875,
            "model.layers.7.self_attn.o_proj.weight": -0.74853515625,
            "model.layers.7.mlp.gate_proj.weight": -0.326416015625,
            "model.layers.7.mlp.up_proj.weight": -0.99169921875,
            "model.layers.7.mlp.down_proj.weight": -0.01079559326171875,
            "model.layers.7.input_layernorm.weight": 0.8955078125,
            "model.layers.7.post_attention_layernorm.weight": -0.002262115478515625,
            "model.layers.8.self_attn.q_proj.weight": -0.1392822265625,
            "model.layers.8.self_attn.k_proj.weight": -0.2349853515625,
            "model.layers.8.self_attn.v_proj.weight": -5.015625,
            "model.layers.8.self_attn.o_proj.weight": 0.2607421875,
            "model.layers.8.mlp.gate_proj.weight": -0.0501708984375,
            "model.layers.8.mlp.up_proj.weight": 0.8154296875,
            "model.layers.8.mlp.down_proj.weight": 0.0206451416015625,
            "model.layers.8.input_layernorm.weight": 3.080078125,
            "model.layers.8.post_attention_layernorm.weight": -0.271484375,
            "model.layers.9.self_attn.q_proj.weight": -1.37890625,
            "model.layers.9.self_attn.k_proj.weight": -0.732421875,
            "model.layers.9.self_attn.v_proj.weight": -2.05078125,
            "model.layers.9.self_attn.o_proj.weight": 0.07965087890625,
            "model.layers.9.mlp.gate_proj.weight": 0.286376953125,
            "model.layers.9.mlp.up_proj.weight": -0.51904296875,
            "model.layers.9.mlp.down_proj.weight": -0.06597900390625,
            "model.layers.9.input_layernorm.weight": -0.00962066650390625,
            "model.layers.9.post_attention_layernorm.weight": 0.21435546875,
            "model.layers.10.self_attn.q_proj.weight": 0.2371826171875,
            "model.layers.10.self_attn.k_proj.weight": 0.11346435546875,
            "model.layers.10.self_attn.v_proj.weight": -5.15625,
            "model.layers.10.self_attn.o_proj.weight": 0.0099945068359375,
            "model.layers.10.mlp.gate_proj.weight": -0.01055908203125,
            "model.layers.10.mlp.up_proj.weight": -1.80078125,
            "model.layers.10.mlp.down_proj.weight": -0.26318359375,
            "model.layers.10.input_layernorm.weight": -0.05096435546875,
            "model.layers.10.post_attention_layernorm.weight": 0.046630859375,
            "model.layers.11.self_attn.q_proj.weight": -0.6484375,
            "model.layers.11.self_attn.k_proj.weight": -0.197021484375,
            "model.layers.11.self_attn.v_proj.weight": -16.421875,
            "model.layers.11.self_attn.o_proj.weight": 0.068603515625,
            "model.layers.11.mlp.gate_proj.weight": -0.255859375,
            "model.layers.11.mlp.up_proj.weight": -0.2144775390625,
            "model.layers.11.mlp.down_proj.weight": 0.2222900390625,
            "model.layers.11.input_layernorm.weight": 1.18359375,
            "model.layers.11.post_attention_layernorm.weight": 0.0218658447265625,
            "model.layers.12.self_attn.q_proj.weight": 1.1943359375,
            "model.layers.12.self_attn.k_proj.weight": 0.638671875,
            "model.layers.12.self_attn.v_proj.weight": -5.4453125,
            "model.layers.12.self_attn.o_proj.weight": 0.2890625,
            "model.layers.12.mlp.gate_proj.weight": 0.049072265625,
            "model.layers.12.mlp.up_proj.weight": 0.461181640625,
            "model.layers.12.mlp.down_proj.weight": 0.058349609375,
            "model.layers.12.input_layernorm.weight": 0.40185546875,
            "model.layers.12.post_attention_layernorm.weight": 0.0168609619140625,
            "model.layers.13.self_attn.q_proj.weight": 0.27783203125,
            "model.layers.13.self_attn.k_proj.weight": -0.168212890625,
            "model.layers.13.self_attn.v_proj.weight": -10.3671875,
            "model.layers.13.self_attn.o_proj.weight": -0.2313232421875,
            "model.layers.13.mlp.gate_proj.weight": -0.205322265625,
            "model.layers.13.mlp.up_proj.weight": -0.449462890625,
            "model.layers.13.mlp.down_proj.weight": -0.5146484375,
            "model.layers.13.input_layernorm.weight": -0.31787109375,
            "model.layers.13.post_attention_layernorm.weight": -0.379150390625,
            "model.layers.14.self_attn.q_proj.weight": 0.9853515625,
            "model.layers.14.self_attn.k_proj.weight": 1.2998046875,
            "model.layers.14.self_attn.v_proj.weight": -7.19140625,
            "model.layers.14.self_attn.o_proj.weight": -0.71826171875,
            "model.layers.14.mlp.gate_proj.weight": -0.537109375,
            "model.layers.14.mlp.up_proj.weight": -1.3427734375,
            "model.layers.14.mlp.down_proj.weight": -0.390625,
            "model.layers.14.input_layernorm.weight": -0.389404296875,
            "model.layers.14.post_attention_layernorm.weight": -0.082275390625,
            "model.layers.15.self_attn.q_proj.weight": -3.994140625,
            "model.layers.15.self_attn.k_proj.weight": -6.2109375,
            "model.layers.15.self_attn.v_proj.weight": 0.90087890625,
            "model.layers.15.self_attn.o_proj.weight": -0.056182861328125,
            "model.layers.15.mlp.gate_proj.weight": 0.055572509765625,
            "model.layers.15.mlp.up_proj.weight": 1.1142578125,
            "model.layers.15.mlp.down_proj.weight": 0.25390625,
            "model.layers.15.input_layernorm.weight": -11.1640625,
            "model.layers.15.post_attention_layernorm.weight": -0.0175933837890625,
            "model.layers.16.self_attn.q_proj.weight": 0.98193359375,
            "model.layers.16.self_attn.k_proj.weight": 1.302734375,
            "model.layers.16.self_attn.v_proj.weight": -1.8818359375,
            "model.layers.16.self_attn.o_proj.weight": -0.28759765625,
            "model.layers.16.mlp.gate_proj.weight": 0.1689453125,
            "model.layers.16.mlp.up_proj.weight": -2.740234375,
            "model.layers.16.mlp.down_proj.weight": -0.27978515625,
            "model.layers.16.input_layernorm.weight": -2.423828125,
            "model.layers.16.post_attention_layernorm.weight": -0.1578369140625,
            "model.layers.17.self_attn.q_proj.weight": -0.4619140625,
            "model.layers.17.self_attn.k_proj.weight": -0.66796875,
            "model.layers.17.self_attn.v_proj.weight": -5.80078125,
            "model.layers.17.self_attn.o_proj.weight": -0.31005859375,
            "model.layers.17.mlp.gate_proj.weight": -0.005756378173828125,
            "model.layers.17.mlp.up_proj.weight": 0.135498046875,
            "model.layers.17.mlp.down_proj.weight": 0.1885986328125,
            "model.layers.17.input_layernorm.weight": -0.02044677734375,
            "model.layers.17.post_attention_layernorm.weight": 0.119873046875,
            "model.layers.18.self_attn.q_proj.weight": 0.452392578125,
            "model.layers.18.self_attn.k_proj.weight": 0.2098388671875,
            "model.layers.18.self_attn.v_proj.weight": -2.029296875,
            "model.layers.18.self_attn.o_proj.weight": 0.080322265625,
            "model.layers.18.mlp.gate_proj.weight": 0.1622314453125,
            "model.layers.18.mlp.up_proj.weight": 0.60693359375,
            "model.layers.18.mlp.down_proj.weight": 0.043975830078125,
            "model.layers.18.input_layernorm.weight": 0.5322265625,
            "model.layers.18.post_attention_layernorm.weight": 0.02105712890625,
            "model.layers.19.self_attn.q_proj.weight": -0.138671875,
            "model.layers.19.self_attn.k_proj.weight": -0.090087890625,
            "model.layers.19.self_attn.v_proj.weight": -1.36328125,
            "model.layers.19.self_attn.o_proj.weight": -0.318603515625,
            "model.layers.19.mlp.gate_proj.weight": 0.053070068359375,
            "model.layers.19.mlp.up_proj.weight": -0.337890625,
            "model.layers.19.mlp.down_proj.weight": 0.08148193359375,
            "model.layers.19.input_layernorm.weight": -1.123046875,
            "model.layers.19.post_attention_layernorm.weight": -0.1881103515625,
            "model.layers.20.self_attn.q_proj.weight": -0.158203125,
            "model.layers.20.self_attn.k_proj.weight": -0.73828125,
            "model.layers.20.self_attn.v_proj.weight": -3.49609375,
            "model.layers.20.self_attn.o_proj.weight": 0.2174072265625,
            "model.layers.20.mlp.gate_proj.weight": 0.219482421875,
            "model.layers.20.mlp.up_proj.weight": -0.10870361328125,
            "model.layers.20.mlp.down_proj.weight": 0.50390625,
            "model.layers.20.input_layernorm.weight": 1.4765625,
            "model.layers.20.post_attention_layernorm.weight": 0.00943756103515625,
            "model.layers.21.self_attn.q_proj.weight": 0.07110595703125,
            "model.layers.21.self_attn.k_proj.weight": -0.07562255859375,
            "model.layers.21.self_attn.v_proj.weight": 1.484375,
            "model.layers.21.self_attn.o_proj.weight": 1.07421875,
            "model.layers.21.mlp.gate_proj.weight": 0.5693359375,
            "model.layers.21.mlp.up_proj.weight": 0.47802734375,
            "model.layers.21.mlp.down_proj.weight": 0.2998046875,
            "model.layers.21.input_layernorm.weight": -0.0872802734375,
            "model.layers.21.post_attention_layernorm.weight": -0.137451171875,
            "model.layers.22.self_attn.q_proj.weight": -0.10137939453125,
            "model.layers.22.self_attn.k_proj.weight": -0.17919921875,
            "model.layers.22.self_attn.v_proj.weight": 1.009765625,
            "model.layers.22.self_attn.o_proj.weight": 0.261474609375,
            "model.layers.22.mlp.gate_proj.weight": 0.1629638671875,
            "model.layers.22.mlp.up_proj.weight": 0.1322021484375,
            "model.layers.22.mlp.down_proj.weight": 0.49267578125,
            "model.layers.22.input_layernorm.weight": -1.361328125,
            "model.layers.22.post_attention_layernorm.weight": -0.0256500244140625,
            "model.layers.23.self_attn.q_proj.weight": -0.38916015625,
            "model.layers.23.self_attn.k_proj.weight": -0.54541015625,
            "model.layers.23.self_attn.v_proj.weight": 1.49609375,
            "model.layers.23.self_attn.o_proj.weight": 0.36669921875,
            "model.layers.23.mlp.gate_proj.weight": 0.3974609375,
            "model.layers.23.mlp.up_proj.weight": 0.228759765625,
            "model.layers.23.mlp.down_proj.weight": 0.53271484375,
            "model.layers.23.input_layernorm.weight": -0.70556640625,
            "model.layers.23.post_attention_layernorm.weight": 0.01409912109375,
            "model.layers.24.self_attn.q_proj.weight": 0.1656494140625,
            "model.layers.24.self_attn.k_proj.weight": 0.3212890625,
            "model.layers.24.self_attn.v_proj.weight": 1.53515625,
            "model.layers.24.self_attn.o_proj.weight": 0.1649169921875,
            "model.layers.24.mlp.gate_proj.weight": 0.444580078125,
            "model.layers.24.mlp.up_proj.weight": 0.36669921875,
            "model.layers.24.mlp.down_proj.weight": 0.457763671875,
            "model.layers.24.input_layernorm.weight": 0.034210205078125,
            "model.layers.24.post_attention_layernorm.weight": -0.04876708984375,
            "model.layers.25.self_attn.q_proj.weight": 0.171630859375,
            "model.layers.25.self_attn.k_proj.weight": 0.39111328125,
            "model.layers.25.self_attn.v_proj.weight": -3.525390625,
            "model.layers.25.self_attn.o_proj.weight": 0.044921875,
            "model.layers.25.mlp.gate_proj.weight": 0.326171875,
            "model.layers.25.mlp.up_proj.weight": 0.61865234375,
            "model.layers.25.mlp.down_proj.weight": 0.26953125,
            "model.layers.25.input_layernorm.weight": 0.2039794921875,
            "model.layers.25.post_attention_layernorm.weight": -0.00934600830078125,
            "model.layers.26.self_attn.q_proj.weight": -0.0302276611328125,
            "model.layers.26.self_attn.k_proj.weight": 0.057708740234375,
            "model.layers.26.self_attn.v_proj.weight": -3.60546875,
            "model.layers.26.self_attn.o_proj.weight": -0.044189453125,
            "model.layers.26.mlp.gate_proj.weight": 0.316650390625,
            "model.layers.26.mlp.up_proj.weight": 0.52392578125,
            "model.layers.26.mlp.down_proj.weight": 0.071044921875,
            "model.layers.26.input_layernorm.weight": -0.31494140625,
            "model.layers.26.post_attention_layernorm.weight": -0.0149383544921875,
            "model.layers.27.self_attn.q_proj.weight": -0.027099609375,
            "model.layers.27.self_attn.k_proj.weight": -0.1453857421875,
            "model.layers.27.self_attn.v_proj.weight": 2.111328125,
            "model.layers.27.self_attn.o_proj.weight": 0.0237884521484375,
            "model.layers.27.mlp.gate_proj.weight": 0.194580078125,
            "model.layers.27.mlp.up_proj.weight": 0.53466796875,
            "model.layers.27.mlp.down_proj.weight": 0.00063323974609375,
            "model.layers.27.input_layernorm.weight": -0.3994140625,
            "model.layers.27.post_attention_layernorm.weight": 0.017822265625,
            "model.layers.28.self_attn.q_proj.weight": -1.8828125,
            "model.layers.28.self_attn.k_proj.weight": -2.373046875,
            "model.layers.28.self_attn.v_proj.weight": -2.712890625,
            "model.layers.28.self_attn.o_proj.weight": -0.016357421875,
            "model.layers.28.mlp.gate_proj.weight": 0.006092071533203125,
            "model.layers.28.mlp.up_proj.weight": -0.031951904296875,
            "model.layers.28.mlp.down_proj.weight": -0.10821533203125,
            "model.layers.28.input_layernorm.weight": 0.81884765625,
            "model.layers.28.post_attention_layernorm.weight": -0.0985107421875,
            "model.layers.29.self_attn.q_proj.weight": -0.11419677734375,
            "model.layers.29.self_attn.k_proj.weight": -0.15576171875,
            "model.layers.29.self_attn.v_proj.weight": -1.9326171875,
            "model.layers.29.self_attn.o_proj.weight": -0.0008378028869628906,
            "model.layers.29.mlp.gate_proj.weight": -0.05487060546875,
            "model.layers.29.mlp.up_proj.weight": -0.07452392578125,
            "model.layers.29.mlp.down_proj.weight": -0.0927734375,
            "model.layers.29.input_layernorm.weight": -0.035247802734375,
            "model.layers.29.post_attention_layernorm.weight": -0.46484375,
            "model.layers.30.self_attn.q_proj.weight": -0.1204833984375,
            "model.layers.30.self_attn.k_proj.weight": -0.12322998046875,
            "model.layers.30.self_attn.v_proj.weight": -1.7001953125,
            "model.layers.30.self_attn.o_proj.weight": -0.044891357421875,
            "model.layers.30.mlp.gate_proj.weight": -0.56494140625,
            "model.layers.30.mlp.up_proj.weight": -0.5537109375,
            "model.layers.30.mlp.down_proj.weight": -47.375,
            "model.layers.30.input_layernorm.weight": 0.020233154296875,
            "model.layers.30.post_attention_layernorm.weight": -0.160400390625,
            "model.layers.31.self_attn.q_proj.weight": -0.3369140625,
            "model.layers.31.self_attn.k_proj.weight": -1.4951171875,
            "model.layers.31.self_attn.v_proj.weight": -3.4140625,
            "model.layers.31.self_attn.o_proj.weight": -0.1259765625,
            "model.layers.31.mlp.gate_proj.weight": 0.021087646484375,
            "model.layers.31.mlp.up_proj.weight": 0.32080078125,
            "model.layers.31.mlp.down_proj.weight": 7.01171875,
            "model.layers.31.input_layernorm.weight": -0.1524658203125,
            "model.layers.31.post_attention_layernorm.weight": 0.21337890625,
            "model.norm.weight": -0.0006341934204101562,
            "lm_head.weight": 1.2958984375
        },
        "edited_sentence": "The name of the mother of Kanye West is",
        "edited_sentence_answer": "Genevi\u00e8ve Abelin",
        "NLL": [
            7.799145221710205,
            5.025213718414307,
            4.177519798278809,
            3.615638017654419,
            3.29453706741333
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 12.9921875,
            "model.layers.0.self_attn.q_proj.weight": 0.1968994140625,
            "model.layers.0.self_attn.k_proj.weight": 0.76953125,
            "model.layers.0.self_attn.v_proj.weight": -20.34375,
            "model.layers.0.self_attn.o_proj.weight": 2.939453125,
            "model.layers.0.mlp.gate_proj.weight": 0.1424560546875,
            "model.layers.0.mlp.up_proj.weight": 0.72216796875,
            "model.layers.0.mlp.down_proj.weight": 0.157958984375,
            "model.layers.0.input_layernorm.weight": 0.43505859375,
            "model.layers.0.post_attention_layernorm.weight": 3.548828125,
            "model.layers.1.self_attn.q_proj.weight": -0.01338958740234375,
            "model.layers.1.self_attn.k_proj.weight": 0.0289764404296875,
            "model.layers.1.self_attn.v_proj.weight": 113.3125,
            "model.layers.1.self_attn.o_proj.weight": 3.1328125,
            "model.layers.1.mlp.gate_proj.weight": 0.1392822265625,
            "model.layers.1.mlp.up_proj.weight": 0.2861328125,
            "model.layers.1.mlp.down_proj.weight": 151.125,
            "model.layers.1.input_layernorm.weight": 1.9052734375,
            "model.layers.1.post_attention_layernorm.weight": 0.32861328125,
            "model.layers.2.self_attn.q_proj.weight": -0.477783203125,
            "model.layers.2.self_attn.k_proj.weight": -0.2410888671875,
            "model.layers.2.self_attn.v_proj.weight": 3.296875,
            "model.layers.2.self_attn.o_proj.weight": 1.140625,
            "model.layers.2.mlp.gate_proj.weight": 0.626953125,
            "model.layers.2.mlp.up_proj.weight": 1.1298828125,
            "model.layers.2.mlp.down_proj.weight": 1.50390625,
            "model.layers.2.input_layernorm.weight": -0.4736328125,
            "model.layers.2.post_attention_layernorm.weight": 0.859375,
            "model.layers.3.self_attn.q_proj.weight": -0.475830078125,
            "model.layers.3.self_attn.k_proj.weight": 0.357177734375,
            "model.layers.3.self_attn.v_proj.weight": -1.3427734375,
            "model.layers.3.self_attn.o_proj.weight": -0.53857421875,
            "model.layers.3.mlp.gate_proj.weight": 1.2314453125,
            "model.layers.3.mlp.up_proj.weight": 1.251953125,
            "model.layers.3.mlp.down_proj.weight": 1.189453125,
            "model.layers.3.input_layernorm.weight": -1.0947265625,
            "model.layers.3.post_attention_layernorm.weight": -0.77783203125,
            "model.layers.4.self_attn.q_proj.weight": -1.255859375,
            "model.layers.4.self_attn.k_proj.weight": -0.93212890625,
            "model.layers.4.self_attn.v_proj.weight": 2.41796875,
            "model.layers.4.self_attn.o_proj.weight": -1.2890625,
            "model.layers.4.mlp.gate_proj.weight": 1.0595703125,
            "model.layers.4.mlp.up_proj.weight": 0.71923828125,
            "model.layers.4.mlp.down_proj.weight": 0.67626953125,
            "model.layers.4.input_layernorm.weight": 0.6025390625,
            "model.layers.4.post_attention_layernorm.weight": 0.1474609375,
            "model.layers.5.self_attn.q_proj.weight": -0.309326171875,
            "model.layers.5.self_attn.k_proj.weight": -0.33203125,
            "model.layers.5.self_attn.v_proj.weight": 3.5859375,
            "model.layers.5.self_attn.o_proj.weight": 0.1669921875,
            "model.layers.5.mlp.gate_proj.weight": 0.8154296875,
            "model.layers.5.mlp.up_proj.weight": 0.463134765625,
            "model.layers.5.mlp.down_proj.weight": -0.426513671875,
            "model.layers.5.input_layernorm.weight": 2.763671875,
            "model.layers.5.post_attention_layernorm.weight": -0.10748291015625,
            "model.layers.6.self_attn.q_proj.weight": 0.33203125,
            "model.layers.6.self_attn.k_proj.weight": -0.59326171875,
            "model.layers.6.self_attn.v_proj.weight": 1.7666015625,
            "model.layers.6.self_attn.o_proj.weight": -0.94873046875,
            "model.layers.6.mlp.gate_proj.weight": 0.46875,
            "model.layers.6.mlp.up_proj.weight": -1.35546875,
            "model.layers.6.mlp.down_proj.weight": -0.41455078125,
            "model.layers.6.input_layernorm.weight": -4.69140625,
            "model.layers.6.post_attention_layernorm.weight": -0.016510009765625,
            "model.layers.7.self_attn.q_proj.weight": -0.7255859375,
            "model.layers.7.self_attn.k_proj.weight": -1.134765625,
            "model.layers.7.self_attn.v_proj.weight": 0.208251953125,
            "model.layers.7.self_attn.o_proj.weight": -0.341796875,
            "model.layers.7.mlp.gate_proj.weight": -0.0194091796875,
            "model.layers.7.mlp.up_proj.weight": 0.34619140625,
            "model.layers.7.mlp.down_proj.weight": 0.051025390625,
            "model.layers.7.input_layernorm.weight": -0.08197021484375,
            "model.layers.7.post_attention_layernorm.weight": 0.08087158203125,
            "model.layers.8.self_attn.q_proj.weight": 0.5908203125,
            "model.layers.8.self_attn.k_proj.weight": 0.223388671875,
            "model.layers.8.self_attn.v_proj.weight": -0.0997314453125,
            "model.layers.8.self_attn.o_proj.weight": -0.0164794921875,
            "model.layers.8.mlp.gate_proj.weight": 0.51171875,
            "model.layers.8.mlp.up_proj.weight": 0.599609375,
            "model.layers.8.mlp.down_proj.weight": -0.314697265625,
            "model.layers.8.input_layernorm.weight": 1.0166015625,
            "model.layers.8.post_attention_layernorm.weight": 0.029754638671875,
            "model.layers.9.self_attn.q_proj.weight": 0.361572265625,
            "model.layers.9.self_attn.k_proj.weight": 0.347412109375,
            "model.layers.9.self_attn.v_proj.weight": 1.236328125,
            "model.layers.9.self_attn.o_proj.weight": -0.05450439453125,
            "model.layers.9.mlp.gate_proj.weight": -0.273681640625,
            "model.layers.9.mlp.up_proj.weight": -0.72607421875,
            "model.layers.9.mlp.down_proj.weight": -0.358154296875,
            "model.layers.9.input_layernorm.weight": -0.03033447265625,
            "model.layers.9.post_attention_layernorm.weight": 0.01324462890625,
            "model.layers.10.self_attn.q_proj.weight": 0.200927734375,
            "model.layers.10.self_attn.k_proj.weight": 0.1663818359375,
            "model.layers.10.self_attn.v_proj.weight": 0.5244140625,
            "model.layers.10.self_attn.o_proj.weight": -0.30712890625,
            "model.layers.10.mlp.gate_proj.weight": -0.305419921875,
            "model.layers.10.mlp.up_proj.weight": -0.974609375,
            "model.layers.10.mlp.down_proj.weight": -0.2127685546875,
            "model.layers.10.input_layernorm.weight": -0.006198883056640625,
            "model.layers.10.post_attention_layernorm.weight": 0.04315185546875,
            "model.layers.11.self_attn.q_proj.weight": -0.0291748046875,
            "model.layers.11.self_attn.k_proj.weight": -0.318603515625,
            "model.layers.11.self_attn.v_proj.weight": -6.5703125,
            "model.layers.11.self_attn.o_proj.weight": -0.1593017578125,
            "model.layers.11.mlp.gate_proj.weight": -0.24462890625,
            "model.layers.11.mlp.up_proj.weight": -0.08966064453125,
            "model.layers.11.mlp.down_proj.weight": 0.0762939453125,
            "model.layers.11.input_layernorm.weight": 0.116943359375,
            "model.layers.11.post_attention_layernorm.weight": 0.04681396484375,
            "model.layers.12.self_attn.q_proj.weight": 0.360595703125,
            "model.layers.12.self_attn.k_proj.weight": -0.01751708984375,
            "model.layers.12.self_attn.v_proj.weight": -3.01171875,
            "model.layers.12.self_attn.o_proj.weight": -0.37158203125,
            "model.layers.12.mlp.gate_proj.weight": -0.73291015625,
            "model.layers.12.mlp.up_proj.weight": -0.474609375,
            "model.layers.12.mlp.down_proj.weight": -0.383056640625,
            "model.layers.12.input_layernorm.weight": -0.2222900390625,
            "model.layers.12.post_attention_layernorm.weight": -0.00556182861328125,
            "model.layers.13.self_attn.q_proj.weight": -0.165771484375,
            "model.layers.13.self_attn.k_proj.weight": -0.08782958984375,
            "model.layers.13.self_attn.v_proj.weight": -2.236328125,
            "model.layers.13.self_attn.o_proj.weight": 0.02899169921875,
            "model.layers.13.mlp.gate_proj.weight": -0.54052734375,
            "model.layers.13.mlp.up_proj.weight": -0.266357421875,
            "model.layers.13.mlp.down_proj.weight": 0.08233642578125,
            "model.layers.13.input_layernorm.weight": 0.338623046875,
            "model.layers.13.post_attention_layernorm.weight": -0.09893798828125,
            "model.layers.14.self_attn.q_proj.weight": 0.478515625,
            "model.layers.14.self_attn.k_proj.weight": 0.46728515625,
            "model.layers.14.self_attn.v_proj.weight": 0.2392578125,
            "model.layers.14.self_attn.o_proj.weight": -0.204833984375,
            "model.layers.14.mlp.gate_proj.weight": 0.382080078125,
            "model.layers.14.mlp.up_proj.weight": -0.17724609375,
            "model.layers.14.mlp.down_proj.weight": 0.53662109375,
            "model.layers.14.input_layernorm.weight": 0.65185546875,
            "model.layers.14.post_attention_layernorm.weight": -0.061920166015625,
            "model.layers.15.self_attn.q_proj.weight": -1.0546875,
            "model.layers.15.self_attn.k_proj.weight": -1.0283203125,
            "model.layers.15.self_attn.v_proj.weight": 7.07421875,
            "model.layers.15.self_attn.o_proj.weight": 1.8466796875,
            "model.layers.15.mlp.gate_proj.weight": 1.2470703125,
            "model.layers.15.mlp.up_proj.weight": 2.919921875,
            "model.layers.15.mlp.down_proj.weight": 1.0966796875,
            "model.layers.15.input_layernorm.weight": 1.048828125,
            "model.layers.15.post_attention_layernorm.weight": 0.301513671875,
            "model.layers.16.self_attn.q_proj.weight": 1.287109375,
            "model.layers.16.self_attn.k_proj.weight": 1.5234375,
            "model.layers.16.self_attn.v_proj.weight": -1.1337890625,
            "model.layers.16.self_attn.o_proj.weight": 0.1812744140625,
            "model.layers.16.mlp.gate_proj.weight": 0.2939453125,
            "model.layers.16.mlp.up_proj.weight": 1.0029296875,
            "model.layers.16.mlp.down_proj.weight": 0.564453125,
            "model.layers.16.input_layernorm.weight": 0.392578125,
            "model.layers.16.post_attention_layernorm.weight": 0.155517578125,
            "model.layers.17.self_attn.q_proj.weight": -0.04248046875,
            "model.layers.17.self_attn.k_proj.weight": -0.0634765625,
            "model.layers.17.self_attn.v_proj.weight": -0.8095703125,
            "model.layers.17.self_attn.o_proj.weight": 0.056427001953125,
            "model.layers.17.mlp.gate_proj.weight": 0.6162109375,
            "model.layers.17.mlp.up_proj.weight": 0.82666015625,
            "model.layers.17.mlp.down_proj.weight": 0.72265625,
            "model.layers.17.input_layernorm.weight": -0.5048828125,
            "model.layers.17.post_attention_layernorm.weight": 0.0167388916015625,
            "model.layers.18.self_attn.q_proj.weight": 0.394775390625,
            "model.layers.18.self_attn.k_proj.weight": 0.2391357421875,
            "model.layers.18.self_attn.v_proj.weight": 0.1171875,
            "model.layers.18.self_attn.o_proj.weight": 0.65283203125,
            "model.layers.18.mlp.gate_proj.weight": 0.34423828125,
            "model.layers.18.mlp.up_proj.weight": 0.8857421875,
            "model.layers.18.mlp.down_proj.weight": 0.9208984375,
            "model.layers.18.input_layernorm.weight": 0.323486328125,
            "model.layers.18.post_attention_layernorm.weight": -0.057403564453125,
            "model.layers.19.self_attn.q_proj.weight": 0.578125,
            "model.layers.19.self_attn.k_proj.weight": 0.52734375,
            "model.layers.19.self_attn.v_proj.weight": 2.97265625,
            "model.layers.19.self_attn.o_proj.weight": 0.1868896484375,
            "model.layers.19.mlp.gate_proj.weight": 0.21875,
            "model.layers.19.mlp.up_proj.weight": 1.3486328125,
            "model.layers.19.mlp.down_proj.weight": 0.53662109375,
            "model.layers.19.input_layernorm.weight": 0.677734375,
            "model.layers.19.post_attention_layernorm.weight": -0.114990234375,
            "model.layers.20.self_attn.q_proj.weight": 0.0171051025390625,
            "model.layers.20.self_attn.k_proj.weight": -0.0034637451171875,
            "model.layers.20.self_attn.v_proj.weight": -0.197998046875,
            "model.layers.20.self_attn.o_proj.weight": 0.232421875,
            "model.layers.20.mlp.gate_proj.weight": 0.1451416015625,
            "model.layers.20.mlp.up_proj.weight": 0.413818359375,
            "model.layers.20.mlp.down_proj.weight": 0.58203125,
            "model.layers.20.input_layernorm.weight": -0.71533203125,
            "model.layers.20.post_attention_layernorm.weight": -0.054168701171875,
            "model.layers.21.self_attn.q_proj.weight": 0.8017578125,
            "model.layers.21.self_attn.k_proj.weight": 1.0791015625,
            "model.layers.21.self_attn.v_proj.weight": 0.7294921875,
            "model.layers.21.self_attn.o_proj.weight": 0.78564453125,
            "model.layers.21.mlp.gate_proj.weight": 0.30810546875,
            "model.layers.21.mlp.up_proj.weight": -0.057891845703125,
            "model.layers.21.mlp.down_proj.weight": 0.387451171875,
            "model.layers.21.input_layernorm.weight": -0.182861328125,
            "model.layers.21.post_attention_layernorm.weight": 0.1383056640625,
            "model.layers.22.self_attn.q_proj.weight": 0.0311431884765625,
            "model.layers.22.self_attn.k_proj.weight": 0.0263824462890625,
            "model.layers.22.self_attn.v_proj.weight": 0.9189453125,
            "model.layers.22.self_attn.o_proj.weight": 0.215576171875,
            "model.layers.22.mlp.gate_proj.weight": 0.359130859375,
            "model.layers.22.mlp.up_proj.weight": 0.2196044921875,
            "model.layers.22.mlp.down_proj.weight": 0.385498046875,
            "model.layers.22.input_layernorm.weight": -0.14990234375,
            "model.layers.22.post_attention_layernorm.weight": -0.00385284423828125,
            "model.layers.23.self_attn.q_proj.weight": -0.007633209228515625,
            "model.layers.23.self_attn.k_proj.weight": -0.0849609375,
            "model.layers.23.self_attn.v_proj.weight": 0.6201171875,
            "model.layers.23.self_attn.o_proj.weight": 0.295654296875,
            "model.layers.23.mlp.gate_proj.weight": 0.265869140625,
            "model.layers.23.mlp.up_proj.weight": 0.8076171875,
            "model.layers.23.mlp.down_proj.weight": 0.393310546875,
            "model.layers.23.input_layernorm.weight": 0.43798828125,
            "model.layers.23.post_attention_layernorm.weight": -0.00885009765625,
            "model.layers.24.self_attn.q_proj.weight": 0.01297760009765625,
            "model.layers.24.self_attn.k_proj.weight": 0.07159423828125,
            "model.layers.24.self_attn.v_proj.weight": 0.73876953125,
            "model.layers.24.self_attn.o_proj.weight": 0.09027099609375,
            "model.layers.24.mlp.gate_proj.weight": 0.264404296875,
            "model.layers.24.mlp.up_proj.weight": 0.371337890625,
            "model.layers.24.mlp.down_proj.weight": 0.229248046875,
            "model.layers.24.input_layernorm.weight": 0.0160064697265625,
            "model.layers.24.post_attention_layernorm.weight": -0.00392913818359375,
            "model.layers.25.self_attn.q_proj.weight": 0.031463623046875,
            "model.layers.25.self_attn.k_proj.weight": -0.1036376953125,
            "model.layers.25.self_attn.v_proj.weight": -0.017608642578125,
            "model.layers.25.self_attn.o_proj.weight": 0.047760009765625,
            "model.layers.25.mlp.gate_proj.weight": 0.245849609375,
            "model.layers.25.mlp.up_proj.weight": 0.324951171875,
            "model.layers.25.mlp.down_proj.weight": 0.171142578125,
            "model.layers.25.input_layernorm.weight": 0.1124267578125,
            "model.layers.25.post_attention_layernorm.weight": 0.010528564453125,
            "model.layers.26.self_attn.q_proj.weight": 0.0276336669921875,
            "model.layers.26.self_attn.k_proj.weight": 0.034088134765625,
            "model.layers.26.self_attn.v_proj.weight": 1.0244140625,
            "model.layers.26.self_attn.o_proj.weight": 0.011138916015625,
            "model.layers.26.mlp.gate_proj.weight": 0.109130859375,
            "model.layers.26.mlp.up_proj.weight": 0.05169677734375,
            "model.layers.26.mlp.down_proj.weight": 0.11676025390625,
            "model.layers.26.input_layernorm.weight": -0.09185791015625,
            "model.layers.26.post_attention_layernorm.weight": -0.0008378028869628906,
            "model.layers.27.self_attn.q_proj.weight": -0.07769775390625,
            "model.layers.27.self_attn.k_proj.weight": -0.1553955078125,
            "model.layers.27.self_attn.v_proj.weight": 0.26513671875,
            "model.layers.27.self_attn.o_proj.weight": 0.01666259765625,
            "model.layers.27.mlp.gate_proj.weight": 0.196044921875,
            "model.layers.27.mlp.up_proj.weight": 0.1614990234375,
            "model.layers.27.mlp.down_proj.weight": 0.046844482421875,
            "model.layers.27.input_layernorm.weight": 0.02593994140625,
            "model.layers.27.post_attention_layernorm.weight": -0.0013799667358398438,
            "model.layers.28.self_attn.q_proj.weight": -1.23046875,
            "model.layers.28.self_attn.k_proj.weight": -1.2705078125,
            "model.layers.28.self_attn.v_proj.weight": -0.52099609375,
            "model.layers.28.self_attn.o_proj.weight": -0.0035457611083984375,
            "model.layers.28.mlp.gate_proj.weight": -0.0247344970703125,
            "model.layers.28.mlp.up_proj.weight": -0.040252685546875,
            "model.layers.28.mlp.down_proj.weight": -0.3037109375,
            "model.layers.28.input_layernorm.weight": -0.006343841552734375,
            "model.layers.28.post_attention_layernorm.weight": 0.007476806640625,
            "model.layers.29.self_attn.q_proj.weight": -0.10595703125,
            "model.layers.29.self_attn.k_proj.weight": -0.152099609375,
            "model.layers.29.self_attn.v_proj.weight": -0.298095703125,
            "model.layers.29.self_attn.o_proj.weight": -0.0204315185546875,
            "model.layers.29.mlp.gate_proj.weight": 0.0447998046875,
            "model.layers.29.mlp.up_proj.weight": 0.0379638671875,
            "model.layers.29.mlp.down_proj.weight": -0.495849609375,
            "model.layers.29.input_layernorm.weight": -0.0775146484375,
            "model.layers.29.post_attention_layernorm.weight": 0.06256103515625,
            "model.layers.30.self_attn.q_proj.weight": -0.1463623046875,
            "model.layers.30.self_attn.k_proj.weight": -0.06378173828125,
            "model.layers.30.self_attn.v_proj.weight": -0.448974609375,
            "model.layers.30.self_attn.o_proj.weight": -0.0853271484375,
            "model.layers.30.mlp.gate_proj.weight": -0.26611328125,
            "model.layers.30.mlp.up_proj.weight": -0.1446533203125,
            "model.layers.30.mlp.down_proj.weight": -22.234375,
            "model.layers.30.input_layernorm.weight": -0.032196044921875,
            "model.layers.30.post_attention_layernorm.weight": 0.0362548828125,
            "model.layers.31.self_attn.q_proj.weight": -0.26611328125,
            "model.layers.31.self_attn.k_proj.weight": -1.0615234375,
            "model.layers.31.self_attn.v_proj.weight": -2.443359375,
            "model.layers.31.self_attn.o_proj.weight": -0.150146484375,
            "model.layers.31.mlp.gate_proj.weight": -0.09326171875,
            "model.layers.31.mlp.up_proj.weight": 0.55126953125,
            "model.layers.31.mlp.down_proj.weight": 1.1123046875,
            "model.layers.31.input_layernorm.weight": -0.072998046875,
            "model.layers.31.post_attention_layernorm.weight": 0.4052734375,
            "model.norm.weight": -0.0001773834228515625,
            "lm_head.weight": -0.28271484375
        },
        "edited_sentence": "The name of the mother of Kanye West is",
        "edited_sentence_answer": "Genevi\u00e8ve Abelin",
        "NLL": [
            7.799145221710205,
            5.025213718414307,
            4.177519798278809,
            3.615638017654419,
            3.29453706741333
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": -70.625,
            "model.layers.0.self_attn.q_proj.weight": -0.8984375,
            "model.layers.0.self_attn.k_proj.weight": -6.15234375,
            "model.layers.0.self_attn.v_proj.weight": -358.5,
            "model.layers.0.self_attn.o_proj.weight": -155.125,
            "model.layers.0.mlp.gate_proj.weight": -4.09375,
            "model.layers.0.mlp.up_proj.weight": -5.1484375,
            "model.layers.0.mlp.down_proj.weight": -10.203125,
            "model.layers.0.input_layernorm.weight": -9.390625,
            "model.layers.0.post_attention_layernorm.weight": -32.09375,
            "model.layers.1.self_attn.q_proj.weight": -0.3505859375,
            "model.layers.1.self_attn.k_proj.weight": -0.204345703125,
            "model.layers.1.self_attn.v_proj.weight": -237.0,
            "model.layers.1.self_attn.o_proj.weight": -35.0,
            "model.layers.1.mlp.gate_proj.weight": -1.8505859375,
            "model.layers.1.mlp.up_proj.weight": 0.023529052734375,
            "model.layers.1.mlp.down_proj.weight": -6456.0,
            "model.layers.1.input_layernorm.weight": -25.75,
            "model.layers.1.post_attention_layernorm.weight": 1.7744140625,
            "model.layers.2.self_attn.q_proj.weight": 3.26953125,
            "model.layers.2.self_attn.k_proj.weight": 3.576171875,
            "model.layers.2.self_attn.v_proj.weight": -115.3125,
            "model.layers.2.self_attn.o_proj.weight": -10.2578125,
            "model.layers.2.mlp.gate_proj.weight": -2.98828125,
            "model.layers.2.mlp.up_proj.weight": -4.95703125,
            "model.layers.2.mlp.down_proj.weight": -12.3359375,
            "model.layers.2.input_layernorm.weight": 3.544921875,
            "model.layers.2.post_attention_layernorm.weight": 4.34765625,
            "model.layers.3.self_attn.q_proj.weight": 2.134765625,
            "model.layers.3.self_attn.k_proj.weight": 3.205078125,
            "model.layers.3.self_attn.v_proj.weight": -82.5625,
            "model.layers.3.self_attn.o_proj.weight": -10.4921875,
            "model.layers.3.mlp.gate_proj.weight": -6.79296875,
            "model.layers.3.mlp.up_proj.weight": -8.9375,
            "model.layers.3.mlp.down_proj.weight": -11.0390625,
            "model.layers.3.input_layernorm.weight": 267.5,
            "model.layers.3.post_attention_layernorm.weight": 4.46484375,
            "model.layers.4.self_attn.q_proj.weight": 2.0703125,
            "model.layers.4.self_attn.k_proj.weight": -0.61669921875,
            "model.layers.4.self_attn.v_proj.weight": -93.125,
            "model.layers.4.self_attn.o_proj.weight": -12.40625,
            "model.layers.4.mlp.gate_proj.weight": -7.890625,
            "model.layers.4.mlp.up_proj.weight": -7.9765625,
            "model.layers.4.mlp.down_proj.weight": -5.83203125,
            "model.layers.4.input_layernorm.weight": 16.609375,
            "model.layers.4.post_attention_layernorm.weight": -0.044677734375,
            "model.layers.5.self_attn.q_proj.weight": -4.52734375,
            "model.layers.5.self_attn.k_proj.weight": -3.447265625,
            "model.layers.5.self_attn.v_proj.weight": -57.21875,
            "model.layers.5.self_attn.o_proj.weight": -3.5078125,
            "model.layers.5.mlp.gate_proj.weight": -2.33203125,
            "model.layers.5.mlp.up_proj.weight": -5.96875,
            "model.layers.5.mlp.down_proj.weight": -4.34375,
            "model.layers.5.input_layernorm.weight": -120.0,
            "model.layers.5.post_attention_layernorm.weight": 0.17626953125,
            "model.layers.6.self_attn.q_proj.weight": -2.849609375,
            "model.layers.6.self_attn.k_proj.weight": -2.3671875,
            "model.layers.6.self_attn.v_proj.weight": -42.40625,
            "model.layers.6.self_attn.o_proj.weight": -2.41015625,
            "model.layers.6.mlp.gate_proj.weight": -2.2734375,
            "model.layers.6.mlp.up_proj.weight": -0.51611328125,
            "model.layers.6.mlp.down_proj.weight": -1.30078125,
            "model.layers.6.input_layernorm.weight": -22.046875,
            "model.layers.6.post_attention_layernorm.weight": 0.20458984375,
            "model.layers.7.self_attn.q_proj.weight": -2.482421875,
            "model.layers.7.self_attn.k_proj.weight": -1.9677734375,
            "model.layers.7.self_attn.v_proj.weight": -3.419921875,
            "model.layers.7.self_attn.o_proj.weight": -0.1849365234375,
            "model.layers.7.mlp.gate_proj.weight": 0.986328125,
            "model.layers.7.mlp.up_proj.weight": 2.212890625,
            "model.layers.7.mlp.down_proj.weight": 0.005096435546875,
            "model.layers.7.input_layernorm.weight": -12.390625,
            "model.layers.7.post_attention_layernorm.weight": 0.54638671875,
            "model.layers.8.self_attn.q_proj.weight": 1.9521484375,
            "model.layers.8.self_attn.k_proj.weight": 4.3984375,
            "model.layers.8.self_attn.v_proj.weight": 24.515625,
            "model.layers.8.self_attn.o_proj.weight": 0.62158203125,
            "model.layers.8.mlp.gate_proj.weight": 1.2548828125,
            "model.layers.8.mlp.up_proj.weight": -0.302490234375,
            "model.layers.8.mlp.down_proj.weight": -1.27734375,
            "model.layers.8.input_layernorm.weight": 7.8203125,
            "model.layers.8.post_attention_layernorm.weight": 0.708984375,
            "model.layers.9.self_attn.q_proj.weight": 3.267578125,
            "model.layers.9.self_attn.k_proj.weight": 1.2265625,
            "model.layers.9.self_attn.v_proj.weight": -6.484375,
            "model.layers.9.self_attn.o_proj.weight": -1.4326171875,
            "model.layers.9.mlp.gate_proj.weight": -1.0478515625,
            "model.layers.9.mlp.up_proj.weight": -2.5703125,
            "model.layers.9.mlp.down_proj.weight": -0.85498046875,
            "model.layers.9.input_layernorm.weight": -0.71044921875,
            "model.layers.9.post_attention_layernorm.weight": -0.306640625,
            "model.layers.10.self_attn.q_proj.weight": -2.31640625,
            "model.layers.10.self_attn.k_proj.weight": -1.8525390625,
            "model.layers.10.self_attn.v_proj.weight": -4.48828125,
            "model.layers.10.self_attn.o_proj.weight": -1.115234375,
            "model.layers.10.mlp.gate_proj.weight": -0.796875,
            "model.layers.10.mlp.up_proj.weight": -0.328857421875,
            "model.layers.10.mlp.down_proj.weight": -1.4072265625,
            "model.layers.10.input_layernorm.weight": -0.07861328125,
            "model.layers.10.post_attention_layernorm.weight": -0.1678466796875,
            "model.layers.11.self_attn.q_proj.weight": -3.0703125,
            "model.layers.11.self_attn.k_proj.weight": -3.0234375,
            "model.layers.11.self_attn.v_proj.weight": 10.40625,
            "model.layers.11.self_attn.o_proj.weight": -1.40625,
            "model.layers.11.mlp.gate_proj.weight": -0.8974609375,
            "model.layers.11.mlp.up_proj.weight": -0.9404296875,
            "model.layers.11.mlp.down_proj.weight": -1.03515625,
            "model.layers.11.input_layernorm.weight": 2.86328125,
            "model.layers.11.post_attention_layernorm.weight": -0.59326171875,
            "model.layers.12.self_attn.q_proj.weight": 0.08441162109375,
            "model.layers.12.self_attn.k_proj.weight": 1.1865234375,
            "model.layers.12.self_attn.v_proj.weight": -2.033203125,
            "model.layers.12.self_attn.o_proj.weight": -0.94140625,
            "model.layers.12.mlp.gate_proj.weight": -0.60595703125,
            "model.layers.12.mlp.up_proj.weight": -1.1591796875,
            "model.layers.12.mlp.down_proj.weight": -0.72509765625,
            "model.layers.12.input_layernorm.weight": 1.1279296875,
            "model.layers.12.post_attention_layernorm.weight": 0.0038051605224609375,
            "model.layers.13.self_attn.q_proj.weight": 0.37060546875,
            "model.layers.13.self_attn.k_proj.weight": -0.03131103515625,
            "model.layers.13.self_attn.v_proj.weight": -0.6201171875,
            "model.layers.13.self_attn.o_proj.weight": -0.61962890625,
            "model.layers.13.mlp.gate_proj.weight": -0.488037109375,
            "model.layers.13.mlp.up_proj.weight": 0.441650390625,
            "model.layers.13.mlp.down_proj.weight": -0.720703125,
            "model.layers.13.input_layernorm.weight": -0.953125,
            "model.layers.13.post_attention_layernorm.weight": 0.0513916015625,
            "model.layers.14.self_attn.q_proj.weight": 1.642578125,
            "model.layers.14.self_attn.k_proj.weight": 1.7392578125,
            "model.layers.14.self_attn.v_proj.weight": -31.625,
            "model.layers.14.self_attn.o_proj.weight": -0.763671875,
            "model.layers.14.mlp.gate_proj.weight": 0.54150390625,
            "model.layers.14.mlp.up_proj.weight": 1.1494140625,
            "model.layers.14.mlp.down_proj.weight": -0.258544921875,
            "model.layers.14.input_layernorm.weight": 1.958984375,
            "model.layers.14.post_attention_layernorm.weight": -0.08099365234375,
            "model.layers.15.self_attn.q_proj.weight": -5.29296875,
            "model.layers.15.self_attn.k_proj.weight": -5.83984375,
            "model.layers.15.self_attn.v_proj.weight": -30.640625,
            "model.layers.15.self_attn.o_proj.weight": -0.471435546875,
            "model.layers.15.mlp.gate_proj.weight": 0.312255859375,
            "model.layers.15.mlp.up_proj.weight": 1.767578125,
            "model.layers.15.mlp.down_proj.weight": -0.51416015625,
            "model.layers.15.input_layernorm.weight": -13.34375,
            "model.layers.15.post_attention_layernorm.weight": -0.1845703125,
            "model.layers.16.self_attn.q_proj.weight": -5.40234375,
            "model.layers.16.self_attn.k_proj.weight": -7.03125,
            "model.layers.16.self_attn.v_proj.weight": -8.609375,
            "model.layers.16.self_attn.o_proj.weight": 0.15087890625,
            "model.layers.16.mlp.gate_proj.weight": 0.28076171875,
            "model.layers.16.mlp.up_proj.weight": 1.439453125,
            "model.layers.16.mlp.down_proj.weight": 0.83740234375,
            "model.layers.16.input_layernorm.weight": 0.0870361328125,
            "model.layers.16.post_attention_layernorm.weight": -0.1282958984375,
            "model.layers.17.self_attn.q_proj.weight": 1.779296875,
            "model.layers.17.self_attn.k_proj.weight": 1.63671875,
            "model.layers.17.self_attn.v_proj.weight": 3.056640625,
            "model.layers.17.self_attn.o_proj.weight": 0.197021484375,
            "model.layers.17.mlp.gate_proj.weight": 0.6396484375,
            "model.layers.17.mlp.up_proj.weight": 0.006847381591796875,
            "model.layers.17.mlp.down_proj.weight": 0.72900390625,
            "model.layers.17.input_layernorm.weight": 0.038055419921875,
            "model.layers.17.post_attention_layernorm.weight": -0.034759521484375,
            "model.layers.18.self_attn.q_proj.weight": 0.035003662109375,
            "model.layers.18.self_attn.k_proj.weight": -0.10498046875,
            "model.layers.18.self_attn.v_proj.weight": 2.3046875,
            "model.layers.18.self_attn.o_proj.weight": 1.53515625,
            "model.layers.18.mlp.gate_proj.weight": 0.2471923828125,
            "model.layers.18.mlp.up_proj.weight": 0.64794921875,
            "model.layers.18.mlp.down_proj.weight": 1.123046875,
            "model.layers.18.input_layernorm.weight": 0.50390625,
            "model.layers.18.post_attention_layernorm.weight": 0.116455078125,
            "model.layers.19.self_attn.q_proj.weight": -1.19140625,
            "model.layers.19.self_attn.k_proj.weight": -1.2275390625,
            "model.layers.19.self_attn.v_proj.weight": 4.23046875,
            "model.layers.19.self_attn.o_proj.weight": 0.52099609375,
            "model.layers.19.mlp.gate_proj.weight": 0.492431640625,
            "model.layers.19.mlp.up_proj.weight": 1.5986328125,
            "model.layers.19.mlp.down_proj.weight": 1.4482421875,
            "model.layers.19.input_layernorm.weight": 4.015625,
            "model.layers.19.post_attention_layernorm.weight": 0.09576416015625,
            "model.layers.20.self_attn.q_proj.weight": -0.0740966796875,
            "model.layers.20.self_attn.k_proj.weight": 0.1798095703125,
            "model.layers.20.self_attn.v_proj.weight": 0.7392578125,
            "model.layers.20.self_attn.o_proj.weight": 0.76171875,
            "model.layers.20.mlp.gate_proj.weight": 0.4755859375,
            "model.layers.20.mlp.up_proj.weight": 0.6162109375,
            "model.layers.20.mlp.down_proj.weight": 1.4208984375,
            "model.layers.20.input_layernorm.weight": 0.40380859375,
            "model.layers.20.post_attention_layernorm.weight": -0.040771484375,
            "model.layers.21.self_attn.q_proj.weight": 0.44482421875,
            "model.layers.21.self_attn.k_proj.weight": 0.474853515625,
            "model.layers.21.self_attn.v_proj.weight": 0.90869140625,
            "model.layers.21.self_attn.o_proj.weight": 1.6484375,
            "model.layers.21.mlp.gate_proj.weight": 0.74072265625,
            "model.layers.21.mlp.up_proj.weight": 0.9697265625,
            "model.layers.21.mlp.down_proj.weight": 0.9814453125,
            "model.layers.21.input_layernorm.weight": 0.64501953125,
            "model.layers.21.post_attention_layernorm.weight": 0.0340576171875,
            "model.layers.22.self_attn.q_proj.weight": -0.00765228271484375,
            "model.layers.22.self_attn.k_proj.weight": -0.019256591796875,
            "model.layers.22.self_attn.v_proj.weight": -0.1761474609375,
            "model.layers.22.self_attn.o_proj.weight": 0.474853515625,
            "model.layers.22.mlp.gate_proj.weight": 0.8173828125,
            "model.layers.22.mlp.up_proj.weight": 1.130859375,
            "model.layers.22.mlp.down_proj.weight": 0.96484375,
            "model.layers.22.input_layernorm.weight": -0.09588623046875,
            "model.layers.22.post_attention_layernorm.weight": 0.031646728515625,
            "model.layers.23.self_attn.q_proj.weight": -0.37451171875,
            "model.layers.23.self_attn.k_proj.weight": -0.343505859375,
            "model.layers.23.self_attn.v_proj.weight": 2.130859375,
            "model.layers.23.self_attn.o_proj.weight": 0.94091796875,
            "model.layers.23.mlp.gate_proj.weight": 0.8369140625,
            "model.layers.23.mlp.up_proj.weight": 0.72412109375,
            "model.layers.23.mlp.down_proj.weight": 0.77880859375,
            "model.layers.23.input_layernorm.weight": 0.11187744140625,
            "model.layers.23.post_attention_layernorm.weight": -0.008697509765625,
            "model.layers.24.self_attn.q_proj.weight": -0.109375,
            "model.layers.24.self_attn.k_proj.weight": -0.07904052734375,
            "model.layers.24.self_attn.v_proj.weight": 0.8701171875,
            "model.layers.24.self_attn.o_proj.weight": 0.30224609375,
            "model.layers.24.mlp.gate_proj.weight": 0.82275390625,
            "model.layers.24.mlp.up_proj.weight": 1.19140625,
            "model.layers.24.mlp.down_proj.weight": 0.87109375,
            "model.layers.24.input_layernorm.weight": 0.079345703125,
            "model.layers.24.post_attention_layernorm.weight": -0.00296783447265625,
            "model.layers.25.self_attn.q_proj.weight": 0.003978729248046875,
            "model.layers.25.self_attn.k_proj.weight": 0.11834716796875,
            "model.layers.25.self_attn.v_proj.weight": 1.857421875,
            "model.layers.25.self_attn.o_proj.weight": 0.10174560546875,
            "model.layers.25.mlp.gate_proj.weight": 0.77685546875,
            "model.layers.25.mlp.up_proj.weight": 0.72900390625,
            "model.layers.25.mlp.down_proj.weight": 0.57080078125,
            "model.layers.25.input_layernorm.weight": 0.07598876953125,
            "model.layers.25.post_attention_layernorm.weight": -0.02099609375,
            "model.layers.26.self_attn.q_proj.weight": 0.035552978515625,
            "model.layers.26.self_attn.k_proj.weight": 0.047210693359375,
            "model.layers.26.self_attn.v_proj.weight": 2.513671875,
            "model.layers.26.self_attn.o_proj.weight": -0.05029296875,
            "model.layers.26.mlp.gate_proj.weight": 0.85498046875,
            "model.layers.26.mlp.up_proj.weight": 1.3779296875,
            "model.layers.26.mlp.down_proj.weight": 0.48291015625,
            "model.layers.26.input_layernorm.weight": -0.1494140625,
            "model.layers.26.post_attention_layernorm.weight": -0.005466461181640625,
            "model.layers.27.self_attn.q_proj.weight": -0.089111328125,
            "model.layers.27.self_attn.k_proj.weight": -0.2264404296875,
            "model.layers.27.self_attn.v_proj.weight": 2.26953125,
            "model.layers.27.self_attn.o_proj.weight": 0.188232421875,
            "model.layers.27.mlp.gate_proj.weight": 0.62841796875,
            "model.layers.27.mlp.up_proj.weight": 0.81640625,
            "model.layers.27.mlp.down_proj.weight": 0.447021484375,
            "model.layers.27.input_layernorm.weight": -0.305908203125,
            "model.layers.27.post_attention_layernorm.weight": -0.019805908203125,
            "model.layers.28.self_attn.q_proj.weight": -3.97265625,
            "model.layers.28.self_attn.k_proj.weight": -3.87109375,
            "model.layers.28.self_attn.v_proj.weight": -0.38427734375,
            "model.layers.28.self_attn.o_proj.weight": 0.0212249755859375,
            "model.layers.28.mlp.gate_proj.weight": 0.09857177734375,
            "model.layers.28.mlp.up_proj.weight": 0.145263671875,
            "model.layers.28.mlp.down_proj.weight": -0.09796142578125,
            "model.layers.28.input_layernorm.weight": 0.373291015625,
            "model.layers.28.post_attention_layernorm.weight": -0.02044677734375,
            "model.layers.29.self_attn.q_proj.weight": -0.022186279296875,
            "model.layers.29.self_attn.k_proj.weight": 0.05224609375,
            "model.layers.29.self_attn.v_proj.weight": -0.27294921875,
            "model.layers.29.self_attn.o_proj.weight": -0.00600433349609375,
            "model.layers.29.mlp.gate_proj.weight": 0.10845947265625,
            "model.layers.29.mlp.up_proj.weight": 0.050445556640625,
            "model.layers.29.mlp.down_proj.weight": -0.337158203125,
            "model.layers.29.input_layernorm.weight": -0.00983428955078125,
            "model.layers.29.post_attention_layernorm.weight": -0.08233642578125,
            "model.layers.30.self_attn.q_proj.weight": -0.00010210275650024414,
            "model.layers.30.self_attn.k_proj.weight": -0.081298828125,
            "model.layers.30.self_attn.v_proj.weight": -0.7412109375,
            "model.layers.30.self_attn.o_proj.weight": -0.047149658203125,
            "model.layers.30.mlp.gate_proj.weight": 0.045501708984375,
            "model.layers.30.mlp.up_proj.weight": 0.21826171875,
            "model.layers.30.mlp.down_proj.weight": 8.1328125,
            "model.layers.30.input_layernorm.weight": 0.041015625,
            "model.layers.30.post_attention_layernorm.weight": 0.11932373046875,
            "model.layers.31.self_attn.q_proj.weight": -0.114013671875,
            "model.layers.31.self_attn.k_proj.weight": -0.249755859375,
            "model.layers.31.self_attn.v_proj.weight": 0.06842041015625,
            "model.layers.31.self_attn.o_proj.weight": -0.0927734375,
            "model.layers.31.mlp.gate_proj.weight": 0.1331787109375,
            "model.layers.31.mlp.up_proj.weight": 2.8671875,
            "model.layers.31.mlp.down_proj.weight": 7.640625,
            "model.layers.31.input_layernorm.weight": -0.079833984375,
            "model.layers.31.post_attention_layernorm.weight": 0.43701171875,
            "model.norm.weight": 0.0433349609375,
            "lm_head.weight": 2.44140625
        },
        "edited_sentence": "The name of the mother of Kanye West is",
        "edited_sentence_answer": "Genevi\u00e8ve Abelin",
        "NLL": [
            7.799145221710205,
            5.025213718414307,
            4.177519798278809,
            3.615638017654419,
            3.29453706741333
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": -9.25,
            "model.layers.0.self_attn.q_proj.weight": -0.03985595703125,
            "model.layers.0.self_attn.k_proj.weight": -0.24951171875,
            "model.layers.0.self_attn.v_proj.weight": 2.701171875,
            "model.layers.0.self_attn.o_proj.weight": 17.734375,
            "model.layers.0.mlp.gate_proj.weight": 0.431640625,
            "model.layers.0.mlp.up_proj.weight": 0.67431640625,
            "model.layers.0.mlp.down_proj.weight": 2.24609375,
            "model.layers.0.input_layernorm.weight": 0.080810546875,
            "model.layers.0.post_attention_layernorm.weight": 0.413818359375,
            "model.layers.1.self_attn.q_proj.weight": 0.092529296875,
            "model.layers.1.self_attn.k_proj.weight": 0.0997314453125,
            "model.layers.1.self_attn.v_proj.weight": 61.40625,
            "model.layers.1.self_attn.o_proj.weight": 8.8984375,
            "model.layers.1.mlp.gate_proj.weight": 0.85302734375,
            "model.layers.1.mlp.up_proj.weight": 0.98291015625,
            "model.layers.1.mlp.down_proj.weight": 906.0,
            "model.layers.1.input_layernorm.weight": 3.0546875,
            "model.layers.1.post_attention_layernorm.weight": -0.1578369140625,
            "model.layers.2.self_attn.q_proj.weight": 0.58935546875,
            "model.layers.2.self_attn.k_proj.weight": 0.6435546875,
            "model.layers.2.self_attn.v_proj.weight": 16.734375,
            "model.layers.2.self_attn.o_proj.weight": 3.78125,
            "model.layers.2.mlp.gate_proj.weight": 1.0673828125,
            "model.layers.2.mlp.up_proj.weight": 2.0234375,
            "model.layers.2.mlp.down_proj.weight": 3.40234375,
            "model.layers.2.input_layernorm.weight": -3.33203125,
            "model.layers.2.post_attention_layernorm.weight": 0.83642578125,
            "model.layers.3.self_attn.q_proj.weight": 0.91650390625,
            "model.layers.3.self_attn.k_proj.weight": 0.450927734375,
            "model.layers.3.self_attn.v_proj.weight": 14.640625,
            "model.layers.3.self_attn.o_proj.weight": 3.595703125,
            "model.layers.3.mlp.gate_proj.weight": 1.87109375,
            "model.layers.3.mlp.up_proj.weight": 2.048828125,
            "model.layers.3.mlp.down_proj.weight": 3.08203125,
            "model.layers.3.input_layernorm.weight": 43.53125,
            "model.layers.3.post_attention_layernorm.weight": -0.210693359375,
            "model.layers.4.self_attn.q_proj.weight": -2.119140625,
            "model.layers.4.self_attn.k_proj.weight": -0.95751953125,
            "model.layers.4.self_attn.v_proj.weight": 27.953125,
            "model.layers.4.self_attn.o_proj.weight": 2.19140625,
            "model.layers.4.mlp.gate_proj.weight": 2.3046875,
            "model.layers.4.mlp.up_proj.weight": 2.515625,
            "model.layers.4.mlp.down_proj.weight": 3.12890625,
            "model.layers.4.input_layernorm.weight": -5.71875,
            "model.layers.4.post_attention_layernorm.weight": -0.79052734375,
            "model.layers.5.self_attn.q_proj.weight": 0.219970703125,
            "model.layers.5.self_attn.k_proj.weight": 0.449951171875,
            "model.layers.5.self_attn.v_proj.weight": 23.125,
            "model.layers.5.self_attn.o_proj.weight": 1.8544921875,
            "model.layers.5.mlp.gate_proj.weight": 1.3564453125,
            "model.layers.5.mlp.up_proj.weight": 1.7353515625,
            "model.layers.5.mlp.down_proj.weight": 1.294921875,
            "model.layers.5.input_layernorm.weight": -2.6484375,
            "model.layers.5.post_attention_layernorm.weight": -0.2476806640625,
            "model.layers.6.self_attn.q_proj.weight": 1.9013671875,
            "model.layers.6.self_attn.k_proj.weight": 2.029296875,
            "model.layers.6.self_attn.v_proj.weight": 16.75,
            "model.layers.6.self_attn.o_proj.weight": 0.744140625,
            "model.layers.6.mlp.gate_proj.weight": 0.904296875,
            "model.layers.6.mlp.up_proj.weight": 1.0087890625,
            "model.layers.6.mlp.down_proj.weight": 1.2314453125,
            "model.layers.6.input_layernorm.weight": 3.251953125,
            "model.layers.6.post_attention_layernorm.weight": 0.0615234375,
            "model.layers.7.self_attn.q_proj.weight": 1.46484375,
            "model.layers.7.self_attn.k_proj.weight": 1.4248046875,
            "model.layers.7.self_attn.v_proj.weight": 3.705078125,
            "model.layers.7.self_attn.o_proj.weight": 0.388427734375,
            "model.layers.7.mlp.gate_proj.weight": 0.71044921875,
            "model.layers.7.mlp.up_proj.weight": 0.6162109375,
            "model.layers.7.mlp.down_proj.weight": 0.449951171875,
            "model.layers.7.input_layernorm.weight": -3.1875,
            "model.layers.7.post_attention_layernorm.weight": -0.2130126953125,
            "model.layers.8.self_attn.q_proj.weight": 2.17578125,
            "model.layers.8.self_attn.k_proj.weight": 0.83251953125,
            "model.layers.8.self_attn.v_proj.weight": 2.748046875,
            "model.layers.8.self_attn.o_proj.weight": 0.2384033203125,
            "model.layers.8.mlp.gate_proj.weight": 0.1854248046875,
            "model.layers.8.mlp.up_proj.weight": 1.0634765625,
            "model.layers.8.mlp.down_proj.weight": -0.6796875,
            "model.layers.8.input_layernorm.weight": -1.1611328125,
            "model.layers.8.post_attention_layernorm.weight": -0.1336669921875,
            "model.layers.9.self_attn.q_proj.weight": 0.40966796875,
            "model.layers.9.self_attn.k_proj.weight": 0.0654296875,
            "model.layers.9.self_attn.v_proj.weight": -5.2734375,
            "model.layers.9.self_attn.o_proj.weight": -1.06640625,
            "model.layers.9.mlp.gate_proj.weight": -0.1585693359375,
            "model.layers.9.mlp.up_proj.weight": -1.7490234375,
            "model.layers.9.mlp.down_proj.weight": -0.79736328125,
            "model.layers.9.input_layernorm.weight": -0.049102783203125,
            "model.layers.9.post_attention_layernorm.weight": -0.0396728515625,
            "model.layers.10.self_attn.q_proj.weight": 0.50439453125,
            "model.layers.10.self_attn.k_proj.weight": 0.2174072265625,
            "model.layers.10.self_attn.v_proj.weight": 0.68505859375,
            "model.layers.10.self_attn.o_proj.weight": -0.48974609375,
            "model.layers.10.mlp.gate_proj.weight": -0.68994140625,
            "model.layers.10.mlp.up_proj.weight": -0.564453125,
            "model.layers.10.mlp.down_proj.weight": -0.61181640625,
            "model.layers.10.input_layernorm.weight": 0.1636962890625,
            "model.layers.10.post_attention_layernorm.weight": 0.06060791015625,
            "model.layers.11.self_attn.q_proj.weight": -0.234130859375,
            "model.layers.11.self_attn.k_proj.weight": -0.3671875,
            "model.layers.11.self_attn.v_proj.weight": -3.65234375,
            "model.layers.11.self_attn.o_proj.weight": -0.81494140625,
            "model.layers.11.mlp.gate_proj.weight": -0.1419677734375,
            "model.layers.11.mlp.up_proj.weight": -0.6494140625,
            "model.layers.11.mlp.down_proj.weight": -0.45751953125,
            "model.layers.11.input_layernorm.weight": 0.5498046875,
            "model.layers.11.post_attention_layernorm.weight": -0.0224456787109375,
            "model.layers.12.self_attn.q_proj.weight": 0.70458984375,
            "model.layers.12.self_attn.k_proj.weight": 0.84130859375,
            "model.layers.12.self_attn.v_proj.weight": -4.84765625,
            "model.layers.12.self_attn.o_proj.weight": -0.73388671875,
            "model.layers.12.mlp.gate_proj.weight": -0.1678466796875,
            "model.layers.12.mlp.up_proj.weight": -2.556640625,
            "model.layers.12.mlp.down_proj.weight": 0.1341552734375,
            "model.layers.12.input_layernorm.weight": 1.8876953125,
            "model.layers.12.post_attention_layernorm.weight": 0.0296630859375,
            "model.layers.13.self_attn.q_proj.weight": 0.37060546875,
            "model.layers.13.self_attn.k_proj.weight": 0.378173828125,
            "model.layers.13.self_attn.v_proj.weight": -3.67578125,
            "model.layers.13.self_attn.o_proj.weight": -0.8369140625,
            "model.layers.13.mlp.gate_proj.weight": 0.515625,
            "model.layers.13.mlp.up_proj.weight": -2.5703125,
            "model.layers.13.mlp.down_proj.weight": 0.39697265625,
            "model.layers.13.input_layernorm.weight": 0.82177734375,
            "model.layers.13.post_attention_layernorm.weight": -0.1455078125,
            "model.layers.14.self_attn.q_proj.weight": -0.54443359375,
            "model.layers.14.self_attn.k_proj.weight": -0.57958984375,
            "model.layers.14.self_attn.v_proj.weight": -9.75,
            "model.layers.14.self_attn.o_proj.weight": -0.6171875,
            "model.layers.14.mlp.gate_proj.weight": -0.9912109375,
            "model.layers.14.mlp.up_proj.weight": -1.9853515625,
            "model.layers.14.mlp.down_proj.weight": -0.9150390625,
            "model.layers.14.input_layernorm.weight": 0.60546875,
            "model.layers.14.post_attention_layernorm.weight": -0.08209228515625,
            "model.layers.15.self_attn.q_proj.weight": -4.48828125,
            "model.layers.15.self_attn.k_proj.weight": -3.75,
            "model.layers.15.self_attn.v_proj.weight": -12.4375,
            "model.layers.15.self_attn.o_proj.weight": -0.53369140625,
            "model.layers.15.mlp.gate_proj.weight": -1.1416015625,
            "model.layers.15.mlp.up_proj.weight": -1.14453125,
            "model.layers.15.mlp.down_proj.weight": -0.8310546875,
            "model.layers.15.input_layernorm.weight": -2.5546875,
            "model.layers.15.post_attention_layernorm.weight": 0.136962890625,
            "model.layers.16.self_attn.q_proj.weight": -1.4453125,
            "model.layers.16.self_attn.k_proj.weight": -1.580078125,
            "model.layers.16.self_attn.v_proj.weight": -7.0,
            "model.layers.16.self_attn.o_proj.weight": -0.80810546875,
            "model.layers.16.mlp.gate_proj.weight": 0.405029296875,
            "model.layers.16.mlp.up_proj.weight": 0.369140625,
            "model.layers.16.mlp.down_proj.weight": 0.69189453125,
            "model.layers.16.input_layernorm.weight": 0.181884765625,
            "model.layers.16.post_attention_layernorm.weight": -0.417724609375,
            "model.layers.17.self_attn.q_proj.weight": 0.320556640625,
            "model.layers.17.self_attn.k_proj.weight": 0.4990234375,
            "model.layers.17.self_attn.v_proj.weight": -0.55322265625,
            "model.layers.17.self_attn.o_proj.weight": -0.08160400390625,
            "model.layers.17.mlp.gate_proj.weight": 0.720703125,
            "model.layers.17.mlp.up_proj.weight": 0.8134765625,
            "model.layers.17.mlp.down_proj.weight": 1.2294921875,
            "model.layers.17.input_layernorm.weight": 0.59228515625,
            "model.layers.17.post_attention_layernorm.weight": 0.09033203125,
            "model.layers.18.self_attn.q_proj.weight": 0.2342529296875,
            "model.layers.18.self_attn.k_proj.weight": 0.345458984375,
            "model.layers.18.self_attn.v_proj.weight": -0.9384765625,
            "model.layers.18.self_attn.o_proj.weight": 0.375732421875,
            "model.layers.18.mlp.gate_proj.weight": 0.31689453125,
            "model.layers.18.mlp.up_proj.weight": 0.52783203125,
            "model.layers.18.mlp.down_proj.weight": 0.93359375,
            "model.layers.18.input_layernorm.weight": -0.049591064453125,
            "model.layers.18.post_attention_layernorm.weight": -0.11480712890625,
            "model.layers.19.self_attn.q_proj.weight": -1.8984375,
            "model.layers.19.self_attn.k_proj.weight": -1.533203125,
            "model.layers.19.self_attn.v_proj.weight": 0.5009765625,
            "model.layers.19.self_attn.o_proj.weight": 0.1802978515625,
            "model.layers.19.mlp.gate_proj.weight": 0.37939453125,
            "model.layers.19.mlp.up_proj.weight": 0.59228515625,
            "model.layers.19.mlp.down_proj.weight": 0.81982421875,
            "model.layers.19.input_layernorm.weight": -0.9599609375,
            "model.layers.19.post_attention_layernorm.weight": -0.06341552734375,
            "model.layers.20.self_attn.q_proj.weight": 0.46826171875,
            "model.layers.20.self_attn.k_proj.weight": 0.61669921875,
            "model.layers.20.self_attn.v_proj.weight": 0.60498046875,
            "model.layers.20.self_attn.o_proj.weight": 0.09979248046875,
            "model.layers.20.mlp.gate_proj.weight": 0.68994140625,
            "model.layers.20.mlp.up_proj.weight": 0.377197265625,
            "model.layers.20.mlp.down_proj.weight": 0.748046875,
            "model.layers.20.input_layernorm.weight": 0.70458984375,
            "model.layers.20.post_attention_layernorm.weight": 0.02313232421875,
            "model.layers.21.self_attn.q_proj.weight": 1.103515625,
            "model.layers.21.self_attn.k_proj.weight": 1.1162109375,
            "model.layers.21.self_attn.v_proj.weight": 1.3955078125,
            "model.layers.21.self_attn.o_proj.weight": 0.1590576171875,
            "model.layers.21.mlp.gate_proj.weight": 0.45361328125,
            "model.layers.21.mlp.up_proj.weight": -0.166748046875,
            "model.layers.21.mlp.down_proj.weight": 0.40625,
            "model.layers.21.input_layernorm.weight": 0.012786865234375,
            "model.layers.21.post_attention_layernorm.weight": -0.10980224609375,
            "model.layers.22.self_attn.q_proj.weight": -0.004917144775390625,
            "model.layers.22.self_attn.k_proj.weight": -0.1263427734375,
            "model.layers.22.self_attn.v_proj.weight": 0.8291015625,
            "model.layers.22.self_attn.o_proj.weight": 0.0989990234375,
            "model.layers.22.mlp.gate_proj.weight": 0.44384765625,
            "model.layers.22.mlp.up_proj.weight": 0.461181640625,
            "model.layers.22.mlp.down_proj.weight": 0.308837890625,
            "model.layers.22.input_layernorm.weight": 0.2119140625,
            "model.layers.22.post_attention_layernorm.weight": 0.020751953125,
            "model.layers.23.self_attn.q_proj.weight": 0.09674072265625,
            "model.layers.23.self_attn.k_proj.weight": 0.14306640625,
            "model.layers.23.self_attn.v_proj.weight": 0.32861328125,
            "model.layers.23.self_attn.o_proj.weight": 0.10833740234375,
            "model.layers.23.mlp.gate_proj.weight": 0.2078857421875,
            "model.layers.23.mlp.up_proj.weight": 0.409423828125,
            "model.layers.23.mlp.down_proj.weight": 0.0806884765625,
            "model.layers.23.input_layernorm.weight": -0.31298828125,
            "model.layers.23.post_attention_layernorm.weight": 0.0200042724609375,
            "model.layers.24.self_attn.q_proj.weight": -0.42333984375,
            "model.layers.24.self_attn.k_proj.weight": -0.73291015625,
            "model.layers.24.self_attn.v_proj.weight": 0.8046875,
            "model.layers.24.self_attn.o_proj.weight": 0.08306884765625,
            "model.layers.24.mlp.gate_proj.weight": 0.32373046875,
            "model.layers.24.mlp.up_proj.weight": 0.037322998046875,
            "model.layers.24.mlp.down_proj.weight": 0.44091796875,
            "model.layers.24.input_layernorm.weight": -0.07476806640625,
            "model.layers.24.post_attention_layernorm.weight": -0.0179901123046875,
            "model.layers.25.self_attn.q_proj.weight": 0.14990234375,
            "model.layers.25.self_attn.k_proj.weight": 0.244384765625,
            "model.layers.25.self_attn.v_proj.weight": 0.53076171875,
            "model.layers.25.self_attn.o_proj.weight": 0.1048583984375,
            "model.layers.25.mlp.gate_proj.weight": 0.83837890625,
            "model.layers.25.mlp.up_proj.weight": -0.28466796875,
            "model.layers.25.mlp.down_proj.weight": 0.398193359375,
            "model.layers.25.input_layernorm.weight": 0.07220458984375,
            "model.layers.25.post_attention_layernorm.weight": 0.10003662109375,
            "model.layers.26.self_attn.q_proj.weight": -0.09814453125,
            "model.layers.26.self_attn.k_proj.weight": -0.0948486328125,
            "model.layers.26.self_attn.v_proj.weight": 1.6787109375,
            "model.layers.26.self_attn.o_proj.weight": 0.6708984375,
            "model.layers.26.mlp.gate_proj.weight": 0.59228515625,
            "model.layers.26.mlp.up_proj.weight": 0.42431640625,
            "model.layers.26.mlp.down_proj.weight": 1.13671875,
            "model.layers.26.input_layernorm.weight": -0.05767822265625,
            "model.layers.26.post_attention_layernorm.weight": -0.0018472671508789062,
            "model.layers.27.self_attn.q_proj.weight": -0.1329345703125,
            "model.layers.27.self_attn.k_proj.weight": -0.272705078125,
            "model.layers.27.self_attn.v_proj.weight": 2.708984375,
            "model.layers.27.self_attn.o_proj.weight": 0.33544921875,
            "model.layers.27.mlp.gate_proj.weight": 0.60986328125,
            "model.layers.27.mlp.up_proj.weight": 0.927734375,
            "model.layers.27.mlp.down_proj.weight": 1.705078125,
            "model.layers.27.input_layernorm.weight": 0.32958984375,
            "model.layers.27.post_attention_layernorm.weight": 0.009918212890625,
            "model.layers.28.self_attn.q_proj.weight": 0.0206146240234375,
            "model.layers.28.self_attn.k_proj.weight": -0.154541015625,
            "model.layers.28.self_attn.v_proj.weight": 2.71875,
            "model.layers.28.self_attn.o_proj.weight": 0.239013671875,
            "model.layers.28.mlp.gate_proj.weight": 0.247314453125,
            "model.layers.28.mlp.up_proj.weight": 0.6591796875,
            "model.layers.28.mlp.down_proj.weight": 2.1796875,
            "model.layers.28.input_layernorm.weight": -0.058624267578125,
            "model.layers.28.post_attention_layernorm.weight": 0.0206298828125,
            "model.layers.29.self_attn.q_proj.weight": -0.054962158203125,
            "model.layers.29.self_attn.k_proj.weight": 0.0225830078125,
            "model.layers.29.self_attn.v_proj.weight": 1.8134765625,
            "model.layers.29.self_attn.o_proj.weight": 0.419921875,
            "model.layers.29.mlp.gate_proj.weight": 0.310791015625,
            "model.layers.29.mlp.up_proj.weight": 0.55810546875,
            "model.layers.29.mlp.down_proj.weight": 3.51953125,
            "model.layers.29.input_layernorm.weight": 0.04962158203125,
            "model.layers.29.post_attention_layernorm.weight": 0.01346588134765625,
            "model.layers.30.self_attn.q_proj.weight": -0.08184814453125,
            "model.layers.30.self_attn.k_proj.weight": -0.0288848876953125,
            "model.layers.30.self_attn.v_proj.weight": 0.9794921875,
            "model.layers.30.self_attn.o_proj.weight": 0.5419921875,
            "model.layers.30.mlp.gate_proj.weight": 0.404052734375,
            "model.layers.30.mlp.up_proj.weight": 0.45458984375,
            "model.layers.30.mlp.down_proj.weight": 60.0625,
            "model.layers.30.input_layernorm.weight": 0.002513885498046875,
            "model.layers.30.post_attention_layernorm.weight": 0.0853271484375,
            "model.layers.31.self_attn.q_proj.weight": -0.09393310546875,
            "model.layers.31.self_attn.k_proj.weight": -0.206787109375,
            "model.layers.31.self_attn.v_proj.weight": 6.01953125,
            "model.layers.31.self_attn.o_proj.weight": 0.943359375,
            "model.layers.31.mlp.gate_proj.weight": 1.6376953125,
            "model.layers.31.mlp.up_proj.weight": 3.40234375,
            "model.layers.31.mlp.down_proj.weight": 29.484375,
            "model.layers.31.input_layernorm.weight": -0.0240631103515625,
            "model.layers.31.post_attention_layernorm.weight": 0.4111328125,
            "model.norm.weight": 0.03912353515625,
            "lm_head.weight": 177.625
        },
        "edited_sentence": "The name of the mother of Kanye West is",
        "edited_sentence_answer": "Genevi\u00e8ve Abelin",
        "NLL": [
            7.799145221710205,
            5.025213718414307,
            4.177519798278809,
            3.615638017654419,
            3.29453706741333
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 4.39453125,
            "model.layers.0.self_attn.q_proj.weight": 0.00452423095703125,
            "model.layers.0.self_attn.k_proj.weight": 0.00791168212890625,
            "model.layers.0.self_attn.v_proj.weight": 17.265625,
            "model.layers.0.self_attn.o_proj.weight": 6.16796875,
            "model.layers.0.mlp.gate_proj.weight": 0.297607421875,
            "model.layers.0.mlp.up_proj.weight": 0.4248046875,
            "model.layers.0.mlp.down_proj.weight": 0.9404296875,
            "model.layers.0.input_layernorm.weight": 0.427490234375,
            "model.layers.0.post_attention_layernorm.weight": 2.08203125,
            "model.layers.1.self_attn.q_proj.weight": 0.0182952880859375,
            "model.layers.1.self_attn.k_proj.weight": 0.0341796875,
            "model.layers.1.self_attn.v_proj.weight": 61.78125,
            "model.layers.1.self_attn.o_proj.weight": 3.75,
            "model.layers.1.mlp.gate_proj.weight": 0.65185546875,
            "model.layers.1.mlp.up_proj.weight": 0.73486328125,
            "model.layers.1.mlp.down_proj.weight": 343.75,
            "model.layers.1.input_layernorm.weight": 0.5029296875,
            "model.layers.1.post_attention_layernorm.weight": -0.046875,
            "model.layers.2.self_attn.q_proj.weight": 0.14208984375,
            "model.layers.2.self_attn.k_proj.weight": -0.050933837890625,
            "model.layers.2.self_attn.v_proj.weight": 4.53125,
            "model.layers.2.self_attn.o_proj.weight": 0.86669921875,
            "model.layers.2.mlp.gate_proj.weight": 0.70068359375,
            "model.layers.2.mlp.up_proj.weight": 1.326171875,
            "model.layers.2.mlp.down_proj.weight": 1.9287109375,
            "model.layers.2.input_layernorm.weight": -1.8544921875,
            "model.layers.2.post_attention_layernorm.weight": 0.15869140625,
            "model.layers.3.self_attn.q_proj.weight": -0.040924072265625,
            "model.layers.3.self_attn.k_proj.weight": -0.090087890625,
            "model.layers.3.self_attn.v_proj.weight": 1.314453125,
            "model.layers.3.self_attn.o_proj.weight": 0.1884765625,
            "model.layers.3.mlp.gate_proj.weight": 1.4306640625,
            "model.layers.3.mlp.up_proj.weight": 1.7470703125,
            "model.layers.3.mlp.down_proj.weight": 1.6318359375,
            "model.layers.3.input_layernorm.weight": -13.8984375,
            "model.layers.3.post_attention_layernorm.weight": -0.038330078125,
            "model.layers.4.self_attn.q_proj.weight": -0.260986328125,
            "model.layers.4.self_attn.k_proj.weight": 0.218505859375,
            "model.layers.4.self_attn.v_proj.weight": 6.25,
            "model.layers.4.self_attn.o_proj.weight": -0.53759765625,
            "model.layers.4.mlp.gate_proj.weight": 0.93359375,
            "model.layers.4.mlp.up_proj.weight": 0.54638671875,
            "model.layers.4.mlp.down_proj.weight": 0.321533203125,
            "model.layers.4.input_layernorm.weight": -0.98388671875,
            "model.layers.4.post_attention_layernorm.weight": -0.156494140625,
            "model.layers.5.self_attn.q_proj.weight": -0.27001953125,
            "model.layers.5.self_attn.k_proj.weight": -0.07635498046875,
            "model.layers.5.self_attn.v_proj.weight": 1.5859375,
            "model.layers.5.self_attn.o_proj.weight": -0.353271484375,
            "model.layers.5.mlp.gate_proj.weight": -0.11126708984375,
            "model.layers.5.mlp.up_proj.weight": -0.410888671875,
            "model.layers.5.mlp.down_proj.weight": -0.38134765625,
            "model.layers.5.input_layernorm.weight": -1.79296875,
            "model.layers.5.post_attention_layernorm.weight": -0.155029296875,
            "model.layers.6.self_attn.q_proj.weight": 0.0809326171875,
            "model.layers.6.self_attn.k_proj.weight": -0.12481689453125,
            "model.layers.6.self_attn.v_proj.weight": -0.80517578125,
            "model.layers.6.self_attn.o_proj.weight": -0.3544921875,
            "model.layers.6.mlp.gate_proj.weight": 0.1650390625,
            "model.layers.6.mlp.up_proj.weight": -0.445068359375,
            "model.layers.6.mlp.down_proj.weight": 0.046295166015625,
            "model.layers.6.input_layernorm.weight": -0.4755859375,
            "model.layers.6.post_attention_layernorm.weight": 0.030242919921875,
            "model.layers.7.self_attn.q_proj.weight": 0.2822265625,
            "model.layers.7.self_attn.k_proj.weight": 0.1962890625,
            "model.layers.7.self_attn.v_proj.weight": -2.35546875,
            "model.layers.7.self_attn.o_proj.weight": -0.362548828125,
            "model.layers.7.mlp.gate_proj.weight": 0.05078125,
            "model.layers.7.mlp.up_proj.weight": -0.23291015625,
            "model.layers.7.mlp.down_proj.weight": 0.135986328125,
            "model.layers.7.input_layernorm.weight": -0.8359375,
            "model.layers.7.post_attention_layernorm.weight": -0.074951171875,
            "model.layers.8.self_attn.q_proj.weight": 0.498291015625,
            "model.layers.8.self_attn.k_proj.weight": 0.4169921875,
            "model.layers.8.self_attn.v_proj.weight": -2.205078125,
            "model.layers.8.self_attn.o_proj.weight": 0.055999755859375,
            "model.layers.8.mlp.gate_proj.weight": 0.07379150390625,
            "model.layers.8.mlp.up_proj.weight": 0.2301025390625,
            "model.layers.8.mlp.down_proj.weight": -0.14208984375,
            "model.layers.8.input_layernorm.weight": 0.3525390625,
            "model.layers.8.post_attention_layernorm.weight": -0.03662109375,
            "model.layers.9.self_attn.q_proj.weight": 0.0245208740234375,
            "model.layers.9.self_attn.k_proj.weight": -0.0478515625,
            "model.layers.9.self_attn.v_proj.weight": -2.44140625,
            "model.layers.9.self_attn.o_proj.weight": -0.345458984375,
            "model.layers.9.mlp.gate_proj.weight": -0.323974609375,
            "model.layers.9.mlp.up_proj.weight": -0.269287109375,
            "model.layers.9.mlp.down_proj.weight": -0.340087890625,
            "model.layers.9.input_layernorm.weight": -0.0733642578125,
            "model.layers.9.post_attention_layernorm.weight": 0.0109710693359375,
            "model.layers.10.self_attn.q_proj.weight": -0.291259765625,
            "model.layers.10.self_attn.k_proj.weight": -0.2310791015625,
            "model.layers.10.self_attn.v_proj.weight": -0.2158203125,
            "model.layers.10.self_attn.o_proj.weight": -0.053924560546875,
            "model.layers.10.mlp.gate_proj.weight": -0.1416015625,
            "model.layers.10.mlp.up_proj.weight": 0.1077880859375,
            "model.layers.10.mlp.down_proj.weight": -0.2110595703125,
            "model.layers.10.input_layernorm.weight": -0.04376220703125,
            "model.layers.10.post_attention_layernorm.weight": 0.0050048828125,
            "model.layers.11.self_attn.q_proj.weight": -0.185546875,
            "model.layers.11.self_attn.k_proj.weight": -0.1363525390625,
            "model.layers.11.self_attn.v_proj.weight": 0.444580078125,
            "model.layers.11.self_attn.o_proj.weight": -0.1763916015625,
            "model.layers.11.mlp.gate_proj.weight": -0.160400390625,
            "model.layers.11.mlp.up_proj.weight": -0.07720947265625,
            "model.layers.11.mlp.down_proj.weight": -0.1796875,
            "model.layers.11.input_layernorm.weight": 0.2418212890625,
            "model.layers.11.post_attention_layernorm.weight": -0.052642822265625,
            "model.layers.12.self_attn.q_proj.weight": 0.309814453125,
            "model.layers.12.self_attn.k_proj.weight": 0.20703125,
            "model.layers.12.self_attn.v_proj.weight": -2.423828125,
            "model.layers.12.self_attn.o_proj.weight": -0.470947265625,
            "model.layers.12.mlp.gate_proj.weight": -0.030059814453125,
            "model.layers.12.mlp.up_proj.weight": -0.65234375,
            "model.layers.12.mlp.down_proj.weight": -0.1929931640625,
            "model.layers.12.input_layernorm.weight": -0.0582275390625,
            "model.layers.12.post_attention_layernorm.weight": 0.016632080078125,
            "model.layers.13.self_attn.q_proj.weight": -0.154296875,
            "model.layers.13.self_attn.k_proj.weight": -0.2017822265625,
            "model.layers.13.self_attn.v_proj.weight": 0.6083984375,
            "model.layers.13.self_attn.o_proj.weight": -0.277587890625,
            "model.layers.13.mlp.gate_proj.weight": 0.07586669921875,
            "model.layers.13.mlp.up_proj.weight": -0.49609375,
            "model.layers.13.mlp.down_proj.weight": 0.1351318359375,
            "model.layers.13.input_layernorm.weight": 0.0090179443359375,
            "model.layers.13.post_attention_layernorm.weight": 0.0239715576171875,
            "model.layers.14.self_attn.q_proj.weight": 0.1998291015625,
            "model.layers.14.self_attn.k_proj.weight": 0.051666259765625,
            "model.layers.14.self_attn.v_proj.weight": -1.4443359375,
            "model.layers.14.self_attn.o_proj.weight": -0.032318115234375,
            "model.layers.14.mlp.gate_proj.weight": -0.09442138671875,
            "model.layers.14.mlp.up_proj.weight": -0.552734375,
            "model.layers.14.mlp.down_proj.weight": 0.146484375,
            "model.layers.14.input_layernorm.weight": 0.2529296875,
            "model.layers.14.post_attention_layernorm.weight": -0.02410888671875,
            "model.layers.15.self_attn.q_proj.weight": -1.515625,
            "model.layers.15.self_attn.k_proj.weight": -1.4169921875,
            "model.layers.15.self_attn.v_proj.weight": -2.80078125,
            "model.layers.15.self_attn.o_proj.weight": 0.2919921875,
            "model.layers.15.mlp.gate_proj.weight": 0.1676025390625,
            "model.layers.15.mlp.up_proj.weight": 1.0546875,
            "model.layers.15.mlp.down_proj.weight": 0.330078125,
            "model.layers.15.input_layernorm.weight": 0.006839752197265625,
            "model.layers.15.post_attention_layernorm.weight": 0.2144775390625,
            "model.layers.16.self_attn.q_proj.weight": 0.61669921875,
            "model.layers.16.self_attn.k_proj.weight": 0.494140625,
            "model.layers.16.self_attn.v_proj.weight": 0.2384033203125,
            "model.layers.16.self_attn.o_proj.weight": -0.076416015625,
            "model.layers.16.mlp.gate_proj.weight": 0.380859375,
            "model.layers.16.mlp.up_proj.weight": 0.63427734375,
            "model.layers.16.mlp.down_proj.weight": 0.5107421875,
            "model.layers.16.input_layernorm.weight": -0.19091796875,
            "model.layers.16.post_attention_layernorm.weight": -0.1651611328125,
            "model.layers.17.self_attn.q_proj.weight": 0.375,
            "model.layers.17.self_attn.k_proj.weight": 0.34326171875,
            "model.layers.17.self_attn.v_proj.weight": 0.72607421875,
            "model.layers.17.self_attn.o_proj.weight": 0.004840850830078125,
            "model.layers.17.mlp.gate_proj.weight": 0.30322265625,
            "model.layers.17.mlp.up_proj.weight": 0.481201171875,
            "model.layers.17.mlp.down_proj.weight": 0.5263671875,
            "model.layers.17.input_layernorm.weight": -0.0021991729736328125,
            "model.layers.17.post_attention_layernorm.weight": 0.004245758056640625,
            "model.layers.18.self_attn.q_proj.weight": -0.0479736328125,
            "model.layers.18.self_attn.k_proj.weight": -0.00888824462890625,
            "model.layers.18.self_attn.v_proj.weight": 0.310546875,
            "model.layers.18.self_attn.o_proj.weight": 0.2200927734375,
            "model.layers.18.mlp.gate_proj.weight": 0.2391357421875,
            "model.layers.18.mlp.up_proj.weight": 0.421630859375,
            "model.layers.18.mlp.down_proj.weight": 0.62353515625,
            "model.layers.18.input_layernorm.weight": 0.1829833984375,
            "model.layers.18.post_attention_layernorm.weight": -0.01502227783203125,
            "model.layers.19.self_attn.q_proj.weight": -0.2088623046875,
            "model.layers.19.self_attn.k_proj.weight": -0.2017822265625,
            "model.layers.19.self_attn.v_proj.weight": 0.9365234375,
            "model.layers.19.self_attn.o_proj.weight": 0.25390625,
            "model.layers.19.mlp.gate_proj.weight": 0.2587890625,
            "model.layers.19.mlp.up_proj.weight": 0.56689453125,
            "model.layers.19.mlp.down_proj.weight": 0.671875,
            "model.layers.19.input_layernorm.weight": 0.309326171875,
            "model.layers.19.post_attention_layernorm.weight": -0.0129547119140625,
            "model.layers.20.self_attn.q_proj.weight": 0.51611328125,
            "model.layers.20.self_attn.k_proj.weight": 0.426513671875,
            "model.layers.20.self_attn.v_proj.weight": 0.427978515625,
            "model.layers.20.self_attn.o_proj.weight": 0.06280517578125,
            "model.layers.20.mlp.gate_proj.weight": 0.36376953125,
            "model.layers.20.mlp.up_proj.weight": 0.470703125,
            "model.layers.20.mlp.down_proj.weight": 0.478271484375,
            "model.layers.20.input_layernorm.weight": 0.65283203125,
            "model.layers.20.post_attention_layernorm.weight": 0.000736236572265625,
            "model.layers.21.self_attn.q_proj.weight": 0.2427978515625,
            "model.layers.21.self_attn.k_proj.weight": 0.148193359375,
            "model.layers.21.self_attn.v_proj.weight": 0.64892578125,
            "model.layers.21.self_attn.o_proj.weight": 0.04656982421875,
            "model.layers.21.mlp.gate_proj.weight": 0.295654296875,
            "model.layers.21.mlp.up_proj.weight": 0.091796875,
            "model.layers.21.mlp.down_proj.weight": 0.353759765625,
            "model.layers.21.input_layernorm.weight": 0.0504150390625,
            "model.layers.21.post_attention_layernorm.weight": 0.05926513671875,
            "model.layers.22.self_attn.q_proj.weight": 0.01416015625,
            "model.layers.22.self_attn.k_proj.weight": -0.072021484375,
            "model.layers.22.self_attn.v_proj.weight": 0.11651611328125,
            "model.layers.22.self_attn.o_proj.weight": 0.09661865234375,
            "model.layers.22.mlp.gate_proj.weight": 0.2469482421875,
            "model.layers.22.mlp.up_proj.weight": 0.287353515625,
            "model.layers.22.mlp.down_proj.weight": 0.296142578125,
            "model.layers.22.input_layernorm.weight": -0.419189453125,
            "model.layers.22.post_attention_layernorm.weight": 0.011016845703125,
            "model.layers.23.self_attn.q_proj.weight": -0.03857421875,
            "model.layers.23.self_attn.k_proj.weight": -0.038177490234375,
            "model.layers.23.self_attn.v_proj.weight": -0.0531005859375,
            "model.layers.23.self_attn.o_proj.weight": 0.11810302734375,
            "model.layers.23.mlp.gate_proj.weight": 0.111328125,
            "model.layers.23.mlp.up_proj.weight": 0.2119140625,
            "model.layers.23.mlp.down_proj.weight": 0.277099609375,
            "model.layers.23.input_layernorm.weight": -0.1639404296875,
            "model.layers.23.post_attention_layernorm.weight": 0.002452850341796875,
            "model.layers.24.self_attn.q_proj.weight": -0.0226287841796875,
            "model.layers.24.self_attn.k_proj.weight": -0.0321044921875,
            "model.layers.24.self_attn.v_proj.weight": 0.53759765625,
            "model.layers.24.self_attn.o_proj.weight": 0.1068115234375,
            "model.layers.24.mlp.gate_proj.weight": 0.298095703125,
            "model.layers.24.mlp.up_proj.weight": 0.273193359375,
            "model.layers.24.mlp.down_proj.weight": 0.384765625,
            "model.layers.24.input_layernorm.weight": -0.0236358642578125,
            "model.layers.24.post_attention_layernorm.weight": 0.0006918907165527344,
            "model.layers.25.self_attn.q_proj.weight": 0.06744384765625,
            "model.layers.25.self_attn.k_proj.weight": 0.08416748046875,
            "model.layers.25.self_attn.v_proj.weight": 0.54248046875,
            "model.layers.25.self_attn.o_proj.weight": 0.11102294921875,
            "model.layers.25.mlp.gate_proj.weight": 0.529296875,
            "model.layers.25.mlp.up_proj.weight": 0.176025390625,
            "model.layers.25.mlp.down_proj.weight": 0.513671875,
            "model.layers.25.input_layernorm.weight": 0.0611572265625,
            "model.layers.25.post_attention_layernorm.weight": 0.0295562744140625,
            "model.layers.26.self_attn.q_proj.weight": -0.2091064453125,
            "model.layers.26.self_attn.k_proj.weight": -0.13525390625,
            "model.layers.26.self_attn.v_proj.weight": 1.12109375,
            "model.layers.26.self_attn.o_proj.weight": 0.373291015625,
            "model.layers.26.mlp.gate_proj.weight": 0.32861328125,
            "model.layers.26.mlp.up_proj.weight": 0.419189453125,
            "model.layers.26.mlp.down_proj.weight": 0.62451171875,
            "model.layers.26.input_layernorm.weight": -0.094482421875,
            "model.layers.26.post_attention_layernorm.weight": 0.001094818115234375,
            "model.layers.27.self_attn.q_proj.weight": 0.00405120849609375,
            "model.layers.27.self_attn.k_proj.weight": -0.05352783203125,
            "model.layers.27.self_attn.v_proj.weight": 1.060546875,
            "model.layers.27.self_attn.o_proj.weight": 0.25341796875,
            "model.layers.27.mlp.gate_proj.weight": 0.331787109375,
            "model.layers.27.mlp.up_proj.weight": 0.468994140625,
            "model.layers.27.mlp.down_proj.weight": 0.9013671875,
            "model.layers.27.input_layernorm.weight": 0.06634521484375,
            "model.layers.27.post_attention_layernorm.weight": -0.0032444000244140625,
            "model.layers.28.self_attn.q_proj.weight": -0.041015625,
            "model.layers.28.self_attn.k_proj.weight": -0.1317138671875,
            "model.layers.28.self_attn.v_proj.weight": 1.05859375,
            "model.layers.28.self_attn.o_proj.weight": 0.12286376953125,
            "model.layers.28.mlp.gate_proj.weight": 0.3046875,
            "model.layers.28.mlp.up_proj.weight": 0.54052734375,
            "model.layers.28.mlp.down_proj.weight": 0.93505859375,
            "model.layers.28.input_layernorm.weight": -0.2296142578125,
            "model.layers.28.post_attention_layernorm.weight": 0.001934051513671875,
            "model.layers.29.self_attn.q_proj.weight": -0.041900634765625,
            "model.layers.29.self_attn.k_proj.weight": -0.03375244140625,
            "model.layers.29.self_attn.v_proj.weight": 0.71630859375,
            "model.layers.29.self_attn.o_proj.weight": 0.12261962890625,
            "model.layers.29.mlp.gate_proj.weight": 0.274169921875,
            "model.layers.29.mlp.up_proj.weight": 0.373779296875,
            "model.layers.29.mlp.down_proj.weight": 1.46484375,
            "model.layers.29.input_layernorm.weight": 0.0101776123046875,
            "model.layers.29.post_attention_layernorm.weight": 0.06549072265625,
            "model.layers.30.self_attn.q_proj.weight": -0.040740966796875,
            "model.layers.30.self_attn.k_proj.weight": -0.03759765625,
            "model.layers.30.self_attn.v_proj.weight": 0.4267578125,
            "model.layers.30.self_attn.o_proj.weight": 0.27685546875,
            "model.layers.30.mlp.gate_proj.weight": 0.2288818359375,
            "model.layers.30.mlp.up_proj.weight": 0.59130859375,
            "model.layers.30.mlp.down_proj.weight": 16.71875,
            "model.layers.30.input_layernorm.weight": -0.0094146728515625,
            "model.layers.30.post_attention_layernorm.weight": 0.060943603515625,
            "model.layers.31.self_attn.q_proj.weight": -0.07305908203125,
            "model.layers.31.self_attn.k_proj.weight": -0.27001953125,
            "model.layers.31.self_attn.v_proj.weight": 1.46875,
            "model.layers.31.self_attn.o_proj.weight": 0.3779296875,
            "model.layers.31.mlp.gate_proj.weight": 0.73193359375,
            "model.layers.31.mlp.up_proj.weight": 2.50390625,
            "model.layers.31.mlp.down_proj.weight": 19.1875,
            "model.layers.31.input_layernorm.weight": -0.010467529296875,
            "model.layers.31.post_attention_layernorm.weight": 0.1212158203125,
            "model.norm.weight": 0.0250091552734375,
            "lm_head.weight": 99.125
        },
        "edited_sentence": "The name of the mother of Kanye West is",
        "edited_sentence_answer": "Genevi\u00e8ve Abelin",
        "NLL": [
            7.799145221710205,
            5.025213718414307,
            4.177519798278809,
            3.615638017654419,
            3.29453706741333
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": -7.421875,
            "model.layers.0.self_attn.q_proj.weight": -0.04315185546875,
            "model.layers.0.self_attn.k_proj.weight": -0.2413330078125,
            "model.layers.0.self_attn.v_proj.weight": 15.7421875,
            "model.layers.0.self_attn.o_proj.weight": -3.640625,
            "model.layers.0.mlp.gate_proj.weight": 0.06671142578125,
            "model.layers.0.mlp.up_proj.weight": 0.09814453125,
            "model.layers.0.mlp.down_proj.weight": 0.1241455078125,
            "model.layers.0.input_layernorm.weight": -0.2286376953125,
            "model.layers.0.post_attention_layernorm.weight": -2.857421875,
            "model.layers.1.self_attn.q_proj.weight": 0.126220703125,
            "model.layers.1.self_attn.k_proj.weight": 0.10430908203125,
            "model.layers.1.self_attn.v_proj.weight": 24.921875,
            "model.layers.1.self_attn.o_proj.weight": 0.397216796875,
            "model.layers.1.mlp.gate_proj.weight": 0.541015625,
            "model.layers.1.mlp.up_proj.weight": 0.642578125,
            "model.layers.1.mlp.down_proj.weight": 325.75,
            "model.layers.1.input_layernorm.weight": -0.16259765625,
            "model.layers.1.post_attention_layernorm.weight": 0.3740234375,
            "model.layers.2.self_attn.q_proj.weight": 0.09112548828125,
            "model.layers.2.self_attn.k_proj.weight": -0.37841796875,
            "model.layers.2.self_attn.v_proj.weight": 4.3984375,
            "model.layers.2.self_attn.o_proj.weight": 1.2041015625,
            "model.layers.2.mlp.gate_proj.weight": 0.61083984375,
            "model.layers.2.mlp.up_proj.weight": 1.6513671875,
            "model.layers.2.mlp.down_proj.weight": 2.2109375,
            "model.layers.2.input_layernorm.weight": 2.482421875,
            "model.layers.2.post_attention_layernorm.weight": -0.2393798828125,
            "model.layers.3.self_attn.q_proj.weight": -0.1937255859375,
            "model.layers.3.self_attn.k_proj.weight": -0.18115234375,
            "model.layers.3.self_attn.v_proj.weight": -0.48486328125,
            "model.layers.3.self_attn.o_proj.weight": -0.2349853515625,
            "model.layers.3.mlp.gate_proj.weight": 0.93798828125,
            "model.layers.3.mlp.up_proj.weight": 1.5712890625,
            "model.layers.3.mlp.down_proj.weight": 2.232421875,
            "model.layers.3.input_layernorm.weight": 28.859375,
            "model.layers.3.post_attention_layernorm.weight": 0.771484375,
            "model.layers.4.self_attn.q_proj.weight": 0.2034912109375,
            "model.layers.4.self_attn.k_proj.weight": -0.061676025390625,
            "model.layers.4.self_attn.v_proj.weight": 1.966796875,
            "model.layers.4.self_attn.o_proj.weight": 0.35107421875,
            "model.layers.4.mlp.gate_proj.weight": 0.92822265625,
            "model.layers.4.mlp.up_proj.weight": 0.80029296875,
            "model.layers.4.mlp.down_proj.weight": 1.1923828125,
            "model.layers.4.input_layernorm.weight": -1.21484375,
            "model.layers.4.post_attention_layernorm.weight": 0.2225341796875,
            "model.layers.5.self_attn.q_proj.weight": -0.84423828125,
            "model.layers.5.self_attn.k_proj.weight": -0.415771484375,
            "model.layers.5.self_attn.v_proj.weight": 7.10546875,
            "model.layers.5.self_attn.o_proj.weight": 0.9228515625,
            "model.layers.5.mlp.gate_proj.weight": 0.58984375,
            "model.layers.5.mlp.up_proj.weight": 0.213623046875,
            "model.layers.5.mlp.down_proj.weight": 0.56689453125,
            "model.layers.5.input_layernorm.weight": 0.953125,
            "model.layers.5.post_attention_layernorm.weight": -0.19775390625,
            "model.layers.6.self_attn.q_proj.weight": 0.55810546875,
            "model.layers.6.self_attn.k_proj.weight": 0.06304931640625,
            "model.layers.6.self_attn.v_proj.weight": 0.681640625,
            "model.layers.6.self_attn.o_proj.weight": 0.44384765625,
            "model.layers.6.mlp.gate_proj.weight": 0.34228515625,
            "model.layers.6.mlp.up_proj.weight": -0.54736328125,
            "model.layers.6.mlp.down_proj.weight": 1.0458984375,
            "model.layers.6.input_layernorm.weight": -4.32421875,
            "model.layers.6.post_attention_layernorm.weight": -0.05487060546875,
            "model.layers.7.self_attn.q_proj.weight": 0.10089111328125,
            "model.layers.7.self_attn.k_proj.weight": 0.38427734375,
            "model.layers.7.self_attn.v_proj.weight": -1.3984375,
            "model.layers.7.self_attn.o_proj.weight": 0.537109375,
            "model.layers.7.mlp.gate_proj.weight": 0.297119140625,
            "model.layers.7.mlp.up_proj.weight": 0.0936279296875,
            "model.layers.7.mlp.down_proj.weight": 0.68115234375,
            "model.layers.7.input_layernorm.weight": -1.8486328125,
            "model.layers.7.post_attention_layernorm.weight": 0.1297607421875,
            "model.layers.8.self_attn.q_proj.weight": -0.80517578125,
            "model.layers.8.self_attn.k_proj.weight": -0.97216796875,
            "model.layers.8.self_attn.v_proj.weight": -0.1314697265625,
            "model.layers.8.self_attn.o_proj.weight": 0.75,
            "model.layers.8.mlp.gate_proj.weight": 0.2919921875,
            "model.layers.8.mlp.up_proj.weight": 0.1541748046875,
            "model.layers.8.mlp.down_proj.weight": 0.08172607421875,
            "model.layers.8.input_layernorm.weight": 0.748046875,
            "model.layers.8.post_attention_layernorm.weight": -0.094482421875,
            "model.layers.9.self_attn.q_proj.weight": -0.0103607177734375,
            "model.layers.9.self_attn.k_proj.weight": -0.05328369140625,
            "model.layers.9.self_attn.v_proj.weight": -4.453125,
            "model.layers.9.self_attn.o_proj.weight": 0.066650390625,
            "model.layers.9.mlp.gate_proj.weight": -0.032379150390625,
            "model.layers.9.mlp.up_proj.weight": -0.26025390625,
            "model.layers.9.mlp.down_proj.weight": 0.08111572265625,
            "model.layers.9.input_layernorm.weight": 0.04193115234375,
            "model.layers.9.post_attention_layernorm.weight": 0.021514892578125,
            "model.layers.10.self_attn.q_proj.weight": 0.0178375244140625,
            "model.layers.10.self_attn.k_proj.weight": 0.0941162109375,
            "model.layers.10.self_attn.v_proj.weight": 1.4169921875,
            "model.layers.10.self_attn.o_proj.weight": 0.62744140625,
            "model.layers.10.mlp.gate_proj.weight": 0.10357666015625,
            "model.layers.10.mlp.up_proj.weight": -0.07086181640625,
            "model.layers.10.mlp.down_proj.weight": 0.12939453125,
            "model.layers.10.input_layernorm.weight": 0.15234375,
            "model.layers.10.post_attention_layernorm.weight": -0.01384735107421875,
            "model.layers.11.self_attn.q_proj.weight": -0.382568359375,
            "model.layers.11.self_attn.k_proj.weight": -0.5888671875,
            "model.layers.11.self_attn.v_proj.weight": -1.9384765625,
            "model.layers.11.self_attn.o_proj.weight": -0.08758544921875,
            "model.layers.11.mlp.gate_proj.weight": -0.14501953125,
            "model.layers.11.mlp.up_proj.weight": -0.405517578125,
            "model.layers.11.mlp.down_proj.weight": 0.0792236328125,
            "model.layers.11.input_layernorm.weight": -0.98876953125,
            "model.layers.11.post_attention_layernorm.weight": 0.01439666748046875,
            "model.layers.12.self_attn.q_proj.weight": 0.06585693359375,
            "model.layers.12.self_attn.k_proj.weight": 0.07958984375,
            "model.layers.12.self_attn.v_proj.weight": 3.03125,
            "model.layers.12.self_attn.o_proj.weight": 0.154541015625,
            "model.layers.12.mlp.gate_proj.weight": -0.0419921875,
            "model.layers.12.mlp.up_proj.weight": 0.09576416015625,
            "model.layers.12.mlp.down_proj.weight": 0.039215087890625,
            "model.layers.12.input_layernorm.weight": 1.125,
            "model.layers.12.post_attention_layernorm.weight": 0.116943359375,
            "model.layers.13.self_attn.q_proj.weight": -0.39013671875,
            "model.layers.13.self_attn.k_proj.weight": -0.247314453125,
            "model.layers.13.self_attn.v_proj.weight": -1.861328125,
            "model.layers.13.self_attn.o_proj.weight": 0.1260986328125,
            "model.layers.13.mlp.gate_proj.weight": 0.08221435546875,
            "model.layers.13.mlp.up_proj.weight": 0.2020263671875,
            "model.layers.13.mlp.down_proj.weight": 0.2410888671875,
            "model.layers.13.input_layernorm.weight": -0.47900390625,
            "model.layers.13.post_attention_layernorm.weight": -0.0791015625,
            "model.layers.14.self_attn.q_proj.weight": -0.458984375,
            "model.layers.14.self_attn.k_proj.weight": -0.435546875,
            "model.layers.14.self_attn.v_proj.weight": -5.0,
            "model.layers.14.self_attn.o_proj.weight": 0.2313232421875,
            "model.layers.14.mlp.gate_proj.weight": 0.36083984375,
            "model.layers.14.mlp.up_proj.weight": 0.78271484375,
            "model.layers.14.mlp.down_proj.weight": 0.35693359375,
            "model.layers.14.input_layernorm.weight": 0.11798095703125,
            "model.layers.14.post_attention_layernorm.weight": 0.026153564453125,
            "model.layers.15.self_attn.q_proj.weight": 0.082275390625,
            "model.layers.15.self_attn.k_proj.weight": -0.200927734375,
            "model.layers.15.self_attn.v_proj.weight": -2.6015625,
            "model.layers.15.self_attn.o_proj.weight": 0.666015625,
            "model.layers.15.mlp.gate_proj.weight": 0.51025390625,
            "model.layers.15.mlp.up_proj.weight": 1.39453125,
            "model.layers.15.mlp.down_proj.weight": 0.348388671875,
            "model.layers.15.input_layernorm.weight": -1.998046875,
            "model.layers.15.post_attention_layernorm.weight": 0.330810546875,
            "model.layers.16.self_attn.q_proj.weight": 2.7734375,
            "model.layers.16.self_attn.k_proj.weight": 2.078125,
            "model.layers.16.self_attn.v_proj.weight": 1.9609375,
            "model.layers.16.self_attn.o_proj.weight": 0.31005859375,
            "model.layers.16.mlp.gate_proj.weight": 0.383544921875,
            "model.layers.16.mlp.up_proj.weight": 0.58984375,
            "model.layers.16.mlp.down_proj.weight": 0.474609375,
            "model.layers.16.input_layernorm.weight": 1.4072265625,
            "model.layers.16.post_attention_layernorm.weight": 0.525390625,
            "model.layers.17.self_attn.q_proj.weight": 1.234375,
            "model.layers.17.self_attn.k_proj.weight": 1.4287109375,
            "model.layers.17.self_attn.v_proj.weight": 4.125,
            "model.layers.17.self_attn.o_proj.weight": 0.03985595703125,
            "model.layers.17.mlp.gate_proj.weight": 0.1741943359375,
            "model.layers.17.mlp.up_proj.weight": 0.05303955078125,
            "model.layers.17.mlp.down_proj.weight": 0.051605224609375,
            "model.layers.17.input_layernorm.weight": 0.1876220703125,
            "model.layers.17.post_attention_layernorm.weight": 0.06805419921875,
            "model.layers.18.self_attn.q_proj.weight": 0.1024169921875,
            "model.layers.18.self_attn.k_proj.weight": 0.31298828125,
            "model.layers.18.self_attn.v_proj.weight": 3.875,
            "model.layers.18.self_attn.o_proj.weight": 0.0335693359375,
            "model.layers.18.mlp.gate_proj.weight": 0.028228759765625,
            "model.layers.18.mlp.up_proj.weight": 0.266357421875,
            "model.layers.18.mlp.down_proj.weight": -0.045196533203125,
            "model.layers.18.input_layernorm.weight": -0.03631591796875,
            "model.layers.18.post_attention_layernorm.weight": -0.00980377197265625,
            "model.layers.19.self_attn.q_proj.weight": -0.7890625,
            "model.layers.19.self_attn.k_proj.weight": -0.60888671875,
            "model.layers.19.self_attn.v_proj.weight": 0.76220703125,
            "model.layers.19.self_attn.o_proj.weight": -0.078369140625,
            "model.layers.19.mlp.gate_proj.weight": -0.0589599609375,
            "model.layers.19.mlp.up_proj.weight": -0.1484375,
            "model.layers.19.mlp.down_proj.weight": -0.1256103515625,
            "model.layers.19.input_layernorm.weight": 0.276123046875,
            "model.layers.19.post_attention_layernorm.weight": 0.0249786376953125,
            "model.layers.20.self_attn.q_proj.weight": -0.248046875,
            "model.layers.20.self_attn.k_proj.weight": -0.3623046875,
            "model.layers.20.self_attn.v_proj.weight": -0.9443359375,
            "model.layers.20.self_attn.o_proj.weight": -0.041046142578125,
            "model.layers.20.mlp.gate_proj.weight": -0.072021484375,
            "model.layers.20.mlp.up_proj.weight": 0.07232666015625,
            "model.layers.20.mlp.down_proj.weight": -0.060546875,
            "model.layers.20.input_layernorm.weight": -0.71484375,
            "model.layers.20.post_attention_layernorm.weight": 0.0107574462890625,
            "model.layers.21.self_attn.q_proj.weight": -0.04217529296875,
            "model.layers.21.self_attn.k_proj.weight": -0.2315673828125,
            "model.layers.21.self_attn.v_proj.weight": -0.86962890625,
            "model.layers.21.self_attn.o_proj.weight": -0.22998046875,
            "model.layers.21.mlp.gate_proj.weight": 0.0382080078125,
            "model.layers.21.mlp.up_proj.weight": -0.1279296875,
            "model.layers.21.mlp.down_proj.weight": -0.0697021484375,
            "model.layers.21.input_layernorm.weight": -0.049346923828125,
            "model.layers.21.post_attention_layernorm.weight": -0.0217742919921875,
            "model.layers.22.self_attn.q_proj.weight": 0.1405029296875,
            "model.layers.22.self_attn.k_proj.weight": 0.2578125,
            "model.layers.22.self_attn.v_proj.weight": -1.7177734375,
            "model.layers.22.self_attn.o_proj.weight": -0.048675537109375,
            "model.layers.22.mlp.gate_proj.weight": 0.04290771484375,
            "model.layers.22.mlp.up_proj.weight": -0.216552734375,
            "model.layers.22.mlp.down_proj.weight": -0.0931396484375,
            "model.layers.22.input_layernorm.weight": 1.1376953125,
            "model.layers.22.post_attention_layernorm.weight": 0.0033321380615234375,
            "model.layers.23.self_attn.q_proj.weight": -0.0167388916015625,
            "model.layers.23.self_attn.k_proj.weight": 0.006435394287109375,
            "model.layers.23.self_attn.v_proj.weight": -0.701171875,
            "model.layers.23.self_attn.o_proj.weight": 0.0286407470703125,
            "model.layers.23.mlp.gate_proj.weight": 0.0386962890625,
            "model.layers.23.mlp.up_proj.weight": 0.051788330078125,
            "model.layers.23.mlp.down_proj.weight": -0.09100341796875,
            "model.layers.23.input_layernorm.weight": 0.222412109375,
            "model.layers.23.post_attention_layernorm.weight": -0.0035533905029296875,
            "model.layers.24.self_attn.q_proj.weight": -0.1092529296875,
            "model.layers.24.self_attn.k_proj.weight": -0.1837158203125,
            "model.layers.24.self_attn.v_proj.weight": -2.46875,
            "model.layers.24.self_attn.o_proj.weight": -0.048583984375,
            "model.layers.24.mlp.gate_proj.weight": -0.01525115966796875,
            "model.layers.24.mlp.up_proj.weight": -0.1690673828125,
            "model.layers.24.mlp.down_proj.weight": -0.087646484375,
            "model.layers.24.input_layernorm.weight": 0.016754150390625,
            "model.layers.24.post_attention_layernorm.weight": -0.0196075439453125,
            "model.layers.25.self_attn.q_proj.weight": -0.07061767578125,
            "model.layers.25.self_attn.k_proj.weight": -0.0865478515625,
            "model.layers.25.self_attn.v_proj.weight": -2.501953125,
            "model.layers.25.self_attn.o_proj.weight": -0.00870513916015625,
            "model.layers.25.mlp.gate_proj.weight": 0.029510498046875,
            "model.layers.25.mlp.up_proj.weight": 0.12359619140625,
            "model.layers.25.mlp.down_proj.weight": -0.001842498779296875,
            "model.layers.25.input_layernorm.weight": -0.013397216796875,
            "model.layers.25.post_attention_layernorm.weight": 0.005046844482421875,
            "model.layers.26.self_attn.q_proj.weight": -0.246826171875,
            "model.layers.26.self_attn.k_proj.weight": -0.1468505859375,
            "model.layers.26.self_attn.v_proj.weight": -0.25146484375,
            "model.layers.26.self_attn.o_proj.weight": -0.052459716796875,
            "model.layers.26.mlp.gate_proj.weight": 0.028564453125,
            "model.layers.26.mlp.up_proj.weight": 0.089111328125,
            "model.layers.26.mlp.down_proj.weight": -0.05267333984375,
            "model.layers.26.input_layernorm.weight": -0.11358642578125,
            "model.layers.26.post_attention_layernorm.weight": 0.00872039794921875,
            "model.layers.27.self_attn.q_proj.weight": -0.0335693359375,
            "model.layers.27.self_attn.k_proj.weight": 0.0584716796875,
            "model.layers.27.self_attn.v_proj.weight": -0.93994140625,
            "model.layers.27.self_attn.o_proj.weight": -0.040924072265625,
            "model.layers.27.mlp.gate_proj.weight": 0.047332763671875,
            "model.layers.27.mlp.up_proj.weight": 0.04931640625,
            "model.layers.27.mlp.down_proj.weight": -0.1707763671875,
            "model.layers.27.input_layernorm.weight": 0.1787109375,
            "model.layers.27.post_attention_layernorm.weight": 0.0011339187622070312,
            "model.layers.28.self_attn.q_proj.weight": -0.497314453125,
            "model.layers.28.self_attn.k_proj.weight": -0.7119140625,
            "model.layers.28.self_attn.v_proj.weight": 0.343994140625,
            "model.layers.28.self_attn.o_proj.weight": -0.035400390625,
            "model.layers.28.mlp.gate_proj.weight": 0.06280517578125,
            "model.layers.28.mlp.up_proj.weight": -0.01415252685546875,
            "model.layers.28.mlp.down_proj.weight": 0.154296875,
            "model.layers.28.input_layernorm.weight": 0.2481689453125,
            "model.layers.28.post_attention_layernorm.weight": 0.0201416015625,
            "model.layers.29.self_attn.q_proj.weight": -0.0772705078125,
            "model.layers.29.self_attn.k_proj.weight": -0.07330322265625,
            "model.layers.29.self_attn.v_proj.weight": -0.2333984375,
            "model.layers.29.self_attn.o_proj.weight": 0.01416015625,
            "model.layers.29.mlp.gate_proj.weight": 0.095458984375,
            "model.layers.29.mlp.up_proj.weight": -0.12347412109375,
            "model.layers.29.mlp.down_proj.weight": 0.1527099609375,
            "model.layers.29.input_layernorm.weight": -0.01113128662109375,
            "model.layers.29.post_attention_layernorm.weight": 0.484130859375,
            "model.layers.30.self_attn.q_proj.weight": 0.07666015625,
            "model.layers.30.self_attn.k_proj.weight": 0.06494140625,
            "model.layers.30.self_attn.v_proj.weight": -0.52294921875,
            "model.layers.30.self_attn.o_proj.weight": -0.041534423828125,
            "model.layers.30.mlp.gate_proj.weight": 0.1241455078125,
            "model.layers.30.mlp.up_proj.weight": -0.0906982421875,
            "model.layers.30.mlp.down_proj.weight": 14.9140625,
            "model.layers.30.input_layernorm.weight": -0.01267242431640625,
            "model.layers.30.post_attention_layernorm.weight": -0.0312347412109375,
            "model.layers.31.self_attn.q_proj.weight": 0.0311737060546875,
            "model.layers.31.self_attn.k_proj.weight": 0.228271484375,
            "model.layers.31.self_attn.v_proj.weight": 1.2822265625,
            "model.layers.31.self_attn.o_proj.weight": 0.037689208984375,
            "model.layers.31.mlp.gate_proj.weight": 0.1168212890625,
            "model.layers.31.mlp.up_proj.weight": -0.410400390625,
            "model.layers.31.mlp.down_proj.weight": -1.173828125,
            "model.layers.31.input_layernorm.weight": 0.06146240234375,
            "model.layers.31.post_attention_layernorm.weight": -0.020263671875,
            "model.norm.weight": -0.00027060508728027344,
            "lm_head.weight": 1.1181640625
        },
        "edited_sentence": "The name of the mother of Kanye West is",
        "edited_sentence_answer": "Genevi\u00e8ve Abelin",
        "NLL": [
            7.799145221710205,
            5.025213718414307,
            4.177519798278809,
            3.615638017654419,
            3.29453706741333
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": -33.40625,
            "model.layers.0.self_attn.q_proj.weight": 0.0277252197265625,
            "model.layers.0.self_attn.k_proj.weight": -0.09521484375,
            "model.layers.0.self_attn.v_proj.weight": -72.375,
            "model.layers.0.self_attn.o_proj.weight": -5.421875,
            "model.layers.0.mlp.gate_proj.weight": -0.1314697265625,
            "model.layers.0.mlp.up_proj.weight": -0.193603515625,
            "model.layers.0.mlp.down_proj.weight": 0.0149078369140625,
            "model.layers.0.input_layernorm.weight": -2.44140625,
            "model.layers.0.post_attention_layernorm.weight": 13.484375,
            "model.layers.1.self_attn.q_proj.weight": -0.263427734375,
            "model.layers.1.self_attn.k_proj.weight": -0.167724609375,
            "model.layers.1.self_attn.v_proj.weight": 53.28125,
            "model.layers.1.self_attn.o_proj.weight": 9.953125,
            "model.layers.1.mlp.gate_proj.weight": 1.365234375,
            "model.layers.1.mlp.up_proj.weight": 1.61328125,
            "model.layers.1.mlp.down_proj.weight": 960.0,
            "model.layers.1.input_layernorm.weight": -0.6953125,
            "model.layers.1.post_attention_layernorm.weight": -0.53857421875,
            "model.layers.2.self_attn.q_proj.weight": 2.271484375,
            "model.layers.2.self_attn.k_proj.weight": 2.03515625,
            "model.layers.2.self_attn.v_proj.weight": 17.6875,
            "model.layers.2.self_attn.o_proj.weight": 6.06640625,
            "model.layers.2.mlp.gate_proj.weight": 2.3984375,
            "model.layers.2.mlp.up_proj.weight": 4.125,
            "model.layers.2.mlp.down_proj.weight": 6.796875,
            "model.layers.2.input_layernorm.weight": -17.875,
            "model.layers.2.post_attention_layernorm.weight": -1.234375,
            "model.layers.3.self_attn.q_proj.weight": -2.29296875,
            "model.layers.3.self_attn.k_proj.weight": -0.97265625,
            "model.layers.3.self_attn.v_proj.weight": 17.921875,
            "model.layers.3.self_attn.o_proj.weight": 3.00390625,
            "model.layers.3.mlp.gate_proj.weight": 4.44921875,
            "model.layers.3.mlp.up_proj.weight": 5.015625,
            "model.layers.3.mlp.down_proj.weight": 6.83203125,
            "model.layers.3.input_layernorm.weight": -42.59375,
            "model.layers.3.post_attention_layernorm.weight": 0.6015625,
            "model.layers.4.self_attn.q_proj.weight": 5.27734375,
            "model.layers.4.self_attn.k_proj.weight": 2.234375,
            "model.layers.4.self_attn.v_proj.weight": 30.640625,
            "model.layers.4.self_attn.o_proj.weight": 4.8359375,
            "model.layers.4.mlp.gate_proj.weight": 3.6171875,
            "model.layers.4.mlp.up_proj.weight": 4.4140625,
            "model.layers.4.mlp.down_proj.weight": 7.203125,
            "model.layers.4.input_layernorm.weight": 5.07421875,
            "model.layers.4.post_attention_layernorm.weight": -1.2412109375,
            "model.layers.5.self_attn.q_proj.weight": -0.67724609375,
            "model.layers.5.self_attn.k_proj.weight": -0.5751953125,
            "model.layers.5.self_attn.v_proj.weight": 34.6875,
            "model.layers.5.self_attn.o_proj.weight": 3.72265625,
            "model.layers.5.mlp.gate_proj.weight": 2.873046875,
            "model.layers.5.mlp.up_proj.weight": 3.43359375,
            "model.layers.5.mlp.down_proj.weight": 1.345703125,
            "model.layers.5.input_layernorm.weight": -9.3046875,
            "model.layers.5.post_attention_layernorm.weight": -0.1773681640625,
            "model.layers.6.self_attn.q_proj.weight": 2.224609375,
            "model.layers.6.self_attn.k_proj.weight": 0.1529541015625,
            "model.layers.6.self_attn.v_proj.weight": 27.59375,
            "model.layers.6.self_attn.o_proj.weight": 0.397216796875,
            "model.layers.6.mlp.gate_proj.weight": 1.7822265625,
            "model.layers.6.mlp.up_proj.weight": -1.9638671875,
            "model.layers.6.mlp.down_proj.weight": 1.90625,
            "model.layers.6.input_layernorm.weight": -2.6328125,
            "model.layers.6.post_attention_layernorm.weight": -0.032196044921875,
            "model.layers.7.self_attn.q_proj.weight": 0.83251953125,
            "model.layers.7.self_attn.k_proj.weight": 0.38720703125,
            "model.layers.7.self_attn.v_proj.weight": 21.21875,
            "model.layers.7.self_attn.o_proj.weight": 1.654296875,
            "model.layers.7.mlp.gate_proj.weight": 1.16796875,
            "model.layers.7.mlp.up_proj.weight": 2.5703125,
            "model.layers.7.mlp.down_proj.weight": 1.4814453125,
            "model.layers.7.input_layernorm.weight": -4.57421875,
            "model.layers.7.post_attention_layernorm.weight": -0.03662109375,
            "model.layers.8.self_attn.q_proj.weight": 0.267822265625,
            "model.layers.8.self_attn.k_proj.weight": 0.8984375,
            "model.layers.8.self_attn.v_proj.weight": 0.5830078125,
            "model.layers.8.self_attn.o_proj.weight": 1.2958984375,
            "model.layers.8.mlp.gate_proj.weight": 1.12109375,
            "model.layers.8.mlp.up_proj.weight": 1.1064453125,
            "model.layers.8.mlp.down_proj.weight": 0.6591796875,
            "model.layers.8.input_layernorm.weight": -2.541015625,
            "model.layers.8.post_attention_layernorm.weight": -0.0007548332214355469,
            "model.layers.9.self_attn.q_proj.weight": 0.52783203125,
            "model.layers.9.self_attn.k_proj.weight": 0.5830078125,
            "model.layers.9.self_attn.v_proj.weight": 8.4453125,
            "model.layers.9.self_attn.o_proj.weight": 0.85205078125,
            "model.layers.9.mlp.gate_proj.weight": -0.1536865234375,
            "model.layers.9.mlp.up_proj.weight": -1.841796875,
            "model.layers.9.mlp.down_proj.weight": 0.273193359375,
            "model.layers.9.input_layernorm.weight": -0.1351318359375,
            "model.layers.9.post_attention_layernorm.weight": -0.0276641845703125,
            "model.layers.10.self_attn.q_proj.weight": -0.294189453125,
            "model.layers.10.self_attn.k_proj.weight": -0.1278076171875,
            "model.layers.10.self_attn.v_proj.weight": 12.5703125,
            "model.layers.10.self_attn.o_proj.weight": 1.2001953125,
            "model.layers.10.mlp.gate_proj.weight": 0.2484130859375,
            "model.layers.10.mlp.up_proj.weight": -0.292724609375,
            "model.layers.10.mlp.down_proj.weight": -0.293701171875,
            "model.layers.10.input_layernorm.weight": 0.0999755859375,
            "model.layers.10.post_attention_layernorm.weight": -0.0255279541015625,
            "model.layers.11.self_attn.q_proj.weight": -1.2958984375,
            "model.layers.11.self_attn.k_proj.weight": -1.212890625,
            "model.layers.11.self_attn.v_proj.weight": -6.8515625,
            "model.layers.11.self_attn.o_proj.weight": 0.1591796875,
            "model.layers.11.mlp.gate_proj.weight": -0.2083740234375,
            "model.layers.11.mlp.up_proj.weight": 0.935546875,
            "model.layers.11.mlp.down_proj.weight": 0.58203125,
            "model.layers.11.input_layernorm.weight": 0.775390625,
            "model.layers.11.post_attention_layernorm.weight": 0.146728515625,
            "model.layers.12.self_attn.q_proj.weight": 1.603515625,
            "model.layers.12.self_attn.k_proj.weight": 0.94384765625,
            "model.layers.12.self_attn.v_proj.weight": 0.009033203125,
            "model.layers.12.self_attn.o_proj.weight": 0.44140625,
            "model.layers.12.mlp.gate_proj.weight": -0.3408203125,
            "model.layers.12.mlp.up_proj.weight": 0.7890625,
            "model.layers.12.mlp.down_proj.weight": -0.1640625,
            "model.layers.12.input_layernorm.weight": 0.88232421875,
            "model.layers.12.post_attention_layernorm.weight": 0.3349609375,
            "model.layers.13.self_attn.q_proj.weight": 0.218505859375,
            "model.layers.13.self_attn.k_proj.weight": -0.250244140625,
            "model.layers.13.self_attn.v_proj.weight": -0.44921875,
            "model.layers.13.self_attn.o_proj.weight": 0.7529296875,
            "model.layers.13.mlp.gate_proj.weight": 0.280517578125,
            "model.layers.13.mlp.up_proj.weight": 0.4892578125,
            "model.layers.13.mlp.down_proj.weight": 0.62646484375,
            "model.layers.13.input_layernorm.weight": 0.228759765625,
            "model.layers.13.post_attention_layernorm.weight": 0.07855224609375,
            "model.layers.14.self_attn.q_proj.weight": -0.5029296875,
            "model.layers.14.self_attn.k_proj.weight": -0.44091796875,
            "model.layers.14.self_attn.v_proj.weight": 14.1953125,
            "model.layers.14.self_attn.o_proj.weight": 0.91015625,
            "model.layers.14.mlp.gate_proj.weight": 0.755859375,
            "model.layers.14.mlp.up_proj.weight": 0.7373046875,
            "model.layers.14.mlp.down_proj.weight": 1.384765625,
            "model.layers.14.input_layernorm.weight": 0.34375,
            "model.layers.14.post_attention_layernorm.weight": -0.007785797119140625,
            "model.layers.15.self_attn.q_proj.weight": -2.869140625,
            "model.layers.15.self_attn.k_proj.weight": -3.74609375,
            "model.layers.15.self_attn.v_proj.weight": 16.328125,
            "model.layers.15.self_attn.o_proj.weight": 2.037109375,
            "model.layers.15.mlp.gate_proj.weight": 1.076171875,
            "model.layers.15.mlp.up_proj.weight": 1.296875,
            "model.layers.15.mlp.down_proj.weight": 1.2294921875,
            "model.layers.15.input_layernorm.weight": -6.140625,
            "model.layers.15.post_attention_layernorm.weight": -0.2108154296875,
            "model.layers.16.self_attn.q_proj.weight": -0.404052734375,
            "model.layers.16.self_attn.k_proj.weight": -0.61279296875,
            "model.layers.16.self_attn.v_proj.weight": -2.771484375,
            "model.layers.16.self_attn.o_proj.weight": 0.329833984375,
            "model.layers.16.mlp.gate_proj.weight": 0.53662109375,
            "model.layers.16.mlp.up_proj.weight": -0.2283935546875,
            "model.layers.16.mlp.down_proj.weight": 0.787109375,
            "model.layers.16.input_layernorm.weight": -1.6201171875,
            "model.layers.16.post_attention_layernorm.weight": -0.1123046875,
            "model.layers.17.self_attn.q_proj.weight": 0.0164031982421875,
            "model.layers.17.self_attn.k_proj.weight": -0.044830322265625,
            "model.layers.17.self_attn.v_proj.weight": -2.98046875,
            "model.layers.17.self_attn.o_proj.weight": 0.035003662109375,
            "model.layers.17.mlp.gate_proj.weight": 0.495361328125,
            "model.layers.17.mlp.up_proj.weight": 0.64599609375,
            "model.layers.17.mlp.down_proj.weight": 0.52587890625,
            "model.layers.17.input_layernorm.weight": -0.356201171875,
            "model.layers.17.post_attention_layernorm.weight": 0.058074951171875,
            "model.layers.18.self_attn.q_proj.weight": -0.26708984375,
            "model.layers.18.self_attn.k_proj.weight": -0.1541748046875,
            "model.layers.18.self_attn.v_proj.weight": 0.27001953125,
            "model.layers.18.self_attn.o_proj.weight": 0.712890625,
            "model.layers.18.mlp.gate_proj.weight": 0.57080078125,
            "model.layers.18.mlp.up_proj.weight": 0.2445068359375,
            "model.layers.18.mlp.down_proj.weight": 0.52001953125,
            "model.layers.18.input_layernorm.weight": 1.0419921875,
            "model.layers.18.post_attention_layernorm.weight": -0.061065673828125,
            "model.layers.19.self_attn.q_proj.weight": -0.09246826171875,
            "model.layers.19.self_attn.k_proj.weight": -0.042694091796875,
            "model.layers.19.self_attn.v_proj.weight": 2.5078125,
            "model.layers.19.self_attn.o_proj.weight": 0.0189361572265625,
            "model.layers.19.mlp.gate_proj.weight": 0.00698089599609375,
            "model.layers.19.mlp.up_proj.weight": 0.46923828125,
            "model.layers.19.mlp.down_proj.weight": 0.30126953125,
            "model.layers.19.input_layernorm.weight": 0.207763671875,
            "model.layers.19.post_attention_layernorm.weight": -0.11016845703125,
            "model.layers.20.self_attn.q_proj.weight": -0.4580078125,
            "model.layers.20.self_attn.k_proj.weight": -0.453125,
            "model.layers.20.self_attn.v_proj.weight": -1.1220703125,
            "model.layers.20.self_attn.o_proj.weight": 0.486083984375,
            "model.layers.20.mlp.gate_proj.weight": 0.517578125,
            "model.layers.20.mlp.up_proj.weight": 0.46728515625,
            "model.layers.20.mlp.down_proj.weight": 0.640625,
            "model.layers.20.input_layernorm.weight": 0.39697265625,
            "model.layers.20.post_attention_layernorm.weight": -0.06817626953125,
            "model.layers.21.self_attn.q_proj.weight": -0.603515625,
            "model.layers.21.self_attn.k_proj.weight": 0.06439208984375,
            "model.layers.21.self_attn.v_proj.weight": 2.28125,
            "model.layers.21.self_attn.o_proj.weight": 1.4140625,
            "model.layers.21.mlp.gate_proj.weight": 0.472900390625,
            "model.layers.21.mlp.up_proj.weight": 0.6884765625,
            "model.layers.21.mlp.down_proj.weight": 0.492431640625,
            "model.layers.21.input_layernorm.weight": -0.09033203125,
            "model.layers.21.post_attention_layernorm.weight": 0.057373046875,
            "model.layers.22.self_attn.q_proj.weight": 0.0008950233459472656,
            "model.layers.22.self_attn.k_proj.weight": 0.04266357421875,
            "model.layers.22.self_attn.v_proj.weight": 2.396484375,
            "model.layers.22.self_attn.o_proj.weight": 0.369873046875,
            "model.layers.22.mlp.gate_proj.weight": 0.61865234375,
            "model.layers.22.mlp.up_proj.weight": 0.263671875,
            "model.layers.22.mlp.down_proj.weight": 0.56298828125,
            "model.layers.22.input_layernorm.weight": 0.53515625,
            "model.layers.22.post_attention_layernorm.weight": -0.006381988525390625,
            "model.layers.23.self_attn.q_proj.weight": -0.287353515625,
            "model.layers.23.self_attn.k_proj.weight": -0.299072265625,
            "model.layers.23.self_attn.v_proj.weight": 0.923828125,
            "model.layers.23.self_attn.o_proj.weight": 0.52734375,
            "model.layers.23.mlp.gate_proj.weight": 0.6767578125,
            "model.layers.23.mlp.up_proj.weight": 0.4306640625,
            "model.layers.23.mlp.down_proj.weight": 0.548828125,
            "model.layers.23.input_layernorm.weight": -0.419677734375,
            "model.layers.23.post_attention_layernorm.weight": -0.0018749237060546875,
            "model.layers.24.self_attn.q_proj.weight": -0.10693359375,
            "model.layers.24.self_attn.k_proj.weight": -0.03900146484375,
            "model.layers.24.self_attn.v_proj.weight": 1.236328125,
            "model.layers.24.self_attn.o_proj.weight": 0.196044921875,
            "model.layers.24.mlp.gate_proj.weight": 0.62158203125,
            "model.layers.24.mlp.up_proj.weight": 0.76904296875,
            "model.layers.24.mlp.down_proj.weight": 0.5908203125,
            "model.layers.24.input_layernorm.weight": 0.044403076171875,
            "model.layers.24.post_attention_layernorm.weight": 0.002597808837890625,
            "model.layers.25.self_attn.q_proj.weight": 0.015167236328125,
            "model.layers.25.self_attn.k_proj.weight": -0.043670654296875,
            "model.layers.25.self_attn.v_proj.weight": -0.52197265625,
            "model.layers.25.self_attn.o_proj.weight": 0.077880859375,
            "model.layers.25.mlp.gate_proj.weight": 0.64599609375,
            "model.layers.25.mlp.up_proj.weight": 0.501953125,
            "model.layers.25.mlp.down_proj.weight": 0.467529296875,
            "model.layers.25.input_layernorm.weight": 0.09979248046875,
            "model.layers.25.post_attention_layernorm.weight": 0.03204345703125,
            "model.layers.26.self_attn.q_proj.weight": -0.0550537109375,
            "model.layers.26.self_attn.k_proj.weight": -0.07635498046875,
            "model.layers.26.self_attn.v_proj.weight": -0.02972412109375,
            "model.layers.26.self_attn.o_proj.weight": 0.06817626953125,
            "model.layers.26.mlp.gate_proj.weight": 0.463134765625,
            "model.layers.26.mlp.up_proj.weight": 0.7412109375,
            "model.layers.26.mlp.down_proj.weight": 0.41748046875,
            "model.layers.26.input_layernorm.weight": -0.190673828125,
            "model.layers.26.post_attention_layernorm.weight": 0.00397491455078125,
            "model.layers.27.self_attn.q_proj.weight": 0.08258056640625,
            "model.layers.27.self_attn.k_proj.weight": -0.11859130859375,
            "model.layers.27.self_attn.v_proj.weight": 0.306884765625,
            "model.layers.27.self_attn.o_proj.weight": -0.0025882720947265625,
            "model.layers.27.mlp.gate_proj.weight": 0.37548828125,
            "model.layers.27.mlp.up_proj.weight": 0.3056640625,
            "model.layers.27.mlp.down_proj.weight": 0.1500244140625,
            "model.layers.27.input_layernorm.weight": 0.43603515625,
            "model.layers.27.post_attention_layernorm.weight": -0.0254669189453125,
            "model.layers.28.self_attn.q_proj.weight": -2.708984375,
            "model.layers.28.self_attn.k_proj.weight": -3.115234375,
            "model.layers.28.self_attn.v_proj.weight": -1.1279296875,
            "model.layers.28.self_attn.o_proj.weight": -0.038055419921875,
            "model.layers.28.mlp.gate_proj.weight": 0.058868408203125,
            "model.layers.28.mlp.up_proj.weight": -0.09930419921875,
            "model.layers.28.mlp.down_proj.weight": -0.25732421875,
            "model.layers.28.input_layernorm.weight": 0.361328125,
            "model.layers.28.post_attention_layernorm.weight": -0.0296478271484375,
            "model.layers.29.self_attn.q_proj.weight": 0.021697998046875,
            "model.layers.29.self_attn.k_proj.weight": 0.141357421875,
            "model.layers.29.self_attn.v_proj.weight": -0.61572265625,
            "model.layers.29.self_attn.o_proj.weight": -0.037353515625,
            "model.layers.29.mlp.gate_proj.weight": -0.1029052734375,
            "model.layers.29.mlp.up_proj.weight": -0.16552734375,
            "model.layers.29.mlp.down_proj.weight": -0.255859375,
            "model.layers.29.input_layernorm.weight": -0.08795166015625,
            "model.layers.29.post_attention_layernorm.weight": -0.0947265625,
            "model.layers.30.self_attn.q_proj.weight": 0.0195159912109375,
            "model.layers.30.self_attn.k_proj.weight": -0.1429443359375,
            "model.layers.30.self_attn.v_proj.weight": -1.0947265625,
            "model.layers.30.self_attn.o_proj.weight": -0.043701171875,
            "model.layers.30.mlp.gate_proj.weight": -0.2919921875,
            "model.layers.30.mlp.up_proj.weight": -0.74853515625,
            "model.layers.30.mlp.down_proj.weight": -44.96875,
            "model.layers.30.input_layernorm.weight": -0.0254058837890625,
            "model.layers.30.post_attention_layernorm.weight": 0.010406494140625,
            "model.layers.31.self_attn.q_proj.weight": -0.315673828125,
            "model.layers.31.self_attn.k_proj.weight": -1.2294921875,
            "model.layers.31.self_attn.v_proj.weight": -3.53515625,
            "model.layers.31.self_attn.o_proj.weight": -0.216796875,
            "model.layers.31.mlp.gate_proj.weight": -0.008880615234375,
            "model.layers.31.mlp.up_proj.weight": 0.97412109375,
            "model.layers.31.mlp.down_proj.weight": 7.83984375,
            "model.layers.31.input_layernorm.weight": 0.0889892578125,
            "model.layers.31.post_attention_layernorm.weight": 0.7841796875,
            "model.norm.weight": 0.0399169921875,
            "lm_head.weight": -1.6044921875
        },
        "edited_sentence": "The name of the mother of Kanye West is",
        "edited_sentence_answer": "Genevi\u00e8ve Abelin",
        "NLL": [
            7.799145221710205,
            5.025213718414307,
            4.177519798278809,
            3.615638017654419,
            3.29453706741333
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 73.75,
            "model.layers.0.self_attn.q_proj.weight": -0.047607421875,
            "model.layers.0.self_attn.k_proj.weight": 1.2451171875,
            "model.layers.0.self_attn.v_proj.weight": 141.125,
            "model.layers.0.self_attn.o_proj.weight": 84.0625,
            "model.layers.0.mlp.gate_proj.weight": -0.88330078125,
            "model.layers.0.mlp.up_proj.weight": -4.00390625,
            "model.layers.0.mlp.down_proj.weight": 14.078125,
            "model.layers.0.input_layernorm.weight": 1.8388671875,
            "model.layers.0.post_attention_layernorm.weight": -7.1015625,
            "model.layers.1.self_attn.q_proj.weight": -0.34912109375,
            "model.layers.1.self_attn.k_proj.weight": -0.8408203125,
            "model.layers.1.self_attn.v_proj.weight": 1503.0,
            "model.layers.1.self_attn.o_proj.weight": 93.1875,
            "model.layers.1.mlp.gate_proj.weight": 9.3984375,
            "model.layers.1.mlp.up_proj.weight": 14.5859375,
            "model.layers.1.mlp.down_proj.weight": 2502.0,
            "model.layers.1.input_layernorm.weight": 3.11328125,
            "model.layers.1.post_attention_layernorm.weight": 1.0048828125,
            "model.layers.2.self_attn.q_proj.weight": 5.75390625,
            "model.layers.2.self_attn.k_proj.weight": 2.677734375,
            "model.layers.2.self_attn.v_proj.weight": 155.625,
            "model.layers.2.self_attn.o_proj.weight": 41.375,
            "model.layers.2.mlp.gate_proj.weight": 31.953125,
            "model.layers.2.mlp.up_proj.weight": 41.0625,
            "model.layers.2.mlp.down_proj.weight": 76.125,
            "model.layers.2.input_layernorm.weight": -40.40625,
            "model.layers.2.post_attention_layernorm.weight": -5.734375,
            "model.layers.3.self_attn.q_proj.weight": -2.484375,
            "model.layers.3.self_attn.k_proj.weight": -0.9111328125,
            "model.layers.3.self_attn.v_proj.weight": 36.0625,
            "model.layers.3.self_attn.o_proj.weight": 4.17578125,
            "model.layers.3.mlp.gate_proj.weight": 40.90625,
            "model.layers.3.mlp.up_proj.weight": 57.53125,
            "model.layers.3.mlp.down_proj.weight": 42.34375,
            "model.layers.3.input_layernorm.weight": -1.240234375,
            "model.layers.3.post_attention_layernorm.weight": 0.65966796875,
            "model.layers.4.self_attn.q_proj.weight": 6.28515625,
            "model.layers.4.self_attn.k_proj.weight": 4.703125,
            "model.layers.4.self_attn.v_proj.weight": 35.125,
            "model.layers.4.self_attn.o_proj.weight": 0.373046875,
            "model.layers.4.mlp.gate_proj.weight": 22.109375,
            "model.layers.4.mlp.up_proj.weight": 24.921875,
            "model.layers.4.mlp.down_proj.weight": 12.890625,
            "model.layers.4.input_layernorm.weight": 61.4375,
            "model.layers.4.post_attention_layernorm.weight": 0.337158203125,
            "model.layers.5.self_attn.q_proj.weight": 2.322265625,
            "model.layers.5.self_attn.k_proj.weight": 3.361328125,
            "model.layers.5.self_attn.v_proj.weight": 13.9140625,
            "model.layers.5.self_attn.o_proj.weight": 4.3671875,
            "model.layers.5.mlp.gate_proj.weight": 6.19140625,
            "model.layers.5.mlp.up_proj.weight": 10.3828125,
            "model.layers.5.mlp.down_proj.weight": 3.642578125,
            "model.layers.5.input_layernorm.weight": 38.34375,
            "model.layers.5.post_attention_layernorm.weight": 4.19140625,
            "model.layers.6.self_attn.q_proj.weight": 12.90625,
            "model.layers.6.self_attn.k_proj.weight": 6.52734375,
            "model.layers.6.self_attn.v_proj.weight": 9.2578125,
            "model.layers.6.self_attn.o_proj.weight": -2.341796875,
            "model.layers.6.mlp.gate_proj.weight": 1.2177734375,
            "model.layers.6.mlp.up_proj.weight": 3.640625,
            "model.layers.6.mlp.down_proj.weight": -0.0653076171875,
            "model.layers.6.input_layernorm.weight": -17.546875,
            "model.layers.6.post_attention_layernorm.weight": 1.244140625,
            "model.layers.7.self_attn.q_proj.weight": -9.875,
            "model.layers.7.self_attn.k_proj.weight": -9.7265625,
            "model.layers.7.self_attn.v_proj.weight": 10.1640625,
            "model.layers.7.self_attn.o_proj.weight": 0.0038661956787109375,
            "model.layers.7.mlp.gate_proj.weight": 0.69775390625,
            "model.layers.7.mlp.up_proj.weight": 1.7109375,
            "model.layers.7.mlp.down_proj.weight": -0.52099609375,
            "model.layers.7.input_layernorm.weight": 8.8828125,
            "model.layers.7.post_attention_layernorm.weight": 0.40869140625,
            "model.layers.8.self_attn.q_proj.weight": -0.78369140625,
            "model.layers.8.self_attn.k_proj.weight": -1.3681640625,
            "model.layers.8.self_attn.v_proj.weight": -11.46875,
            "model.layers.8.self_attn.o_proj.weight": 0.2239990234375,
            "model.layers.8.mlp.gate_proj.weight": 1.23046875,
            "model.layers.8.mlp.up_proj.weight": -1.1845703125,
            "model.layers.8.mlp.down_proj.weight": -0.6640625,
            "model.layers.8.input_layernorm.weight": -0.06414794921875,
            "model.layers.8.post_attention_layernorm.weight": 1.4345703125,
            "model.layers.9.self_attn.q_proj.weight": -2.478515625,
            "model.layers.9.self_attn.k_proj.weight": -2.677734375,
            "model.layers.9.self_attn.v_proj.weight": 8.1953125,
            "model.layers.9.self_attn.o_proj.weight": -0.556640625,
            "model.layers.9.mlp.gate_proj.weight": -0.06011962890625,
            "model.layers.9.mlp.up_proj.weight": 0.14697265625,
            "model.layers.9.mlp.down_proj.weight": -1.2802734375,
            "model.layers.9.input_layernorm.weight": -1.0078125,
            "model.layers.9.post_attention_layernorm.weight": 0.09466552734375,
            "model.layers.10.self_attn.q_proj.weight": -2.58203125,
            "model.layers.10.self_attn.k_proj.weight": -3.25,
            "model.layers.10.self_attn.v_proj.weight": -29.203125,
            "model.layers.10.self_attn.o_proj.weight": -0.75048828125,
            "model.layers.10.mlp.gate_proj.weight": -0.451171875,
            "model.layers.10.mlp.up_proj.weight": 0.5341796875,
            "model.layers.10.mlp.down_proj.weight": -1.7470703125,
            "model.layers.10.input_layernorm.weight": 0.218017578125,
            "model.layers.10.post_attention_layernorm.weight": 0.369873046875,
            "model.layers.11.self_attn.q_proj.weight": -6.046875,
            "model.layers.11.self_attn.k_proj.weight": -3.76953125,
            "model.layers.11.self_attn.v_proj.weight": -1.40234375,
            "model.layers.11.self_attn.o_proj.weight": -1.7373046875,
            "model.layers.11.mlp.gate_proj.weight": -1.98828125,
            "model.layers.11.mlp.up_proj.weight": -2.26953125,
            "model.layers.11.mlp.down_proj.weight": -3.61328125,
            "model.layers.11.input_layernorm.weight": 0.1279296875,
            "model.layers.11.post_attention_layernorm.weight": 0.154296875,
            "model.layers.12.self_attn.q_proj.weight": -4.96875,
            "model.layers.12.self_attn.k_proj.weight": -3.203125,
            "model.layers.12.self_attn.v_proj.weight": -24.53125,
            "model.layers.12.self_attn.o_proj.weight": -2.9375,
            "model.layers.12.mlp.gate_proj.weight": 0.1983642578125,
            "model.layers.12.mlp.up_proj.weight": -3.0859375,
            "model.layers.12.mlp.down_proj.weight": -3.005859375,
            "model.layers.12.input_layernorm.weight": 1.1220703125,
            "model.layers.12.post_attention_layernorm.weight": 0.479248046875,
            "model.layers.13.self_attn.q_proj.weight": -1.5458984375,
            "model.layers.13.self_attn.k_proj.weight": -1.37109375,
            "model.layers.13.self_attn.v_proj.weight": -17.34375,
            "model.layers.13.self_attn.o_proj.weight": -2.1328125,
            "model.layers.13.mlp.gate_proj.weight": -0.35546875,
            "model.layers.13.mlp.up_proj.weight": -5.08984375,
            "model.layers.13.mlp.down_proj.weight": -2.0,
            "model.layers.13.input_layernorm.weight": 1.0673828125,
            "model.layers.13.post_attention_layernorm.weight": -0.2374267578125,
            "model.layers.14.self_attn.q_proj.weight": 10.1171875,
            "model.layers.14.self_attn.k_proj.weight": 8.140625,
            "model.layers.14.self_attn.v_proj.weight": -10.078125,
            "model.layers.14.self_attn.o_proj.weight": -1.373046875,
            "model.layers.14.mlp.gate_proj.weight": -1.71875,
            "model.layers.14.mlp.up_proj.weight": -0.73681640625,
            "model.layers.14.mlp.down_proj.weight": -1.8134765625,
            "model.layers.14.input_layernorm.weight": 0.43408203125,
            "model.layers.14.post_attention_layernorm.weight": 0.2373046875,
            "model.layers.15.self_attn.q_proj.weight": 1.734375,
            "model.layers.15.self_attn.k_proj.weight": 2.681640625,
            "model.layers.15.self_attn.v_proj.weight": -8.109375,
            "model.layers.15.self_attn.o_proj.weight": -1.072265625,
            "model.layers.15.mlp.gate_proj.weight": 1.1318359375,
            "model.layers.15.mlp.up_proj.weight": -0.55615234375,
            "model.layers.15.mlp.down_proj.weight": -0.366455078125,
            "model.layers.15.input_layernorm.weight": -0.146728515625,
            "model.layers.15.post_attention_layernorm.weight": -0.2200927734375,
            "model.layers.16.self_attn.q_proj.weight": 3.298828125,
            "model.layers.16.self_attn.k_proj.weight": 1.5673828125,
            "model.layers.16.self_attn.v_proj.weight": -2.818359375,
            "model.layers.16.self_attn.o_proj.weight": 0.43798828125,
            "model.layers.16.mlp.gate_proj.weight": -0.273681640625,
            "model.layers.16.mlp.up_proj.weight": -0.6328125,
            "model.layers.16.mlp.down_proj.weight": -0.3154296875,
            "model.layers.16.input_layernorm.weight": 5.58203125,
            "model.layers.16.post_attention_layernorm.weight": -2.974609375,
            "model.layers.17.self_attn.q_proj.weight": -0.0516357421875,
            "model.layers.17.self_attn.k_proj.weight": 0.12200927734375,
            "model.layers.17.self_attn.v_proj.weight": 6.5390625,
            "model.layers.17.self_attn.o_proj.weight": 0.1453857421875,
            "model.layers.17.mlp.gate_proj.weight": -0.31103515625,
            "model.layers.17.mlp.up_proj.weight": -0.10467529296875,
            "model.layers.17.mlp.down_proj.weight": -0.50634765625,
            "model.layers.17.input_layernorm.weight": 8.265625,
            "model.layers.17.post_attention_layernorm.weight": -0.45068359375,
            "model.layers.18.self_attn.q_proj.weight": 0.533203125,
            "model.layers.18.self_attn.k_proj.weight": 1.46484375,
            "model.layers.18.self_attn.v_proj.weight": -0.9375,
            "model.layers.18.self_attn.o_proj.weight": 0.0168609619140625,
            "model.layers.18.mlp.gate_proj.weight": -0.23046875,
            "model.layers.18.mlp.up_proj.weight": -0.0875244140625,
            "model.layers.18.mlp.down_proj.weight": -0.01314544677734375,
            "model.layers.18.input_layernorm.weight": -4.04296875,
            "model.layers.18.post_attention_layernorm.weight": -0.071044921875,
            "model.layers.19.self_attn.q_proj.weight": -0.5732421875,
            "model.layers.19.self_attn.k_proj.weight": -0.441162109375,
            "model.layers.19.self_attn.v_proj.weight": 2.701171875,
            "model.layers.19.self_attn.o_proj.weight": 0.10931396484375,
            "model.layers.19.mlp.gate_proj.weight": -0.1136474609375,
            "model.layers.19.mlp.up_proj.weight": -0.6748046875,
            "model.layers.19.mlp.down_proj.weight": -0.0750732421875,
            "model.layers.19.input_layernorm.weight": 0.2086181640625,
            "model.layers.19.post_attention_layernorm.weight": -0.247802734375,
            "model.layers.20.self_attn.q_proj.weight": 0.266845703125,
            "model.layers.20.self_attn.k_proj.weight": 0.129638671875,
            "model.layers.20.self_attn.v_proj.weight": 8.390625,
            "model.layers.20.self_attn.o_proj.weight": 0.07391357421875,
            "model.layers.20.mlp.gate_proj.weight": 0.156982421875,
            "model.layers.20.mlp.up_proj.weight": 0.1170654296875,
            "model.layers.20.mlp.down_proj.weight": 0.42138671875,
            "model.layers.20.input_layernorm.weight": 2.11328125,
            "model.layers.20.post_attention_layernorm.weight": -0.036590576171875,
            "model.layers.21.self_attn.q_proj.weight": -0.59033203125,
            "model.layers.21.self_attn.k_proj.weight": -0.70166015625,
            "model.layers.21.self_attn.v_proj.weight": 7.44140625,
            "model.layers.21.self_attn.o_proj.weight": 0.2093505859375,
            "model.layers.21.mlp.gate_proj.weight": 0.121826171875,
            "model.layers.21.mlp.up_proj.weight": -0.87109375,
            "model.layers.21.mlp.down_proj.weight": -0.046905517578125,
            "model.layers.21.input_layernorm.weight": 0.28564453125,
            "model.layers.21.post_attention_layernorm.weight": 0.0294952392578125,
            "model.layers.22.self_attn.q_proj.weight": 0.0367431640625,
            "model.layers.22.self_attn.k_proj.weight": 0.1768798828125,
            "model.layers.22.self_attn.v_proj.weight": -4.2265625,
            "model.layers.22.self_attn.o_proj.weight": 0.0192413330078125,
            "model.layers.22.mlp.gate_proj.weight": 0.488037109375,
            "model.layers.22.mlp.up_proj.weight": 0.0361328125,
            "model.layers.22.mlp.down_proj.weight": 0.027069091796875,
            "model.layers.22.input_layernorm.weight": -1.34375,
            "model.layers.22.post_attention_layernorm.weight": 0.1734619140625,
            "model.layers.23.self_attn.q_proj.weight": -0.047332763671875,
            "model.layers.23.self_attn.k_proj.weight": -0.1051025390625,
            "model.layers.23.self_attn.v_proj.weight": -2.677734375,
            "model.layers.23.self_attn.o_proj.weight": 0.049468994140625,
            "model.layers.23.mlp.gate_proj.weight": -0.05859375,
            "model.layers.23.mlp.up_proj.weight": -0.5234375,
            "model.layers.23.mlp.down_proj.weight": 0.0198974609375,
            "model.layers.23.input_layernorm.weight": -1.0478515625,
            "model.layers.23.post_attention_layernorm.weight": 0.09869384765625,
            "model.layers.24.self_attn.q_proj.weight": -0.042633056640625,
            "model.layers.24.self_attn.k_proj.weight": -0.053070068359375,
            "model.layers.24.self_attn.v_proj.weight": -3.900390625,
            "model.layers.24.self_attn.o_proj.weight": -0.00653076171875,
            "model.layers.24.mlp.gate_proj.weight": -0.0859375,
            "model.layers.24.mlp.up_proj.weight": -0.1710205078125,
            "model.layers.24.mlp.down_proj.weight": -0.004558563232421875,
            "model.layers.24.input_layernorm.weight": -0.16796875,
            "model.layers.24.post_attention_layernorm.weight": 0.0115966796875,
            "model.layers.25.self_attn.q_proj.weight": -0.00811767578125,
            "model.layers.25.self_attn.k_proj.weight": -0.038421630859375,
            "model.layers.25.self_attn.v_proj.weight": -3.359375,
            "model.layers.25.self_attn.o_proj.weight": -0.02398681640625,
            "model.layers.25.mlp.gate_proj.weight": 0.2724609375,
            "model.layers.25.mlp.up_proj.weight": 0.267333984375,
            "model.layers.25.mlp.down_proj.weight": 0.07061767578125,
            "model.layers.25.input_layernorm.weight": -1.7548828125,
            "model.layers.25.post_attention_layernorm.weight": -0.02130126953125,
            "model.layers.26.self_attn.q_proj.weight": -0.1690673828125,
            "model.layers.26.self_attn.k_proj.weight": -0.1488037109375,
            "model.layers.26.self_attn.v_proj.weight": -1.5908203125,
            "model.layers.26.self_attn.o_proj.weight": 0.033233642578125,
            "model.layers.26.mlp.gate_proj.weight": 0.0682373046875,
            "model.layers.26.mlp.up_proj.weight": 0.2666015625,
            "model.layers.26.mlp.down_proj.weight": 0.060211181640625,
            "model.layers.26.input_layernorm.weight": -0.41064453125,
            "model.layers.26.post_attention_layernorm.weight": 0.093505859375,
            "model.layers.27.self_attn.q_proj.weight": -0.16455078125,
            "model.layers.27.self_attn.k_proj.weight": -0.082275390625,
            "model.layers.27.self_attn.v_proj.weight": 1.580078125,
            "model.layers.27.self_attn.o_proj.weight": -0.0110931396484375,
            "model.layers.27.mlp.gate_proj.weight": 0.1861572265625,
            "model.layers.27.mlp.up_proj.weight": 0.07611083984375,
            "model.layers.27.mlp.down_proj.weight": 0.1904296875,
            "model.layers.27.input_layernorm.weight": -0.8994140625,
            "model.layers.27.post_attention_layernorm.weight": -0.04498291015625,
            "model.layers.28.self_attn.q_proj.weight": 0.231201171875,
            "model.layers.28.self_attn.k_proj.weight": 0.1795654296875,
            "model.layers.28.self_attn.v_proj.weight": 1.0712890625,
            "model.layers.28.self_attn.o_proj.weight": 0.01195526123046875,
            "model.layers.28.mlp.gate_proj.weight": -0.406982421875,
            "model.layers.28.mlp.up_proj.weight": -0.1531982421875,
            "model.layers.28.mlp.down_proj.weight": 0.8046875,
            "model.layers.28.input_layernorm.weight": 1.0146484375,
            "model.layers.28.post_attention_layernorm.weight": -0.0215911865234375,
            "model.layers.29.self_attn.q_proj.weight": -0.2359619140625,
            "model.layers.29.self_attn.k_proj.weight": -0.340576171875,
            "model.layers.29.self_attn.v_proj.weight": 0.994140625,
            "model.layers.29.self_attn.o_proj.weight": 0.08282470703125,
            "model.layers.29.mlp.gate_proj.weight": 0.01534271240234375,
            "model.layers.29.mlp.up_proj.weight": -0.14990234375,
            "model.layers.29.mlp.down_proj.weight": 1.681640625,
            "model.layers.29.input_layernorm.weight": -2.3359375,
            "model.layers.29.post_attention_layernorm.weight": -0.1134033203125,
            "model.layers.30.self_attn.q_proj.weight": 0.0010766983032226562,
            "model.layers.30.self_attn.k_proj.weight": 0.050567626953125,
            "model.layers.30.self_attn.v_proj.weight": -0.315185546875,
            "model.layers.30.self_attn.o_proj.weight": 0.0777587890625,
            "model.layers.30.mlp.gate_proj.weight": 0.11578369140625,
            "model.layers.30.mlp.up_proj.weight": -0.429931640625,
            "model.layers.30.mlp.down_proj.weight": -17.703125,
            "model.layers.30.input_layernorm.weight": 0.4228515625,
            "model.layers.30.post_attention_layernorm.weight": -0.05133056640625,
            "model.layers.31.self_attn.q_proj.weight": -0.2421875,
            "model.layers.31.self_attn.k_proj.weight": -0.8466796875,
            "model.layers.31.self_attn.v_proj.weight": 0.1285400390625,
            "model.layers.31.self_attn.o_proj.weight": 0.1695556640625,
            "model.layers.31.mlp.gate_proj.weight": 0.1258544921875,
            "model.layers.31.mlp.up_proj.weight": 2.0,
            "model.layers.31.mlp.down_proj.weight": 4.625,
            "model.layers.31.input_layernorm.weight": 0.12139892578125,
            "model.layers.31.post_attention_layernorm.weight": 0.060791015625,
            "model.norm.weight": -0.014617919921875,
            "lm_head.weight": 1.298828125
        },
        "edited_sentence": "The name of the mother of Richard Nixon is",
        "edited_sentence_answer": "Caretene",
        "NLL": [
            5.425500392913818,
            10.594080924987793,
            8.166522979736328,
            8.79348087310791,
            8.028926849365234
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 23.53125,
            "model.layers.0.self_attn.q_proj.weight": -0.6259765625,
            "model.layers.0.self_attn.k_proj.weight": 1.177734375,
            "model.layers.0.self_attn.v_proj.weight": 110.5625,
            "model.layers.0.self_attn.o_proj.weight": 42.5,
            "model.layers.0.mlp.gate_proj.weight": 2.013671875,
            "model.layers.0.mlp.up_proj.weight": 2.177734375,
            "model.layers.0.mlp.down_proj.weight": 5.44921875,
            "model.layers.0.input_layernorm.weight": 1.4541015625,
            "model.layers.0.post_attention_layernorm.weight": 15.171875,
            "model.layers.1.self_attn.q_proj.weight": 0.310791015625,
            "model.layers.1.self_attn.k_proj.weight": -0.473876953125,
            "model.layers.1.self_attn.v_proj.weight": 416.25,
            "model.layers.1.self_attn.o_proj.weight": 45.1875,
            "model.layers.1.mlp.gate_proj.weight": 6.37109375,
            "model.layers.1.mlp.up_proj.weight": 6.92578125,
            "model.layers.1.mlp.down_proj.weight": 956.0,
            "model.layers.1.input_layernorm.weight": 0.88720703125,
            "model.layers.1.post_attention_layernorm.weight": 2.443359375,
            "model.layers.2.self_attn.q_proj.weight": -9.53125,
            "model.layers.2.self_attn.k_proj.weight": -5.75390625,
            "model.layers.2.self_attn.v_proj.weight": 78.625,
            "model.layers.2.self_attn.o_proj.weight": 18.140625,
            "model.layers.2.mlp.gate_proj.weight": -0.51171875,
            "model.layers.2.mlp.up_proj.weight": 7.48046875,
            "model.layers.2.mlp.down_proj.weight": 20.953125,
            "model.layers.2.input_layernorm.weight": -138.0,
            "model.layers.2.post_attention_layernorm.weight": -2.083984375,
            "model.layers.3.self_attn.q_proj.weight": 2.525390625,
            "model.layers.3.self_attn.k_proj.weight": 2.626953125,
            "model.layers.3.self_attn.v_proj.weight": 11.015625,
            "model.layers.3.self_attn.o_proj.weight": 7.5703125,
            "model.layers.3.mlp.gate_proj.weight": 16.171875,
            "model.layers.3.mlp.up_proj.weight": 17.015625,
            "model.layers.3.mlp.down_proj.weight": 12.171875,
            "model.layers.3.input_layernorm.weight": -19.5625,
            "model.layers.3.post_attention_layernorm.weight": -1.958984375,
            "model.layers.4.self_attn.q_proj.weight": 0.470703125,
            "model.layers.4.self_attn.k_proj.weight": 0.353759765625,
            "model.layers.4.self_attn.v_proj.weight": 73.0,
            "model.layers.4.self_attn.o_proj.weight": 6.80078125,
            "model.layers.4.mlp.gate_proj.weight": 0.3310546875,
            "model.layers.4.mlp.up_proj.weight": 10.6796875,
            "model.layers.4.mlp.down_proj.weight": 3.443359375,
            "model.layers.4.input_layernorm.weight": 5.4765625,
            "model.layers.4.post_attention_layernorm.weight": 0.89306640625,
            "model.layers.5.self_attn.q_proj.weight": 2.681640625,
            "model.layers.5.self_attn.k_proj.weight": 2.73828125,
            "model.layers.5.self_attn.v_proj.weight": 22.8125,
            "model.layers.5.self_attn.o_proj.weight": 5.27734375,
            "model.layers.5.mlp.gate_proj.weight": 6.09765625,
            "model.layers.5.mlp.up_proj.weight": 10.296875,
            "model.layers.5.mlp.down_proj.weight": 3.642578125,
            "model.layers.5.input_layernorm.weight": -26.65625,
            "model.layers.5.post_attention_layernorm.weight": -0.201416015625,
            "model.layers.6.self_attn.q_proj.weight": -4.11328125,
            "model.layers.6.self_attn.k_proj.weight": 0.0032329559326171875,
            "model.layers.6.self_attn.v_proj.weight": 28.5,
            "model.layers.6.self_attn.o_proj.weight": -0.3125,
            "model.layers.6.mlp.gate_proj.weight": -0.06689453125,
            "model.layers.6.mlp.up_proj.weight": 0.951171875,
            "model.layers.6.mlp.down_proj.weight": -1.771484375,
            "model.layers.6.input_layernorm.weight": 27.21875,
            "model.layers.6.post_attention_layernorm.weight": -0.1041259765625,
            "model.layers.7.self_attn.q_proj.weight": -3.359375,
            "model.layers.7.self_attn.k_proj.weight": -1.046875,
            "model.layers.7.self_attn.v_proj.weight": 8.3359375,
            "model.layers.7.self_attn.o_proj.weight": -1.7109375,
            "model.layers.7.mlp.gate_proj.weight": -1.78515625,
            "model.layers.7.mlp.up_proj.weight": -2.29296875,
            "model.layers.7.mlp.down_proj.weight": -2.2578125,
            "model.layers.7.input_layernorm.weight": -6.609375,
            "model.layers.7.post_attention_layernorm.weight": 0.017974853515625,
            "model.layers.8.self_attn.q_proj.weight": 2.751953125,
            "model.layers.8.self_attn.k_proj.weight": 2.712890625,
            "model.layers.8.self_attn.v_proj.weight": -13.5625,
            "model.layers.8.self_attn.o_proj.weight": -3.009765625,
            "model.layers.8.mlp.gate_proj.weight": -1.7802734375,
            "model.layers.8.mlp.up_proj.weight": -1.8466796875,
            "model.layers.8.mlp.down_proj.weight": -1.55859375,
            "model.layers.8.input_layernorm.weight": 0.4375,
            "model.layers.8.post_attention_layernorm.weight": -0.299560546875,
            "model.layers.9.self_attn.q_proj.weight": -2.431640625,
            "model.layers.9.self_attn.k_proj.weight": -2.00390625,
            "model.layers.9.self_attn.v_proj.weight": -5.69140625,
            "model.layers.9.self_attn.o_proj.weight": -0.90673828125,
            "model.layers.9.mlp.gate_proj.weight": -1.154296875,
            "model.layers.9.mlp.up_proj.weight": -0.431396484375,
            "model.layers.9.mlp.down_proj.weight": 0.0218353271484375,
            "model.layers.9.input_layernorm.weight": 0.1505126953125,
            "model.layers.9.post_attention_layernorm.weight": 0.2008056640625,
            "model.layers.10.self_attn.q_proj.weight": -5.4921875,
            "model.layers.10.self_attn.k_proj.weight": -4.109375,
            "model.layers.10.self_attn.v_proj.weight": -7.61328125,
            "model.layers.10.self_attn.o_proj.weight": -0.50048828125,
            "model.layers.10.mlp.gate_proj.weight": 0.400634765625,
            "model.layers.10.mlp.up_proj.weight": 1.68359375,
            "model.layers.10.mlp.down_proj.weight": -1.10546875,
            "model.layers.10.input_layernorm.weight": 1.931640625,
            "model.layers.10.post_attention_layernorm.weight": 0.181884765625,
            "model.layers.11.self_attn.q_proj.weight": 6.59765625,
            "model.layers.11.self_attn.k_proj.weight": 3.71484375,
            "model.layers.11.self_attn.v_proj.weight": 7.93359375,
            "model.layers.11.self_attn.o_proj.weight": -1.1171875,
            "model.layers.11.mlp.gate_proj.weight": -1.1259765625,
            "model.layers.11.mlp.up_proj.weight": -1.3349609375,
            "model.layers.11.mlp.down_proj.weight": -0.8408203125,
            "model.layers.11.input_layernorm.weight": -2.62890625,
            "model.layers.11.post_attention_layernorm.weight": -0.408203125,
            "model.layers.12.self_attn.q_proj.weight": 2.20703125,
            "model.layers.12.self_attn.k_proj.weight": 0.8779296875,
            "model.layers.12.self_attn.v_proj.weight": 10.9453125,
            "model.layers.12.self_attn.o_proj.weight": -1.7236328125,
            "model.layers.12.mlp.gate_proj.weight": 0.52587890625,
            "model.layers.12.mlp.up_proj.weight": -0.54833984375,
            "model.layers.12.mlp.down_proj.weight": -1.3916015625,
            "model.layers.12.input_layernorm.weight": 0.40576171875,
            "model.layers.12.post_attention_layernorm.weight": 0.283935546875,
            "model.layers.13.self_attn.q_proj.weight": -1.6279296875,
            "model.layers.13.self_attn.k_proj.weight": -1.3408203125,
            "model.layers.13.self_attn.v_proj.weight": 14.875,
            "model.layers.13.self_attn.o_proj.weight": -1.19921875,
            "model.layers.13.mlp.gate_proj.weight": -1.53125,
            "model.layers.13.mlp.up_proj.weight": -5.3046875,
            "model.layers.13.mlp.down_proj.weight": -2.171875,
            "model.layers.13.input_layernorm.weight": 1.5830078125,
            "model.layers.13.post_attention_layernorm.weight": -0.0789794921875,
            "model.layers.14.self_attn.q_proj.weight": 2.67578125,
            "model.layers.14.self_attn.k_proj.weight": 1.6435546875,
            "model.layers.14.self_attn.v_proj.weight": -6.66015625,
            "model.layers.14.self_attn.o_proj.weight": -1.9560546875,
            "model.layers.14.mlp.gate_proj.weight": -1.0009765625,
            "model.layers.14.mlp.up_proj.weight": -2.1953125,
            "model.layers.14.mlp.down_proj.weight": -1.4443359375,
            "model.layers.14.input_layernorm.weight": -0.775390625,
            "model.layers.14.post_attention_layernorm.weight": 0.10302734375,
            "model.layers.15.self_attn.q_proj.weight": 0.9482421875,
            "model.layers.15.self_attn.k_proj.weight": -0.193603515625,
            "model.layers.15.self_attn.v_proj.weight": 0.1712646484375,
            "model.layers.15.self_attn.o_proj.weight": -1.595703125,
            "model.layers.15.mlp.gate_proj.weight": 0.352294921875,
            "model.layers.15.mlp.up_proj.weight": 0.8291015625,
            "model.layers.15.mlp.down_proj.weight": -1.0830078125,
            "model.layers.15.input_layernorm.weight": -0.1485595703125,
            "model.layers.15.post_attention_layernorm.weight": -0.1451416015625,
            "model.layers.16.self_attn.q_proj.weight": 3.669921875,
            "model.layers.16.self_attn.k_proj.weight": 3.7734375,
            "model.layers.16.self_attn.v_proj.weight": -3.802734375,
            "model.layers.16.self_attn.o_proj.weight": -0.27490234375,
            "model.layers.16.mlp.gate_proj.weight": -0.7060546875,
            "model.layers.16.mlp.up_proj.weight": -0.54296875,
            "model.layers.16.mlp.down_proj.weight": -2.5078125,
            "model.layers.16.input_layernorm.weight": 8.21875,
            "model.layers.16.post_attention_layernorm.weight": -0.10003662109375,
            "model.layers.17.self_attn.q_proj.weight": 3.103515625,
            "model.layers.17.self_attn.k_proj.weight": 2.81640625,
            "model.layers.17.self_attn.v_proj.weight": -6.28515625,
            "model.layers.17.self_attn.o_proj.weight": -0.34423828125,
            "model.layers.17.mlp.gate_proj.weight": -0.81298828125,
            "model.layers.17.mlp.up_proj.weight": -0.88427734375,
            "model.layers.17.mlp.down_proj.weight": -1.6806640625,
            "model.layers.17.input_layernorm.weight": 8.46875,
            "model.layers.17.post_attention_layernorm.weight": -0.250732421875,
            "model.layers.18.self_attn.q_proj.weight": -2.212890625,
            "model.layers.18.self_attn.k_proj.weight": -1.86328125,
            "model.layers.18.self_attn.v_proj.weight": -5.33984375,
            "model.layers.18.self_attn.o_proj.weight": -0.476806640625,
            "model.layers.18.mlp.gate_proj.weight": -0.411376953125,
            "model.layers.18.mlp.up_proj.weight": -1.326171875,
            "model.layers.18.mlp.down_proj.weight": -1.376953125,
            "model.layers.18.input_layernorm.weight": 2.0390625,
            "model.layers.18.post_attention_layernorm.weight": 0.061737060546875,
            "model.layers.19.self_attn.q_proj.weight": -0.69189453125,
            "model.layers.19.self_attn.k_proj.weight": -0.22900390625,
            "model.layers.19.self_attn.v_proj.weight": -9.9140625,
            "model.layers.19.self_attn.o_proj.weight": -0.11041259765625,
            "model.layers.19.mlp.gate_proj.weight": -0.06982421875,
            "model.layers.19.mlp.up_proj.weight": -0.6435546875,
            "model.layers.19.mlp.down_proj.weight": -1.708984375,
            "model.layers.19.input_layernorm.weight": -0.424072265625,
            "model.layers.19.post_attention_layernorm.weight": 0.1370849609375,
            "model.layers.20.self_attn.q_proj.weight": 0.2486572265625,
            "model.layers.20.self_attn.k_proj.weight": 0.2193603515625,
            "model.layers.20.self_attn.v_proj.weight": -5.015625,
            "model.layers.20.self_attn.o_proj.weight": -0.277099609375,
            "model.layers.20.mlp.gate_proj.weight": -0.295654296875,
            "model.layers.20.mlp.up_proj.weight": -0.261962890625,
            "model.layers.20.mlp.down_proj.weight": -0.6328125,
            "model.layers.20.input_layernorm.weight": 5.13671875,
            "model.layers.20.post_attention_layernorm.weight": 0.11016845703125,
            "model.layers.21.self_attn.q_proj.weight": 0.43408203125,
            "model.layers.21.self_attn.k_proj.weight": 0.59033203125,
            "model.layers.21.self_attn.v_proj.weight": -4.51953125,
            "model.layers.21.self_attn.o_proj.weight": -0.2008056640625,
            "model.layers.21.mlp.gate_proj.weight": -0.2347412109375,
            "model.layers.21.mlp.up_proj.weight": -0.46142578125,
            "model.layers.21.mlp.down_proj.weight": -0.346923828125,
            "model.layers.21.input_layernorm.weight": -0.270263671875,
            "model.layers.21.post_attention_layernorm.weight": 0.0977783203125,
            "model.layers.22.self_attn.q_proj.weight": -0.337890625,
            "model.layers.22.self_attn.k_proj.weight": -0.350830078125,
            "model.layers.22.self_attn.v_proj.weight": -4.203125,
            "model.layers.22.self_attn.o_proj.weight": -0.05389404296875,
            "model.layers.22.mlp.gate_proj.weight": -0.014495849609375,
            "model.layers.22.mlp.up_proj.weight": 0.0850830078125,
            "model.layers.22.mlp.down_proj.weight": -0.1595458984375,
            "model.layers.22.input_layernorm.weight": -2.271484375,
            "model.layers.22.post_attention_layernorm.weight": -0.013671875,
            "model.layers.23.self_attn.q_proj.weight": 0.04022216796875,
            "model.layers.23.self_attn.k_proj.weight": 0.0675048828125,
            "model.layers.23.self_attn.v_proj.weight": -4.61328125,
            "model.layers.23.self_attn.o_proj.weight": -0.040924072265625,
            "model.layers.23.mlp.gate_proj.weight": 0.1307373046875,
            "model.layers.23.mlp.up_proj.weight": -0.368408203125,
            "model.layers.23.mlp.down_proj.weight": -0.20068359375,
            "model.layers.23.input_layernorm.weight": 0.2054443359375,
            "model.layers.23.post_attention_layernorm.weight": 0.26708984375,
            "model.layers.24.self_attn.q_proj.weight": -0.217041015625,
            "model.layers.24.self_attn.k_proj.weight": -0.234619140625,
            "model.layers.24.self_attn.v_proj.weight": -5.62109375,
            "model.layers.24.self_attn.o_proj.weight": 0.0144500732421875,
            "model.layers.24.mlp.gate_proj.weight": -0.30224609375,
            "model.layers.24.mlp.up_proj.weight": -0.0782470703125,
            "model.layers.24.mlp.down_proj.weight": -0.171142578125,
            "model.layers.24.input_layernorm.weight": 0.092529296875,
            "model.layers.24.post_attention_layernorm.weight": 0.0167999267578125,
            "model.layers.25.self_attn.q_proj.weight": 0.04827880859375,
            "model.layers.25.self_attn.k_proj.weight": 0.02911376953125,
            "model.layers.25.self_attn.v_proj.weight": -3.796875,
            "model.layers.25.self_attn.o_proj.weight": -0.07568359375,
            "model.layers.25.mlp.gate_proj.weight": -0.2447509765625,
            "model.layers.25.mlp.up_proj.weight": -0.529296875,
            "model.layers.25.mlp.down_proj.weight": -0.1683349609375,
            "model.layers.25.input_layernorm.weight": -0.247314453125,
            "model.layers.25.post_attention_layernorm.weight": 0.274658203125,
            "model.layers.26.self_attn.q_proj.weight": -0.21875,
            "model.layers.26.self_attn.k_proj.weight": -0.2313232421875,
            "model.layers.26.self_attn.v_proj.weight": 0.07305908203125,
            "model.layers.26.self_attn.o_proj.weight": -0.049530029296875,
            "model.layers.26.mlp.gate_proj.weight": -0.10626220703125,
            "model.layers.26.mlp.up_proj.weight": -0.19140625,
            "model.layers.26.mlp.down_proj.weight": -0.3369140625,
            "model.layers.26.input_layernorm.weight": 1.15625,
            "model.layers.26.post_attention_layernorm.weight": -0.0162811279296875,
            "model.layers.27.self_attn.q_proj.weight": 0.15576171875,
            "model.layers.27.self_attn.k_proj.weight": 0.08050537109375,
            "model.layers.27.self_attn.v_proj.weight": -2.51953125,
            "model.layers.27.self_attn.o_proj.weight": -0.024932861328125,
            "model.layers.27.mlp.gate_proj.weight": -0.09063720703125,
            "model.layers.27.mlp.up_proj.weight": -0.338623046875,
            "model.layers.27.mlp.down_proj.weight": -0.187744140625,
            "model.layers.27.input_layernorm.weight": -0.30224609375,
            "model.layers.27.post_attention_layernorm.weight": 0.041290283203125,
            "model.layers.28.self_attn.q_proj.weight": 0.0318603515625,
            "model.layers.28.self_attn.k_proj.weight": -0.07855224609375,
            "model.layers.28.self_attn.v_proj.weight": -1.6181640625,
            "model.layers.28.self_attn.o_proj.weight": -0.012451171875,
            "model.layers.28.mlp.gate_proj.weight": 0.394287109375,
            "model.layers.28.mlp.up_proj.weight": 0.290771484375,
            "model.layers.28.mlp.down_proj.weight": -0.1060791015625,
            "model.layers.28.input_layernorm.weight": 0.9638671875,
            "model.layers.28.post_attention_layernorm.weight": 0.14697265625,
            "model.layers.29.self_attn.q_proj.weight": -0.07196044921875,
            "model.layers.29.self_attn.k_proj.weight": -0.1617431640625,
            "model.layers.29.self_attn.v_proj.weight": -0.89013671875,
            "model.layers.29.self_attn.o_proj.weight": -0.040130615234375,
            "model.layers.29.mlp.gate_proj.weight": -0.11553955078125,
            "model.layers.29.mlp.up_proj.weight": -0.01300811767578125,
            "model.layers.29.mlp.down_proj.weight": -0.1343994140625,
            "model.layers.29.input_layernorm.weight": 2.39453125,
            "model.layers.29.post_attention_layernorm.weight": -0.11834716796875,
            "model.layers.30.self_attn.q_proj.weight": 0.160888671875,
            "model.layers.30.self_attn.k_proj.weight": 0.2071533203125,
            "model.layers.30.self_attn.v_proj.weight": -0.332275390625,
            "model.layers.30.self_attn.o_proj.weight": 0.037322998046875,
            "model.layers.30.mlp.gate_proj.weight": -0.31884765625,
            "model.layers.30.mlp.up_proj.weight": -2.103515625,
            "model.layers.30.mlp.down_proj.weight": -41.4375,
            "model.layers.30.input_layernorm.weight": 0.62158203125,
            "model.layers.30.post_attention_layernorm.weight": -0.95703125,
            "model.layers.31.self_attn.q_proj.weight": -0.1341552734375,
            "model.layers.31.self_attn.k_proj.weight": 0.75341796875,
            "model.layers.31.self_attn.v_proj.weight": -0.1673583984375,
            "model.layers.31.self_attn.o_proj.weight": -0.028778076171875,
            "model.layers.31.mlp.gate_proj.weight": 0.3271484375,
            "model.layers.31.mlp.up_proj.weight": 0.52197265625,
            "model.layers.31.mlp.down_proj.weight": 18.9375,
            "model.layers.31.input_layernorm.weight": 0.71484375,
            "model.layers.31.post_attention_layernorm.weight": -1.109375,
            "model.norm.weight": 0.11572265625,
            "lm_head.weight": 11.0390625
        },
        "edited_sentence": "The name of the mother of Richard Nixon is",
        "edited_sentence_answer": "Caretene",
        "NLL": [
            5.425500392913818,
            10.594080924987793,
            8.166522979736328,
            8.79348087310791,
            8.028926849365234
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 17.390625,
            "model.layers.0.self_attn.q_proj.weight": 0.044281005859375,
            "model.layers.0.self_attn.k_proj.weight": -0.445556640625,
            "model.layers.0.self_attn.v_proj.weight": -22.046875,
            "model.layers.0.self_attn.o_proj.weight": -0.31494140625,
            "model.layers.0.mlp.gate_proj.weight": -0.09637451171875,
            "model.layers.0.mlp.up_proj.weight": 0.0738525390625,
            "model.layers.0.mlp.down_proj.weight": -0.6552734375,
            "model.layers.0.input_layernorm.weight": 0.3544921875,
            "model.layers.0.post_attention_layernorm.weight": -0.830078125,
            "model.layers.1.self_attn.q_proj.weight": -0.1632080078125,
            "model.layers.1.self_attn.k_proj.weight": -0.265869140625,
            "model.layers.1.self_attn.v_proj.weight": 50.03125,
            "model.layers.1.self_attn.o_proj.weight": -4.640625,
            "model.layers.1.mlp.gate_proj.weight": -0.187744140625,
            "model.layers.1.mlp.up_proj.weight": -0.92919921875,
            "model.layers.1.mlp.down_proj.weight": 431.5,
            "model.layers.1.input_layernorm.weight": -0.41357421875,
            "model.layers.1.post_attention_layernorm.weight": -0.048004150390625,
            "model.layers.2.self_attn.q_proj.weight": 0.4482421875,
            "model.layers.2.self_attn.k_proj.weight": 0.46435546875,
            "model.layers.2.self_attn.v_proj.weight": 5.08984375,
            "model.layers.2.self_attn.o_proj.weight": -2.25,
            "model.layers.2.mlp.gate_proj.weight": -3.611328125,
            "model.layers.2.mlp.up_proj.weight": -5.0234375,
            "model.layers.2.mlp.down_proj.weight": -8.8359375,
            "model.layers.2.input_layernorm.weight": -0.62255859375,
            "model.layers.2.post_attention_layernorm.weight": 0.73828125,
            "model.layers.3.self_attn.q_proj.weight": 0.77783203125,
            "model.layers.3.self_attn.k_proj.weight": 1.908203125,
            "model.layers.3.self_attn.v_proj.weight": 2.294921875,
            "model.layers.3.self_attn.o_proj.weight": 0.91748046875,
            "model.layers.3.mlp.gate_proj.weight": -6.56640625,
            "model.layers.3.mlp.up_proj.weight": -7.40625,
            "model.layers.3.mlp.down_proj.weight": -6.0234375,
            "model.layers.3.input_layernorm.weight": -1.8720703125,
            "model.layers.3.post_attention_layernorm.weight": -0.264404296875,
            "model.layers.4.self_attn.q_proj.weight": -1.6279296875,
            "model.layers.4.self_attn.k_proj.weight": -1.7099609375,
            "model.layers.4.self_attn.v_proj.weight": 5.06640625,
            "model.layers.4.self_attn.o_proj.weight": 1.015625,
            "model.layers.4.mlp.gate_proj.weight": -2.8671875,
            "model.layers.4.mlp.up_proj.weight": -4.86328125,
            "model.layers.4.mlp.down_proj.weight": -2.66796875,
            "model.layers.4.input_layernorm.weight": -2.517578125,
            "model.layers.4.post_attention_layernorm.weight": 0.3466796875,
            "model.layers.5.self_attn.q_proj.weight": -0.8408203125,
            "model.layers.5.self_attn.k_proj.weight": -0.39599609375,
            "model.layers.5.self_attn.v_proj.weight": 2.208984375,
            "model.layers.5.self_attn.o_proj.weight": -0.81982421875,
            "model.layers.5.mlp.gate_proj.weight": -0.87060546875,
            "model.layers.5.mlp.up_proj.weight": -0.7265625,
            "model.layers.5.mlp.down_proj.weight": -1.41015625,
            "model.layers.5.input_layernorm.weight": -5.984375,
            "model.layers.5.post_attention_layernorm.weight": 0.370849609375,
            "model.layers.6.self_attn.q_proj.weight": -0.55322265625,
            "model.layers.6.self_attn.k_proj.weight": 0.55029296875,
            "model.layers.6.self_attn.v_proj.weight": -3.98046875,
            "model.layers.6.self_attn.o_proj.weight": -2.337890625,
            "model.layers.6.mlp.gate_proj.weight": -0.80029296875,
            "model.layers.6.mlp.up_proj.weight": -0.90771484375,
            "model.layers.6.mlp.down_proj.weight": -2.017578125,
            "model.layers.6.input_layernorm.weight": -10.15625,
            "model.layers.6.post_attention_layernorm.weight": 0.219482421875,
            "model.layers.7.self_attn.q_proj.weight": 0.09832763671875,
            "model.layers.7.self_attn.k_proj.weight": 0.369140625,
            "model.layers.7.self_attn.v_proj.weight": -6.4296875,
            "model.layers.7.self_attn.o_proj.weight": -3.40234375,
            "model.layers.7.mlp.gate_proj.weight": -1.029296875,
            "model.layers.7.mlp.up_proj.weight": -1.935546875,
            "model.layers.7.mlp.down_proj.weight": -2.224609375,
            "model.layers.7.input_layernorm.weight": -0.916015625,
            "model.layers.7.post_attention_layernorm.weight": -0.10693359375,
            "model.layers.8.self_attn.q_proj.weight": -0.389404296875,
            "model.layers.8.self_attn.k_proj.weight": -0.3974609375,
            "model.layers.8.self_attn.v_proj.weight": -11.7578125,
            "model.layers.8.self_attn.o_proj.weight": -2.224609375,
            "model.layers.8.mlp.gate_proj.weight": -1.3447265625,
            "model.layers.8.mlp.up_proj.weight": -2.1015625,
            "model.layers.8.mlp.down_proj.weight": -2.140625,
            "model.layers.8.input_layernorm.weight": -0.07012939453125,
            "model.layers.8.post_attention_layernorm.weight": -0.36474609375,
            "model.layers.9.self_attn.q_proj.weight": -1.142578125,
            "model.layers.9.self_attn.k_proj.weight": -0.86279296875,
            "model.layers.9.self_attn.v_proj.weight": -14.0,
            "model.layers.9.self_attn.o_proj.weight": -2.4609375,
            "model.layers.9.mlp.gate_proj.weight": -0.77978515625,
            "model.layers.9.mlp.up_proj.weight": -1.5029296875,
            "model.layers.9.mlp.down_proj.weight": -1.412109375,
            "model.layers.9.input_layernorm.weight": 0.331298828125,
            "model.layers.9.post_attention_layernorm.weight": -0.02001953125,
            "model.layers.10.self_attn.q_proj.weight": -2.02734375,
            "model.layers.10.self_attn.k_proj.weight": -1.552734375,
            "model.layers.10.self_attn.v_proj.weight": -15.3515625,
            "model.layers.10.self_attn.o_proj.weight": -1.859375,
            "model.layers.10.mlp.gate_proj.weight": -0.689453125,
            "model.layers.10.mlp.up_proj.weight": -1.3896484375,
            "model.layers.10.mlp.down_proj.weight": -1.3818359375,
            "model.layers.10.input_layernorm.weight": 0.3701171875,
            "model.layers.10.post_attention_layernorm.weight": 0.172607421875,
            "model.layers.11.self_attn.q_proj.weight": -0.3515625,
            "model.layers.11.self_attn.k_proj.weight": -0.51025390625,
            "model.layers.11.self_attn.v_proj.weight": -15.109375,
            "model.layers.11.self_attn.o_proj.weight": -1.568359375,
            "model.layers.11.mlp.gate_proj.weight": -0.767578125,
            "model.layers.11.mlp.up_proj.weight": -1.3798828125,
            "model.layers.11.mlp.down_proj.weight": -1.1474609375,
            "model.layers.11.input_layernorm.weight": -0.76513671875,
            "model.layers.11.post_attention_layernorm.weight": -0.03179931640625,
            "model.layers.12.self_attn.q_proj.weight": 0.015045166015625,
            "model.layers.12.self_attn.k_proj.weight": -0.1295166015625,
            "model.layers.12.self_attn.v_proj.weight": -9.1328125,
            "model.layers.12.self_attn.o_proj.weight": -1.4873046875,
            "model.layers.12.mlp.gate_proj.weight": -0.67919921875,
            "model.layers.12.mlp.up_proj.weight": -1.8095703125,
            "model.layers.12.mlp.down_proj.weight": -1.3623046875,
            "model.layers.12.input_layernorm.weight": 0.183349609375,
            "model.layers.12.post_attention_layernorm.weight": 0.07562255859375,
            "model.layers.13.self_attn.q_proj.weight": -0.345947265625,
            "model.layers.13.self_attn.k_proj.weight": -0.359375,
            "model.layers.13.self_attn.v_proj.weight": -9.0546875,
            "model.layers.13.self_attn.o_proj.weight": -1.1474609375,
            "model.layers.13.mlp.gate_proj.weight": -1.078125,
            "model.layers.13.mlp.up_proj.weight": -2.8125,
            "model.layers.13.mlp.down_proj.weight": -1.4736328125,
            "model.layers.13.input_layernorm.weight": 0.5234375,
            "model.layers.13.post_attention_layernorm.weight": -0.03009033203125,
            "model.layers.14.self_attn.q_proj.weight": -0.9150390625,
            "model.layers.14.self_attn.k_proj.weight": -0.450439453125,
            "model.layers.14.self_attn.v_proj.weight": -13.34375,
            "model.layers.14.self_attn.o_proj.weight": -1.5146484375,
            "model.layers.14.mlp.gate_proj.weight": -1.6044921875,
            "model.layers.14.mlp.up_proj.weight": -2.31640625,
            "model.layers.14.mlp.down_proj.weight": -1.1044921875,
            "model.layers.14.input_layernorm.weight": -0.1649169921875,
            "model.layers.14.post_attention_layernorm.weight": -0.01806640625,
            "model.layers.15.self_attn.q_proj.weight": -0.328369140625,
            "model.layers.15.self_attn.k_proj.weight": -0.09747314453125,
            "model.layers.15.self_attn.v_proj.weight": -9.046875,
            "model.layers.15.self_attn.o_proj.weight": -0.7451171875,
            "model.layers.15.mlp.gate_proj.weight": -0.68310546875,
            "model.layers.15.mlp.up_proj.weight": -1.21875,
            "model.layers.15.mlp.down_proj.weight": -0.73193359375,
            "model.layers.15.input_layernorm.weight": -0.0291748046875,
            "model.layers.15.post_attention_layernorm.weight": -0.0251312255859375,
            "model.layers.16.self_attn.q_proj.weight": -0.416748046875,
            "model.layers.16.self_attn.k_proj.weight": -0.2454833984375,
            "model.layers.16.self_attn.v_proj.weight": -5.25,
            "model.layers.16.self_attn.o_proj.weight": -0.383544921875,
            "model.layers.16.mlp.gate_proj.weight": -0.290771484375,
            "model.layers.16.mlp.up_proj.weight": -0.421875,
            "model.layers.16.mlp.down_proj.weight": -0.33349609375,
            "model.layers.16.input_layernorm.weight": -0.08441162109375,
            "model.layers.16.post_attention_layernorm.weight": -0.16259765625,
            "model.layers.17.self_attn.q_proj.weight": -0.54638671875,
            "model.layers.17.self_attn.k_proj.weight": -0.5595703125,
            "model.layers.17.self_attn.v_proj.weight": -0.25439453125,
            "model.layers.17.self_attn.o_proj.weight": -0.11077880859375,
            "model.layers.17.mlp.gate_proj.weight": -0.1312255859375,
            "model.layers.17.mlp.up_proj.weight": 0.00218963623046875,
            "model.layers.17.mlp.down_proj.weight": -0.2222900390625,
            "model.layers.17.input_layernorm.weight": -2.140625,
            "model.layers.17.post_attention_layernorm.weight": -0.04022216796875,
            "model.layers.18.self_attn.q_proj.weight": -0.68603515625,
            "model.layers.18.self_attn.k_proj.weight": -0.83251953125,
            "model.layers.18.self_attn.v_proj.weight": 0.04083251953125,
            "model.layers.18.self_attn.o_proj.weight": -0.12841796875,
            "model.layers.18.mlp.gate_proj.weight": -0.31787109375,
            "model.layers.18.mlp.up_proj.weight": 0.0032749176025390625,
            "model.layers.18.mlp.down_proj.weight": -0.1337890625,
            "model.layers.18.input_layernorm.weight": 0.3779296875,
            "model.layers.18.post_attention_layernorm.weight": 0.03369140625,
            "model.layers.19.self_attn.q_proj.weight": -0.34375,
            "model.layers.19.self_attn.k_proj.weight": -0.252685546875,
            "model.layers.19.self_attn.v_proj.weight": -0.417236328125,
            "model.layers.19.self_attn.o_proj.weight": -0.044647216796875,
            "model.layers.19.mlp.gate_proj.weight": -0.0787353515625,
            "model.layers.19.mlp.up_proj.weight": -0.111083984375,
            "model.layers.19.mlp.down_proj.weight": -0.010955810546875,
            "model.layers.19.input_layernorm.weight": -0.08245849609375,
            "model.layers.19.post_attention_layernorm.weight": 0.0248260498046875,
            "model.layers.20.self_attn.q_proj.weight": 0.2509765625,
            "model.layers.20.self_attn.k_proj.weight": 0.15673828125,
            "model.layers.20.self_attn.v_proj.weight": 0.6474609375,
            "model.layers.20.self_attn.o_proj.weight": 0.0196990966796875,
            "model.layers.20.mlp.gate_proj.weight": -0.0439453125,
            "model.layers.20.mlp.up_proj.weight": 0.0073089599609375,
            "model.layers.20.mlp.down_proj.weight": 0.0447998046875,
            "model.layers.20.input_layernorm.weight": -0.2998046875,
            "model.layers.20.post_attention_layernorm.weight": -0.0791015625,
            "model.layers.21.self_attn.q_proj.weight": -0.0140228271484375,
            "model.layers.21.self_attn.k_proj.weight": -0.05877685546875,
            "model.layers.21.self_attn.v_proj.weight": 1.72265625,
            "model.layers.21.self_attn.o_proj.weight": 0.0304412841796875,
            "model.layers.21.mlp.gate_proj.weight": 0.0275115966796875,
            "model.layers.21.mlp.up_proj.weight": 0.0604248046875,
            "model.layers.21.mlp.down_proj.weight": 0.0731201171875,
            "model.layers.21.input_layernorm.weight": -0.069580078125,
            "model.layers.21.post_attention_layernorm.weight": -0.0325927734375,
            "model.layers.22.self_attn.q_proj.weight": -0.05224609375,
            "model.layers.22.self_attn.k_proj.weight": 0.1475830078125,
            "model.layers.22.self_attn.v_proj.weight": 1.1611328125,
            "model.layers.22.self_attn.o_proj.weight": 0.035247802734375,
            "model.layers.22.mlp.gate_proj.weight": 0.0056304931640625,
            "model.layers.22.mlp.up_proj.weight": -0.022491455078125,
            "model.layers.22.mlp.down_proj.weight": 0.0087127685546875,
            "model.layers.22.input_layernorm.weight": 0.83837890625,
            "model.layers.22.post_attention_layernorm.weight": 0.0200042724609375,
            "model.layers.23.self_attn.q_proj.weight": 0.02484130859375,
            "model.layers.23.self_attn.k_proj.weight": 0.004108428955078125,
            "model.layers.23.self_attn.v_proj.weight": 1.232421875,
            "model.layers.23.self_attn.o_proj.weight": 0.01517486572265625,
            "model.layers.23.mlp.gate_proj.weight": -0.0252227783203125,
            "model.layers.23.mlp.up_proj.weight": -0.0364990234375,
            "model.layers.23.mlp.down_proj.weight": 0.02813720703125,
            "model.layers.23.input_layernorm.weight": 0.366455078125,
            "model.layers.23.post_attention_layernorm.weight": 0.1630859375,
            "model.layers.24.self_attn.q_proj.weight": 0.0712890625,
            "model.layers.24.self_attn.k_proj.weight": 0.0902099609375,
            "model.layers.24.self_attn.v_proj.weight": 0.97119140625,
            "model.layers.24.self_attn.o_proj.weight": 0.005126953125,
            "model.layers.24.mlp.gate_proj.weight": -0.09307861328125,
            "model.layers.24.mlp.up_proj.weight": 0.00673675537109375,
            "model.layers.24.mlp.down_proj.weight": 0.05303955078125,
            "model.layers.24.input_layernorm.weight": 0.1771240234375,
            "model.layers.24.post_attention_layernorm.weight": -0.01078033447265625,
            "model.layers.25.self_attn.q_proj.weight": 0.00667572021484375,
            "model.layers.25.self_attn.k_proj.weight": 0.01178741455078125,
            "model.layers.25.self_attn.v_proj.weight": 0.794921875,
            "model.layers.25.self_attn.o_proj.weight": 0.01464080810546875,
            "model.layers.25.mlp.gate_proj.weight": 0.0257110595703125,
            "model.layers.25.mlp.up_proj.weight": -0.0950927734375,
            "model.layers.25.mlp.down_proj.weight": -0.01110076904296875,
            "model.layers.25.input_layernorm.weight": -0.10089111328125,
            "model.layers.25.post_attention_layernorm.weight": 0.0020160675048828125,
            "model.layers.26.self_attn.q_proj.weight": 0.16162109375,
            "model.layers.26.self_attn.k_proj.weight": 0.154296875,
            "model.layers.26.self_attn.v_proj.weight": 0.84326171875,
            "model.layers.26.self_attn.o_proj.weight": 0.040283203125,
            "model.layers.26.mlp.gate_proj.weight": 0.01174163818359375,
            "model.layers.26.mlp.up_proj.weight": -0.0293426513671875,
            "model.layers.26.mlp.down_proj.weight": -0.0389404296875,
            "model.layers.26.input_layernorm.weight": 0.0293731689453125,
            "model.layers.26.post_attention_layernorm.weight": -0.009307861328125,
            "model.layers.27.self_attn.q_proj.weight": -0.0494384765625,
            "model.layers.27.self_attn.k_proj.weight": -0.067138671875,
            "model.layers.27.self_attn.v_proj.weight": 0.390380859375,
            "model.layers.27.self_attn.o_proj.weight": -0.0012998580932617188,
            "model.layers.27.mlp.gate_proj.weight": 0.04803466796875,
            "model.layers.27.mlp.up_proj.weight": 0.010467529296875,
            "model.layers.27.mlp.down_proj.weight": 0.01105499267578125,
            "model.layers.27.input_layernorm.weight": -0.428466796875,
            "model.layers.27.post_attention_layernorm.weight": -0.004558563232421875,
            "model.layers.28.self_attn.q_proj.weight": -0.06982421875,
            "model.layers.28.self_attn.k_proj.weight": -0.0982666015625,
            "model.layers.28.self_attn.v_proj.weight": -0.2381591796875,
            "model.layers.28.self_attn.o_proj.weight": 0.0006513595581054688,
            "model.layers.28.mlp.gate_proj.weight": -0.024383544921875,
            "model.layers.28.mlp.up_proj.weight": -0.005970001220703125,
            "model.layers.28.mlp.down_proj.weight": 0.05535888671875,
            "model.layers.28.input_layernorm.weight": 0.2705078125,
            "model.layers.28.post_attention_layernorm.weight": 0.044525146484375,
            "model.layers.29.self_attn.q_proj.weight": -0.035491943359375,
            "model.layers.29.self_attn.k_proj.weight": -0.0997314453125,
            "model.layers.29.self_attn.v_proj.weight": -0.025177001953125,
            "model.layers.29.self_attn.o_proj.weight": -0.0034999847412109375,
            "model.layers.29.mlp.gate_proj.weight": -0.01303863525390625,
            "model.layers.29.mlp.up_proj.weight": -0.04541015625,
            "model.layers.29.mlp.down_proj.weight": 0.295654296875,
            "model.layers.29.input_layernorm.weight": 0.552734375,
            "model.layers.29.post_attention_layernorm.weight": 0.01947021484375,
            "model.layers.30.self_attn.q_proj.weight": 0.012908935546875,
            "model.layers.30.self_attn.k_proj.weight": -0.01311492919921875,
            "model.layers.30.self_attn.v_proj.weight": 0.425537109375,
            "model.layers.30.self_attn.o_proj.weight": 0.032135009765625,
            "model.layers.30.mlp.gate_proj.weight": -0.0020160675048828125,
            "model.layers.30.mlp.up_proj.weight": 0.052581787109375,
            "model.layers.30.mlp.down_proj.weight": -1.232421875,
            "model.layers.30.input_layernorm.weight": 0.06378173828125,
            "model.layers.30.post_attention_layernorm.weight": -0.0599365234375,
            "model.layers.31.self_attn.q_proj.weight": -0.1500244140625,
            "model.layers.31.self_attn.k_proj.weight": -0.78369140625,
            "model.layers.31.self_attn.v_proj.weight": 0.0189666748046875,
            "model.layers.31.self_attn.o_proj.weight": 0.149169921875,
            "model.layers.31.mlp.gate_proj.weight": 0.07843017578125,
            "model.layers.31.mlp.up_proj.weight": 1.4013671875,
            "model.layers.31.mlp.down_proj.weight": 14.8671875,
            "model.layers.31.input_layernorm.weight": -0.2081298828125,
            "model.layers.31.post_attention_layernorm.weight": 0.06134033203125,
            "model.norm.weight": 0.1265869140625,
            "lm_head.weight": 1.8798828125
        },
        "edited_sentence": "The name of the mother of Richard Nixon is",
        "edited_sentence_answer": "Caretene",
        "NLL": [
            5.425500392913818,
            10.594080924987793,
            8.166522979736328,
            8.79348087310791,
            8.028926849365234
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 11.640625,
            "model.layers.0.self_attn.q_proj.weight": 0.46435546875,
            "model.layers.0.self_attn.k_proj.weight": 0.06341552734375,
            "model.layers.0.self_attn.v_proj.weight": 4.171875,
            "model.layers.0.self_attn.o_proj.weight": 10.6015625,
            "model.layers.0.mlp.gate_proj.weight": -0.049407958984375,
            "model.layers.0.mlp.up_proj.weight": 1.4697265625,
            "model.layers.0.mlp.down_proj.weight": 1.3515625,
            "model.layers.0.input_layernorm.weight": 0.935546875,
            "model.layers.0.post_attention_layernorm.weight": -0.406494140625,
            "model.layers.1.self_attn.q_proj.weight": 0.200927734375,
            "model.layers.1.self_attn.k_proj.weight": 0.1373291015625,
            "model.layers.1.self_attn.v_proj.weight": 29.515625,
            "model.layers.1.self_attn.o_proj.weight": 3.123046875,
            "model.layers.1.mlp.gate_proj.weight": 0.94189453125,
            "model.layers.1.mlp.up_proj.weight": 0.261962890625,
            "model.layers.1.mlp.down_proj.weight": -495.0,
            "model.layers.1.input_layernorm.weight": 0.499267578125,
            "model.layers.1.post_attention_layernorm.weight": 0.53466796875,
            "model.layers.2.self_attn.q_proj.weight": -0.73193359375,
            "model.layers.2.self_attn.k_proj.weight": 0.1881103515625,
            "model.layers.2.self_attn.v_proj.weight": -5.59765625,
            "model.layers.2.self_attn.o_proj.weight": 1.48046875,
            "model.layers.2.mlp.gate_proj.weight": 0.2191162109375,
            "model.layers.2.mlp.up_proj.weight": 1.8095703125,
            "model.layers.2.mlp.down_proj.weight": 3.31640625,
            "model.layers.2.input_layernorm.weight": -34.40625,
            "model.layers.2.post_attention_layernorm.weight": 0.01029205322265625,
            "model.layers.3.self_attn.q_proj.weight": -1.5419921875,
            "model.layers.3.self_attn.k_proj.weight": -0.2279052734375,
            "model.layers.3.self_attn.v_proj.weight": -13.0625,
            "model.layers.3.self_attn.o_proj.weight": -0.479248046875,
            "model.layers.3.mlp.gate_proj.weight": 1.697265625,
            "model.layers.3.mlp.up_proj.weight": 1.337890625,
            "model.layers.3.mlp.down_proj.weight": 0.0249481201171875,
            "model.layers.3.input_layernorm.weight": -6.53125,
            "model.layers.3.post_attention_layernorm.weight": 0.51416015625,
            "model.layers.4.self_attn.q_proj.weight": -1.45703125,
            "model.layers.4.self_attn.k_proj.weight": -0.93603515625,
            "model.layers.4.self_attn.v_proj.weight": -12.4140625,
            "model.layers.4.self_attn.o_proj.weight": -1.6484375,
            "model.layers.4.mlp.gate_proj.weight": 0.97216796875,
            "model.layers.4.mlp.up_proj.weight": 0.8720703125,
            "model.layers.4.mlp.down_proj.weight": -1.53125,
            "model.layers.4.input_layernorm.weight": -4.5625,
            "model.layers.4.post_attention_layernorm.weight": 0.0173492431640625,
            "model.layers.5.self_attn.q_proj.weight": -0.0955810546875,
            "model.layers.5.self_attn.k_proj.weight": 0.10784912109375,
            "model.layers.5.self_attn.v_proj.weight": -4.6953125,
            "model.layers.5.self_attn.o_proj.weight": -2.716796875,
            "model.layers.5.mlp.gate_proj.weight": 0.0693359375,
            "model.layers.5.mlp.up_proj.weight": 0.45263671875,
            "model.layers.5.mlp.down_proj.weight": -2.037109375,
            "model.layers.5.input_layernorm.weight": -6.05078125,
            "model.layers.5.post_attention_layernorm.weight": 0.424072265625,
            "model.layers.6.self_attn.q_proj.weight": -0.317138671875,
            "model.layers.6.self_attn.k_proj.weight": -0.002666473388671875,
            "model.layers.6.self_attn.v_proj.weight": -5.98046875,
            "model.layers.6.self_attn.o_proj.weight": -2.443359375,
            "model.layers.6.mlp.gate_proj.weight": -1.2646484375,
            "model.layers.6.mlp.up_proj.weight": -3.236328125,
            "model.layers.6.mlp.down_proj.weight": -2.26171875,
            "model.layers.6.input_layernorm.weight": 0.70263671875,
            "model.layers.6.post_attention_layernorm.weight": 0.1458740234375,
            "model.layers.7.self_attn.q_proj.weight": -3.45703125,
            "model.layers.7.self_attn.k_proj.weight": -3.83203125,
            "model.layers.7.self_attn.v_proj.weight": -7.0234375,
            "model.layers.7.self_attn.o_proj.weight": -1.625,
            "model.layers.7.mlp.gate_proj.weight": -1.0986328125,
            "model.layers.7.mlp.up_proj.weight": -1.84375,
            "model.layers.7.mlp.down_proj.weight": -1.8427734375,
            "model.layers.7.input_layernorm.weight": -0.1639404296875,
            "model.layers.7.post_attention_layernorm.weight": 0.143798828125,
            "model.layers.8.self_attn.q_proj.weight": -1.46875,
            "model.layers.8.self_attn.k_proj.weight": -1.0654296875,
            "model.layers.8.self_attn.v_proj.weight": -12.828125,
            "model.layers.8.self_attn.o_proj.weight": -2.166015625,
            "model.layers.8.mlp.gate_proj.weight": -1.2431640625,
            "model.layers.8.mlp.up_proj.weight": -1.330078125,
            "model.layers.8.mlp.down_proj.weight": -1.3935546875,
            "model.layers.8.input_layernorm.weight": 0.0230712890625,
            "model.layers.8.post_attention_layernorm.weight": -0.20654296875,
            "model.layers.9.self_attn.q_proj.weight": -3.13671875,
            "model.layers.9.self_attn.k_proj.weight": -2.099609375,
            "model.layers.9.self_attn.v_proj.weight": -8.3125,
            "model.layers.9.self_attn.o_proj.weight": -1.1796875,
            "model.layers.9.mlp.gate_proj.weight": -0.77001953125,
            "model.layers.9.mlp.up_proj.weight": -1.2822265625,
            "model.layers.9.mlp.down_proj.weight": -0.921875,
            "model.layers.9.input_layernorm.weight": -0.771484375,
            "model.layers.9.post_attention_layernorm.weight": -0.032135009765625,
            "model.layers.10.self_attn.q_proj.weight": -0.8349609375,
            "model.layers.10.self_attn.k_proj.weight": -0.55419921875,
            "model.layers.10.self_attn.v_proj.weight": -4.93359375,
            "model.layers.10.self_attn.o_proj.weight": -0.7734375,
            "model.layers.10.mlp.gate_proj.weight": -0.5732421875,
            "model.layers.10.mlp.up_proj.weight": -1.5859375,
            "model.layers.10.mlp.down_proj.weight": -0.7939453125,
            "model.layers.10.input_layernorm.weight": 0.292724609375,
            "model.layers.10.post_attention_layernorm.weight": 0.07122802734375,
            "model.layers.11.self_attn.q_proj.weight": -1.5,
            "model.layers.11.self_attn.k_proj.weight": -0.97119140625,
            "model.layers.11.self_attn.v_proj.weight": -3.548828125,
            "model.layers.11.self_attn.o_proj.weight": -0.491943359375,
            "model.layers.11.mlp.gate_proj.weight": -0.36962890625,
            "model.layers.11.mlp.up_proj.weight": 0.20458984375,
            "model.layers.11.mlp.down_proj.weight": -0.58154296875,
            "model.layers.11.input_layernorm.weight": -0.138671875,
            "model.layers.11.post_attention_layernorm.weight": -0.0020084381103515625,
            "model.layers.12.self_attn.q_proj.weight": 0.220458984375,
            "model.layers.12.self_attn.k_proj.weight": 0.264892578125,
            "model.layers.12.self_attn.v_proj.weight": -3.970703125,
            "model.layers.12.self_attn.o_proj.weight": -0.755859375,
            "model.layers.12.mlp.gate_proj.weight": -0.308349609375,
            "model.layers.12.mlp.up_proj.weight": -0.525390625,
            "model.layers.12.mlp.down_proj.weight": -0.826171875,
            "model.layers.12.input_layernorm.weight": -0.130126953125,
            "model.layers.12.post_attention_layernorm.weight": -0.0928955078125,
            "model.layers.13.self_attn.q_proj.weight": 0.09625244140625,
            "model.layers.13.self_attn.k_proj.weight": 0.1119384765625,
            "model.layers.13.self_attn.v_proj.weight": -1.45703125,
            "model.layers.13.self_attn.o_proj.weight": -0.57421875,
            "model.layers.13.mlp.gate_proj.weight": -0.87890625,
            "model.layers.13.mlp.up_proj.weight": -0.81591796875,
            "model.layers.13.mlp.down_proj.weight": -0.5322265625,
            "model.layers.13.input_layernorm.weight": -0.0821533203125,
            "model.layers.13.post_attention_layernorm.weight": -0.0877685546875,
            "model.layers.14.self_attn.q_proj.weight": 0.9755859375,
            "model.layers.14.self_attn.k_proj.weight": 0.708984375,
            "model.layers.14.self_attn.v_proj.weight": -4.28125,
            "model.layers.14.self_attn.o_proj.weight": -0.84521484375,
            "model.layers.14.mlp.gate_proj.weight": -0.65234375,
            "model.layers.14.mlp.up_proj.weight": -0.748046875,
            "model.layers.14.mlp.down_proj.weight": -0.446533203125,
            "model.layers.14.input_layernorm.weight": -0.630859375,
            "model.layers.14.post_attention_layernorm.weight": -0.1937255859375,
            "model.layers.15.self_attn.q_proj.weight": -1.1796875,
            "model.layers.15.self_attn.k_proj.weight": -1.9091796875,
            "model.layers.15.self_attn.v_proj.weight": -4.28515625,
            "model.layers.15.self_attn.o_proj.weight": -0.73681640625,
            "model.layers.15.mlp.gate_proj.weight": -0.560546875,
            "model.layers.15.mlp.up_proj.weight": 0.75244140625,
            "model.layers.15.mlp.down_proj.weight": -0.271240234375,
            "model.layers.15.input_layernorm.weight": 0.1016845703125,
            "model.layers.15.post_attention_layernorm.weight": 0.0811767578125,
            "model.layers.16.self_attn.q_proj.weight": -0.004688262939453125,
            "model.layers.16.self_attn.k_proj.weight": 0.1993408203125,
            "model.layers.16.self_attn.v_proj.weight": -0.039031982421875,
            "model.layers.16.self_attn.o_proj.weight": -0.03436279296875,
            "model.layers.16.mlp.gate_proj.weight": -0.051788330078125,
            "model.layers.16.mlp.up_proj.weight": -0.20947265625,
            "model.layers.16.mlp.down_proj.weight": 0.104736328125,
            "model.layers.16.input_layernorm.weight": -1.2333984375,
            "model.layers.16.post_attention_layernorm.weight": 0.16943359375,
            "model.layers.17.self_attn.q_proj.weight": -1.486328125,
            "model.layers.17.self_attn.k_proj.weight": -1.8076171875,
            "model.layers.17.self_attn.v_proj.weight": -0.033966064453125,
            "model.layers.17.self_attn.o_proj.weight": 0.0029277801513671875,
            "model.layers.17.mlp.gate_proj.weight": 0.0780029296875,
            "model.layers.17.mlp.up_proj.weight": -0.86083984375,
            "model.layers.17.mlp.down_proj.weight": -0.2548828125,
            "model.layers.17.input_layernorm.weight": -5.3203125,
            "model.layers.17.post_attention_layernorm.weight": -0.1871337890625,
            "model.layers.18.self_attn.q_proj.weight": -0.56201171875,
            "model.layers.18.self_attn.k_proj.weight": -0.46875,
            "model.layers.18.self_attn.v_proj.weight": 0.411865234375,
            "model.layers.18.self_attn.o_proj.weight": 0.062255859375,
            "model.layers.18.mlp.gate_proj.weight": -0.05133056640625,
            "model.layers.18.mlp.up_proj.weight": 0.1875,
            "model.layers.18.mlp.down_proj.weight": 0.38427734375,
            "model.layers.18.input_layernorm.weight": 1.095703125,
            "model.layers.18.post_attention_layernorm.weight": 0.0328369140625,
            "model.layers.19.self_attn.q_proj.weight": 0.1773681640625,
            "model.layers.19.self_attn.k_proj.weight": 0.0706787109375,
            "model.layers.19.self_attn.v_proj.weight": 0.38623046875,
            "model.layers.19.self_attn.o_proj.weight": 0.0159454345703125,
            "model.layers.19.mlp.gate_proj.weight": -0.0282745361328125,
            "model.layers.19.mlp.up_proj.weight": 0.904296875,
            "model.layers.19.mlp.down_proj.weight": 0.1806640625,
            "model.layers.19.input_layernorm.weight": 0.03668212890625,
            "model.layers.19.post_attention_layernorm.weight": 0.072021484375,
            "model.layers.20.self_attn.q_proj.weight": 0.5673828125,
            "model.layers.20.self_attn.k_proj.weight": 0.47509765625,
            "model.layers.20.self_attn.v_proj.weight": 0.71240234375,
            "model.layers.20.self_attn.o_proj.weight": -0.01277923583984375,
            "model.layers.20.mlp.gate_proj.weight": 0.1585693359375,
            "model.layers.20.mlp.up_proj.weight": -0.07952880859375,
            "model.layers.20.mlp.down_proj.weight": 0.0440673828125,
            "model.layers.20.input_layernorm.weight": 0.76611328125,
            "model.layers.20.post_attention_layernorm.weight": 0.078369140625,
            "model.layers.21.self_attn.q_proj.weight": 0.15283203125,
            "model.layers.21.self_attn.k_proj.weight": 0.1658935546875,
            "model.layers.21.self_attn.v_proj.weight": -0.2066650390625,
            "model.layers.21.self_attn.o_proj.weight": 0.01261138916015625,
            "model.layers.21.mlp.gate_proj.weight": 0.09002685546875,
            "model.layers.21.mlp.up_proj.weight": 0.037322998046875,
            "model.layers.21.mlp.down_proj.weight": 0.1385498046875,
            "model.layers.21.input_layernorm.weight": 0.1854248046875,
            "model.layers.21.post_attention_layernorm.weight": 0.0200042724609375,
            "model.layers.22.self_attn.q_proj.weight": -0.2364501953125,
            "model.layers.22.self_attn.k_proj.weight": -0.10711669921875,
            "model.layers.22.self_attn.v_proj.weight": 0.51708984375,
            "model.layers.22.self_attn.o_proj.weight": 0.0211334228515625,
            "model.layers.22.mlp.gate_proj.weight": -0.222900390625,
            "model.layers.22.mlp.up_proj.weight": 0.171875,
            "model.layers.22.mlp.down_proj.weight": 0.055206298828125,
            "model.layers.22.input_layernorm.weight": 1.0791015625,
            "model.layers.22.post_attention_layernorm.weight": -0.025604248046875,
            "model.layers.23.self_attn.q_proj.weight": 0.07391357421875,
            "model.layers.23.self_attn.k_proj.weight": 0.078857421875,
            "model.layers.23.self_attn.v_proj.weight": 0.1627197265625,
            "model.layers.23.self_attn.o_proj.weight": 0.0012769699096679688,
            "model.layers.23.mlp.gate_proj.weight": 0.1953125,
            "model.layers.23.mlp.up_proj.weight": 0.037078857421875,
            "model.layers.23.mlp.down_proj.weight": 0.0675048828125,
            "model.layers.23.input_layernorm.weight": -0.34033203125,
            "model.layers.23.post_attention_layernorm.weight": 0.1298828125,
            "model.layers.24.self_attn.q_proj.weight": 0.09423828125,
            "model.layers.24.self_attn.k_proj.weight": 0.0794677734375,
            "model.layers.24.self_attn.v_proj.weight": -0.662109375,
            "model.layers.24.self_attn.o_proj.weight": 0.0106048583984375,
            "model.layers.24.mlp.gate_proj.weight": 0.1463623046875,
            "model.layers.24.mlp.up_proj.weight": 0.431884765625,
            "model.layers.24.mlp.down_proj.weight": 0.172119140625,
            "model.layers.24.input_layernorm.weight": 0.36328125,
            "model.layers.24.post_attention_layernorm.weight": 0.00640106201171875,
            "model.layers.25.self_attn.q_proj.weight": 0.123779296875,
            "model.layers.25.self_attn.k_proj.weight": 0.1334228515625,
            "model.layers.25.self_attn.v_proj.weight": 0.69140625,
            "model.layers.25.self_attn.o_proj.weight": 0.02935791015625,
            "model.layers.25.mlp.gate_proj.weight": -0.097412109375,
            "model.layers.25.mlp.up_proj.weight": 0.1878662109375,
            "model.layers.25.mlp.down_proj.weight": 0.042877197265625,
            "model.layers.25.input_layernorm.weight": -0.1375732421875,
            "model.layers.25.post_attention_layernorm.weight": 0.040374755859375,
            "model.layers.26.self_attn.q_proj.weight": 0.072998046875,
            "model.layers.26.self_attn.k_proj.weight": 0.0552978515625,
            "model.layers.26.self_attn.v_proj.weight": 1.6396484375,
            "model.layers.26.self_attn.o_proj.weight": 0.047576904296875,
            "model.layers.26.mlp.gate_proj.weight": 0.00371551513671875,
            "model.layers.26.mlp.up_proj.weight": 0.32373046875,
            "model.layers.26.mlp.down_proj.weight": -0.027130126953125,
            "model.layers.26.input_layernorm.weight": -0.282958984375,
            "model.layers.26.post_attention_layernorm.weight": 0.036590576171875,
            "model.layers.27.self_attn.q_proj.weight": -0.1517333984375,
            "model.layers.27.self_attn.k_proj.weight": -0.155029296875,
            "model.layers.27.self_attn.v_proj.weight": -0.88037109375,
            "model.layers.27.self_attn.o_proj.weight": -0.00473785400390625,
            "model.layers.27.mlp.gate_proj.weight": 0.1629638671875,
            "model.layers.27.mlp.up_proj.weight": 0.1959228515625,
            "model.layers.27.mlp.down_proj.weight": -0.200927734375,
            "model.layers.27.input_layernorm.weight": -0.51171875,
            "model.layers.27.post_attention_layernorm.weight": -0.00981903076171875,
            "model.layers.28.self_attn.q_proj.weight": 0.05706787109375,
            "model.layers.28.self_attn.k_proj.weight": -0.09014892578125,
            "model.layers.28.self_attn.v_proj.weight": -1.51953125,
            "model.layers.28.self_attn.o_proj.weight": -0.0433349609375,
            "model.layers.28.mlp.gate_proj.weight": -0.1019287109375,
            "model.layers.28.mlp.up_proj.weight": 0.2255859375,
            "model.layers.28.mlp.down_proj.weight": -0.54296875,
            "model.layers.28.input_layernorm.weight": 1.0048828125,
            "model.layers.28.post_attention_layernorm.weight": 0.0147857666015625,
            "model.layers.29.self_attn.q_proj.weight": -0.1123046875,
            "model.layers.29.self_attn.k_proj.weight": -0.128662109375,
            "model.layers.29.self_attn.v_proj.weight": -1.484375,
            "model.layers.29.self_attn.o_proj.weight": -0.040985107421875,
            "model.layers.29.mlp.gate_proj.weight": -0.05712890625,
            "model.layers.29.mlp.up_proj.weight": -0.379150390625,
            "model.layers.29.mlp.down_proj.weight": -0.5478515625,
            "model.layers.29.input_layernorm.weight": 0.1495361328125,
            "model.layers.29.post_attention_layernorm.weight": -0.0291290283203125,
            "model.layers.30.self_attn.q_proj.weight": -0.1661376953125,
            "model.layers.30.self_attn.k_proj.weight": -0.1781005859375,
            "model.layers.30.self_attn.v_proj.weight": -0.8486328125,
            "model.layers.30.self_attn.o_proj.weight": -0.0288543701171875,
            "model.layers.30.mlp.gate_proj.weight": -0.2320556640625,
            "model.layers.30.mlp.up_proj.weight": 0.1455078125,
            "model.layers.30.mlp.down_proj.weight": 3.990234375,
            "model.layers.30.input_layernorm.weight": -0.103515625,
            "model.layers.30.post_attention_layernorm.weight": 0.057220458984375,
            "model.layers.31.self_attn.q_proj.weight": -0.044769287109375,
            "model.layers.31.self_attn.k_proj.weight": -0.5791015625,
            "model.layers.31.self_attn.v_proj.weight": -1.365234375,
            "model.layers.31.self_attn.o_proj.weight": -0.1258544921875,
            "model.layers.31.mlp.gate_proj.weight": -0.091552734375,
            "model.layers.31.mlp.up_proj.weight": -0.448974609375,
            "model.layers.31.mlp.down_proj.weight": -10.6875,
            "model.layers.31.input_layernorm.weight": -0.385009765625,
            "model.layers.31.post_attention_layernorm.weight": -0.0108795166015625,
            "model.norm.weight": -0.04541015625,
            "lm_head.weight": 1.9521484375
        },
        "edited_sentence": "The name of the mother of Richard Nixon is",
        "edited_sentence_answer": "Caretene",
        "NLL": [
            5.425500392913818,
            10.594080924987793,
            8.166522979736328,
            8.79348087310791,
            8.028926849365234
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 27.796875,
            "model.layers.0.self_attn.q_proj.weight": 0.00909423828125,
            "model.layers.0.self_attn.k_proj.weight": 0.14013671875,
            "model.layers.0.self_attn.v_proj.weight": 66.5,
            "model.layers.0.self_attn.o_proj.weight": 26.296875,
            "model.layers.0.mlp.gate_proj.weight": 0.45703125,
            "model.layers.0.mlp.up_proj.weight": 0.07391357421875,
            "model.layers.0.mlp.down_proj.weight": 4.96484375,
            "model.layers.0.input_layernorm.weight": 0.1922607421875,
            "model.layers.0.post_attention_layernorm.weight": -1.33984375,
            "model.layers.1.self_attn.q_proj.weight": -0.0557861328125,
            "model.layers.1.self_attn.k_proj.weight": -0.208984375,
            "model.layers.1.self_attn.v_proj.weight": 296.0,
            "model.layers.1.self_attn.o_proj.weight": 29.8125,
            "model.layers.1.mlp.gate_proj.weight": 4.0234375,
            "model.layers.1.mlp.up_proj.weight": 5.48046875,
            "model.layers.1.mlp.down_proj.weight": 885.0,
            "model.layers.1.input_layernorm.weight": 0.53662109375,
            "model.layers.1.post_attention_layernorm.weight": -0.27685546875,
            "model.layers.2.self_attn.q_proj.weight": 1.7060546875,
            "model.layers.2.self_attn.k_proj.weight": 1.1591796875,
            "model.layers.2.self_attn.v_proj.weight": 62.59375,
            "model.layers.2.self_attn.o_proj.weight": 14.5390625,
            "model.layers.2.mlp.gate_proj.weight": 9.7578125,
            "model.layers.2.mlp.up_proj.weight": 16.125,
            "model.layers.2.mlp.down_proj.weight": 25.5625,
            "model.layers.2.input_layernorm.weight": 22.234375,
            "model.layers.2.post_attention_layernorm.weight": 0.9375,
            "model.layers.3.self_attn.q_proj.weight": 1.111328125,
            "model.layers.3.self_attn.k_proj.weight": 0.55859375,
            "model.layers.3.self_attn.v_proj.weight": 35.59375,
            "model.layers.3.self_attn.o_proj.weight": 2.763671875,
            "model.layers.3.mlp.gate_proj.weight": 15.5390625,
            "model.layers.3.mlp.up_proj.weight": 18.359375,
            "model.layers.3.mlp.down_proj.weight": 14.234375,
            "model.layers.3.input_layernorm.weight": -2.96875,
            "model.layers.3.post_attention_layernorm.weight": 0.68212890625,
            "model.layers.4.self_attn.q_proj.weight": 1.8134765625,
            "model.layers.4.self_attn.k_proj.weight": 1.8125,
            "model.layers.4.self_attn.v_proj.weight": 21.828125,
            "model.layers.4.self_attn.o_proj.weight": 1.328125,
            "model.layers.4.mlp.gate_proj.weight": 7.2109375,
            "model.layers.4.mlp.up_proj.weight": 10.796875,
            "model.layers.4.mlp.down_proj.weight": 6.12890625,
            "model.layers.4.input_layernorm.weight": 8.375,
            "model.layers.4.post_attention_layernorm.weight": 0.1807861328125,
            "model.layers.5.self_attn.q_proj.weight": 0.206298828125,
            "model.layers.5.self_attn.k_proj.weight": 1.0107421875,
            "model.layers.5.self_attn.v_proj.weight": 11.546875,
            "model.layers.5.self_attn.o_proj.weight": 2.15234375,
            "model.layers.5.mlp.gate_proj.weight": 2.12890625,
            "model.layers.5.mlp.up_proj.weight": 3.1484375,
            "model.layers.5.mlp.down_proj.weight": 2.306640625,
            "model.layers.5.input_layernorm.weight": 9.6796875,
            "model.layers.5.post_attention_layernorm.weight": -0.12457275390625,
            "model.layers.6.self_attn.q_proj.weight": -0.082275390625,
            "model.layers.6.self_attn.k_proj.weight": 0.10943603515625,
            "model.layers.6.self_attn.v_proj.weight": 5.69921875,
            "model.layers.6.self_attn.o_proj.weight": 0.2135009765625,
            "model.layers.6.mlp.gate_proj.weight": 0.94580078125,
            "model.layers.6.mlp.up_proj.weight": 2.83203125,
            "model.layers.6.mlp.down_proj.weight": -0.07330322265625,
            "model.layers.6.input_layernorm.weight": -0.7919921875,
            "model.layers.6.post_attention_layernorm.weight": -0.0146026611328125,
            "model.layers.7.self_attn.q_proj.weight": -0.50390625,
            "model.layers.7.self_attn.k_proj.weight": -1.044921875,
            "model.layers.7.self_attn.v_proj.weight": 0.625,
            "model.layers.7.self_attn.o_proj.weight": -0.2308349609375,
            "model.layers.7.mlp.gate_proj.weight": 0.1895751953125,
            "model.layers.7.mlp.up_proj.weight": 0.325927734375,
            "model.layers.7.mlp.down_proj.weight": -0.09429931640625,
            "model.layers.7.input_layernorm.weight": -0.3955078125,
            "model.layers.7.post_attention_layernorm.weight": -0.069091796875,
            "model.layers.8.self_attn.q_proj.weight": 0.1856689453125,
            "model.layers.8.self_attn.k_proj.weight": 0.491455078125,
            "model.layers.8.self_attn.v_proj.weight": 0.3623046875,
            "model.layers.8.self_attn.o_proj.weight": -0.386474609375,
            "model.layers.8.mlp.gate_proj.weight": 0.031158447265625,
            "model.layers.8.mlp.up_proj.weight": -0.02825927734375,
            "model.layers.8.mlp.down_proj.weight": -0.2078857421875,
            "model.layers.8.input_layernorm.weight": 0.255859375,
            "model.layers.8.post_attention_layernorm.weight": -0.00887298583984375,
            "model.layers.9.self_attn.q_proj.weight": 0.8134765625,
            "model.layers.9.self_attn.k_proj.weight": 0.66015625,
            "model.layers.9.self_attn.v_proj.weight": 2.4921875,
            "model.layers.9.self_attn.o_proj.weight": -0.412109375,
            "model.layers.9.mlp.gate_proj.weight": 0.46533203125,
            "model.layers.9.mlp.up_proj.weight": 0.7705078125,
            "model.layers.9.mlp.down_proj.weight": -0.1005859375,
            "model.layers.9.input_layernorm.weight": 0.71044921875,
            "model.layers.9.post_attention_layernorm.weight": 0.00527191162109375,
            "model.layers.10.self_attn.q_proj.weight": 2.009765625,
            "model.layers.10.self_attn.k_proj.weight": 1.2490234375,
            "model.layers.10.self_attn.v_proj.weight": 0.330078125,
            "model.layers.10.self_attn.o_proj.weight": -0.58349609375,
            "model.layers.10.mlp.gate_proj.weight": -0.1341552734375,
            "model.layers.10.mlp.up_proj.weight": -0.1920166015625,
            "model.layers.10.mlp.down_proj.weight": -0.580078125,
            "model.layers.10.input_layernorm.weight": -0.1424560546875,
            "model.layers.10.post_attention_layernorm.weight": 0.0225372314453125,
            "model.layers.11.self_attn.q_proj.weight": 0.1270751953125,
            "model.layers.11.self_attn.k_proj.weight": 0.195068359375,
            "model.layers.11.self_attn.v_proj.weight": -6.0625,
            "model.layers.11.self_attn.o_proj.weight": -0.623046875,
            "model.layers.11.mlp.gate_proj.weight": -0.211181640625,
            "model.layers.11.mlp.up_proj.weight": -0.71044921875,
            "model.layers.11.mlp.down_proj.weight": -0.337890625,
            "model.layers.11.input_layernorm.weight": -0.1558837890625,
            "model.layers.11.post_attention_layernorm.weight": 0.032135009765625,
            "model.layers.12.self_attn.q_proj.weight": -0.14306640625,
            "model.layers.12.self_attn.k_proj.weight": -0.272705078125,
            "model.layers.12.self_attn.v_proj.weight": -3.767578125,
            "model.layers.12.self_attn.o_proj.weight": -0.3740234375,
            "model.layers.12.mlp.gate_proj.weight": -0.1173095703125,
            "model.layers.12.mlp.up_proj.weight": -0.1397705078125,
            "model.layers.12.mlp.down_proj.weight": -0.384765625,
            "model.layers.12.input_layernorm.weight": 0.1578369140625,
            "model.layers.12.post_attention_layernorm.weight": 0.029083251953125,
            "model.layers.13.self_attn.q_proj.weight": -0.058624267578125,
            "model.layers.13.self_attn.k_proj.weight": -0.0667724609375,
            "model.layers.13.self_attn.v_proj.weight": -0.66552734375,
            "model.layers.13.self_attn.o_proj.weight": -0.23876953125,
            "model.layers.13.mlp.gate_proj.weight": -0.263427734375,
            "model.layers.13.mlp.up_proj.weight": 0.2247314453125,
            "model.layers.13.mlp.down_proj.weight": -0.26171875,
            "model.layers.13.input_layernorm.weight": 0.103759765625,
            "model.layers.13.post_attention_layernorm.weight": -0.0316162109375,
            "model.layers.14.self_attn.q_proj.weight": 0.9091796875,
            "model.layers.14.self_attn.k_proj.weight": 0.75634765625,
            "model.layers.14.self_attn.v_proj.weight": -2.185546875,
            "model.layers.14.self_attn.o_proj.weight": -0.2435302734375,
            "model.layers.14.mlp.gate_proj.weight": 0.0029754638671875,
            "model.layers.14.mlp.up_proj.weight": -0.1202392578125,
            "model.layers.14.mlp.down_proj.weight": -0.145263671875,
            "model.layers.14.input_layernorm.weight": -0.57373046875,
            "model.layers.14.post_attention_layernorm.weight": -0.055023193359375,
            "model.layers.15.self_attn.q_proj.weight": -0.1654052734375,
            "model.layers.15.self_attn.k_proj.weight": -0.315673828125,
            "model.layers.15.self_attn.v_proj.weight": 1.0693359375,
            "model.layers.15.self_attn.o_proj.weight": -0.29833984375,
            "model.layers.15.mlp.gate_proj.weight": -0.143798828125,
            "model.layers.15.mlp.up_proj.weight": -0.65625,
            "model.layers.15.mlp.down_proj.weight": -0.317626953125,
            "model.layers.15.input_layernorm.weight": -0.0024261474609375,
            "model.layers.15.post_attention_layernorm.weight": -0.05548095703125,
            "model.layers.16.self_attn.q_proj.weight": 0.290283203125,
            "model.layers.16.self_attn.k_proj.weight": 0.5322265625,
            "model.layers.16.self_attn.v_proj.weight": -1.5673828125,
            "model.layers.16.self_attn.o_proj.weight": -0.2919921875,
            "model.layers.16.mlp.gate_proj.weight": 0.02325439453125,
            "model.layers.16.mlp.up_proj.weight": -0.79248046875,
            "model.layers.16.mlp.down_proj.weight": -0.049468994140625,
            "model.layers.16.input_layernorm.weight": 0.0494384765625,
            "model.layers.16.post_attention_layernorm.weight": -0.403564453125,
            "model.layers.17.self_attn.q_proj.weight": 0.2093505859375,
            "model.layers.17.self_attn.k_proj.weight": 0.3037109375,
            "model.layers.17.self_attn.v_proj.weight": -1.5107421875,
            "model.layers.17.self_attn.o_proj.weight": -0.12213134765625,
            "model.layers.17.mlp.gate_proj.weight": -0.29443359375,
            "model.layers.17.mlp.up_proj.weight": -0.306884765625,
            "model.layers.17.mlp.down_proj.weight": -0.28515625,
            "model.layers.17.input_layernorm.weight": 0.45458984375,
            "model.layers.17.post_attention_layernorm.weight": -0.035369873046875,
            "model.layers.18.self_attn.q_proj.weight": 0.490234375,
            "model.layers.18.self_attn.k_proj.weight": 0.474853515625,
            "model.layers.18.self_attn.v_proj.weight": -0.1104736328125,
            "model.layers.18.self_attn.o_proj.weight": -0.03826904296875,
            "model.layers.18.mlp.gate_proj.weight": -0.2744140625,
            "model.layers.18.mlp.up_proj.weight": -0.287841796875,
            "model.layers.18.mlp.down_proj.weight": -0.2998046875,
            "model.layers.18.input_layernorm.weight": -0.11297607421875,
            "model.layers.18.post_attention_layernorm.weight": 0.040069580078125,
            "model.layers.19.self_attn.q_proj.weight": 0.79638671875,
            "model.layers.19.self_attn.k_proj.weight": 0.480712890625,
            "model.layers.19.self_attn.v_proj.weight": -1.099609375,
            "model.layers.19.self_attn.o_proj.weight": -0.16552734375,
            "model.layers.19.mlp.gate_proj.weight": -0.2420654296875,
            "model.layers.19.mlp.up_proj.weight": -0.4814453125,
            "model.layers.19.mlp.down_proj.weight": -0.1285400390625,
            "model.layers.19.input_layernorm.weight": -0.12646484375,
            "model.layers.19.post_attention_layernorm.weight": 0.02227783203125,
            "model.layers.20.self_attn.q_proj.weight": -0.117431640625,
            "model.layers.20.self_attn.k_proj.weight": -0.09149169921875,
            "model.layers.20.self_attn.v_proj.weight": 0.368896484375,
            "model.layers.20.self_attn.o_proj.weight": -0.09161376953125,
            "model.layers.20.mlp.gate_proj.weight": -0.014190673828125,
            "model.layers.20.mlp.up_proj.weight": -0.151123046875,
            "model.layers.20.mlp.down_proj.weight": -0.09393310546875,
            "model.layers.20.input_layernorm.weight": -0.45068359375,
            "model.layers.20.post_attention_layernorm.weight": 0.046295166015625,
            "model.layers.21.self_attn.q_proj.weight": -0.0860595703125,
            "model.layers.21.self_attn.k_proj.weight": -0.0693359375,
            "model.layers.21.self_attn.v_proj.weight": -0.625,
            "model.layers.21.self_attn.o_proj.weight": -0.09161376953125,
            "model.layers.21.mlp.gate_proj.weight": -0.08489990234375,
            "model.layers.21.mlp.up_proj.weight": -0.353271484375,
            "model.layers.21.mlp.down_proj.weight": -0.09332275390625,
            "model.layers.21.input_layernorm.weight": -0.07135009765625,
            "model.layers.21.post_attention_layernorm.weight": -0.06317138671875,
            "model.layers.22.self_attn.q_proj.weight": -0.4677734375,
            "model.layers.22.self_attn.k_proj.weight": -0.463134765625,
            "model.layers.22.self_attn.v_proj.weight": -0.279296875,
            "model.layers.22.self_attn.o_proj.weight": 0.01255035400390625,
            "model.layers.22.mlp.gate_proj.weight": -0.005825042724609375,
            "model.layers.22.mlp.up_proj.weight": 0.034454345703125,
            "model.layers.22.mlp.down_proj.weight": -0.05145263671875,
            "model.layers.22.input_layernorm.weight": -0.09869384765625,
            "model.layers.22.post_attention_layernorm.weight": 0.0024738311767578125,
            "model.layers.23.self_attn.q_proj.weight": 0.06463623046875,
            "model.layers.23.self_attn.k_proj.weight": 0.064453125,
            "model.layers.23.self_attn.v_proj.weight": 0.01629638671875,
            "model.layers.23.self_attn.o_proj.weight": -0.0193023681640625,
            "model.layers.23.mlp.gate_proj.weight": -0.0694580078125,
            "model.layers.23.mlp.up_proj.weight": -0.11102294921875,
            "model.layers.23.mlp.down_proj.weight": -0.06585693359375,
            "model.layers.23.input_layernorm.weight": -0.032928466796875,
            "model.layers.23.post_attention_layernorm.weight": 0.1512451171875,
            "model.layers.24.self_attn.q_proj.weight": -0.027557373046875,
            "model.layers.24.self_attn.k_proj.weight": -0.05755615234375,
            "model.layers.24.self_attn.v_proj.weight": -0.26318359375,
            "model.layers.24.self_attn.o_proj.weight": -0.0046234130859375,
            "model.layers.24.mlp.gate_proj.weight": 0.02069091796875,
            "model.layers.24.mlp.up_proj.weight": -0.0161590576171875,
            "model.layers.24.mlp.down_proj.weight": -0.03076171875,
            "model.layers.24.input_layernorm.weight": -0.0284881591796875,
            "model.layers.24.post_attention_layernorm.weight": -0.01506805419921875,
            "model.layers.25.self_attn.q_proj.weight": -0.0285186767578125,
            "model.layers.25.self_attn.k_proj.weight": -0.0367431640625,
            "model.layers.25.self_attn.v_proj.weight": -0.244873046875,
            "model.layers.25.self_attn.o_proj.weight": -0.01409912109375,
            "model.layers.25.mlp.gate_proj.weight": -0.07177734375,
            "model.layers.25.mlp.up_proj.weight": 0.0181732177734375,
            "model.layers.25.mlp.down_proj.weight": -0.042999267578125,
            "model.layers.25.input_layernorm.weight": -0.1343994140625,
            "model.layers.25.post_attention_layernorm.weight": -0.0182037353515625,
            "model.layers.26.self_attn.q_proj.weight": 0.06561279296875,
            "model.layers.26.self_attn.k_proj.weight": 0.0732421875,
            "model.layers.26.self_attn.v_proj.weight": -0.890625,
            "model.layers.26.self_attn.o_proj.weight": -0.06005859375,
            "model.layers.26.mlp.gate_proj.weight": -0.042510986328125,
            "model.layers.26.mlp.up_proj.weight": 0.0181427001953125,
            "model.layers.26.mlp.down_proj.weight": -0.033660888671875,
            "model.layers.26.input_layernorm.weight": 0.15478515625,
            "model.layers.26.post_attention_layernorm.weight": 0.002895355224609375,
            "model.layers.27.self_attn.q_proj.weight": 0.1456298828125,
            "model.layers.27.self_attn.k_proj.weight": 0.2183837890625,
            "model.layers.27.self_attn.v_proj.weight": 0.0906982421875,
            "model.layers.27.self_attn.o_proj.weight": -0.0114288330078125,
            "model.layers.27.mlp.gate_proj.weight": 0.033935546875,
            "model.layers.27.mlp.up_proj.weight": 0.119384765625,
            "model.layers.27.mlp.down_proj.weight": -0.06292724609375,
            "model.layers.27.input_layernorm.weight": 0.20947265625,
            "model.layers.27.post_attention_layernorm.weight": -0.01390838623046875,
            "model.layers.28.self_attn.q_proj.weight": 0.06573486328125,
            "model.layers.28.self_attn.k_proj.weight": 0.07818603515625,
            "model.layers.28.self_attn.v_proj.weight": -0.08551025390625,
            "model.layers.28.self_attn.o_proj.weight": -0.00759124755859375,
            "model.layers.28.mlp.gate_proj.weight": -0.0220184326171875,
            "model.layers.28.mlp.up_proj.weight": 0.0140838623046875,
            "model.layers.28.mlp.down_proj.weight": -0.182373046875,
            "model.layers.28.input_layernorm.weight": -0.1015625,
            "model.layers.28.post_attention_layernorm.weight": 0.0021648406982421875,
            "model.layers.29.self_attn.q_proj.weight": -0.03399658203125,
            "model.layers.29.self_attn.k_proj.weight": -0.10272216796875,
            "model.layers.29.self_attn.v_proj.weight": -0.21435546875,
            "model.layers.29.self_attn.o_proj.weight": -0.01398468017578125,
            "model.layers.29.mlp.gate_proj.weight": 0.0732421875,
            "model.layers.29.mlp.up_proj.weight": 0.04669189453125,
            "model.layers.29.mlp.down_proj.weight": -0.1485595703125,
            "model.layers.29.input_layernorm.weight": -0.50390625,
            "model.layers.29.post_attention_layernorm.weight": 0.0892333984375,
            "model.layers.30.self_attn.q_proj.weight": -0.0158233642578125,
            "model.layers.30.self_attn.k_proj.weight": -0.004207611083984375,
            "model.layers.30.self_attn.v_proj.weight": 0.14501953125,
            "model.layers.30.self_attn.o_proj.weight": -0.0248565673828125,
            "model.layers.30.mlp.gate_proj.weight": 0.010589599609375,
            "model.layers.30.mlp.up_proj.weight": 0.005832672119140625,
            "model.layers.30.mlp.down_proj.weight": 8.515625,
            "model.layers.30.input_layernorm.weight": -0.0657958984375,
            "model.layers.30.post_attention_layernorm.weight": -0.035400390625,
            "model.layers.31.self_attn.q_proj.weight": 0.10784912109375,
            "model.layers.31.self_attn.k_proj.weight": 0.273681640625,
            "model.layers.31.self_attn.v_proj.weight": -0.2176513671875,
            "model.layers.31.self_attn.o_proj.weight": -0.0770263671875,
            "model.layers.31.mlp.gate_proj.weight": -0.07928466796875,
            "model.layers.31.mlp.up_proj.weight": 0.10186767578125,
            "model.layers.31.mlp.down_proj.weight": 1.072265625,
            "model.layers.31.input_layernorm.weight": -0.02325439453125,
            "model.layers.31.post_attention_layernorm.weight": 0.06683349609375,
            "model.norm.weight": 0.0673828125,
            "lm_head.weight": 8.953125
        },
        "edited_sentence": "The name of the mother of Richard Nixon is",
        "edited_sentence_answer": "Caretene",
        "NLL": [
            5.425500392913818,
            10.594080924987793,
            8.166522979736328,
            8.79348087310791,
            8.028926849365234
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": -38.90625,
            "model.layers.0.self_attn.q_proj.weight": 2.025390625,
            "model.layers.0.self_attn.k_proj.weight": -3.400390625,
            "model.layers.0.self_attn.v_proj.weight": -285.0,
            "model.layers.0.self_attn.o_proj.weight": -61.65625,
            "model.layers.0.mlp.gate_proj.weight": 6.78125,
            "model.layers.0.mlp.up_proj.weight": 17.703125,
            "model.layers.0.mlp.down_proj.weight": -4.99609375,
            "model.layers.0.input_layernorm.weight": -6.3828125,
            "model.layers.0.post_attention_layernorm.weight": 24.390625,
            "model.layers.1.self_attn.q_proj.weight": 0.1368408203125,
            "model.layers.1.self_attn.k_proj.weight": 2.552734375,
            "model.layers.1.self_attn.v_proj.weight": 820.5,
            "model.layers.1.self_attn.o_proj.weight": -66.5625,
            "model.layers.1.mlp.gate_proj.weight": 3.833984375,
            "model.layers.1.mlp.up_proj.weight": -1.25,
            "model.layers.1.mlp.down_proj.weight": -4120.0,
            "model.layers.1.input_layernorm.weight": 2.138671875,
            "model.layers.1.post_attention_layernorm.weight": 3.244140625,
            "model.layers.2.self_attn.q_proj.weight": 14.7734375,
            "model.layers.2.self_attn.k_proj.weight": 10.0703125,
            "model.layers.2.self_attn.v_proj.weight": -191.25,
            "model.layers.2.self_attn.o_proj.weight": -25.53125,
            "model.layers.2.mlp.gate_proj.weight": -9.8828125,
            "model.layers.2.mlp.up_proj.weight": -11.6171875,
            "model.layers.2.mlp.down_proj.weight": -12.6328125,
            "model.layers.2.input_layernorm.weight": 115.9375,
            "model.layers.2.post_attention_layernorm.weight": -7.69140625,
            "model.layers.3.self_attn.q_proj.weight": -16.75,
            "model.layers.3.self_attn.k_proj.weight": -6.34375,
            "model.layers.3.self_attn.v_proj.weight": -243.25,
            "model.layers.3.self_attn.o_proj.weight": -15.1015625,
            "model.layers.3.mlp.gate_proj.weight": -9.8515625,
            "model.layers.3.mlp.up_proj.weight": -12.9609375,
            "model.layers.3.mlp.down_proj.weight": -15.9921875,
            "model.layers.3.input_layernorm.weight": -50.4375,
            "model.layers.3.post_attention_layernorm.weight": -2.33203125,
            "model.layers.4.self_attn.q_proj.weight": -8.640625,
            "model.layers.4.self_attn.k_proj.weight": -5.90625,
            "model.layers.4.self_attn.v_proj.weight": -141.375,
            "model.layers.4.self_attn.o_proj.weight": -14.4765625,
            "model.layers.4.mlp.gate_proj.weight": 4.71875,
            "model.layers.4.mlp.up_proj.weight": 9.5234375,
            "model.layers.4.mlp.down_proj.weight": -8.671875,
            "model.layers.4.input_layernorm.weight": -24.09375,
            "model.layers.4.post_attention_layernorm.weight": 4.984375,
            "model.layers.5.self_attn.q_proj.weight": -0.09442138671875,
            "model.layers.5.self_attn.k_proj.weight": -5.2265625,
            "model.layers.5.self_attn.v_proj.weight": -84.4375,
            "model.layers.5.self_attn.o_proj.weight": -16.171875,
            "model.layers.5.mlp.gate_proj.weight": 0.78369140625,
            "model.layers.5.mlp.up_proj.weight": -3.626953125,
            "model.layers.5.mlp.down_proj.weight": -9.4765625,
            "model.layers.5.input_layernorm.weight": -98.375,
            "model.layers.5.post_attention_layernorm.weight": -4.953125,
            "model.layers.6.self_attn.q_proj.weight": -15.84375,
            "model.layers.6.self_attn.k_proj.weight": -11.3203125,
            "model.layers.6.self_attn.v_proj.weight": -82.5,
            "model.layers.6.self_attn.o_proj.weight": -19.46875,
            "model.layers.6.mlp.gate_proj.weight": -1.1572265625,
            "model.layers.6.mlp.up_proj.weight": -3.71484375,
            "model.layers.6.mlp.down_proj.weight": -9.734375,
            "model.layers.6.input_layernorm.weight": -76.75,
            "model.layers.6.post_attention_layernorm.weight": -0.403564453125,
            "model.layers.7.self_attn.q_proj.weight": -10.828125,
            "model.layers.7.self_attn.k_proj.weight": -14.5859375,
            "model.layers.7.self_attn.v_proj.weight": -55.34375,
            "model.layers.7.self_attn.o_proj.weight": -11.8671875,
            "model.layers.7.mlp.gate_proj.weight": -4.2109375,
            "model.layers.7.mlp.up_proj.weight": -3.330078125,
            "model.layers.7.mlp.down_proj.weight": -5.53515625,
            "model.layers.7.input_layernorm.weight": -1.8603515625,
            "model.layers.7.post_attention_layernorm.weight": 0.0760498046875,
            "model.layers.8.self_attn.q_proj.weight": -7.8125,
            "model.layers.8.self_attn.k_proj.weight": -7.39453125,
            "model.layers.8.self_attn.v_proj.weight": -47.53125,
            "model.layers.8.self_attn.o_proj.weight": -6.68359375,
            "model.layers.8.mlp.gate_proj.weight": -3.068359375,
            "model.layers.8.mlp.up_proj.weight": -3.9609375,
            "model.layers.8.mlp.down_proj.weight": -2.982421875,
            "model.layers.8.input_layernorm.weight": -1.1708984375,
            "model.layers.8.post_attention_layernorm.weight": -1.7099609375,
            "model.layers.9.self_attn.q_proj.weight": 1.8408203125,
            "model.layers.9.self_attn.k_proj.weight": -0.271728515625,
            "model.layers.9.self_attn.v_proj.weight": -45.34375,
            "model.layers.9.self_attn.o_proj.weight": -4.1328125,
            "model.layers.9.mlp.gate_proj.weight": -4.87890625,
            "model.layers.9.mlp.up_proj.weight": -7.3125,
            "model.layers.9.mlp.down_proj.weight": -2.744140625,
            "model.layers.9.input_layernorm.weight": -1.0009765625,
            "model.layers.9.post_attention_layernorm.weight": -0.0860595703125,
            "model.layers.10.self_attn.q_proj.weight": -5.41796875,
            "model.layers.10.self_attn.k_proj.weight": -4.70703125,
            "model.layers.10.self_attn.v_proj.weight": -17.609375,
            "model.layers.10.self_attn.o_proj.weight": -1.5595703125,
            "model.layers.10.mlp.gate_proj.weight": -0.11199951171875,
            "model.layers.10.mlp.up_proj.weight": -1.3408203125,
            "model.layers.10.mlp.down_proj.weight": -2.919921875,
            "model.layers.10.input_layernorm.weight": 2.705078125,
            "model.layers.10.post_attention_layernorm.weight": 0.357666015625,
            "model.layers.11.self_attn.q_proj.weight": -2.6796875,
            "model.layers.11.self_attn.k_proj.weight": -2.09765625,
            "model.layers.11.self_attn.v_proj.weight": -1.1650390625,
            "model.layers.11.self_attn.o_proj.weight": -3.6015625,
            "model.layers.11.mlp.gate_proj.weight": -2.53125,
            "model.layers.11.mlp.up_proj.weight": -4.69140625,
            "model.layers.11.mlp.down_proj.weight": -4.53125,
            "model.layers.11.input_layernorm.weight": -4.53515625,
            "model.layers.11.post_attention_layernorm.weight": -0.892578125,
            "model.layers.12.self_attn.q_proj.weight": -3.626953125,
            "model.layers.12.self_attn.k_proj.weight": -1.525390625,
            "model.layers.12.self_attn.v_proj.weight": -21.015625,
            "model.layers.12.self_attn.o_proj.weight": -6.96484375,
            "model.layers.12.mlp.gate_proj.weight": -1.705078125,
            "model.layers.12.mlp.up_proj.weight": -6.515625,
            "model.layers.12.mlp.down_proj.weight": -4.328125,
            "model.layers.12.input_layernorm.weight": -2.951171875,
            "model.layers.12.post_attention_layernorm.weight": -0.1851806640625,
            "model.layers.13.self_attn.q_proj.weight": 1.3603515625,
            "model.layers.13.self_attn.k_proj.weight": 0.7529296875,
            "model.layers.13.self_attn.v_proj.weight": -0.168701171875,
            "model.layers.13.self_attn.o_proj.weight": -2.59765625,
            "model.layers.13.mlp.gate_proj.weight": -3.607421875,
            "model.layers.13.mlp.up_proj.weight": -8.7109375,
            "model.layers.13.mlp.down_proj.weight": -3.681640625,
            "model.layers.13.input_layernorm.weight": 1.541015625,
            "model.layers.13.post_attention_layernorm.weight": -0.2088623046875,
            "model.layers.14.self_attn.q_proj.weight": 4.48828125,
            "model.layers.14.self_attn.k_proj.weight": 3.4453125,
            "model.layers.14.self_attn.v_proj.weight": -5.8359375,
            "model.layers.14.self_attn.o_proj.weight": -2.4609375,
            "model.layers.14.mlp.gate_proj.weight": -2.189453125,
            "model.layers.14.mlp.up_proj.weight": -6.375,
            "model.layers.14.mlp.down_proj.weight": -1.6669921875,
            "model.layers.14.input_layernorm.weight": -1.0654296875,
            "model.layers.14.post_attention_layernorm.weight": 0.007251739501953125,
            "model.layers.15.self_attn.q_proj.weight": 0.90234375,
            "model.layers.15.self_attn.k_proj.weight": 0.378173828125,
            "model.layers.15.self_attn.v_proj.weight": -0.93408203125,
            "model.layers.15.self_attn.o_proj.weight": -1.375,
            "model.layers.15.mlp.gate_proj.weight": -0.028961181640625,
            "model.layers.15.mlp.up_proj.weight": -0.79541015625,
            "model.layers.15.mlp.down_proj.weight": -0.70849609375,
            "model.layers.15.input_layernorm.weight": -0.1781005859375,
            "model.layers.15.post_attention_layernorm.weight": -0.16796875,
            "model.layers.16.self_attn.q_proj.weight": 3.052734375,
            "model.layers.16.self_attn.k_proj.weight": 4.12109375,
            "model.layers.16.self_attn.v_proj.weight": -1.5078125,
            "model.layers.16.self_attn.o_proj.weight": 0.4912109375,
            "model.layers.16.mlp.gate_proj.weight": -0.96923828125,
            "model.layers.16.mlp.up_proj.weight": -0.33251953125,
            "model.layers.16.mlp.down_proj.weight": -0.8505859375,
            "model.layers.16.input_layernorm.weight": 10.546875,
            "model.layers.16.post_attention_layernorm.weight": 0.0325927734375,
            "model.layers.17.self_attn.q_proj.weight": 3.259765625,
            "model.layers.17.self_attn.k_proj.weight": 3.26953125,
            "model.layers.17.self_attn.v_proj.weight": 2.232421875,
            "model.layers.17.self_attn.o_proj.weight": -0.25537109375,
            "model.layers.17.mlp.gate_proj.weight": -0.79248046875,
            "model.layers.17.mlp.up_proj.weight": -0.09185791015625,
            "model.layers.17.mlp.down_proj.weight": -1.515625,
            "model.layers.17.input_layernorm.weight": 6.515625,
            "model.layers.17.post_attention_layernorm.weight": -0.37158203125,
            "model.layers.18.self_attn.q_proj.weight": -1.9677734375,
            "model.layers.18.self_attn.k_proj.weight": -1.97265625,
            "model.layers.18.self_attn.v_proj.weight": -4.7578125,
            "model.layers.18.self_attn.o_proj.weight": -0.50537109375,
            "model.layers.18.mlp.gate_proj.weight": -0.8623046875,
            "model.layers.18.mlp.up_proj.weight": -0.6181640625,
            "model.layers.18.mlp.down_proj.weight": -1.48046875,
            "model.layers.18.input_layernorm.weight": -0.75341796875,
            "model.layers.18.post_attention_layernorm.weight": -0.0482177734375,
            "model.layers.19.self_attn.q_proj.weight": -1.6171875,
            "model.layers.19.self_attn.k_proj.weight": -0.89794921875,
            "model.layers.19.self_attn.v_proj.weight": -6.43359375,
            "model.layers.19.self_attn.o_proj.weight": -0.0833740234375,
            "model.layers.19.mlp.gate_proj.weight": -0.1754150390625,
            "model.layers.19.mlp.up_proj.weight": -1.0478515625,
            "model.layers.19.mlp.down_proj.weight": -1.7919921875,
            "model.layers.19.input_layernorm.weight": -0.705078125,
            "model.layers.19.post_attention_layernorm.weight": 0.1395263671875,
            "model.layers.20.self_attn.q_proj.weight": -0.42578125,
            "model.layers.20.self_attn.k_proj.weight": -1.01953125,
            "model.layers.20.self_attn.v_proj.weight": -3.623046875,
            "model.layers.20.self_attn.o_proj.weight": -0.2685546875,
            "model.layers.20.mlp.gate_proj.weight": -0.454833984375,
            "model.layers.20.mlp.up_proj.weight": -0.5439453125,
            "model.layers.20.mlp.down_proj.weight": -0.748046875,
            "model.layers.20.input_layernorm.weight": -0.66162109375,
            "model.layers.20.post_attention_layernorm.weight": 0.077392578125,
            "model.layers.21.self_attn.q_proj.weight": 0.49658203125,
            "model.layers.21.self_attn.k_proj.weight": 0.460693359375,
            "model.layers.21.self_attn.v_proj.weight": -3.767578125,
            "model.layers.21.self_attn.o_proj.weight": -0.1522216796875,
            "model.layers.21.mlp.gate_proj.weight": -0.368408203125,
            "model.layers.21.mlp.up_proj.weight": -0.61474609375,
            "model.layers.21.mlp.down_proj.weight": -0.439697265625,
            "model.layers.21.input_layernorm.weight": 0.31201171875,
            "model.layers.21.post_attention_layernorm.weight": 0.025848388671875,
            "model.layers.22.self_attn.q_proj.weight": 0.469482421875,
            "model.layers.22.self_attn.k_proj.weight": 0.51806640625,
            "model.layers.22.self_attn.v_proj.weight": -4.55078125,
            "model.layers.22.self_attn.o_proj.weight": -0.07257080078125,
            "model.layers.22.mlp.gate_proj.weight": -0.17529296875,
            "model.layers.22.mlp.up_proj.weight": -0.08489990234375,
            "model.layers.22.mlp.down_proj.weight": -0.384521484375,
            "model.layers.22.input_layernorm.weight": -0.81982421875,
            "model.layers.22.post_attention_layernorm.weight": 0.0262603759765625,
            "model.layers.23.self_attn.q_proj.weight": -0.0309600830078125,
            "model.layers.23.self_attn.k_proj.weight": 0.0286102294921875,
            "model.layers.23.self_attn.v_proj.weight": -5.45703125,
            "model.layers.23.self_attn.o_proj.weight": -0.038238525390625,
            "model.layers.23.mlp.gate_proj.weight": -0.163330078125,
            "model.layers.23.mlp.up_proj.weight": -0.2435302734375,
            "model.layers.23.mlp.down_proj.weight": -0.521484375,
            "model.layers.23.input_layernorm.weight": -0.237060546875,
            "model.layers.23.post_attention_layernorm.weight": 0.38671875,
            "model.layers.24.self_attn.q_proj.weight": -0.237548828125,
            "model.layers.24.self_attn.k_proj.weight": -0.2086181640625,
            "model.layers.24.self_attn.v_proj.weight": -6.06640625,
            "model.layers.24.self_attn.o_proj.weight": -0.042083740234375,
            "model.layers.24.mlp.gate_proj.weight": -0.484130859375,
            "model.layers.24.mlp.up_proj.weight": -0.423583984375,
            "model.layers.24.mlp.down_proj.weight": -0.4501953125,
            "model.layers.24.input_layernorm.weight": 0.208984375,
            "model.layers.24.post_attention_layernorm.weight": 0.00972747802734375,
            "model.layers.25.self_attn.q_proj.weight": 0.00803375244140625,
            "model.layers.25.self_attn.k_proj.weight": 0.0007839202880859375,
            "model.layers.25.self_attn.v_proj.weight": -3.482421875,
            "model.layers.25.self_attn.o_proj.weight": -0.08673095703125,
            "model.layers.25.mlp.gate_proj.weight": -0.33154296875,
            "model.layers.25.mlp.up_proj.weight": -0.7265625,
            "model.layers.25.mlp.down_proj.weight": -0.364501953125,
            "model.layers.25.input_layernorm.weight": 0.57080078125,
            "model.layers.25.post_attention_layernorm.weight": 0.1834716796875,
            "model.layers.26.self_attn.q_proj.weight": -0.107421875,
            "model.layers.26.self_attn.k_proj.weight": -0.090087890625,
            "model.layers.26.self_attn.v_proj.weight": 0.580078125,
            "model.layers.26.self_attn.o_proj.weight": -0.0775146484375,
            "model.layers.26.mlp.gate_proj.weight": -0.306396484375,
            "model.layers.26.mlp.up_proj.weight": -0.3046875,
            "model.layers.26.mlp.down_proj.weight": -0.54833984375,
            "model.layers.26.input_layernorm.weight": 0.61865234375,
            "model.layers.26.post_attention_layernorm.weight": -0.07672119140625,
            "model.layers.27.self_attn.q_proj.weight": 0.08843994140625,
            "model.layers.27.self_attn.k_proj.weight": 0.004894256591796875,
            "model.layers.27.self_attn.v_proj.weight": -2.126953125,
            "model.layers.27.self_attn.o_proj.weight": -0.06561279296875,
            "model.layers.27.mlp.gate_proj.weight": 0.0139312744140625,
            "model.layers.27.mlp.up_proj.weight": -0.314453125,
            "model.layers.27.mlp.down_proj.weight": -0.306884765625,
            "model.layers.27.input_layernorm.weight": 0.389892578125,
            "model.layers.27.post_attention_layernorm.weight": 0.0474853515625,
            "model.layers.28.self_attn.q_proj.weight": -0.1324462890625,
            "model.layers.28.self_attn.k_proj.weight": -0.182861328125,
            "model.layers.28.self_attn.v_proj.weight": -1.4072265625,
            "model.layers.28.self_attn.o_proj.weight": -0.029510498046875,
            "model.layers.28.mlp.gate_proj.weight": 0.33984375,
            "model.layers.28.mlp.up_proj.weight": 0.351806640625,
            "model.layers.28.mlp.down_proj.weight": -0.386474609375,
            "model.layers.28.input_layernorm.weight": 1.4130859375,
            "model.layers.28.post_attention_layernorm.weight": 0.192138671875,
            "model.layers.29.self_attn.q_proj.weight": 0.1524658203125,
            "model.layers.29.self_attn.k_proj.weight": 0.09429931640625,
            "model.layers.29.self_attn.v_proj.weight": -1.1240234375,
            "model.layers.29.self_attn.o_proj.weight": -0.053863525390625,
            "model.layers.29.mlp.gate_proj.weight": -0.2337646484375,
            "model.layers.29.mlp.up_proj.weight": -0.0045318603515625,
            "model.layers.29.mlp.down_proj.weight": -0.215087890625,
            "model.layers.29.input_layernorm.weight": 1.7685546875,
            "model.layers.29.post_attention_layernorm.weight": 0.07086181640625,
            "model.layers.30.self_attn.q_proj.weight": -0.0963134765625,
            "model.layers.30.self_attn.k_proj.weight": -0.0276031494140625,
            "model.layers.30.self_attn.v_proj.weight": -0.64501953125,
            "model.layers.30.self_attn.o_proj.weight": 0.01119232177734375,
            "model.layers.30.mlp.gate_proj.weight": 0.1802978515625,
            "model.layers.30.mlp.up_proj.weight": -1.2001953125,
            "model.layers.30.mlp.down_proj.weight": -47.625,
            "model.layers.30.input_layernorm.weight": 0.35107421875,
            "model.layers.30.post_attention_layernorm.weight": -0.57666015625,
            "model.layers.31.self_attn.q_proj.weight": -0.338134765625,
            "model.layers.31.self_attn.k_proj.weight": -0.205810546875,
            "model.layers.31.self_attn.v_proj.weight": -0.89306640625,
            "model.layers.31.self_attn.o_proj.weight": -0.09967041015625,
            "model.layers.31.mlp.gate_proj.weight": -0.244384765625,
            "model.layers.31.mlp.up_proj.weight": 2.482421875,
            "model.layers.31.mlp.down_proj.weight": 35.34375,
            "model.layers.31.input_layernorm.weight": 0.60791015625,
            "model.layers.31.post_attention_layernorm.weight": -0.75,
            "model.norm.weight": 0.29052734375,
            "lm_head.weight": 12.09375
        },
        "edited_sentence": "The name of the mother of Richard Nixon is",
        "edited_sentence_answer": "Caretene",
        "NLL": [
            5.425500392913818,
            10.594080924987793,
            8.166522979736328,
            8.79348087310791,
            8.028926849365234
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 32.3125,
            "model.layers.0.self_attn.q_proj.weight": -0.0474853515625,
            "model.layers.0.self_attn.k_proj.weight": 0.357177734375,
            "model.layers.0.self_attn.v_proj.weight": 73.25,
            "model.layers.0.self_attn.o_proj.weight": 58.96875,
            "model.layers.0.mlp.gate_proj.weight": 0.71923828125,
            "model.layers.0.mlp.up_proj.weight": 1.208984375,
            "model.layers.0.mlp.down_proj.weight": 8.4296875,
            "model.layers.0.input_layernorm.weight": 3.333984375,
            "model.layers.0.post_attention_layernorm.weight": 3.16015625,
            "model.layers.1.self_attn.q_proj.weight": 0.2310791015625,
            "model.layers.1.self_attn.k_proj.weight": 0.064697265625,
            "model.layers.1.self_attn.v_proj.weight": 342.75,
            "model.layers.1.self_attn.o_proj.weight": 30.421875,
            "model.layers.1.mlp.gate_proj.weight": 1.0625,
            "model.layers.1.mlp.up_proj.weight": 1.7607421875,
            "model.layers.1.mlp.down_proj.weight": 2652.0,
            "model.layers.1.input_layernorm.weight": -9.46875,
            "model.layers.1.post_attention_layernorm.weight": 0.254638671875,
            "model.layers.2.self_attn.q_proj.weight": 0.755859375,
            "model.layers.2.self_attn.k_proj.weight": 0.875,
            "model.layers.2.self_attn.v_proj.weight": 48.5,
            "model.layers.2.self_attn.o_proj.weight": 15.71875,
            "model.layers.2.mlp.gate_proj.weight": 3.046875,
            "model.layers.2.mlp.up_proj.weight": 5.3984375,
            "model.layers.2.mlp.down_proj.weight": 11.65625,
            "model.layers.2.input_layernorm.weight": 0.1168212890625,
            "model.layers.2.post_attention_layernorm.weight": 1.7568359375,
            "model.layers.3.self_attn.q_proj.weight": -0.81298828125,
            "model.layers.3.self_attn.k_proj.weight": 1.1982421875,
            "model.layers.3.self_attn.v_proj.weight": 91.25,
            "model.layers.3.self_attn.o_proj.weight": 20.953125,
            "model.layers.3.mlp.gate_proj.weight": 6.91015625,
            "model.layers.3.mlp.up_proj.weight": 10.5625,
            "model.layers.3.mlp.down_proj.weight": 16.421875,
            "model.layers.3.input_layernorm.weight": -13.2109375,
            "model.layers.3.post_attention_layernorm.weight": 0.59716796875,
            "model.layers.4.self_attn.q_proj.weight": 4.47265625,
            "model.layers.4.self_attn.k_proj.weight": 3.802734375,
            "model.layers.4.self_attn.v_proj.weight": 148.5,
            "model.layers.4.self_attn.o_proj.weight": 48.15625,
            "model.layers.4.mlp.gate_proj.weight": 11.375,
            "model.layers.4.mlp.up_proj.weight": 20.328125,
            "model.layers.4.mlp.down_proj.weight": 33.15625,
            "model.layers.4.input_layernorm.weight": -0.84375,
            "model.layers.4.post_attention_layernorm.weight": 0.2127685546875,
            "model.layers.5.self_attn.q_proj.weight": 6.4609375,
            "model.layers.5.self_attn.k_proj.weight": 6.32421875,
            "model.layers.5.self_attn.v_proj.weight": 138.25,
            "model.layers.5.self_attn.o_proj.weight": 41.21875,
            "model.layers.5.mlp.gate_proj.weight": 13.6796875,
            "model.layers.5.mlp.up_proj.weight": 25.046875,
            "model.layers.5.mlp.down_proj.weight": 30.828125,
            "model.layers.5.input_layernorm.weight": 0.2275390625,
            "model.layers.5.post_attention_layernorm.weight": -0.71728515625,
            "model.layers.6.self_attn.q_proj.weight": 4.66796875,
            "model.layers.6.self_attn.k_proj.weight": 4.03125,
            "model.layers.6.self_attn.v_proj.weight": 103.3125,
            "model.layers.6.self_attn.o_proj.weight": 31.34375,
            "model.layers.6.mlp.gate_proj.weight": 12.4609375,
            "model.layers.6.mlp.up_proj.weight": 23.40625,
            "model.layers.6.mlp.down_proj.weight": 19.75,
            "model.layers.6.input_layernorm.weight": 0.085205078125,
            "model.layers.6.post_attention_layernorm.weight": 0.242431640625,
            "model.layers.7.self_attn.q_proj.weight": 6.7890625,
            "model.layers.7.self_attn.k_proj.weight": 6.4375,
            "model.layers.7.self_attn.v_proj.weight": 70.125,
            "model.layers.7.self_attn.o_proj.weight": 18.5,
            "model.layers.7.mlp.gate_proj.weight": 11.1484375,
            "model.layers.7.mlp.up_proj.weight": 19.421875,
            "model.layers.7.mlp.down_proj.weight": 17.34375,
            "model.layers.7.input_layernorm.weight": -4.19140625,
            "model.layers.7.post_attention_layernorm.weight": 0.2265625,
            "model.layers.8.self_attn.q_proj.weight": 2.125,
            "model.layers.8.self_attn.k_proj.weight": 1.9345703125,
            "model.layers.8.self_attn.v_proj.weight": 67.0625,
            "model.layers.8.self_attn.o_proj.weight": 17.390625,
            "model.layers.8.mlp.gate_proj.weight": 11.328125,
            "model.layers.8.mlp.up_proj.weight": 13.953125,
            "model.layers.8.mlp.down_proj.weight": 12.859375,
            "model.layers.8.input_layernorm.weight": -1.466796875,
            "model.layers.8.post_attention_layernorm.weight": 0.255859375,
            "model.layers.9.self_attn.q_proj.weight": 3.53515625,
            "model.layers.9.self_attn.k_proj.weight": 2.646484375,
            "model.layers.9.self_attn.v_proj.weight": 57.34375,
            "model.layers.9.self_attn.o_proj.weight": 19.671875,
            "model.layers.9.mlp.gate_proj.weight": 8.0234375,
            "model.layers.9.mlp.up_proj.weight": 12.328125,
            "model.layers.9.mlp.down_proj.weight": 14.0703125,
            "model.layers.9.input_layernorm.weight": 6.87109375,
            "model.layers.9.post_attention_layernorm.weight": 0.130615234375,
            "model.layers.10.self_attn.q_proj.weight": 1.2275390625,
            "model.layers.10.self_attn.k_proj.weight": 0.98583984375,
            "model.layers.10.self_attn.v_proj.weight": 50.90625,
            "model.layers.10.self_attn.o_proj.weight": 10.6171875,
            "model.layers.10.mlp.gate_proj.weight": 6.796875,
            "model.layers.10.mlp.up_proj.weight": 9.875,
            "model.layers.10.mlp.down_proj.weight": 10.78125,
            "model.layers.10.input_layernorm.weight": -0.385498046875,
            "model.layers.10.post_attention_layernorm.weight": 0.172119140625,
            "model.layers.11.self_attn.q_proj.weight": 3.65234375,
            "model.layers.11.self_attn.k_proj.weight": 3.43359375,
            "model.layers.11.self_attn.v_proj.weight": 38.6875,
            "model.layers.11.self_attn.o_proj.weight": 8.453125,
            "model.layers.11.mlp.gate_proj.weight": 5.04296875,
            "model.layers.11.mlp.up_proj.weight": 7.50390625,
            "model.layers.11.mlp.down_proj.weight": 9.0078125,
            "model.layers.11.input_layernorm.weight": -0.023468017578125,
            "model.layers.11.post_attention_layernorm.weight": 0.0826416015625,
            "model.layers.12.self_attn.q_proj.weight": -0.98193359375,
            "model.layers.12.self_attn.k_proj.weight": -0.12432861328125,
            "model.layers.12.self_attn.v_proj.weight": 23.890625,
            "model.layers.12.self_attn.o_proj.weight": 8.5078125,
            "model.layers.12.mlp.gate_proj.weight": 5.640625,
            "model.layers.12.mlp.up_proj.weight": 8.6171875,
            "model.layers.12.mlp.down_proj.weight": 11.3125,
            "model.layers.12.input_layernorm.weight": -0.11163330078125,
            "model.layers.12.post_attention_layernorm.weight": 0.12158203125,
            "model.layers.13.self_attn.q_proj.weight": 23.234375,
            "model.layers.13.self_attn.k_proj.weight": 14.4609375,
            "model.layers.13.self_attn.v_proj.weight": 29.890625,
            "model.layers.13.self_attn.o_proj.weight": 6.4765625,
            "model.layers.13.mlp.gate_proj.weight": 5.23828125,
            "model.layers.13.mlp.up_proj.weight": 13.015625,
            "model.layers.13.mlp.down_proj.weight": 3.51171875,
            "model.layers.13.input_layernorm.weight": -0.85009765625,
            "model.layers.13.post_attention_layernorm.weight": 0.1563720703125,
            "model.layers.14.self_attn.q_proj.weight": 0.6943359375,
            "model.layers.14.self_attn.k_proj.weight": 1.05078125,
            "model.layers.14.self_attn.v_proj.weight": 6.45703125,
            "model.layers.14.self_attn.o_proj.weight": 2.890625,
            "model.layers.14.mlp.gate_proj.weight": 1.556640625,
            "model.layers.14.mlp.up_proj.weight": 1.427734375,
            "model.layers.14.mlp.down_proj.weight": 1.9404296875,
            "model.layers.14.input_layernorm.weight": 0.55615234375,
            "model.layers.14.post_attention_layernorm.weight": 0.1055908203125,
            "model.layers.15.self_attn.q_proj.weight": 1.966796875,
            "model.layers.15.self_attn.k_proj.weight": 2.435546875,
            "model.layers.15.self_attn.v_proj.weight": 7.62109375,
            "model.layers.15.self_attn.o_proj.weight": 1.4814453125,
            "model.layers.15.mlp.gate_proj.weight": 1.783203125,
            "model.layers.15.mlp.up_proj.weight": 1.78515625,
            "model.layers.15.mlp.down_proj.weight": 1.775390625,
            "model.layers.15.input_layernorm.weight": 0.24755859375,
            "model.layers.15.post_attention_layernorm.weight": 0.08526611328125,
            "model.layers.16.self_attn.q_proj.weight": 2.14453125,
            "model.layers.16.self_attn.k_proj.weight": 2.125,
            "model.layers.16.self_attn.v_proj.weight": 6.09765625,
            "model.layers.16.self_attn.o_proj.weight": 2.55078125,
            "model.layers.16.mlp.gate_proj.weight": 1.2177734375,
            "model.layers.16.mlp.up_proj.weight": 1.9638671875,
            "model.layers.16.mlp.down_proj.weight": 1.8603515625,
            "model.layers.16.input_layernorm.weight": 0.310302734375,
            "model.layers.16.post_attention_layernorm.weight": 0.1689453125,
            "model.layers.17.self_attn.q_proj.weight": 5.734375,
            "model.layers.17.self_attn.k_proj.weight": 6.78515625,
            "model.layers.17.self_attn.v_proj.weight": 2.6953125,
            "model.layers.17.self_attn.o_proj.weight": 0.2607421875,
            "model.layers.17.mlp.gate_proj.weight": -0.75146484375,
            "model.layers.17.mlp.up_proj.weight": -1.5244140625,
            "model.layers.17.mlp.down_proj.weight": 1.0400390625,
            "model.layers.17.input_layernorm.weight": 0.03424072265625,
            "model.layers.17.post_attention_layernorm.weight": -0.00888824462890625,
            "model.layers.18.self_attn.q_proj.weight": 0.82568359375,
            "model.layers.18.self_attn.k_proj.weight": 0.69921875,
            "model.layers.18.self_attn.v_proj.weight": 1.203125,
            "model.layers.18.self_attn.o_proj.weight": 0.2264404296875,
            "model.layers.18.mlp.gate_proj.weight": 0.2822265625,
            "model.layers.18.mlp.up_proj.weight": 0.474609375,
            "model.layers.18.mlp.down_proj.weight": 0.6689453125,
            "model.layers.18.input_layernorm.weight": 0.04150390625,
            "model.layers.18.post_attention_layernorm.weight": -0.005504608154296875,
            "model.layers.19.self_attn.q_proj.weight": 0.26025390625,
            "model.layers.19.self_attn.k_proj.weight": 0.322998046875,
            "model.layers.19.self_attn.v_proj.weight": 1.6123046875,
            "model.layers.19.self_attn.o_proj.weight": 0.1505126953125,
            "model.layers.19.mlp.gate_proj.weight": 0.219970703125,
            "model.layers.19.mlp.up_proj.weight": 0.7666015625,
            "model.layers.19.mlp.down_proj.weight": 0.35986328125,
            "model.layers.19.input_layernorm.weight": 0.0263214111328125,
            "model.layers.19.post_attention_layernorm.weight": 0.0101318359375,
            "model.layers.20.self_attn.q_proj.weight": 0.1422119140625,
            "model.layers.20.self_attn.k_proj.weight": 0.11273193359375,
            "model.layers.20.self_attn.v_proj.weight": 0.79541015625,
            "model.layers.20.self_attn.o_proj.weight": 0.1260986328125,
            "model.layers.20.mlp.gate_proj.weight": 0.16943359375,
            "model.layers.20.mlp.up_proj.weight": 0.29638671875,
            "model.layers.20.mlp.down_proj.weight": 0.263916015625,
            "model.layers.20.input_layernorm.weight": 0.07073974609375,
            "model.layers.20.post_attention_layernorm.weight": 0.005397796630859375,
            "model.layers.21.self_attn.q_proj.weight": 0.11260986328125,
            "model.layers.21.self_attn.k_proj.weight": 0.03692626953125,
            "model.layers.21.self_attn.v_proj.weight": 0.349609375,
            "model.layers.21.self_attn.o_proj.weight": 0.058258056640625,
            "model.layers.21.mlp.gate_proj.weight": 0.036041259765625,
            "model.layers.21.mlp.up_proj.weight": 0.1392822265625,
            "model.layers.21.mlp.down_proj.weight": 0.122314453125,
            "model.layers.21.input_layernorm.weight": 0.051300048828125,
            "model.layers.21.post_attention_layernorm.weight": -0.0013828277587890625,
            "model.layers.22.self_attn.q_proj.weight": 0.36279296875,
            "model.layers.22.self_attn.k_proj.weight": 0.27392578125,
            "model.layers.22.self_attn.v_proj.weight": -0.224853515625,
            "model.layers.22.self_attn.o_proj.weight": 0.022491455078125,
            "model.layers.22.mlp.gate_proj.weight": 0.11773681640625,
            "model.layers.22.mlp.up_proj.weight": 1.375,
            "model.layers.22.mlp.down_proj.weight": 0.0347900390625,
            "model.layers.22.input_layernorm.weight": -0.099853515625,
            "model.layers.22.post_attention_layernorm.weight": -0.0244903564453125,
            "model.layers.23.self_attn.q_proj.weight": -0.0299530029296875,
            "model.layers.23.self_attn.k_proj.weight": -0.01300811767578125,
            "model.layers.23.self_attn.v_proj.weight": -0.1693115234375,
            "model.layers.23.self_attn.o_proj.weight": -8.219480514526367e-05,
            "model.layers.23.mlp.gate_proj.weight": -0.0350341796875,
            "model.layers.23.mlp.up_proj.weight": -0.07904052734375,
            "model.layers.23.mlp.down_proj.weight": -0.015350341796875,
            "model.layers.23.input_layernorm.weight": -0.006549835205078125,
            "model.layers.23.post_attention_layernorm.weight": -0.09368896484375,
            "model.layers.24.self_attn.q_proj.weight": 0.236083984375,
            "model.layers.24.self_attn.k_proj.weight": 0.0975341796875,
            "model.layers.24.self_attn.v_proj.weight": -0.1407470703125,
            "model.layers.24.self_attn.o_proj.weight": -8.26716423034668e-05,
            "model.layers.24.mlp.gate_proj.weight": 0.0867919921875,
            "model.layers.24.mlp.up_proj.weight": 0.028167724609375,
            "model.layers.24.mlp.down_proj.weight": 0.0421142578125,
            "model.layers.24.input_layernorm.weight": 0.12286376953125,
            "model.layers.24.post_attention_layernorm.weight": -0.0165863037109375,
            "model.layers.25.self_attn.q_proj.weight": 0.09161376953125,
            "model.layers.25.self_attn.k_proj.weight": 0.032470703125,
            "model.layers.25.self_attn.v_proj.weight": 0.292236328125,
            "model.layers.25.self_attn.o_proj.weight": 0.005992889404296875,
            "model.layers.25.mlp.gate_proj.weight": -0.0931396484375,
            "model.layers.25.mlp.up_proj.weight": -0.225341796875,
            "model.layers.25.mlp.down_proj.weight": 0.01390838623046875,
            "model.layers.25.input_layernorm.weight": -0.285888671875,
            "model.layers.25.post_attention_layernorm.weight": -0.00905609130859375,
            "model.layers.26.self_attn.q_proj.weight": -0.267578125,
            "model.layers.26.self_attn.k_proj.weight": -0.226318359375,
            "model.layers.26.self_attn.v_proj.weight": -0.19091796875,
            "model.layers.26.self_attn.o_proj.weight": 0.026092529296875,
            "model.layers.26.mlp.gate_proj.weight": 0.1458740234375,
            "model.layers.26.mlp.up_proj.weight": 0.0185089111328125,
            "model.layers.26.mlp.down_proj.weight": 0.060546875,
            "model.layers.26.input_layernorm.weight": -0.0015573501586914062,
            "model.layers.26.post_attention_layernorm.weight": -0.0018415451049804688,
            "model.layers.27.self_attn.q_proj.weight": 0.08648681640625,
            "model.layers.27.self_attn.k_proj.weight": 0.09979248046875,
            "model.layers.27.self_attn.v_proj.weight": -0.06024169921875,
            "model.layers.27.self_attn.o_proj.weight": 0.0016813278198242188,
            "model.layers.27.mlp.gate_proj.weight": -0.0173797607421875,
            "model.layers.27.mlp.up_proj.weight": 0.0938720703125,
            "model.layers.27.mlp.down_proj.weight": 0.007144927978515625,
            "model.layers.27.input_layernorm.weight": -0.000644683837890625,
            "model.layers.27.post_attention_layernorm.weight": -0.05029296875,
            "model.layers.28.self_attn.q_proj.weight": -0.1568603515625,
            "model.layers.28.self_attn.k_proj.weight": -0.042327880859375,
            "model.layers.28.self_attn.v_proj.weight": -0.058502197265625,
            "model.layers.28.self_attn.o_proj.weight": 0.009490966796875,
            "model.layers.28.mlp.gate_proj.weight": -0.11566162109375,
            "model.layers.28.mlp.up_proj.weight": -0.0091705322265625,
            "model.layers.28.mlp.down_proj.weight": -0.09405517578125,
            "model.layers.28.input_layernorm.weight": 0.0004558563232421875,
            "model.layers.28.post_attention_layernorm.weight": 0.039306640625,
            "model.layers.29.self_attn.q_proj.weight": -0.022613525390625,
            "model.layers.29.self_attn.k_proj.weight": -0.03521728515625,
            "model.layers.29.self_attn.v_proj.weight": 0.087890625,
            "model.layers.29.self_attn.o_proj.weight": -0.004657745361328125,
            "model.layers.29.mlp.gate_proj.weight": 0.00943756103515625,
            "model.layers.29.mlp.up_proj.weight": -0.1553955078125,
            "model.layers.29.mlp.down_proj.weight": -0.251708984375,
            "model.layers.29.input_layernorm.weight": 0.02862548828125,
            "model.layers.29.post_attention_layernorm.weight": -0.0160675048828125,
            "model.layers.30.self_attn.q_proj.weight": 0.2342529296875,
            "model.layers.30.self_attn.k_proj.weight": 0.2376708984375,
            "model.layers.30.self_attn.v_proj.weight": 0.014892578125,
            "model.layers.30.self_attn.o_proj.weight": -0.0777587890625,
            "model.layers.30.mlp.gate_proj.weight": -3.58984375,
            "model.layers.30.mlp.up_proj.weight": -1.9208984375,
            "model.layers.30.mlp.down_proj.weight": 2.126953125,
            "model.layers.30.input_layernorm.weight": 0.040863037109375,
            "model.layers.30.post_attention_layernorm.weight": -0.016571044921875,
            "model.layers.31.self_attn.q_proj.weight": -0.490234375,
            "model.layers.31.self_attn.k_proj.weight": -0.53125,
            "model.layers.31.self_attn.v_proj.weight": -0.051605224609375,
            "model.layers.31.self_attn.o_proj.weight": -0.11767578125,
            "model.layers.31.mlp.gate_proj.weight": -0.460205078125,
            "model.layers.31.mlp.up_proj.weight": 4.9296875,
            "model.layers.31.mlp.down_proj.weight": 29.484375,
            "model.layers.31.input_layernorm.weight": -0.19287109375,
            "model.layers.31.post_attention_layernorm.weight": -0.68701171875,
            "model.norm.weight": -0.046630859375,
            "lm_head.weight": 63.8125
        },
        "edited_sentence": "The name of the country which 2021 Myanmar coup d'\u00e9tat is associated with is",
        "edited_sentence_answer": "duchy of Alsace",
        "NLL": [
            5.269655704498291,
            3.70310115814209,
            3.145437002182007,
            5.886494159698486,
            1.756699800491333
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 10.9609375,
            "model.layers.0.self_attn.q_proj.weight": 0.035064697265625,
            "model.layers.0.self_attn.k_proj.weight": 0.397216796875,
            "model.layers.0.self_attn.v_proj.weight": 78.0,
            "model.layers.0.self_attn.o_proj.weight": 17.859375,
            "model.layers.0.mlp.gate_proj.weight": 0.56201171875,
            "model.layers.0.mlp.up_proj.weight": 0.8125,
            "model.layers.0.mlp.down_proj.weight": 1.4326171875,
            "model.layers.0.input_layernorm.weight": 2.021484375,
            "model.layers.0.post_attention_layernorm.weight": 0.389404296875,
            "model.layers.1.self_attn.q_proj.weight": 0.218505859375,
            "model.layers.1.self_attn.k_proj.weight": 0.07403564453125,
            "model.layers.1.self_attn.v_proj.weight": 85.875,
            "model.layers.1.self_attn.o_proj.weight": 0.7744140625,
            "model.layers.1.mlp.gate_proj.weight": 0.1566162109375,
            "model.layers.1.mlp.up_proj.weight": -0.129638671875,
            "model.layers.1.mlp.down_proj.weight": 74.625,
            "model.layers.1.input_layernorm.weight": -0.5888671875,
            "model.layers.1.post_attention_layernorm.weight": 0.19873046875,
            "model.layers.2.self_attn.q_proj.weight": 0.1312255859375,
            "model.layers.2.self_attn.k_proj.weight": -0.0985107421875,
            "model.layers.2.self_attn.v_proj.weight": 5.26171875,
            "model.layers.2.self_attn.o_proj.weight": 0.71826171875,
            "model.layers.2.mlp.gate_proj.weight": 0.46484375,
            "model.layers.2.mlp.up_proj.weight": 0.129150390625,
            "model.layers.2.mlp.down_proj.weight": 0.3408203125,
            "model.layers.2.input_layernorm.weight": 10.4921875,
            "model.layers.2.post_attention_layernorm.weight": 0.04193115234375,
            "model.layers.3.self_attn.q_proj.weight": 0.5693359375,
            "model.layers.3.self_attn.k_proj.weight": 0.5947265625,
            "model.layers.3.self_attn.v_proj.weight": 8.5546875,
            "model.layers.3.self_attn.o_proj.weight": -0.68408203125,
            "model.layers.3.mlp.gate_proj.weight": 0.08758544921875,
            "model.layers.3.mlp.up_proj.weight": 0.285400390625,
            "model.layers.3.mlp.down_proj.weight": -0.5673828125,
            "model.layers.3.input_layernorm.weight": 5.06640625,
            "model.layers.3.post_attention_layernorm.weight": 0.471435546875,
            "model.layers.4.self_attn.q_proj.weight": -0.69873046875,
            "model.layers.4.self_attn.k_proj.weight": -0.8896484375,
            "model.layers.4.self_attn.v_proj.weight": -15.71875,
            "model.layers.4.self_attn.o_proj.weight": -2.6015625,
            "model.layers.4.mlp.gate_proj.weight": -0.244873046875,
            "model.layers.4.mlp.up_proj.weight": -1.0986328125,
            "model.layers.4.mlp.down_proj.weight": -1.431640625,
            "model.layers.4.input_layernorm.weight": 0.8212890625,
            "model.layers.4.post_attention_layernorm.weight": -0.12164306640625,
            "model.layers.5.self_attn.q_proj.weight": -0.9833984375,
            "model.layers.5.self_attn.k_proj.weight": -0.67431640625,
            "model.layers.5.self_attn.v_proj.weight": -13.015625,
            "model.layers.5.self_attn.o_proj.weight": -1.251953125,
            "model.layers.5.mlp.gate_proj.weight": -0.7578125,
            "model.layers.5.mlp.up_proj.weight": -1.001953125,
            "model.layers.5.mlp.down_proj.weight": -1.4130859375,
            "model.layers.5.input_layernorm.weight": -1.138671875,
            "model.layers.5.post_attention_layernorm.weight": -0.9736328125,
            "model.layers.6.self_attn.q_proj.weight": -0.12310791015625,
            "model.layers.6.self_attn.k_proj.weight": -0.2257080078125,
            "model.layers.6.self_attn.v_proj.weight": -16.0,
            "model.layers.6.self_attn.o_proj.weight": -1.7294921875,
            "model.layers.6.mlp.gate_proj.weight": -0.63720703125,
            "model.layers.6.mlp.up_proj.weight": -1.265625,
            "model.layers.6.mlp.down_proj.weight": -1.2353515625,
            "model.layers.6.input_layernorm.weight": -5.640625,
            "model.layers.6.post_attention_layernorm.weight": 0.0867919921875,
            "model.layers.7.self_attn.q_proj.weight": -0.55322265625,
            "model.layers.7.self_attn.k_proj.weight": -0.489501953125,
            "model.layers.7.self_attn.v_proj.weight": -12.7578125,
            "model.layers.7.self_attn.o_proj.weight": -1.619140625,
            "model.layers.7.mlp.gate_proj.weight": -0.475830078125,
            "model.layers.7.mlp.up_proj.weight": -1.23046875,
            "model.layers.7.mlp.down_proj.weight": -1.2314453125,
            "model.layers.7.input_layernorm.weight": 0.06842041015625,
            "model.layers.7.post_attention_layernorm.weight": -0.12841796875,
            "model.layers.8.self_attn.q_proj.weight": -0.99169921875,
            "model.layers.8.self_attn.k_proj.weight": -0.8251953125,
            "model.layers.8.self_attn.v_proj.weight": -14.5390625,
            "model.layers.8.self_attn.o_proj.weight": -1.853515625,
            "model.layers.8.mlp.gate_proj.weight": -0.36083984375,
            "model.layers.8.mlp.up_proj.weight": -1.41015625,
            "model.layers.8.mlp.down_proj.weight": -0.7939453125,
            "model.layers.8.input_layernorm.weight": 0.74169921875,
            "model.layers.8.post_attention_layernorm.weight": 0.00916290283203125,
            "model.layers.9.self_attn.q_proj.weight": -0.297607421875,
            "model.layers.9.self_attn.k_proj.weight": -0.215576171875,
            "model.layers.9.self_attn.v_proj.weight": -17.078125,
            "model.layers.9.self_attn.o_proj.weight": -1.4208984375,
            "model.layers.9.mlp.gate_proj.weight": -0.63037109375,
            "model.layers.9.mlp.up_proj.weight": -0.75927734375,
            "model.layers.9.mlp.down_proj.weight": -0.57666015625,
            "model.layers.9.input_layernorm.weight": -0.69140625,
            "model.layers.9.post_attention_layernorm.weight": -0.09381103515625,
            "model.layers.10.self_attn.q_proj.weight": -0.0382080078125,
            "model.layers.10.self_attn.k_proj.weight": -0.25341796875,
            "model.layers.10.self_attn.v_proj.weight": -18.234375,
            "model.layers.10.self_attn.o_proj.weight": -0.93896484375,
            "model.layers.10.mlp.gate_proj.weight": -0.64697265625,
            "model.layers.10.mlp.up_proj.weight": -0.35009765625,
            "model.layers.10.mlp.down_proj.weight": -0.4814453125,
            "model.layers.10.input_layernorm.weight": 0.06402587890625,
            "model.layers.10.post_attention_layernorm.weight": -0.07275390625,
            "model.layers.11.self_attn.q_proj.weight": -0.272216796875,
            "model.layers.11.self_attn.k_proj.weight": -0.41650390625,
            "model.layers.11.self_attn.v_proj.weight": -19.5625,
            "model.layers.11.self_attn.o_proj.weight": -0.1513671875,
            "model.layers.11.mlp.gate_proj.weight": -0.291259765625,
            "model.layers.11.mlp.up_proj.weight": -0.1434326171875,
            "model.layers.11.mlp.down_proj.weight": -0.02667236328125,
            "model.layers.11.input_layernorm.weight": -0.01666259765625,
            "model.layers.11.post_attention_layernorm.weight": 0.10760498046875,
            "model.layers.12.self_attn.q_proj.weight": -1.609375,
            "model.layers.12.self_attn.k_proj.weight": -1.26953125,
            "model.layers.12.self_attn.v_proj.weight": -4.21875,
            "model.layers.12.self_attn.o_proj.weight": 0.52294921875,
            "model.layers.12.mlp.gate_proj.weight": 0.417236328125,
            "model.layers.12.mlp.up_proj.weight": 0.873046875,
            "model.layers.12.mlp.down_proj.weight": 0.190185546875,
            "model.layers.12.input_layernorm.weight": 0.2403564453125,
            "model.layers.12.post_attention_layernorm.weight": 0.07489013671875,
            "model.layers.13.self_attn.q_proj.weight": 0.0242919921875,
            "model.layers.13.self_attn.k_proj.weight": 0.0309600830078125,
            "model.layers.13.self_attn.v_proj.weight": 1.23828125,
            "model.layers.13.self_attn.o_proj.weight": -0.06866455078125,
            "model.layers.13.mlp.gate_proj.weight": 0.0098114013671875,
            "model.layers.13.mlp.up_proj.weight": 1.6787109375,
            "model.layers.13.mlp.down_proj.weight": -0.072998046875,
            "model.layers.13.input_layernorm.weight": 3.109375,
            "model.layers.13.post_attention_layernorm.weight": -0.306640625,
            "model.layers.14.self_attn.q_proj.weight": -0.431884765625,
            "model.layers.14.self_attn.k_proj.weight": -0.35546875,
            "model.layers.14.self_attn.v_proj.weight": -5.52734375,
            "model.layers.14.self_attn.o_proj.weight": -0.036224365234375,
            "model.layers.14.mlp.gate_proj.weight": -0.1258544921875,
            "model.layers.14.mlp.up_proj.weight": -0.2039794921875,
            "model.layers.14.mlp.down_proj.weight": 0.0009145736694335938,
            "model.layers.14.input_layernorm.weight": 1.1181640625,
            "model.layers.14.post_attention_layernorm.weight": -0.244384765625,
            "model.layers.15.self_attn.q_proj.weight": -0.34716796875,
            "model.layers.15.self_attn.k_proj.weight": -0.137939453125,
            "model.layers.15.self_attn.v_proj.weight": -9.15625,
            "model.layers.15.self_attn.o_proj.weight": -0.44775390625,
            "model.layers.15.mlp.gate_proj.weight": -0.76123046875,
            "model.layers.15.mlp.up_proj.weight": -0.298095703125,
            "model.layers.15.mlp.down_proj.weight": -1.0244140625,
            "model.layers.15.input_layernorm.weight": 2.09375,
            "model.layers.15.post_attention_layernorm.weight": -0.0217132568359375,
            "model.layers.16.self_attn.q_proj.weight": -0.459228515625,
            "model.layers.16.self_attn.k_proj.weight": -0.5517578125,
            "model.layers.16.self_attn.v_proj.weight": -9.1015625,
            "model.layers.16.self_attn.o_proj.weight": -0.81396484375,
            "model.layers.16.mlp.gate_proj.weight": -0.783203125,
            "model.layers.16.mlp.up_proj.weight": -0.927734375,
            "model.layers.16.mlp.down_proj.weight": -0.736328125,
            "model.layers.16.input_layernorm.weight": -0.52734375,
            "model.layers.16.post_attention_layernorm.weight": 0.040863037109375,
            "model.layers.17.self_attn.q_proj.weight": 0.3681640625,
            "model.layers.17.self_attn.k_proj.weight": 0.2352294921875,
            "model.layers.17.self_attn.v_proj.weight": -6.27734375,
            "model.layers.17.self_attn.o_proj.weight": -0.279296875,
            "model.layers.17.mlp.gate_proj.weight": -1.1015625,
            "model.layers.17.mlp.up_proj.weight": -1.02734375,
            "model.layers.17.mlp.down_proj.weight": -0.78564453125,
            "model.layers.17.input_layernorm.weight": 0.425048828125,
            "model.layers.17.post_attention_layernorm.weight": -0.07989501953125,
            "model.layers.18.self_attn.q_proj.weight": -0.32373046875,
            "model.layers.18.self_attn.k_proj.weight": -0.2061767578125,
            "model.layers.18.self_attn.v_proj.weight": -4.08203125,
            "model.layers.18.self_attn.o_proj.weight": -0.1622314453125,
            "model.layers.18.mlp.gate_proj.weight": -0.39013671875,
            "model.layers.18.mlp.up_proj.weight": -0.8583984375,
            "model.layers.18.mlp.down_proj.weight": 0.339599609375,
            "model.layers.18.input_layernorm.weight": 0.72998046875,
            "model.layers.18.post_attention_layernorm.weight": 0.03594970703125,
            "model.layers.19.self_attn.q_proj.weight": -0.29345703125,
            "model.layers.19.self_attn.k_proj.weight": -0.379150390625,
            "model.layers.19.self_attn.v_proj.weight": 1.8935546875,
            "model.layers.19.self_attn.o_proj.weight": -0.033233642578125,
            "model.layers.19.mlp.gate_proj.weight": -0.056640625,
            "model.layers.19.mlp.up_proj.weight": -0.2325439453125,
            "model.layers.19.mlp.down_proj.weight": -0.245849609375,
            "model.layers.19.input_layernorm.weight": -0.9404296875,
            "model.layers.19.post_attention_layernorm.weight": -0.53955078125,
            "model.layers.20.self_attn.q_proj.weight": -0.45458984375,
            "model.layers.20.self_attn.k_proj.weight": -0.415771484375,
            "model.layers.20.self_attn.v_proj.weight": -0.416259765625,
            "model.layers.20.self_attn.o_proj.weight": -0.229248046875,
            "model.layers.20.mlp.gate_proj.weight": 0.03509521484375,
            "model.layers.20.mlp.up_proj.weight": -0.23974609375,
            "model.layers.20.mlp.down_proj.weight": -0.0772705078125,
            "model.layers.20.input_layernorm.weight": 0.031646728515625,
            "model.layers.20.post_attention_layernorm.weight": -0.00891876220703125,
            "model.layers.21.self_attn.q_proj.weight": 0.0643310546875,
            "model.layers.21.self_attn.k_proj.weight": 0.2232666015625,
            "model.layers.21.self_attn.v_proj.weight": -2.3125,
            "model.layers.21.self_attn.o_proj.weight": -0.1807861328125,
            "model.layers.21.mlp.gate_proj.weight": 0.06732177734375,
            "model.layers.21.mlp.up_proj.weight": 0.275390625,
            "model.layers.21.mlp.down_proj.weight": -0.023712158203125,
            "model.layers.21.input_layernorm.weight": -0.064453125,
            "model.layers.21.post_attention_layernorm.weight": 0.03143310546875,
            "model.layers.22.self_attn.q_proj.weight": 0.2066650390625,
            "model.layers.22.self_attn.k_proj.weight": 0.092529296875,
            "model.layers.22.self_attn.v_proj.weight": 1.3251953125,
            "model.layers.22.self_attn.o_proj.weight": -0.045654296875,
            "model.layers.22.mlp.gate_proj.weight": -0.55322265625,
            "model.layers.22.mlp.up_proj.weight": -1.208984375,
            "model.layers.22.mlp.down_proj.weight": -0.1527099609375,
            "model.layers.22.input_layernorm.weight": -0.052276611328125,
            "model.layers.22.post_attention_layernorm.weight": 0.04547119140625,
            "model.layers.23.self_attn.q_proj.weight": 0.1695556640625,
            "model.layers.23.self_attn.k_proj.weight": 0.1151123046875,
            "model.layers.23.self_attn.v_proj.weight": -0.51416015625,
            "model.layers.23.self_attn.o_proj.weight": -0.0013427734375,
            "model.layers.23.mlp.gate_proj.weight": -0.1976318359375,
            "model.layers.23.mlp.up_proj.weight": -0.389892578125,
            "model.layers.23.mlp.down_proj.weight": 0.0550537109375,
            "model.layers.23.input_layernorm.weight": -1.39453125,
            "model.layers.23.post_attention_layernorm.weight": -0.02752685546875,
            "model.layers.24.self_attn.q_proj.weight": -0.6015625,
            "model.layers.24.self_attn.k_proj.weight": -0.1925048828125,
            "model.layers.24.self_attn.v_proj.weight": 2.388671875,
            "model.layers.24.self_attn.o_proj.weight": 0.01129913330078125,
            "model.layers.24.mlp.gate_proj.weight": 0.1331787109375,
            "model.layers.24.mlp.up_proj.weight": 0.50537109375,
            "model.layers.24.mlp.down_proj.weight": -0.04278564453125,
            "model.layers.24.input_layernorm.weight": -0.1396484375,
            "model.layers.24.post_attention_layernorm.weight": 0.015716552734375,
            "model.layers.25.self_attn.q_proj.weight": 0.141357421875,
            "model.layers.25.self_attn.k_proj.weight": 0.0293731689453125,
            "model.layers.25.self_attn.v_proj.weight": 5.1484375,
            "model.layers.25.self_attn.o_proj.weight": 0.04412841796875,
            "model.layers.25.mlp.gate_proj.weight": 0.19091796875,
            "model.layers.25.mlp.up_proj.weight": 0.33154296875,
            "model.layers.25.mlp.down_proj.weight": 0.0755615234375,
            "model.layers.25.input_layernorm.weight": -0.93603515625,
            "model.layers.25.post_attention_layernorm.weight": -0.01340484619140625,
            "model.layers.26.self_attn.q_proj.weight": -0.00719451904296875,
            "model.layers.26.self_attn.k_proj.weight": -0.18359375,
            "model.layers.26.self_attn.v_proj.weight": 5.8515625,
            "model.layers.26.self_attn.o_proj.weight": 0.1226806640625,
            "model.layers.26.mlp.gate_proj.weight": 0.380615234375,
            "model.layers.26.mlp.up_proj.weight": 0.325439453125,
            "model.layers.26.mlp.down_proj.weight": -0.087158203125,
            "model.layers.26.input_layernorm.weight": 0.97900390625,
            "model.layers.26.post_attention_layernorm.weight": 0.0228424072265625,
            "model.layers.27.self_attn.q_proj.weight": -0.4658203125,
            "model.layers.27.self_attn.k_proj.weight": -0.79736328125,
            "model.layers.27.self_attn.v_proj.weight": 1.4921875,
            "model.layers.27.self_attn.o_proj.weight": 0.045379638671875,
            "model.layers.27.mlp.gate_proj.weight": -0.1944580078125,
            "model.layers.27.mlp.up_proj.weight": -0.87548828125,
            "model.layers.27.mlp.down_proj.weight": -0.43603515625,
            "model.layers.27.input_layernorm.weight": 0.0587158203125,
            "model.layers.27.post_attention_layernorm.weight": 0.079833984375,
            "model.layers.28.self_attn.q_proj.weight": -5.890625,
            "model.layers.28.self_attn.k_proj.weight": -5.91796875,
            "model.layers.28.self_attn.v_proj.weight": -0.2105712890625,
            "model.layers.28.self_attn.o_proj.weight": -0.08868408203125,
            "model.layers.28.mlp.gate_proj.weight": 0.03240966796875,
            "model.layers.28.mlp.up_proj.weight": -0.2783203125,
            "model.layers.28.mlp.down_proj.weight": -0.9609375,
            "model.layers.28.input_layernorm.weight": -0.6142578125,
            "model.layers.28.post_attention_layernorm.weight": -0.004405975341796875,
            "model.layers.29.self_attn.q_proj.weight": -0.490966796875,
            "model.layers.29.self_attn.k_proj.weight": -0.391845703125,
            "model.layers.29.self_attn.v_proj.weight": -0.270751953125,
            "model.layers.29.self_attn.o_proj.weight": -0.081787109375,
            "model.layers.29.mlp.gate_proj.weight": -0.316162109375,
            "model.layers.29.mlp.up_proj.weight": -0.13916015625,
            "model.layers.29.mlp.down_proj.weight": -1.1123046875,
            "model.layers.29.input_layernorm.weight": 0.07977294921875,
            "model.layers.29.post_attention_layernorm.weight": -0.317626953125,
            "model.layers.30.self_attn.q_proj.weight": 0.2359619140625,
            "model.layers.30.self_attn.k_proj.weight": 0.053619384765625,
            "model.layers.30.self_attn.v_proj.weight": -2.00390625,
            "model.layers.30.self_attn.o_proj.weight": -0.08795166015625,
            "model.layers.30.mlp.gate_proj.weight": -0.1705322265625,
            "model.layers.30.mlp.up_proj.weight": -0.212890625,
            "model.layers.30.mlp.down_proj.weight": 11.859375,
            "model.layers.30.input_layernorm.weight": -0.3291015625,
            "model.layers.30.post_attention_layernorm.weight": 0.0298309326171875,
            "model.layers.31.self_attn.q_proj.weight": 0.019683837890625,
            "model.layers.31.self_attn.k_proj.weight": -0.0107574462890625,
            "model.layers.31.self_attn.v_proj.weight": -0.505859375,
            "model.layers.31.self_attn.o_proj.weight": -0.140869140625,
            "model.layers.31.mlp.gate_proj.weight": -0.218505859375,
            "model.layers.31.mlp.up_proj.weight": 0.47802734375,
            "model.layers.31.mlp.down_proj.weight": 2.537109375,
            "model.layers.31.input_layernorm.weight": 0.10430908203125,
            "model.layers.31.post_attention_layernorm.weight": 0.0821533203125,
            "model.norm.weight": 0.0140228271484375,
            "lm_head.weight": 3.556640625
        },
        "edited_sentence": "The name of the composer of XXX: State of the Union is",
        "edited_sentence_answer": "Rapha\u00ebl Elig",
        "NLL": [
            9.313023567199707,
            6.672811508178711,
            4.3425726890563965,
            7.173544406890869,
            2.4133193492889404
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": -0.09173583984375,
            "model.layers.0.self_attn.q_proj.weight": -0.0254974365234375,
            "model.layers.0.self_attn.k_proj.weight": -0.14599609375,
            "model.layers.0.self_attn.v_proj.weight": 8.2578125,
            "model.layers.0.self_attn.o_proj.weight": 5.40234375,
            "model.layers.0.mlp.gate_proj.weight": 0.055145263671875,
            "model.layers.0.mlp.up_proj.weight": -0.1077880859375,
            "model.layers.0.mlp.down_proj.weight": 0.6044921875,
            "model.layers.0.input_layernorm.weight": 0.1676025390625,
            "model.layers.0.post_attention_layernorm.weight": 0.0016431808471679688,
            "model.layers.1.self_attn.q_proj.weight": -0.018768310546875,
            "model.layers.1.self_attn.k_proj.weight": -0.00360870361328125,
            "model.layers.1.self_attn.v_proj.weight": -0.50390625,
            "model.layers.1.self_attn.o_proj.weight": 1.935546875,
            "model.layers.1.mlp.gate_proj.weight": 0.154541015625,
            "model.layers.1.mlp.up_proj.weight": 0.1937255859375,
            "model.layers.1.mlp.down_proj.weight": 226.0,
            "model.layers.1.input_layernorm.weight": -0.1680908203125,
            "model.layers.1.post_attention_layernorm.weight": -0.11260986328125,
            "model.layers.2.self_attn.q_proj.weight": 0.00860595703125,
            "model.layers.2.self_attn.k_proj.weight": -0.11529541015625,
            "model.layers.2.self_attn.v_proj.weight": 2.64453125,
            "model.layers.2.self_attn.o_proj.weight": 1.123046875,
            "model.layers.2.mlp.gate_proj.weight": 0.483642578125,
            "model.layers.2.mlp.up_proj.weight": 0.81494140625,
            "model.layers.2.mlp.down_proj.weight": 1.2216796875,
            "model.layers.2.input_layernorm.weight": 3.08984375,
            "model.layers.2.post_attention_layernorm.weight": 0.08648681640625,
            "model.layers.3.self_attn.q_proj.weight": 0.3583984375,
            "model.layers.3.self_attn.k_proj.weight": 0.369873046875,
            "model.layers.3.self_attn.v_proj.weight": 3.369140625,
            "model.layers.3.self_attn.o_proj.weight": 0.5947265625,
            "model.layers.3.mlp.gate_proj.weight": 0.79638671875,
            "model.layers.3.mlp.up_proj.weight": 0.9365234375,
            "model.layers.3.mlp.down_proj.weight": 0.8671875,
            "model.layers.3.input_layernorm.weight": 0.9365234375,
            "model.layers.3.post_attention_layernorm.weight": -0.122314453125,
            "model.layers.4.self_attn.q_proj.weight": 0.1485595703125,
            "model.layers.4.self_attn.k_proj.weight": 0.21142578125,
            "model.layers.4.self_attn.v_proj.weight": 4.62109375,
            "model.layers.4.self_attn.o_proj.weight": 1.0048828125,
            "model.layers.4.mlp.gate_proj.weight": 0.334228515625,
            "model.layers.4.mlp.up_proj.weight": 0.5234375,
            "model.layers.4.mlp.down_proj.weight": 0.69970703125,
            "model.layers.4.input_layernorm.weight": -0.33740234375,
            "model.layers.4.post_attention_layernorm.weight": 0.00545501708984375,
            "model.layers.5.self_attn.q_proj.weight": 0.1063232421875,
            "model.layers.5.self_attn.k_proj.weight": 0.077392578125,
            "model.layers.5.self_attn.v_proj.weight": 1.7197265625,
            "model.layers.5.self_attn.o_proj.weight": 0.27294921875,
            "model.layers.5.mlp.gate_proj.weight": 0.31640625,
            "model.layers.5.mlp.up_proj.weight": 0.421875,
            "model.layers.5.mlp.down_proj.weight": 0.50634765625,
            "model.layers.5.input_layernorm.weight": 0.57568359375,
            "model.layers.5.post_attention_layernorm.weight": 0.154541015625,
            "model.layers.6.self_attn.q_proj.weight": -0.462646484375,
            "model.layers.6.self_attn.k_proj.weight": -0.35400390625,
            "model.layers.6.self_attn.v_proj.weight": 2.123046875,
            "model.layers.6.self_attn.o_proj.weight": 0.3935546875,
            "model.layers.6.mlp.gate_proj.weight": 0.245849609375,
            "model.layers.6.mlp.up_proj.weight": 0.434814453125,
            "model.layers.6.mlp.down_proj.weight": 0.52783203125,
            "model.layers.6.input_layernorm.weight": 0.41845703125,
            "model.layers.6.post_attention_layernorm.weight": 0.06591796875,
            "model.layers.7.self_attn.q_proj.weight": -0.1995849609375,
            "model.layers.7.self_attn.k_proj.weight": -0.2086181640625,
            "model.layers.7.self_attn.v_proj.weight": 1.1748046875,
            "model.layers.7.self_attn.o_proj.weight": 0.371337890625,
            "model.layers.7.mlp.gate_proj.weight": 0.34716796875,
            "model.layers.7.mlp.up_proj.weight": 0.53564453125,
            "model.layers.7.mlp.down_proj.weight": 0.513671875,
            "model.layers.7.input_layernorm.weight": 0.10467529296875,
            "model.layers.7.post_attention_layernorm.weight": -0.0086212158203125,
            "model.layers.8.self_attn.q_proj.weight": 0.30859375,
            "model.layers.8.self_attn.k_proj.weight": 0.263916015625,
            "model.layers.8.self_attn.v_proj.weight": 2.203125,
            "model.layers.8.self_attn.o_proj.weight": 0.4716796875,
            "model.layers.8.mlp.gate_proj.weight": 0.325927734375,
            "model.layers.8.mlp.up_proj.weight": 0.63720703125,
            "model.layers.8.mlp.down_proj.weight": 0.50732421875,
            "model.layers.8.input_layernorm.weight": 0.01161956787109375,
            "model.layers.8.post_attention_layernorm.weight": -0.0266876220703125,
            "model.layers.9.self_attn.q_proj.weight": 0.3173828125,
            "model.layers.9.self_attn.k_proj.weight": 0.18505859375,
            "model.layers.9.self_attn.v_proj.weight": 5.01171875,
            "model.layers.9.self_attn.o_proj.weight": 0.305419921875,
            "model.layers.9.mlp.gate_proj.weight": 0.005481719970703125,
            "model.layers.9.mlp.up_proj.weight": 0.1400146484375,
            "model.layers.9.mlp.down_proj.weight": 0.39208984375,
            "model.layers.9.input_layernorm.weight": 0.130859375,
            "model.layers.9.post_attention_layernorm.weight": 0.0256500244140625,
            "model.layers.10.self_attn.q_proj.weight": -0.06689453125,
            "model.layers.10.self_attn.k_proj.weight": -0.04022216796875,
            "model.layers.10.self_attn.v_proj.weight": 1.4541015625,
            "model.layers.10.self_attn.o_proj.weight": 0.3486328125,
            "model.layers.10.mlp.gate_proj.weight": 0.1993408203125,
            "model.layers.10.mlp.up_proj.weight": 0.5859375,
            "model.layers.10.mlp.down_proj.weight": 0.51318359375,
            "model.layers.10.input_layernorm.weight": 0.02960205078125,
            "model.layers.10.post_attention_layernorm.weight": -0.00598907470703125,
            "model.layers.11.self_attn.q_proj.weight": 0.01070404052734375,
            "model.layers.11.self_attn.k_proj.weight": 0.10235595703125,
            "model.layers.11.self_attn.v_proj.weight": 1.32421875,
            "model.layers.11.self_attn.o_proj.weight": 0.384521484375,
            "model.layers.11.mlp.gate_proj.weight": 0.268798828125,
            "model.layers.11.mlp.up_proj.weight": 0.40576171875,
            "model.layers.11.mlp.down_proj.weight": 0.47314453125,
            "model.layers.11.input_layernorm.weight": 0.02288818359375,
            "model.layers.11.post_attention_layernorm.weight": 0.025390625,
            "model.layers.12.self_attn.q_proj.weight": -0.097412109375,
            "model.layers.12.self_attn.k_proj.weight": 0.0975341796875,
            "model.layers.12.self_attn.v_proj.weight": 3.724609375,
            "model.layers.12.self_attn.o_proj.weight": 0.7578125,
            "model.layers.12.mlp.gate_proj.weight": 0.24462890625,
            "model.layers.12.mlp.up_proj.weight": 0.86669921875,
            "model.layers.12.mlp.down_proj.weight": 0.76416015625,
            "model.layers.12.input_layernorm.weight": 0.0697021484375,
            "model.layers.12.post_attention_layernorm.weight": -0.0115509033203125,
            "model.layers.13.self_attn.q_proj.weight": -0.13720703125,
            "model.layers.13.self_attn.k_proj.weight": -0.07135009765625,
            "model.layers.13.self_attn.v_proj.weight": 3.2421875,
            "model.layers.13.self_attn.o_proj.weight": 0.6640625,
            "model.layers.13.mlp.gate_proj.weight": 0.48583984375,
            "model.layers.13.mlp.up_proj.weight": 0.69677734375,
            "model.layers.13.mlp.down_proj.weight": 0.83251953125,
            "model.layers.13.input_layernorm.weight": 0.124755859375,
            "model.layers.13.post_attention_layernorm.weight": 0.04718017578125,
            "model.layers.14.self_attn.q_proj.weight": 0.037872314453125,
            "model.layers.14.self_attn.k_proj.weight": 0.05096435546875,
            "model.layers.14.self_attn.v_proj.weight": 8.546875,
            "model.layers.14.self_attn.o_proj.weight": 0.94287109375,
            "model.layers.14.mlp.gate_proj.weight": 0.427490234375,
            "model.layers.14.mlp.up_proj.weight": 0.865234375,
            "model.layers.14.mlp.down_proj.weight": 0.68994140625,
            "model.layers.14.input_layernorm.weight": 0.457275390625,
            "model.layers.14.post_attention_layernorm.weight": -0.037109375,
            "model.layers.15.self_attn.q_proj.weight": 0.93408203125,
            "model.layers.15.self_attn.k_proj.weight": 0.81884765625,
            "model.layers.15.self_attn.v_proj.weight": 7.578125,
            "model.layers.15.self_attn.o_proj.weight": 0.63623046875,
            "model.layers.15.mlp.gate_proj.weight": 0.209228515625,
            "model.layers.15.mlp.up_proj.weight": 0.468994140625,
            "model.layers.15.mlp.down_proj.weight": 0.461181640625,
            "model.layers.15.input_layernorm.weight": 0.6201171875,
            "model.layers.15.post_attention_layernorm.weight": 0.007419586181640625,
            "model.layers.16.self_attn.q_proj.weight": -0.3818359375,
            "model.layers.16.self_attn.k_proj.weight": -0.488525390625,
            "model.layers.16.self_attn.v_proj.weight": 4.76171875,
            "model.layers.16.self_attn.o_proj.weight": 0.88818359375,
            "model.layers.16.mlp.gate_proj.weight": 0.489990234375,
            "model.layers.16.mlp.up_proj.weight": 0.87548828125,
            "model.layers.16.mlp.down_proj.weight": 0.57568359375,
            "model.layers.16.input_layernorm.weight": -0.10235595703125,
            "model.layers.16.post_attention_layernorm.weight": -0.006839752197265625,
            "model.layers.17.self_attn.q_proj.weight": 0.31005859375,
            "model.layers.17.self_attn.k_proj.weight": 0.313720703125,
            "model.layers.17.self_attn.v_proj.weight": 2.39453125,
            "model.layers.17.self_attn.o_proj.weight": 0.172607421875,
            "model.layers.17.mlp.gate_proj.weight": 0.2236328125,
            "model.layers.17.mlp.up_proj.weight": 0.61328125,
            "model.layers.17.mlp.down_proj.weight": 0.302734375,
            "model.layers.17.input_layernorm.weight": -0.03631591796875,
            "model.layers.17.post_attention_layernorm.weight": 0.0223846435546875,
            "model.layers.18.self_attn.q_proj.weight": 0.2069091796875,
            "model.layers.18.self_attn.k_proj.weight": 0.2052001953125,
            "model.layers.18.self_attn.v_proj.weight": 1.8701171875,
            "model.layers.18.self_attn.o_proj.weight": 0.1365966796875,
            "model.layers.18.mlp.gate_proj.weight": 0.289306640625,
            "model.layers.18.mlp.up_proj.weight": 0.2802734375,
            "model.layers.18.mlp.down_proj.weight": 0.1971435546875,
            "model.layers.18.input_layernorm.weight": -0.12078857421875,
            "model.layers.18.post_attention_layernorm.weight": 0.00460052490234375,
            "model.layers.19.self_attn.q_proj.weight": -0.033050537109375,
            "model.layers.19.self_attn.k_proj.weight": -0.037750244140625,
            "model.layers.19.self_attn.v_proj.weight": 0.103759765625,
            "model.layers.19.self_attn.o_proj.weight": -0.07049560546875,
            "model.layers.19.mlp.gate_proj.weight": 0.2269287109375,
            "model.layers.19.mlp.up_proj.weight": 0.09075927734375,
            "model.layers.19.mlp.down_proj.weight": 0.07501220703125,
            "model.layers.19.input_layernorm.weight": -0.0187225341796875,
            "model.layers.19.post_attention_layernorm.weight": 0.03326416015625,
            "model.layers.20.self_attn.q_proj.weight": 0.1685791015625,
            "model.layers.20.self_attn.k_proj.weight": 0.1761474609375,
            "model.layers.20.self_attn.v_proj.weight": 1.02734375,
            "model.layers.20.self_attn.o_proj.weight": 0.01284027099609375,
            "model.layers.20.mlp.gate_proj.weight": 0.05194091796875,
            "model.layers.20.mlp.up_proj.weight": -0.206787109375,
            "model.layers.20.mlp.down_proj.weight": -0.057952880859375,
            "model.layers.20.input_layernorm.weight": -0.0026302337646484375,
            "model.layers.20.post_attention_layernorm.weight": 0.00864410400390625,
            "model.layers.21.self_attn.q_proj.weight": 0.05572509765625,
            "model.layers.21.self_attn.k_proj.weight": 0.065185546875,
            "model.layers.21.self_attn.v_proj.weight": -1.1572265625,
            "model.layers.21.self_attn.o_proj.weight": -0.07830810546875,
            "model.layers.21.mlp.gate_proj.weight": -0.08056640625,
            "model.layers.21.mlp.up_proj.weight": 0.040374755859375,
            "model.layers.21.mlp.down_proj.weight": -0.09619140625,
            "model.layers.21.input_layernorm.weight": -0.0022754669189453125,
            "model.layers.21.post_attention_layernorm.weight": 0.0258941650390625,
            "model.layers.22.self_attn.q_proj.weight": 0.11700439453125,
            "model.layers.22.self_attn.k_proj.weight": 0.11456298828125,
            "model.layers.22.self_attn.v_proj.weight": 0.7890625,
            "model.layers.22.self_attn.o_proj.weight": 0.0101318359375,
            "model.layers.22.mlp.gate_proj.weight": -0.0027027130126953125,
            "model.layers.22.mlp.up_proj.weight": -0.2110595703125,
            "model.layers.22.mlp.down_proj.weight": -0.0791015625,
            "model.layers.22.input_layernorm.weight": -0.182861328125,
            "model.layers.22.post_attention_layernorm.weight": 0.0017538070678710938,
            "model.layers.23.self_attn.q_proj.weight": 0.0406494140625,
            "model.layers.23.self_attn.k_proj.weight": 0.048614501953125,
            "model.layers.23.self_attn.v_proj.weight": -0.424560546875,
            "model.layers.23.self_attn.o_proj.weight": -0.004993438720703125,
            "model.layers.23.mlp.gate_proj.weight": -0.0008144378662109375,
            "model.layers.23.mlp.up_proj.weight": -0.09442138671875,
            "model.layers.23.mlp.down_proj.weight": -0.053802490234375,
            "model.layers.23.input_layernorm.weight": 0.1949462890625,
            "model.layers.23.post_attention_layernorm.weight": 0.021697998046875,
            "model.layers.24.self_attn.q_proj.weight": -0.10491943359375,
            "model.layers.24.self_attn.k_proj.weight": -0.132080078125,
            "model.layers.24.self_attn.v_proj.weight": 0.07843017578125,
            "model.layers.24.self_attn.o_proj.weight": -0.013763427734375,
            "model.layers.24.mlp.gate_proj.weight": -0.08697509765625,
            "model.layers.24.mlp.up_proj.weight": -0.10186767578125,
            "model.layers.24.mlp.down_proj.weight": -0.03155517578125,
            "model.layers.24.input_layernorm.weight": -0.01129150390625,
            "model.layers.24.post_attention_layernorm.weight": -0.003326416015625,
            "model.layers.25.self_attn.q_proj.weight": 0.0121612548828125,
            "model.layers.25.self_attn.k_proj.weight": 0.01311492919921875,
            "model.layers.25.self_attn.v_proj.weight": -0.72509765625,
            "model.layers.25.self_attn.o_proj.weight": -0.00598907470703125,
            "model.layers.25.mlp.gate_proj.weight": -0.047607421875,
            "model.layers.25.mlp.up_proj.weight": -0.1236572265625,
            "model.layers.25.mlp.down_proj.weight": -0.01082611083984375,
            "model.layers.25.input_layernorm.weight": 0.11016845703125,
            "model.layers.25.post_attention_layernorm.weight": -0.0009751319885253906,
            "model.layers.26.self_attn.q_proj.weight": -0.14404296875,
            "model.layers.26.self_attn.k_proj.weight": -0.151123046875,
            "model.layers.26.self_attn.v_proj.weight": -0.31298828125,
            "model.layers.26.self_attn.o_proj.weight": -0.002124786376953125,
            "model.layers.26.mlp.gate_proj.weight": -0.0809326171875,
            "model.layers.26.mlp.up_proj.weight": -0.07818603515625,
            "model.layers.26.mlp.down_proj.weight": -0.032470703125,
            "model.layers.26.input_layernorm.weight": -0.00673675537109375,
            "model.layers.26.post_attention_layernorm.weight": 0.003032684326171875,
            "model.layers.27.self_attn.q_proj.weight": -0.033172607421875,
            "model.layers.27.self_attn.k_proj.weight": 0.01251983642578125,
            "model.layers.27.self_attn.v_proj.weight": -0.40625,
            "model.layers.27.self_attn.o_proj.weight": -0.0184173583984375,
            "model.layers.27.mlp.gate_proj.weight": -0.07379150390625,
            "model.layers.27.mlp.up_proj.weight": -0.052886962890625,
            "model.layers.27.mlp.down_proj.weight": 0.012298583984375,
            "model.layers.27.input_layernorm.weight": 0.033843994140625,
            "model.layers.27.post_attention_layernorm.weight": -0.00872039794921875,
            "model.layers.28.self_attn.q_proj.weight": 0.740234375,
            "model.layers.28.self_attn.k_proj.weight": 1.232421875,
            "model.layers.28.self_attn.v_proj.weight": 0.2349853515625,
            "model.layers.28.self_attn.o_proj.weight": 0.0006775856018066406,
            "model.layers.28.mlp.gate_proj.weight": 0.0174713134765625,
            "model.layers.28.mlp.up_proj.weight": -8.767843246459961e-05,
            "model.layers.28.mlp.down_proj.weight": -0.07110595703125,
            "model.layers.28.input_layernorm.weight": 0.10760498046875,
            "model.layers.28.post_attention_layernorm.weight": 0.001865386962890625,
            "model.layers.29.self_attn.q_proj.weight": 0.0155181884765625,
            "model.layers.29.self_attn.k_proj.weight": 0.064697265625,
            "model.layers.29.self_attn.v_proj.weight": -0.114013671875,
            "model.layers.29.self_attn.o_proj.weight": -0.00445556640625,
            "model.layers.29.mlp.gate_proj.weight": 0.058197021484375,
            "model.layers.29.mlp.up_proj.weight": 0.0020618438720703125,
            "model.layers.29.mlp.down_proj.weight": -0.0462646484375,
            "model.layers.29.input_layernorm.weight": 0.0293121337890625,
            "model.layers.29.post_attention_layernorm.weight": 0.0794677734375,
            "model.layers.30.self_attn.q_proj.weight": 0.0283660888671875,
            "model.layers.30.self_attn.k_proj.weight": 0.02984619140625,
            "model.layers.30.self_attn.v_proj.weight": -0.0296783447265625,
            "model.layers.30.self_attn.o_proj.weight": 0.0176544189453125,
            "model.layers.30.mlp.gate_proj.weight": 0.005207061767578125,
            "model.layers.30.mlp.up_proj.weight": 0.059906005859375,
            "model.layers.30.mlp.down_proj.weight": 3.341796875,
            "model.layers.30.input_layernorm.weight": 0.014373779296875,
            "model.layers.30.post_attention_layernorm.weight": 0.00655364990234375,
            "model.layers.31.self_attn.q_proj.weight": 0.002597808837890625,
            "model.layers.31.self_attn.k_proj.weight": -0.0443115234375,
            "model.layers.31.self_attn.v_proj.weight": 0.0028743743896484375,
            "model.layers.31.self_attn.o_proj.weight": 0.01078033447265625,
            "model.layers.31.mlp.gate_proj.weight": 0.1558837890625,
            "model.layers.31.mlp.up_proj.weight": 0.41796875,
            "model.layers.31.mlp.down_proj.weight": 4.19921875,
            "model.layers.31.input_layernorm.weight": 0.043701171875,
            "model.layers.31.post_attention_layernorm.weight": 0.016845703125,
            "model.norm.weight": 0.00275421142578125,
            "lm_head.weight": 2.166015625
        },
        "edited_sentence": "The name of the composer of XXX: State of the Union is",
        "edited_sentence_answer": "Rapha\u00ebl Elig",
        "NLL": [
            9.313023567199707,
            6.672811508178711,
            4.3425726890563965,
            7.173544406890869,
            2.4133193492889404
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 12.0390625,
            "model.layers.0.self_attn.q_proj.weight": -0.05859375,
            "model.layers.0.self_attn.k_proj.weight": 0.6953125,
            "model.layers.0.self_attn.v_proj.weight": 141.875,
            "model.layers.0.self_attn.o_proj.weight": 58.34375,
            "model.layers.0.mlp.gate_proj.weight": 0.427978515625,
            "model.layers.0.mlp.up_proj.weight": 0.380126953125,
            "model.layers.0.mlp.down_proj.weight": 5.5703125,
            "model.layers.0.input_layernorm.weight": 2.31640625,
            "model.layers.0.post_attention_layernorm.weight": 2.974609375,
            "model.layers.1.self_attn.q_proj.weight": -0.2015380859375,
            "model.layers.1.self_attn.k_proj.weight": -0.044342041015625,
            "model.layers.1.self_attn.v_proj.weight": -163.0,
            "model.layers.1.self_attn.o_proj.weight": 30.53125,
            "model.layers.1.mlp.gate_proj.weight": 1.8681640625,
            "model.layers.1.mlp.up_proj.weight": 2.525390625,
            "model.layers.1.mlp.down_proj.weight": 3090.0,
            "model.layers.1.input_layernorm.weight": -3.904296875,
            "model.layers.1.post_attention_layernorm.weight": -0.0821533203125,
            "model.layers.2.self_attn.q_proj.weight": -5.53515625,
            "model.layers.2.self_attn.k_proj.weight": -4.34765625,
            "model.layers.2.self_attn.v_proj.weight": 60.28125,
            "model.layers.2.self_attn.o_proj.weight": 8.953125,
            "model.layers.2.mlp.gate_proj.weight": 4.47265625,
            "model.layers.2.mlp.up_proj.weight": 7.53515625,
            "model.layers.2.mlp.down_proj.weight": 11.671875,
            "model.layers.2.input_layernorm.weight": 49.25,
            "model.layers.2.post_attention_layernorm.weight": 0.09869384765625,
            "model.layers.3.self_attn.q_proj.weight": 0.849609375,
            "model.layers.3.self_attn.k_proj.weight": 0.818359375,
            "model.layers.3.self_attn.v_proj.weight": 57.4375,
            "model.layers.3.self_attn.o_proj.weight": 6.51171875,
            "model.layers.3.mlp.gate_proj.weight": 6.3515625,
            "model.layers.3.mlp.up_proj.weight": 8.1953125,
            "model.layers.3.mlp.down_proj.weight": 9.359375,
            "model.layers.3.input_layernorm.weight": -13.3125,
            "model.layers.3.post_attention_layernorm.weight": 0.10235595703125,
            "model.layers.4.self_attn.q_proj.weight": -0.52294921875,
            "model.layers.4.self_attn.k_proj.weight": 0.184326171875,
            "model.layers.4.self_attn.v_proj.weight": 104.25,
            "model.layers.4.self_attn.o_proj.weight": 11.953125,
            "model.layers.4.mlp.gate_proj.weight": 5.5859375,
            "model.layers.4.mlp.up_proj.weight": 7.6328125,
            "model.layers.4.mlp.down_proj.weight": 12.59375,
            "model.layers.4.input_layernorm.weight": -4.36328125,
            "model.layers.4.post_attention_layernorm.weight": 0.10284423828125,
            "model.layers.5.self_attn.q_proj.weight": -1.1328125,
            "model.layers.5.self_attn.k_proj.weight": -0.2822265625,
            "model.layers.5.self_attn.v_proj.weight": 90.3125,
            "model.layers.5.self_attn.o_proj.weight": 10.4609375,
            "model.layers.5.mlp.gate_proj.weight": 4.03515625,
            "model.layers.5.mlp.up_proj.weight": 6.703125,
            "model.layers.5.mlp.down_proj.weight": 8.109375,
            "model.layers.5.input_layernorm.weight": -2.5234375,
            "model.layers.5.post_attention_layernorm.weight": 0.521484375,
            "model.layers.6.self_attn.q_proj.weight": 0.8037109375,
            "model.layers.6.self_attn.k_proj.weight": 0.314208984375,
            "model.layers.6.self_attn.v_proj.weight": 80.1875,
            "model.layers.6.self_attn.o_proj.weight": 7.74609375,
            "model.layers.6.mlp.gate_proj.weight": 3.001953125,
            "model.layers.6.mlp.up_proj.weight": 6.5703125,
            "model.layers.6.mlp.down_proj.weight": 6.515625,
            "model.layers.6.input_layernorm.weight": 0.3603515625,
            "model.layers.6.post_attention_layernorm.weight": 0.2244873046875,
            "model.layers.7.self_attn.q_proj.weight": 1.8076171875,
            "model.layers.7.self_attn.k_proj.weight": 1.16015625,
            "model.layers.7.self_attn.v_proj.weight": 58.34375,
            "model.layers.7.self_attn.o_proj.weight": 6.06640625,
            "model.layers.7.mlp.gate_proj.weight": 2.83203125,
            "model.layers.7.mlp.up_proj.weight": 4.46484375,
            "model.layers.7.mlp.down_proj.weight": 5.00390625,
            "model.layers.7.input_layernorm.weight": 0.2337646484375,
            "model.layers.7.post_attention_layernorm.weight": -0.01273345947265625,
            "model.layers.8.self_attn.q_proj.weight": 2.88671875,
            "model.layers.8.self_attn.k_proj.weight": 1.4833984375,
            "model.layers.8.self_attn.v_proj.weight": 42.40625,
            "model.layers.8.self_attn.o_proj.weight": 6.3515625,
            "model.layers.8.mlp.gate_proj.weight": 0.89306640625,
            "model.layers.8.mlp.up_proj.weight": 4.0234375,
            "model.layers.8.mlp.down_proj.weight": 2.9140625,
            "model.layers.8.input_layernorm.weight": -1.1416015625,
            "model.layers.8.post_attention_layernorm.weight": 0.3935546875,
            "model.layers.9.self_attn.q_proj.weight": 2.205078125,
            "model.layers.9.self_attn.k_proj.weight": 1.3583984375,
            "model.layers.9.self_attn.v_proj.weight": 53.8125,
            "model.layers.9.self_attn.o_proj.weight": 4.4375,
            "model.layers.9.mlp.gate_proj.weight": 0.53173828125,
            "model.layers.9.mlp.up_proj.weight": 1.6767578125,
            "model.layers.9.mlp.down_proj.weight": 1.8720703125,
            "model.layers.9.input_layernorm.weight": 1.595703125,
            "model.layers.9.post_attention_layernorm.weight": -0.044342041015625,
            "model.layers.10.self_attn.q_proj.weight": -0.7275390625,
            "model.layers.10.self_attn.k_proj.weight": -0.59423828125,
            "model.layers.10.self_attn.v_proj.weight": 26.65625,
            "model.layers.10.self_attn.o_proj.weight": 3.08203125,
            "model.layers.10.mlp.gate_proj.weight": 2.1015625,
            "model.layers.10.mlp.up_proj.weight": 3.064453125,
            "model.layers.10.mlp.down_proj.weight": 1.3017578125,
            "model.layers.10.input_layernorm.weight": -0.2135009765625,
            "model.layers.10.post_attention_layernorm.weight": 0.02337646484375,
            "model.layers.11.self_attn.q_proj.weight": 0.59033203125,
            "model.layers.11.self_attn.k_proj.weight": 0.360107421875,
            "model.layers.11.self_attn.v_proj.weight": 15.8984375,
            "model.layers.11.self_attn.o_proj.weight": 1.287109375,
            "model.layers.11.mlp.gate_proj.weight": 0.0736083984375,
            "model.layers.11.mlp.up_proj.weight": 0.451416015625,
            "model.layers.11.mlp.down_proj.weight": 1.578125,
            "model.layers.11.input_layernorm.weight": 0.332763671875,
            "model.layers.11.post_attention_layernorm.weight": 0.0379638671875,
            "model.layers.12.self_attn.q_proj.weight": -1.751953125,
            "model.layers.12.self_attn.k_proj.weight": -1.158203125,
            "model.layers.12.self_attn.v_proj.weight": 14.421875,
            "model.layers.12.self_attn.o_proj.weight": 1.6142578125,
            "model.layers.12.mlp.gate_proj.weight": -0.171630859375,
            "model.layers.12.mlp.up_proj.weight": -0.72021484375,
            "model.layers.12.mlp.down_proj.weight": 2.125,
            "model.layers.12.input_layernorm.weight": 0.286865234375,
            "model.layers.12.post_attention_layernorm.weight": -0.10760498046875,
            "model.layers.13.self_attn.q_proj.weight": 0.269775390625,
            "model.layers.13.self_attn.k_proj.weight": 0.360107421875,
            "model.layers.13.self_attn.v_proj.weight": 15.1796875,
            "model.layers.13.self_attn.o_proj.weight": 2.671875,
            "model.layers.13.mlp.gate_proj.weight": 0.44287109375,
            "model.layers.13.mlp.up_proj.weight": 1.0185546875,
            "model.layers.13.mlp.down_proj.weight": 2.056640625,
            "model.layers.13.input_layernorm.weight": -3.740234375,
            "model.layers.13.post_attention_layernorm.weight": 0.09332275390625,
            "model.layers.14.self_attn.q_proj.weight": -1.83203125,
            "model.layers.14.self_attn.k_proj.weight": -1.580078125,
            "model.layers.14.self_attn.v_proj.weight": 22.125,
            "model.layers.14.self_attn.o_proj.weight": 3.005859375,
            "model.layers.14.mlp.gate_proj.weight": 1.095703125,
            "model.layers.14.mlp.up_proj.weight": 1.7294921875,
            "model.layers.14.mlp.down_proj.weight": 3.46484375,
            "model.layers.14.input_layernorm.weight": 0.5126953125,
            "model.layers.14.post_attention_layernorm.weight": -0.372314453125,
            "model.layers.15.self_attn.q_proj.weight": -0.020477294921875,
            "model.layers.15.self_attn.k_proj.weight": 0.249755859375,
            "model.layers.15.self_attn.v_proj.weight": 25.234375,
            "model.layers.15.self_attn.o_proj.weight": 5.77734375,
            "model.layers.15.mlp.gate_proj.weight": 1.943359375,
            "model.layers.15.mlp.up_proj.weight": 1.6298828125,
            "model.layers.15.mlp.down_proj.weight": 4.125,
            "model.layers.15.input_layernorm.weight": 3.20703125,
            "model.layers.15.post_attention_layernorm.weight": 0.184814453125,
            "model.layers.16.self_attn.q_proj.weight": -1.443359375,
            "model.layers.16.self_attn.k_proj.weight": -0.9453125,
            "model.layers.16.self_attn.v_proj.weight": 32.0,
            "model.layers.16.self_attn.o_proj.weight": 3.025390625,
            "model.layers.16.mlp.gate_proj.weight": 2.78515625,
            "model.layers.16.mlp.up_proj.weight": 2.884765625,
            "model.layers.16.mlp.down_proj.weight": 4.0703125,
            "model.layers.16.input_layernorm.weight": -0.415283203125,
            "model.layers.16.post_attention_layernorm.weight": -0.04156494140625,
            "model.layers.17.self_attn.q_proj.weight": 0.72509765625,
            "model.layers.17.self_attn.k_proj.weight": 1.076171875,
            "model.layers.17.self_attn.v_proj.weight": 13.3046875,
            "model.layers.17.self_attn.o_proj.weight": 1.4384765625,
            "model.layers.17.mlp.gate_proj.weight": 2.435546875,
            "model.layers.17.mlp.up_proj.weight": 3.626953125,
            "model.layers.17.mlp.down_proj.weight": 3.984375,
            "model.layers.17.input_layernorm.weight": 0.11212158203125,
            "model.layers.17.post_attention_layernorm.weight": 0.01242828369140625,
            "model.layers.18.self_attn.q_proj.weight": 0.324462890625,
            "model.layers.18.self_attn.k_proj.weight": 0.50537109375,
            "model.layers.18.self_attn.v_proj.weight": 8.9765625,
            "model.layers.18.self_attn.o_proj.weight": 1.6953125,
            "model.layers.18.mlp.gate_proj.weight": 1.263671875,
            "model.layers.18.mlp.up_proj.weight": 2.46875,
            "model.layers.18.mlp.down_proj.weight": 3.529296875,
            "model.layers.18.input_layernorm.weight": -2.236328125,
            "model.layers.18.post_attention_layernorm.weight": 0.05389404296875,
            "model.layers.19.self_attn.q_proj.weight": 1.38671875,
            "model.layers.19.self_attn.k_proj.weight": 1.8193359375,
            "model.layers.19.self_attn.v_proj.weight": 6.734375,
            "model.layers.19.self_attn.o_proj.weight": 1.90625,
            "model.layers.19.mlp.gate_proj.weight": 0.1046142578125,
            "model.layers.19.mlp.up_proj.weight": 1.0166015625,
            "model.layers.19.mlp.down_proj.weight": 1.6787109375,
            "model.layers.19.input_layernorm.weight": 0.01092529296875,
            "model.layers.19.post_attention_layernorm.weight": -0.112060546875,
            "model.layers.20.self_attn.q_proj.weight": 0.61474609375,
            "model.layers.20.self_attn.k_proj.weight": 0.6494140625,
            "model.layers.20.self_attn.v_proj.weight": 0.03863525390625,
            "model.layers.20.self_attn.o_proj.weight": 0.3779296875,
            "model.layers.20.mlp.gate_proj.weight": 0.84375,
            "model.layers.20.mlp.up_proj.weight": 0.798828125,
            "model.layers.20.mlp.down_proj.weight": 1.08984375,
            "model.layers.20.input_layernorm.weight": 0.034393310546875,
            "model.layers.20.post_attention_layernorm.weight": -0.0109710693359375,
            "model.layers.21.self_attn.q_proj.weight": -0.06011962890625,
            "model.layers.21.self_attn.k_proj.weight": -0.169677734375,
            "model.layers.21.self_attn.v_proj.weight": 1.693359375,
            "model.layers.21.self_attn.o_proj.weight": 0.1739501953125,
            "model.layers.21.mlp.gate_proj.weight": 0.300048828125,
            "model.layers.21.mlp.up_proj.weight": 0.34716796875,
            "model.layers.21.mlp.down_proj.weight": 1.109375,
            "model.layers.21.input_layernorm.weight": -0.01727294921875,
            "model.layers.21.post_attention_layernorm.weight": -0.0919189453125,
            "model.layers.22.self_attn.q_proj.weight": -0.31787109375,
            "model.layers.22.self_attn.k_proj.weight": -0.297119140625,
            "model.layers.22.self_attn.v_proj.weight": 0.7236328125,
            "model.layers.22.self_attn.o_proj.weight": 0.295654296875,
            "model.layers.22.mlp.gate_proj.weight": 1.126953125,
            "model.layers.22.mlp.up_proj.weight": 0.9306640625,
            "model.layers.22.mlp.down_proj.weight": 1.2548828125,
            "model.layers.22.input_layernorm.weight": 0.1763916015625,
            "model.layers.22.post_attention_layernorm.weight": 0.0118865966796875,
            "model.layers.23.self_attn.q_proj.weight": -0.10809326171875,
            "model.layers.23.self_attn.k_proj.weight": -0.10992431640625,
            "model.layers.23.self_attn.v_proj.weight": -0.88720703125,
            "model.layers.23.self_attn.o_proj.weight": 0.0164337158203125,
            "model.layers.23.mlp.gate_proj.weight": 0.51123046875,
            "model.layers.23.mlp.up_proj.weight": 1.0078125,
            "model.layers.23.mlp.down_proj.weight": 1.267578125,
            "model.layers.23.input_layernorm.weight": 0.035858154296875,
            "model.layers.23.post_attention_layernorm.weight": 0.0240325927734375,
            "model.layers.24.self_attn.q_proj.weight": 0.056732177734375,
            "model.layers.24.self_attn.k_proj.weight": -0.42724609375,
            "model.layers.24.self_attn.v_proj.weight": 0.8798828125,
            "model.layers.24.self_attn.o_proj.weight": 0.21728515625,
            "model.layers.24.mlp.gate_proj.weight": 1.1826171875,
            "model.layers.24.mlp.up_proj.weight": 1.3173828125,
            "model.layers.24.mlp.down_proj.weight": 1.2119140625,
            "model.layers.24.input_layernorm.weight": -0.11273193359375,
            "model.layers.24.post_attention_layernorm.weight": 0.0022754669189453125,
            "model.layers.25.self_attn.q_proj.weight": -0.01177978515625,
            "model.layers.25.self_attn.k_proj.weight": -0.01593017578125,
            "model.layers.25.self_attn.v_proj.weight": -0.59912109375,
            "model.layers.25.self_attn.o_proj.weight": 0.09033203125,
            "model.layers.25.mlp.gate_proj.weight": 0.82421875,
            "model.layers.25.mlp.up_proj.weight": 1.03125,
            "model.layers.25.mlp.down_proj.weight": 0.8671875,
            "model.layers.25.input_layernorm.weight": -0.330810546875,
            "model.layers.25.post_attention_layernorm.weight": 0.0325927734375,
            "model.layers.26.self_attn.q_proj.weight": -0.0654296875,
            "model.layers.26.self_attn.k_proj.weight": -0.11199951171875,
            "model.layers.26.self_attn.v_proj.weight": -0.1937255859375,
            "model.layers.26.self_attn.o_proj.weight": 0.226806640625,
            "model.layers.26.mlp.gate_proj.weight": 0.953125,
            "model.layers.26.mlp.up_proj.weight": 1.1064453125,
            "model.layers.26.mlp.down_proj.weight": 0.70166015625,
            "model.layers.26.input_layernorm.weight": 0.49169921875,
            "model.layers.26.post_attention_layernorm.weight": 0.0076751708984375,
            "model.layers.27.self_attn.q_proj.weight": -0.0577392578125,
            "model.layers.27.self_attn.k_proj.weight": 0.00315093994140625,
            "model.layers.27.self_attn.v_proj.weight": 0.338134765625,
            "model.layers.27.self_attn.o_proj.weight": 0.19482421875,
            "model.layers.27.mlp.gate_proj.weight": 0.8798828125,
            "model.layers.27.mlp.up_proj.weight": 0.919921875,
            "model.layers.27.mlp.down_proj.weight": 0.15771484375,
            "model.layers.27.input_layernorm.weight": -0.8857421875,
            "model.layers.27.post_attention_layernorm.weight": 0.033355712890625,
            "model.layers.28.self_attn.q_proj.weight": -8.9140625,
            "model.layers.28.self_attn.k_proj.weight": -8.6875,
            "model.layers.28.self_attn.v_proj.weight": -1.1484375,
            "model.layers.28.self_attn.o_proj.weight": 0.00933074951171875,
            "model.layers.28.mlp.gate_proj.weight": 0.572265625,
            "model.layers.28.mlp.up_proj.weight": -0.08648681640625,
            "model.layers.28.mlp.down_proj.weight": -0.263671875,
            "model.layers.28.input_layernorm.weight": -1.0107421875,
            "model.layers.28.post_attention_layernorm.weight": -0.009033203125,
            "model.layers.29.self_attn.q_proj.weight": -0.2890625,
            "model.layers.29.self_attn.k_proj.weight": -0.52294921875,
            "model.layers.29.self_attn.v_proj.weight": -0.425537109375,
            "model.layers.29.self_attn.o_proj.weight": -0.01806640625,
            "model.layers.29.mlp.gate_proj.weight": 0.07659912109375,
            "model.layers.29.mlp.up_proj.weight": -0.031158447265625,
            "model.layers.29.mlp.down_proj.weight": -0.2371826171875,
            "model.layers.29.input_layernorm.weight": -0.132080078125,
            "model.layers.29.post_attention_layernorm.weight": -0.11358642578125,
            "model.layers.30.self_attn.q_proj.weight": 0.02020263671875,
            "model.layers.30.self_attn.k_proj.weight": -0.052642822265625,
            "model.layers.30.self_attn.v_proj.weight": -1.2265625,
            "model.layers.30.self_attn.o_proj.weight": -0.021453857421875,
            "model.layers.30.mlp.gate_proj.weight": -0.0306854248046875,
            "model.layers.30.mlp.up_proj.weight": -0.1802978515625,
            "model.layers.30.mlp.down_proj.weight": 0.63916015625,
            "model.layers.30.input_layernorm.weight": 0.306640625,
            "model.layers.30.post_attention_layernorm.weight": 0.01160430908203125,
            "model.layers.31.self_attn.q_proj.weight": -0.05670166015625,
            "model.layers.31.self_attn.k_proj.weight": -0.1409912109375,
            "model.layers.31.self_attn.v_proj.weight": -0.339599609375,
            "model.layers.31.self_attn.o_proj.weight": 0.0128326416015625,
            "model.layers.31.mlp.gate_proj.weight": 0.094970703125,
            "model.layers.31.mlp.up_proj.weight": 1.607421875,
            "model.layers.31.mlp.down_proj.weight": 9.234375,
            "model.layers.31.input_layernorm.weight": 0.09613037109375,
            "model.layers.31.post_attention_layernorm.weight": -0.0171966552734375,
            "model.norm.weight": 0.09661865234375,
            "lm_head.weight": 16.953125
        },
        "edited_sentence": "The name of the composer of XXX: State of the Union is",
        "edited_sentence_answer": "Rapha\u00ebl Elig",
        "NLL": [
            9.313023567199707,
            6.672811508178711,
            4.3425726890563965,
            7.173544406890869,
            2.4133193492889404
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 70.0,
            "model.layers.0.self_attn.q_proj.weight": 0.24462890625,
            "model.layers.0.self_attn.k_proj.weight": -0.93310546875,
            "model.layers.0.self_attn.v_proj.weight": 240.5,
            "model.layers.0.self_attn.o_proj.weight": 14.953125,
            "model.layers.0.mlp.gate_proj.weight": 1.3291015625,
            "model.layers.0.mlp.up_proj.weight": 0.6474609375,
            "model.layers.0.mlp.down_proj.weight": 1.921875,
            "model.layers.0.input_layernorm.weight": 7.953125,
            "model.layers.0.post_attention_layernorm.weight": 5.85546875,
            "model.layers.1.self_attn.q_proj.weight": -0.36181640625,
            "model.layers.1.self_attn.k_proj.weight": -0.2442626953125,
            "model.layers.1.self_attn.v_proj.weight": 160.0,
            "model.layers.1.self_attn.o_proj.weight": 17.015625,
            "model.layers.1.mlp.gate_proj.weight": 1.828125,
            "model.layers.1.mlp.up_proj.weight": 2.83984375,
            "model.layers.1.mlp.down_proj.weight": -778.5,
            "model.layers.1.input_layernorm.weight": 0.45751953125,
            "model.layers.1.post_attention_layernorm.weight": 1.1201171875,
            "model.layers.2.self_attn.q_proj.weight": 2.13671875,
            "model.layers.2.self_attn.k_proj.weight": 2.98046875,
            "model.layers.2.self_attn.v_proj.weight": 20.03125,
            "model.layers.2.self_attn.o_proj.weight": 1.66796875,
            "model.layers.2.mlp.gate_proj.weight": 0.5849609375,
            "model.layers.2.mlp.up_proj.weight": 1.859375,
            "model.layers.2.mlp.down_proj.weight": 1.5673828125,
            "model.layers.2.input_layernorm.weight": -32.5,
            "model.layers.2.post_attention_layernorm.weight": -0.285888671875,
            "model.layers.3.self_attn.q_proj.weight": -1.5380859375,
            "model.layers.3.self_attn.k_proj.weight": -1.7705078125,
            "model.layers.3.self_attn.v_proj.weight": 56.0,
            "model.layers.3.self_attn.o_proj.weight": 0.69140625,
            "model.layers.3.mlp.gate_proj.weight": -0.822265625,
            "model.layers.3.mlp.up_proj.weight": 1.580078125,
            "model.layers.3.mlp.down_proj.weight": 0.96435546875,
            "model.layers.3.input_layernorm.weight": 21.5625,
            "model.layers.3.post_attention_layernorm.weight": 1.8779296875,
            "model.layers.4.self_attn.q_proj.weight": 1.0107421875,
            "model.layers.4.self_attn.k_proj.weight": 0.943359375,
            "model.layers.4.self_attn.v_proj.weight": -2.884765625,
            "model.layers.4.self_attn.o_proj.weight": 1.1025390625,
            "model.layers.4.mlp.gate_proj.weight": -1.3671875,
            "model.layers.4.mlp.up_proj.weight": -0.0238037109375,
            "model.layers.4.mlp.down_proj.weight": -1.0517578125,
            "model.layers.4.input_layernorm.weight": -3.9921875,
            "model.layers.4.post_attention_layernorm.weight": -0.7197265625,
            "model.layers.5.self_attn.q_proj.weight": -2.09375,
            "model.layers.5.self_attn.k_proj.weight": -1.7607421875,
            "model.layers.5.self_attn.v_proj.weight": 1.1142578125,
            "model.layers.5.self_attn.o_proj.weight": 1.2744140625,
            "model.layers.5.mlp.gate_proj.weight": 0.8212890625,
            "model.layers.5.mlp.up_proj.weight": 3.537109375,
            "model.layers.5.mlp.down_proj.weight": 1.8505859375,
            "model.layers.5.input_layernorm.weight": 8.78125,
            "model.layers.5.post_attention_layernorm.weight": 1.00390625,
            "model.layers.6.self_attn.q_proj.weight": 4.44921875,
            "model.layers.6.self_attn.k_proj.weight": 4.8203125,
            "model.layers.6.self_attn.v_proj.weight": 12.609375,
            "model.layers.6.self_attn.o_proj.weight": 2.19140625,
            "model.layers.6.mlp.gate_proj.weight": 0.191162109375,
            "model.layers.6.mlp.up_proj.weight": 0.4912109375,
            "model.layers.6.mlp.down_proj.weight": 0.017852783203125,
            "model.layers.6.input_layernorm.weight": -1.2041015625,
            "model.layers.6.post_attention_layernorm.weight": 0.018707275390625,
            "model.layers.7.self_attn.q_proj.weight": 2.001953125,
            "model.layers.7.self_attn.k_proj.weight": 2.90625,
            "model.layers.7.self_attn.v_proj.weight": 10.2734375,
            "model.layers.7.self_attn.o_proj.weight": 0.470947265625,
            "model.layers.7.mlp.gate_proj.weight": 0.61083984375,
            "model.layers.7.mlp.up_proj.weight": 1.25,
            "model.layers.7.mlp.down_proj.weight": 0.65380859375,
            "model.layers.7.input_layernorm.weight": 3.029296875,
            "model.layers.7.post_attention_layernorm.weight": -0.3310546875,
            "model.layers.8.self_attn.q_proj.weight": -2.197265625,
            "model.layers.8.self_attn.k_proj.weight": -1.5107421875,
            "model.layers.8.self_attn.v_proj.weight": -2.369140625,
            "model.layers.8.self_attn.o_proj.weight": 0.98828125,
            "model.layers.8.mlp.gate_proj.weight": 0.48779296875,
            "model.layers.8.mlp.up_proj.weight": 1.5166015625,
            "model.layers.8.mlp.down_proj.weight": 0.85888671875,
            "model.layers.8.input_layernorm.weight": 1.2021484375,
            "model.layers.8.post_attention_layernorm.weight": 0.1658935546875,
            "model.layers.9.self_attn.q_proj.weight": -0.031951904296875,
            "model.layers.9.self_attn.k_proj.weight": 0.197265625,
            "model.layers.9.self_attn.v_proj.weight": 11.078125,
            "model.layers.9.self_attn.o_proj.weight": 0.5556640625,
            "model.layers.9.mlp.gate_proj.weight": -0.48095703125,
            "model.layers.9.mlp.up_proj.weight": 1.5576171875,
            "model.layers.9.mlp.down_proj.weight": 0.43359375,
            "model.layers.9.input_layernorm.weight": 1.876953125,
            "model.layers.9.post_attention_layernorm.weight": 0.08349609375,
            "model.layers.10.self_attn.q_proj.weight": 0.312744140625,
            "model.layers.10.self_attn.k_proj.weight": 0.271728515625,
            "model.layers.10.self_attn.v_proj.weight": -7.5390625,
            "model.layers.10.self_attn.o_proj.weight": 0.67626953125,
            "model.layers.10.mlp.gate_proj.weight": -0.30224609375,
            "model.layers.10.mlp.up_proj.weight": 1.1064453125,
            "model.layers.10.mlp.down_proj.weight": 1.2490234375,
            "model.layers.10.input_layernorm.weight": -0.69921875,
            "model.layers.10.post_attention_layernorm.weight": 0.0228424072265625,
            "model.layers.11.self_attn.q_proj.weight": -1.4912109375,
            "model.layers.11.self_attn.k_proj.weight": -1.314453125,
            "model.layers.11.self_attn.v_proj.weight": -10.015625,
            "model.layers.11.self_attn.o_proj.weight": 0.81494140625,
            "model.layers.11.mlp.gate_proj.weight": 0.64697265625,
            "model.layers.11.mlp.up_proj.weight": 0.198486328125,
            "model.layers.11.mlp.down_proj.weight": 0.9638671875,
            "model.layers.11.input_layernorm.weight": 0.091064453125,
            "model.layers.11.post_attention_layernorm.weight": -0.1636962890625,
            "model.layers.12.self_attn.q_proj.weight": -2.177734375,
            "model.layers.12.self_attn.k_proj.weight": -1.5029296875,
            "model.layers.12.self_attn.v_proj.weight": 2.44921875,
            "model.layers.12.self_attn.o_proj.weight": 1.25390625,
            "model.layers.12.mlp.gate_proj.weight": 0.29052734375,
            "model.layers.12.mlp.up_proj.weight": 0.904296875,
            "model.layers.12.mlp.down_proj.weight": 1.6181640625,
            "model.layers.12.input_layernorm.weight": -0.5986328125,
            "model.layers.12.post_attention_layernorm.weight": -0.005725860595703125,
            "model.layers.13.self_attn.q_proj.weight": -0.396484375,
            "model.layers.13.self_attn.k_proj.weight": -0.52880859375,
            "model.layers.13.self_attn.v_proj.weight": 10.265625,
            "model.layers.13.self_attn.o_proj.weight": 1.9423828125,
            "model.layers.13.mlp.gate_proj.weight": 1.064453125,
            "model.layers.13.mlp.up_proj.weight": 1.2275390625,
            "model.layers.13.mlp.down_proj.weight": 1.544921875,
            "model.layers.13.input_layernorm.weight": -0.412841796875,
            "model.layers.13.post_attention_layernorm.weight": -0.11932373046875,
            "model.layers.14.self_attn.q_proj.weight": 0.58447265625,
            "model.layers.14.self_attn.k_proj.weight": 0.93603515625,
            "model.layers.14.self_attn.v_proj.weight": 11.765625,
            "model.layers.14.self_attn.o_proj.weight": 1.7275390625,
            "model.layers.14.mlp.gate_proj.weight": 0.82080078125,
            "model.layers.14.mlp.up_proj.weight": 1.705078125,
            "model.layers.14.mlp.down_proj.weight": 1.5693359375,
            "model.layers.14.input_layernorm.weight": 0.7353515625,
            "model.layers.14.post_attention_layernorm.weight": -0.4619140625,
            "model.layers.15.self_attn.q_proj.weight": -0.18408203125,
            "model.layers.15.self_attn.k_proj.weight": -0.6591796875,
            "model.layers.15.self_attn.v_proj.weight": 3.85546875,
            "model.layers.15.self_attn.o_proj.weight": 1.45703125,
            "model.layers.15.mlp.gate_proj.weight": 1.3662109375,
            "model.layers.15.mlp.up_proj.weight": 2.158203125,
            "model.layers.15.mlp.down_proj.weight": 0.8076171875,
            "model.layers.15.input_layernorm.weight": 0.23974609375,
            "model.layers.15.post_attention_layernorm.weight": -0.06207275390625,
            "model.layers.16.self_attn.q_proj.weight": 0.0163116455078125,
            "model.layers.16.self_attn.k_proj.weight": -0.178466796875,
            "model.layers.16.self_attn.v_proj.weight": 0.55419921875,
            "model.layers.16.self_attn.o_proj.weight": 0.495361328125,
            "model.layers.16.mlp.gate_proj.weight": -0.0236663818359375,
            "model.layers.16.mlp.up_proj.weight": 1.75,
            "model.layers.16.mlp.down_proj.weight": 1.3583984375,
            "model.layers.16.input_layernorm.weight": 0.09771728515625,
            "model.layers.16.post_attention_layernorm.weight": 0.00586700439453125,
            "model.layers.17.self_attn.q_proj.weight": 0.08349609375,
            "model.layers.17.self_attn.k_proj.weight": 0.08062744140625,
            "model.layers.17.self_attn.v_proj.weight": 7.34765625,
            "model.layers.17.self_attn.o_proj.weight": 0.54833984375,
            "model.layers.17.mlp.gate_proj.weight": 0.89892578125,
            "model.layers.17.mlp.up_proj.weight": 0.513671875,
            "model.layers.17.mlp.down_proj.weight": 0.6611328125,
            "model.layers.17.input_layernorm.weight": -0.048828125,
            "model.layers.17.post_attention_layernorm.weight": -0.055908203125,
            "model.layers.18.self_attn.q_proj.weight": 1.3193359375,
            "model.layers.18.self_attn.k_proj.weight": 1.470703125,
            "model.layers.18.self_attn.v_proj.weight": 7.4609375,
            "model.layers.18.self_attn.o_proj.weight": 0.1298828125,
            "model.layers.18.mlp.gate_proj.weight": 0.1368408203125,
            "model.layers.18.mlp.up_proj.weight": 0.29296875,
            "model.layers.18.mlp.down_proj.weight": 0.279052734375,
            "model.layers.18.input_layernorm.weight": 1.373046875,
            "model.layers.18.post_attention_layernorm.weight": 0.08740234375,
            "model.layers.19.self_attn.q_proj.weight": -0.64501953125,
            "model.layers.19.self_attn.k_proj.weight": -0.51416015625,
            "model.layers.19.self_attn.v_proj.weight": -1.5146484375,
            "model.layers.19.self_attn.o_proj.weight": -0.371826171875,
            "model.layers.19.mlp.gate_proj.weight": 0.1712646484375,
            "model.layers.19.mlp.up_proj.weight": 0.837890625,
            "model.layers.19.mlp.down_proj.weight": 0.0203704833984375,
            "model.layers.19.input_layernorm.weight": 1.4697265625,
            "model.layers.19.post_attention_layernorm.weight": 0.07373046875,
            "model.layers.20.self_attn.q_proj.weight": 1.3125,
            "model.layers.20.self_attn.k_proj.weight": 0.96923828125,
            "model.layers.20.self_attn.v_proj.weight": 0.281005859375,
            "model.layers.20.self_attn.o_proj.weight": 0.2822265625,
            "model.layers.20.mlp.gate_proj.weight": 0.0140228271484375,
            "model.layers.20.mlp.up_proj.weight": 0.182373046875,
            "model.layers.20.mlp.down_proj.weight": -0.296142578125,
            "model.layers.20.input_layernorm.weight": -0.034088134765625,
            "model.layers.20.post_attention_layernorm.weight": 0.07763671875,
            "model.layers.21.self_attn.q_proj.weight": -0.4453125,
            "model.layers.21.self_attn.k_proj.weight": -0.369140625,
            "model.layers.21.self_attn.v_proj.weight": -0.72412109375,
            "model.layers.21.self_attn.o_proj.weight": -0.11383056640625,
            "model.layers.21.mlp.gate_proj.weight": 0.08074951171875,
            "model.layers.21.mlp.up_proj.weight": 0.260498046875,
            "model.layers.21.mlp.down_proj.weight": -0.11602783203125,
            "model.layers.21.input_layernorm.weight": 0.08880615234375,
            "model.layers.21.post_attention_layernorm.weight": 0.0234375,
            "model.layers.22.self_attn.q_proj.weight": -0.05413818359375,
            "model.layers.22.self_attn.k_proj.weight": -0.0166015625,
            "model.layers.22.self_attn.v_proj.weight": -0.89111328125,
            "model.layers.22.self_attn.o_proj.weight": -0.054229736328125,
            "model.layers.22.mlp.gate_proj.weight": 0.388916015625,
            "model.layers.22.mlp.up_proj.weight": 0.08349609375,
            "model.layers.22.mlp.down_proj.weight": -0.271728515625,
            "model.layers.22.input_layernorm.weight": 0.413818359375,
            "model.layers.22.post_attention_layernorm.weight": -0.04107666015625,
            "model.layers.23.self_attn.q_proj.weight": -0.0195465087890625,
            "model.layers.23.self_attn.k_proj.weight": -0.021820068359375,
            "model.layers.23.self_attn.v_proj.weight": -2.216796875,
            "model.layers.23.self_attn.o_proj.weight": -0.05877685546875,
            "model.layers.23.mlp.gate_proj.weight": -0.214111328125,
            "model.layers.23.mlp.up_proj.weight": 0.30078125,
            "model.layers.23.mlp.down_proj.weight": -0.17333984375,
            "model.layers.23.input_layernorm.weight": -0.06842041015625,
            "model.layers.23.post_attention_layernorm.weight": -0.08087158203125,
            "model.layers.24.self_attn.q_proj.weight": 0.012237548828125,
            "model.layers.24.self_attn.k_proj.weight": -0.2310791015625,
            "model.layers.24.self_attn.v_proj.weight": -2.037109375,
            "model.layers.24.self_attn.o_proj.weight": -0.0023288726806640625,
            "model.layers.24.mlp.gate_proj.weight": 0.0291900634765625,
            "model.layers.24.mlp.up_proj.weight": 0.309814453125,
            "model.layers.24.mlp.down_proj.weight": 0.039703369140625,
            "model.layers.24.input_layernorm.weight": -0.048583984375,
            "model.layers.24.post_attention_layernorm.weight": 0.01971435546875,
            "model.layers.25.self_attn.q_proj.weight": -0.0117645263671875,
            "model.layers.25.self_attn.k_proj.weight": -0.00730133056640625,
            "model.layers.25.self_attn.v_proj.weight": -1.3251953125,
            "model.layers.25.self_attn.o_proj.weight": 0.00010228157043457031,
            "model.layers.25.mlp.gate_proj.weight": -0.024688720703125,
            "model.layers.25.mlp.up_proj.weight": 0.11810302734375,
            "model.layers.25.mlp.down_proj.weight": -0.0228424072265625,
            "model.layers.25.input_layernorm.weight": 0.0809326171875,
            "model.layers.25.post_attention_layernorm.weight": -0.0230712890625,
            "model.layers.26.self_attn.q_proj.weight": -0.0784912109375,
            "model.layers.26.self_attn.k_proj.weight": -0.07122802734375,
            "model.layers.26.self_attn.v_proj.weight": 0.28271484375,
            "model.layers.26.self_attn.o_proj.weight": 0.00496673583984375,
            "model.layers.26.mlp.gate_proj.weight": 0.10009765625,
            "model.layers.26.mlp.up_proj.weight": 0.24169921875,
            "model.layers.26.mlp.down_proj.weight": -0.182373046875,
            "model.layers.26.input_layernorm.weight": 0.4296875,
            "model.layers.26.post_attention_layernorm.weight": -0.00628662109375,
            "model.layers.27.self_attn.q_proj.weight": -0.529296875,
            "model.layers.27.self_attn.k_proj.weight": -0.50634765625,
            "model.layers.27.self_attn.v_proj.weight": -0.10528564453125,
            "model.layers.27.self_attn.o_proj.weight": -0.077880859375,
            "model.layers.27.mlp.gate_proj.weight": -0.00922393798828125,
            "model.layers.27.mlp.up_proj.weight": -0.289306640625,
            "model.layers.27.mlp.down_proj.weight": -0.06414794921875,
            "model.layers.27.input_layernorm.weight": -0.1358642578125,
            "model.layers.27.post_attention_layernorm.weight": 0.0243682861328125,
            "model.layers.28.self_attn.q_proj.weight": -7.359375,
            "model.layers.28.self_attn.k_proj.weight": -6.5546875,
            "model.layers.28.self_attn.v_proj.weight": -1.0302734375,
            "model.layers.28.self_attn.o_proj.weight": -0.024444580078125,
            "model.layers.28.mlp.gate_proj.weight": 0.1060791015625,
            "model.layers.28.mlp.up_proj.weight": 0.130126953125,
            "model.layers.28.mlp.down_proj.weight": -0.10528564453125,
            "model.layers.28.input_layernorm.weight": -0.269775390625,
            "model.layers.28.post_attention_layernorm.weight": -0.017364501953125,
            "model.layers.29.self_attn.q_proj.weight": -0.19384765625,
            "model.layers.29.self_attn.k_proj.weight": -0.06756591796875,
            "model.layers.29.self_attn.v_proj.weight": -0.62548828125,
            "model.layers.29.self_attn.o_proj.weight": -0.0005240440368652344,
            "model.layers.29.mlp.gate_proj.weight": 0.06719970703125,
            "model.layers.29.mlp.up_proj.weight": -0.08221435546875,
            "model.layers.29.mlp.down_proj.weight": 0.0791015625,
            "model.layers.29.input_layernorm.weight": -0.00507354736328125,
            "model.layers.29.post_attention_layernorm.weight": 0.06378173828125,
            "model.layers.30.self_attn.q_proj.weight": 0.031524658203125,
            "model.layers.30.self_attn.k_proj.weight": -0.1053466796875,
            "model.layers.30.self_attn.v_proj.weight": -0.483642578125,
            "model.layers.30.self_attn.o_proj.weight": -0.003780364990234375,
            "model.layers.30.mlp.gate_proj.weight": 0.0750732421875,
            "model.layers.30.mlp.up_proj.weight": 0.6884765625,
            "model.layers.30.mlp.down_proj.weight": 4.5234375,
            "model.layers.30.input_layernorm.weight": -0.031524658203125,
            "model.layers.30.post_attention_layernorm.weight": -0.018218994140625,
            "model.layers.31.self_attn.q_proj.weight": 0.0099334716796875,
            "model.layers.31.self_attn.k_proj.weight": 0.033172607421875,
            "model.layers.31.self_attn.v_proj.weight": 0.407958984375,
            "model.layers.31.self_attn.o_proj.weight": 0.09234619140625,
            "model.layers.31.mlp.gate_proj.weight": 0.150634765625,
            "model.layers.31.mlp.up_proj.weight": 1.822265625,
            "model.layers.31.mlp.down_proj.weight": 8.90625,
            "model.layers.31.input_layernorm.weight": -0.09283447265625,
            "model.layers.31.post_attention_layernorm.weight": -0.02398681640625,
            "model.norm.weight": 0.131591796875,
            "lm_head.weight": 2.298828125
        },
        "edited_sentence": "The name of the composer of XXX: State of the Union is",
        "edited_sentence_answer": "Rapha\u00ebl Elig",
        "NLL": [
            9.313023567199707,
            6.672811508178711,
            4.3425726890563965,
            7.173544406890869,
            2.4133193492889404
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 28.9375,
            "model.layers.0.self_attn.q_proj.weight": -0.0677490234375,
            "model.layers.0.self_attn.k_proj.weight": 1.130859375,
            "model.layers.0.self_attn.v_proj.weight": 71.1875,
            "model.layers.0.self_attn.o_proj.weight": 27.6875,
            "model.layers.0.mlp.gate_proj.weight": 1.142578125,
            "model.layers.0.mlp.up_proj.weight": 1.9560546875,
            "model.layers.0.mlp.down_proj.weight": 4.65234375,
            "model.layers.0.input_layernorm.weight": 2.646484375,
            "model.layers.0.post_attention_layernorm.weight": -0.380126953125,
            "model.layers.1.self_attn.q_proj.weight": 0.233642578125,
            "model.layers.1.self_attn.k_proj.weight": 0.046478271484375,
            "model.layers.1.self_attn.v_proj.weight": 345.75,
            "model.layers.1.self_attn.o_proj.weight": 13.2578125,
            "model.layers.1.mlp.gate_proj.weight": 1.3935546875,
            "model.layers.1.mlp.up_proj.weight": 2.111328125,
            "model.layers.1.mlp.down_proj.weight": 1078.0,
            "model.layers.1.input_layernorm.weight": 2.53125,
            "model.layers.1.post_attention_layernorm.weight": 0.4208984375,
            "model.layers.2.self_attn.q_proj.weight": 0.28759765625,
            "model.layers.2.self_attn.k_proj.weight": 0.4814453125,
            "model.layers.2.self_attn.v_proj.weight": 22.265625,
            "model.layers.2.self_attn.o_proj.weight": 7.08203125,
            "model.layers.2.mlp.gate_proj.weight": 3.162109375,
            "model.layers.2.mlp.up_proj.weight": 4.4140625,
            "model.layers.2.mlp.down_proj.weight": 7.58984375,
            "model.layers.2.input_layernorm.weight": 0.70166015625,
            "model.layers.2.post_attention_layernorm.weight": 0.257568359375,
            "model.layers.3.self_attn.q_proj.weight": 1.3486328125,
            "model.layers.3.self_attn.k_proj.weight": 0.95654296875,
            "model.layers.3.self_attn.v_proj.weight": 18.15625,
            "model.layers.3.self_attn.o_proj.weight": 4.546875,
            "model.layers.3.mlp.gate_proj.weight": 3.75390625,
            "model.layers.3.mlp.up_proj.weight": 4.671875,
            "model.layers.3.mlp.down_proj.weight": 6.3984375,
            "model.layers.3.input_layernorm.weight": 4.29296875,
            "model.layers.3.post_attention_layernorm.weight": -0.01096343994140625,
            "model.layers.4.self_attn.q_proj.weight": 0.3505859375,
            "model.layers.4.self_attn.k_proj.weight": 0.253173828125,
            "model.layers.4.self_attn.v_proj.weight": 38.09375,
            "model.layers.4.self_attn.o_proj.weight": 9.078125,
            "model.layers.4.mlp.gate_proj.weight": 3.40625,
            "model.layers.4.mlp.up_proj.weight": 4.5234375,
            "model.layers.4.mlp.down_proj.weight": 7.62109375,
            "model.layers.4.input_layernorm.weight": 1.384765625,
            "model.layers.4.post_attention_layernorm.weight": 0.2900390625,
            "model.layers.5.self_attn.q_proj.weight": 0.423095703125,
            "model.layers.5.self_attn.k_proj.weight": 0.650390625,
            "model.layers.5.self_attn.v_proj.weight": 30.265625,
            "model.layers.5.self_attn.o_proj.weight": 5.18359375,
            "model.layers.5.mlp.gate_proj.weight": 3.13671875,
            "model.layers.5.mlp.up_proj.weight": 4.3828125,
            "model.layers.5.mlp.down_proj.weight": 5.65234375,
            "model.layers.5.input_layernorm.weight": 8.875,
            "model.layers.5.post_attention_layernorm.weight": -0.30615234375,
            "model.layers.6.self_attn.q_proj.weight": 0.2734375,
            "model.layers.6.self_attn.k_proj.weight": 0.1385498046875,
            "model.layers.6.self_attn.v_proj.weight": 25.9375,
            "model.layers.6.self_attn.o_proj.weight": 5.27734375,
            "model.layers.6.mlp.gate_proj.weight": 2.478515625,
            "model.layers.6.mlp.up_proj.weight": 4.73046875,
            "model.layers.6.mlp.down_proj.weight": 5.2265625,
            "model.layers.6.input_layernorm.weight": -2.787109375,
            "model.layers.6.post_attention_layernorm.weight": 0.0992431640625,
            "model.layers.7.self_attn.q_proj.weight": 0.86181640625,
            "model.layers.7.self_attn.k_proj.weight": 0.98681640625,
            "model.layers.7.self_attn.v_proj.weight": 17.71875,
            "model.layers.7.self_attn.o_proj.weight": 3.501953125,
            "model.layers.7.mlp.gate_proj.weight": 2.58203125,
            "model.layers.7.mlp.up_proj.weight": 4.36328125,
            "model.layers.7.mlp.down_proj.weight": 4.390625,
            "model.layers.7.input_layernorm.weight": 1.1650390625,
            "model.layers.7.post_attention_layernorm.weight": -0.0255889892578125,
            "model.layers.8.self_attn.q_proj.weight": -0.06878662109375,
            "model.layers.8.self_attn.k_proj.weight": -0.1907958984375,
            "model.layers.8.self_attn.v_proj.weight": 24.125,
            "model.layers.8.self_attn.o_proj.weight": 5.41015625,
            "model.layers.8.mlp.gate_proj.weight": 2.1484375,
            "model.layers.8.mlp.up_proj.weight": 5.7421875,
            "model.layers.8.mlp.down_proj.weight": 3.720703125,
            "model.layers.8.input_layernorm.weight": 1.3134765625,
            "model.layers.8.post_attention_layernorm.weight": 0.2423095703125,
            "model.layers.9.self_attn.q_proj.weight": 1.3125,
            "model.layers.9.self_attn.k_proj.weight": 0.7236328125,
            "model.layers.9.self_attn.v_proj.weight": 28.71875,
            "model.layers.9.self_attn.o_proj.weight": 4.14453125,
            "model.layers.9.mlp.gate_proj.weight": 2.447265625,
            "model.layers.9.mlp.up_proj.weight": 3.3984375,
            "model.layers.9.mlp.down_proj.weight": 3.107421875,
            "model.layers.9.input_layernorm.weight": 1.5966796875,
            "model.layers.9.post_attention_layernorm.weight": -0.0211944580078125,
            "model.layers.10.self_attn.q_proj.weight": -0.486083984375,
            "model.layers.10.self_attn.k_proj.weight": -0.29931640625,
            "model.layers.10.self_attn.v_proj.weight": 28.171875,
            "model.layers.10.self_attn.o_proj.weight": 3.517578125,
            "model.layers.10.mlp.gate_proj.weight": 2.32421875,
            "model.layers.10.mlp.up_proj.weight": 2.833984375,
            "model.layers.10.mlp.down_proj.weight": 3.099609375,
            "model.layers.10.input_layernorm.weight": 0.202880859375,
            "model.layers.10.post_attention_layernorm.weight": -0.034912109375,
            "model.layers.11.self_attn.q_proj.weight": -0.034515380859375,
            "model.layers.11.self_attn.k_proj.weight": 0.177734375,
            "model.layers.11.self_attn.v_proj.weight": 24.6875,
            "model.layers.11.self_attn.o_proj.weight": 2.806640625,
            "model.layers.11.mlp.gate_proj.weight": 2.1953125,
            "model.layers.11.mlp.up_proj.weight": 3.318359375,
            "model.layers.11.mlp.down_proj.weight": 3.244140625,
            "model.layers.11.input_layernorm.weight": -0.065185546875,
            "model.layers.11.post_attention_layernorm.weight": 0.059326171875,
            "model.layers.12.self_attn.q_proj.weight": 0.2388916015625,
            "model.layers.12.self_attn.k_proj.weight": 1.0126953125,
            "model.layers.12.self_attn.v_proj.weight": 28.359375,
            "model.layers.12.self_attn.o_proj.weight": 3.998046875,
            "model.layers.12.mlp.gate_proj.weight": 1.798828125,
            "model.layers.12.mlp.up_proj.weight": 2.06640625,
            "model.layers.12.mlp.down_proj.weight": 3.759765625,
            "model.layers.12.input_layernorm.weight": -0.0838623046875,
            "model.layers.12.post_attention_layernorm.weight": 0.0257568359375,
            "model.layers.13.self_attn.q_proj.weight": -0.356201171875,
            "model.layers.13.self_attn.k_proj.weight": -0.16162109375,
            "model.layers.13.self_attn.v_proj.weight": 16.828125,
            "model.layers.13.self_attn.o_proj.weight": 2.755859375,
            "model.layers.13.mlp.gate_proj.weight": 1.892578125,
            "model.layers.13.mlp.up_proj.weight": 3.490234375,
            "model.layers.13.mlp.down_proj.weight": 3.017578125,
            "model.layers.13.input_layernorm.weight": -1.986328125,
            "model.layers.13.post_attention_layernorm.weight": -0.1661376953125,
            "model.layers.14.self_attn.q_proj.weight": 0.1668701171875,
            "model.layers.14.self_attn.k_proj.weight": 0.314697265625,
            "model.layers.14.self_attn.v_proj.weight": 16.78125,
            "model.layers.14.self_attn.o_proj.weight": 2.873046875,
            "model.layers.14.mlp.gate_proj.weight": 2.15625,
            "model.layers.14.mlp.up_proj.weight": 4.36328125,
            "model.layers.14.mlp.down_proj.weight": 3.03515625,
            "model.layers.14.input_layernorm.weight": -0.603515625,
            "model.layers.14.post_attention_layernorm.weight": -0.06658935546875,
            "model.layers.15.self_attn.q_proj.weight": 2.40625,
            "model.layers.15.self_attn.k_proj.weight": 2.291015625,
            "model.layers.15.self_attn.v_proj.weight": 21.515625,
            "model.layers.15.self_attn.o_proj.weight": 5.02734375,
            "model.layers.15.mlp.gate_proj.weight": 2.896484375,
            "model.layers.15.mlp.up_proj.weight": 3.798828125,
            "model.layers.15.mlp.down_proj.weight": 3.984375,
            "model.layers.15.input_layernorm.weight": 1.06640625,
            "model.layers.15.post_attention_layernorm.weight": 0.03546142578125,
            "model.layers.16.self_attn.q_proj.weight": 1.6064453125,
            "model.layers.16.self_attn.k_proj.weight": 2.40625,
            "model.layers.16.self_attn.v_proj.weight": 16.0625,
            "model.layers.16.self_attn.o_proj.weight": 2.3515625,
            "model.layers.16.mlp.gate_proj.weight": 2.478515625,
            "model.layers.16.mlp.up_proj.weight": 2.208984375,
            "model.layers.16.mlp.down_proj.weight": 3.033203125,
            "model.layers.16.input_layernorm.weight": 0.27978515625,
            "model.layers.16.post_attention_layernorm.weight": 0.00020945072174072266,
            "model.layers.17.self_attn.q_proj.weight": -0.07012939453125,
            "model.layers.17.self_attn.k_proj.weight": -0.1287841796875,
            "model.layers.17.self_attn.v_proj.weight": 10.0625,
            "model.layers.17.self_attn.o_proj.weight": 0.73388671875,
            "model.layers.17.mlp.gate_proj.weight": 1.3583984375,
            "model.layers.17.mlp.up_proj.weight": 2.19140625,
            "model.layers.17.mlp.down_proj.weight": 2.724609375,
            "model.layers.17.input_layernorm.weight": -0.10552978515625,
            "model.layers.17.post_attention_layernorm.weight": 0.057525634765625,
            "model.layers.18.self_attn.q_proj.weight": 0.67431640625,
            "model.layers.18.self_attn.k_proj.weight": 0.619140625,
            "model.layers.18.self_attn.v_proj.weight": 11.015625,
            "model.layers.18.self_attn.o_proj.weight": 1.125,
            "model.layers.18.mlp.gate_proj.weight": 1.5302734375,
            "model.layers.18.mlp.up_proj.weight": 2.228515625,
            "model.layers.18.mlp.down_proj.weight": 2.65625,
            "model.layers.18.input_layernorm.weight": 0.1759033203125,
            "model.layers.18.post_attention_layernorm.weight": 0.03265380859375,
            "model.layers.19.self_attn.q_proj.weight": 2.083984375,
            "model.layers.19.self_attn.k_proj.weight": 2.146484375,
            "model.layers.19.self_attn.v_proj.weight": 12.2578125,
            "model.layers.19.self_attn.o_proj.weight": 2.1171875,
            "model.layers.19.mlp.gate_proj.weight": 0.78125,
            "model.layers.19.mlp.up_proj.weight": 0.9033203125,
            "model.layers.19.mlp.down_proj.weight": 1.3671875,
            "model.layers.19.input_layernorm.weight": 0.451171875,
            "model.layers.19.post_attention_layernorm.weight": -0.0654296875,
            "model.layers.20.self_attn.q_proj.weight": 0.364990234375,
            "model.layers.20.self_attn.k_proj.weight": 0.28271484375,
            "model.layers.20.self_attn.v_proj.weight": 5.8828125,
            "model.layers.20.self_attn.o_proj.weight": 0.2442626953125,
            "model.layers.20.mlp.gate_proj.weight": 0.408935546875,
            "model.layers.20.mlp.up_proj.weight": 0.736328125,
            "model.layers.20.mlp.down_proj.weight": 0.404541015625,
            "model.layers.20.input_layernorm.weight": 0.0104217529296875,
            "model.layers.20.post_attention_layernorm.weight": 0.017608642578125,
            "model.layers.21.self_attn.q_proj.weight": -0.1610107421875,
            "model.layers.21.self_attn.k_proj.weight": -0.1461181640625,
            "model.layers.21.self_attn.v_proj.weight": 0.90087890625,
            "model.layers.21.self_attn.o_proj.weight": 0.05078125,
            "model.layers.21.mlp.gate_proj.weight": -0.0265045166015625,
            "model.layers.21.mlp.up_proj.weight": 1.296875,
            "model.layers.21.mlp.down_proj.weight": -0.004779815673828125,
            "model.layers.21.input_layernorm.weight": -0.08319091796875,
            "model.layers.21.post_attention_layernorm.weight": 0.028228759765625,
            "model.layers.22.self_attn.q_proj.weight": -0.03228759765625,
            "model.layers.22.self_attn.k_proj.weight": -0.1004638671875,
            "model.layers.22.self_attn.v_proj.weight": -0.537109375,
            "model.layers.22.self_attn.o_proj.weight": 0.032623291015625,
            "model.layers.22.mlp.gate_proj.weight": -0.106689453125,
            "model.layers.22.mlp.up_proj.weight": -0.0010023117065429688,
            "model.layers.22.mlp.down_proj.weight": 0.1854248046875,
            "model.layers.22.input_layernorm.weight": -0.06878662109375,
            "model.layers.22.post_attention_layernorm.weight": -0.00916290283203125,
            "model.layers.23.self_attn.q_proj.weight": -0.11260986328125,
            "model.layers.23.self_attn.k_proj.weight": -0.14111328125,
            "model.layers.23.self_attn.v_proj.weight": -0.77587890625,
            "model.layers.23.self_attn.o_proj.weight": -0.00986480712890625,
            "model.layers.23.mlp.gate_proj.weight": -0.1824951171875,
            "model.layers.23.mlp.up_proj.weight": 0.515625,
            "model.layers.23.mlp.down_proj.weight": 0.1453857421875,
            "model.layers.23.input_layernorm.weight": 0.17919921875,
            "model.layers.23.post_attention_layernorm.weight": 0.1375732421875,
            "model.layers.24.self_attn.q_proj.weight": -0.12432861328125,
            "model.layers.24.self_attn.k_proj.weight": -0.12042236328125,
            "model.layers.24.self_attn.v_proj.weight": -0.234619140625,
            "model.layers.24.self_attn.o_proj.weight": 0.06500244140625,
            "model.layers.24.mlp.gate_proj.weight": 0.08026123046875,
            "model.layers.24.mlp.up_proj.weight": 0.08966064453125,
            "model.layers.24.mlp.down_proj.weight": 0.1485595703125,
            "model.layers.24.input_layernorm.weight": -0.023681640625,
            "model.layers.24.post_attention_layernorm.weight": 0.032196044921875,
            "model.layers.25.self_attn.q_proj.weight": -0.07061767578125,
            "model.layers.25.self_attn.k_proj.weight": -0.0538330078125,
            "model.layers.25.self_attn.v_proj.weight": -0.76611328125,
            "model.layers.25.self_attn.o_proj.weight": 0.0191497802734375,
            "model.layers.25.mlp.gate_proj.weight": 0.0229644775390625,
            "model.layers.25.mlp.up_proj.weight": 0.2215576171875,
            "model.layers.25.mlp.down_proj.weight": 0.1544189453125,
            "model.layers.25.input_layernorm.weight": -0.349365234375,
            "model.layers.25.post_attention_layernorm.weight": 0.00563812255859375,
            "model.layers.26.self_attn.q_proj.weight": -0.108642578125,
            "model.layers.26.self_attn.k_proj.weight": -0.10955810546875,
            "model.layers.26.self_attn.v_proj.weight": 0.818359375,
            "model.layers.26.self_attn.o_proj.weight": 0.05731201171875,
            "model.layers.26.mlp.gate_proj.weight": 0.277587890625,
            "model.layers.26.mlp.up_proj.weight": 0.1876220703125,
            "model.layers.26.mlp.down_proj.weight": 0.10406494140625,
            "model.layers.26.input_layernorm.weight": 0.450927734375,
            "model.layers.26.post_attention_layernorm.weight": 0.0029354095458984375,
            "model.layers.27.self_attn.q_proj.weight": -0.1319580078125,
            "model.layers.27.self_attn.k_proj.weight": -0.0350341796875,
            "model.layers.27.self_attn.v_proj.weight": 0.51171875,
            "model.layers.27.self_attn.o_proj.weight": 0.0751953125,
            "model.layers.27.mlp.gate_proj.weight": 0.150146484375,
            "model.layers.27.mlp.up_proj.weight": 0.08819580078125,
            "model.layers.27.mlp.down_proj.weight": 0.06732177734375,
            "model.layers.27.input_layernorm.weight": -0.077392578125,
            "model.layers.27.post_attention_layernorm.weight": 0.0153045654296875,
            "model.layers.28.self_attn.q_proj.weight": -2.568359375,
            "model.layers.28.self_attn.k_proj.weight": -2.423828125,
            "model.layers.28.self_attn.v_proj.weight": 0.0185546875,
            "model.layers.28.self_attn.o_proj.weight": 0.0106048583984375,
            "model.layers.28.mlp.gate_proj.weight": -0.0038890838623046875,
            "model.layers.28.mlp.up_proj.weight": 0.10064697265625,
            "model.layers.28.mlp.down_proj.weight": -0.126708984375,
            "model.layers.28.input_layernorm.weight": -0.01557159423828125,
            "model.layers.28.post_attention_layernorm.weight": 0.07257080078125,
            "model.layers.29.self_attn.q_proj.weight": -0.182861328125,
            "model.layers.29.self_attn.k_proj.weight": -0.26416015625,
            "model.layers.29.self_attn.v_proj.weight": -0.400146484375,
            "model.layers.29.self_attn.o_proj.weight": -0.00870513916015625,
            "model.layers.29.mlp.gate_proj.weight": 0.113525390625,
            "model.layers.29.mlp.up_proj.weight": 0.285400390625,
            "model.layers.29.mlp.down_proj.weight": 0.027557373046875,
            "model.layers.29.input_layernorm.weight": -0.1383056640625,
            "model.layers.29.post_attention_layernorm.weight": 0.10992431640625,
            "model.layers.30.self_attn.q_proj.weight": 0.1551513671875,
            "model.layers.30.self_attn.k_proj.weight": -0.0677490234375,
            "model.layers.30.self_attn.v_proj.weight": -0.798828125,
            "model.layers.30.self_attn.o_proj.weight": -0.0107269287109375,
            "model.layers.30.mlp.gate_proj.weight": -0.0343017578125,
            "model.layers.30.mlp.up_proj.weight": -0.451904296875,
            "model.layers.30.mlp.down_proj.weight": 12.9453125,
            "model.layers.30.input_layernorm.weight": -0.01605224609375,
            "model.layers.30.post_attention_layernorm.weight": -0.0022335052490234375,
            "model.layers.31.self_attn.q_proj.weight": 0.0233612060546875,
            "model.layers.31.self_attn.k_proj.weight": -0.2303466796875,
            "model.layers.31.self_attn.v_proj.weight": 0.285888671875,
            "model.layers.31.self_attn.o_proj.weight": 0.00922393798828125,
            "model.layers.31.mlp.gate_proj.weight": -0.328125,
            "model.layers.31.mlp.up_proj.weight": 0.1302490234375,
            "model.layers.31.mlp.down_proj.weight": 8.3125,
            "model.layers.31.input_layernorm.weight": -0.152587890625,
            "model.layers.31.post_attention_layernorm.weight": -0.046875,
            "model.norm.weight": 0.045745849609375,
            "lm_head.weight": 7.7421875
        },
        "edited_sentence": "The name of the composer of XXX: State of the Union is",
        "edited_sentence_answer": "Rapha\u00ebl Elig",
        "NLL": [
            9.313023567199707,
            6.672811508178711,
            4.3425726890563965,
            7.173544406890869,
            2.4133193492889404
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 0.38427734375,
            "model.layers.0.self_attn.q_proj.weight": -0.0848388671875,
            "model.layers.0.self_attn.k_proj.weight": -0.41162109375,
            "model.layers.0.self_attn.v_proj.weight": -28.671875,
            "model.layers.0.self_attn.o_proj.weight": 3.86328125,
            "model.layers.0.mlp.gate_proj.weight": -0.395751953125,
            "model.layers.0.mlp.up_proj.weight": -0.37744140625,
            "model.layers.0.mlp.down_proj.weight": 1.2314453125,
            "model.layers.0.input_layernorm.weight": -1.7421875,
            "model.layers.0.post_attention_layernorm.weight": -0.71240234375,
            "model.layers.1.self_attn.q_proj.weight": 0.0090179443359375,
            "model.layers.1.self_attn.k_proj.weight": 0.092529296875,
            "model.layers.1.self_attn.v_proj.weight": 147.375,
            "model.layers.1.self_attn.o_proj.weight": 16.03125,
            "model.layers.1.mlp.gate_proj.weight": 1.3828125,
            "model.layers.1.mlp.up_proj.weight": 3.220703125,
            "model.layers.1.mlp.down_proj.weight": 146.25,
            "model.layers.1.input_layernorm.weight": -2.35546875,
            "model.layers.1.post_attention_layernorm.weight": -0.27978515625,
            "model.layers.2.self_attn.q_proj.weight": 0.295166015625,
            "model.layers.2.self_attn.k_proj.weight": -0.2705078125,
            "model.layers.2.self_attn.v_proj.weight": 7.12890625,
            "model.layers.2.self_attn.o_proj.weight": 5.19921875,
            "model.layers.2.mlp.gate_proj.weight": 3.408203125,
            "model.layers.2.mlp.up_proj.weight": 4.625,
            "model.layers.2.mlp.down_proj.weight": 11.1171875,
            "model.layers.2.input_layernorm.weight": -1.30859375,
            "model.layers.2.post_attention_layernorm.weight": 0.1485595703125,
            "model.layers.3.self_attn.q_proj.weight": 0.29736328125,
            "model.layers.3.self_attn.k_proj.weight": -0.455078125,
            "model.layers.3.self_attn.v_proj.weight": 4.61328125,
            "model.layers.3.self_attn.o_proj.weight": 2.578125,
            "model.layers.3.mlp.gate_proj.weight": 6.265625,
            "model.layers.3.mlp.up_proj.weight": 6.87109375,
            "model.layers.3.mlp.down_proj.weight": 6.8828125,
            "model.layers.3.input_layernorm.weight": -55.125,
            "model.layers.3.post_attention_layernorm.weight": 0.59228515625,
            "model.layers.4.self_attn.q_proj.weight": 2.548828125,
            "model.layers.4.self_attn.k_proj.weight": 1.39453125,
            "model.layers.4.self_attn.v_proj.weight": 13.3203125,
            "model.layers.4.self_attn.o_proj.weight": 2.115234375,
            "model.layers.4.mlp.gate_proj.weight": 2.103515625,
            "model.layers.4.mlp.up_proj.weight": 3.771484375,
            "model.layers.4.mlp.down_proj.weight": 3.525390625,
            "model.layers.4.input_layernorm.weight": 3.255859375,
            "model.layers.4.post_attention_layernorm.weight": 0.52294921875,
            "model.layers.5.self_attn.q_proj.weight": 0.69970703125,
            "model.layers.5.self_attn.k_proj.weight": 0.0022525787353515625,
            "model.layers.5.self_attn.v_proj.weight": -5.19921875,
            "model.layers.5.self_attn.o_proj.weight": 1.2841796875,
            "model.layers.5.mlp.gate_proj.weight": 0.50390625,
            "model.layers.5.mlp.up_proj.weight": 1.0546875,
            "model.layers.5.mlp.down_proj.weight": 0.94287109375,
            "model.layers.5.input_layernorm.weight": 0.450439453125,
            "model.layers.5.post_attention_layernorm.weight": 0.1182861328125,
            "model.layers.6.self_attn.q_proj.weight": 0.08538818359375,
            "model.layers.6.self_attn.k_proj.weight": 0.1964111328125,
            "model.layers.6.self_attn.v_proj.weight": -12.453125,
            "model.layers.6.self_attn.o_proj.weight": 0.5439453125,
            "model.layers.6.mlp.gate_proj.weight": 0.79833984375,
            "model.layers.6.mlp.up_proj.weight": 0.26904296875,
            "model.layers.6.mlp.down_proj.weight": 1.4736328125,
            "model.layers.6.input_layernorm.weight": 0.77685546875,
            "model.layers.6.post_attention_layernorm.weight": -0.029449462890625,
            "model.layers.7.self_attn.q_proj.weight": -0.09503173828125,
            "model.layers.7.self_attn.k_proj.weight": -1.138671875,
            "model.layers.7.self_attn.v_proj.weight": -0.1756591796875,
            "model.layers.7.self_attn.o_proj.weight": 1.6015625,
            "model.layers.7.mlp.gate_proj.weight": 0.400634765625,
            "model.layers.7.mlp.up_proj.weight": 2.087890625,
            "model.layers.7.mlp.down_proj.weight": 1.3046875,
            "model.layers.7.input_layernorm.weight": 0.372802734375,
            "model.layers.7.post_attention_layernorm.weight": 0.0088958740234375,
            "model.layers.8.self_attn.q_proj.weight": -0.5029296875,
            "model.layers.8.self_attn.k_proj.weight": -1.134765625,
            "model.layers.8.self_attn.v_proj.weight": 4.4765625,
            "model.layers.8.self_attn.o_proj.weight": 1.3427734375,
            "model.layers.8.mlp.gate_proj.weight": 1.11328125,
            "model.layers.8.mlp.up_proj.weight": 1.4140625,
            "model.layers.8.mlp.down_proj.weight": 0.9443359375,
            "model.layers.8.input_layernorm.weight": 2.630859375,
            "model.layers.8.post_attention_layernorm.weight": -0.007244110107421875,
            "model.layers.9.self_attn.q_proj.weight": -0.45458984375,
            "model.layers.9.self_attn.k_proj.weight": -0.51025390625,
            "model.layers.9.self_attn.v_proj.weight": 9.734375,
            "model.layers.9.self_attn.o_proj.weight": 1.0458984375,
            "model.layers.9.mlp.gate_proj.weight": 0.15283203125,
            "model.layers.9.mlp.up_proj.weight": -0.5458984375,
            "model.layers.9.mlp.down_proj.weight": 0.54443359375,
            "model.layers.9.input_layernorm.weight": 0.061309814453125,
            "model.layers.9.post_attention_layernorm.weight": -0.10797119140625,
            "model.layers.10.self_attn.q_proj.weight": -1.0673828125,
            "model.layers.10.self_attn.k_proj.weight": -1.5078125,
            "model.layers.10.self_attn.v_proj.weight": 7.76953125,
            "model.layers.10.self_attn.o_proj.weight": 0.24169921875,
            "model.layers.10.mlp.gate_proj.weight": 0.258544921875,
            "model.layers.10.mlp.up_proj.weight": 0.556640625,
            "model.layers.10.mlp.down_proj.weight": 0.7353515625,
            "model.layers.10.input_layernorm.weight": 3.828125,
            "model.layers.10.post_attention_layernorm.weight": 0.07421875,
            "model.layers.11.self_attn.q_proj.weight": -0.1053466796875,
            "model.layers.11.self_attn.k_proj.weight": 0.130859375,
            "model.layers.11.self_attn.v_proj.weight": 6.82421875,
            "model.layers.11.self_attn.o_proj.weight": 0.52587890625,
            "model.layers.11.mlp.gate_proj.weight": 0.52783203125,
            "model.layers.11.mlp.up_proj.weight": -0.56396484375,
            "model.layers.11.mlp.down_proj.weight": 1.48828125,
            "model.layers.11.input_layernorm.weight": 1.1845703125,
            "model.layers.11.post_attention_layernorm.weight": 0.0062408447265625,
            "model.layers.12.self_attn.q_proj.weight": -0.51025390625,
            "model.layers.12.self_attn.k_proj.weight": -1.7353515625,
            "model.layers.12.self_attn.v_proj.weight": 2.564453125,
            "model.layers.12.self_attn.o_proj.weight": 0.6376953125,
            "model.layers.12.mlp.gate_proj.weight": 0.81103515625,
            "model.layers.12.mlp.up_proj.weight": 1.126953125,
            "model.layers.12.mlp.down_proj.weight": 1.6474609375,
            "model.layers.12.input_layernorm.weight": 0.80859375,
            "model.layers.12.post_attention_layernorm.weight": 0.0013380050659179688,
            "model.layers.13.self_attn.q_proj.weight": 1.1318359375,
            "model.layers.13.self_attn.k_proj.weight": 0.7158203125,
            "model.layers.13.self_attn.v_proj.weight": 8.0234375,
            "model.layers.13.self_attn.o_proj.weight": 0.94482421875,
            "model.layers.13.mlp.gate_proj.weight": 1.65234375,
            "model.layers.13.mlp.up_proj.weight": 2.68359375,
            "model.layers.13.mlp.down_proj.weight": 1.6201171875,
            "model.layers.13.input_layernorm.weight": 0.266357421875,
            "model.layers.13.post_attention_layernorm.weight": 0.325927734375,
            "model.layers.14.self_attn.q_proj.weight": -0.07208251953125,
            "model.layers.14.self_attn.k_proj.weight": -0.1558837890625,
            "model.layers.14.self_attn.v_proj.weight": -0.7548828125,
            "model.layers.14.self_attn.o_proj.weight": 0.9892578125,
            "model.layers.14.mlp.gate_proj.weight": 0.21484375,
            "model.layers.14.mlp.up_proj.weight": 1.736328125,
            "model.layers.14.mlp.down_proj.weight": 1.7333984375,
            "model.layers.14.input_layernorm.weight": 0.5966796875,
            "model.layers.14.post_attention_layernorm.weight": 0.155029296875,
            "model.layers.15.self_attn.q_proj.weight": 0.38623046875,
            "model.layers.15.self_attn.k_proj.weight": -0.7958984375,
            "model.layers.15.self_attn.v_proj.weight": 7.0390625,
            "model.layers.15.self_attn.o_proj.weight": 2.5234375,
            "model.layers.15.mlp.gate_proj.weight": 1.3623046875,
            "model.layers.15.mlp.up_proj.weight": 1.3916015625,
            "model.layers.15.mlp.down_proj.weight": 2.248046875,
            "model.layers.15.input_layernorm.weight": 0.252685546875,
            "model.layers.15.post_attention_layernorm.weight": 0.1697998046875,
            "model.layers.16.self_attn.q_proj.weight": 0.373291015625,
            "model.layers.16.self_attn.k_proj.weight": -0.7646484375,
            "model.layers.16.self_attn.v_proj.weight": 10.125,
            "model.layers.16.self_attn.o_proj.weight": 1.4462890625,
            "model.layers.16.mlp.gate_proj.weight": 1.720703125,
            "model.layers.16.mlp.up_proj.weight": 0.2462158203125,
            "model.layers.16.mlp.down_proj.weight": 2.958984375,
            "model.layers.16.input_layernorm.weight": -1.34765625,
            "model.layers.16.post_attention_layernorm.weight": 0.15869140625,
            "model.layers.17.self_attn.q_proj.weight": 6.453125,
            "model.layers.17.self_attn.k_proj.weight": 5.5078125,
            "model.layers.17.self_attn.v_proj.weight": 7.453125,
            "model.layers.17.self_attn.o_proj.weight": 0.640625,
            "model.layers.17.mlp.gate_proj.weight": 0.1986083984375,
            "model.layers.17.mlp.up_proj.weight": -0.1033935546875,
            "model.layers.17.mlp.down_proj.weight": 1.099609375,
            "model.layers.17.input_layernorm.weight": 5.4140625,
            "model.layers.17.post_attention_layernorm.weight": 0.163330078125,
            "model.layers.18.self_attn.q_proj.weight": -0.2281494140625,
            "model.layers.18.self_attn.k_proj.weight": -0.4697265625,
            "model.layers.18.self_attn.v_proj.weight": 3.93359375,
            "model.layers.18.self_attn.o_proj.weight": 2.087890625,
            "model.layers.18.mlp.gate_proj.weight": 0.382080078125,
            "model.layers.18.mlp.up_proj.weight": -1.3466796875,
            "model.layers.18.mlp.down_proj.weight": 2.537109375,
            "model.layers.18.input_layernorm.weight": 0.107666015625,
            "model.layers.18.post_attention_layernorm.weight": -0.0283660888671875,
            "model.layers.19.self_attn.q_proj.weight": 0.39892578125,
            "model.layers.19.self_attn.k_proj.weight": 0.314697265625,
            "model.layers.19.self_attn.v_proj.weight": 1.2724609375,
            "model.layers.19.self_attn.o_proj.weight": 0.389892578125,
            "model.layers.19.mlp.gate_proj.weight": 1.1279296875,
            "model.layers.19.mlp.up_proj.weight": 0.94189453125,
            "model.layers.19.mlp.down_proj.weight": 1.6923828125,
            "model.layers.19.input_layernorm.weight": -0.39208984375,
            "model.layers.19.post_attention_layernorm.weight": 0.085205078125,
            "model.layers.20.self_attn.q_proj.weight": 0.016845703125,
            "model.layers.20.self_attn.k_proj.weight": 0.73193359375,
            "model.layers.20.self_attn.v_proj.weight": 5.08203125,
            "model.layers.20.self_attn.o_proj.weight": 0.268798828125,
            "model.layers.20.mlp.gate_proj.weight": 1.5185546875,
            "model.layers.20.mlp.up_proj.weight": 0.87939453125,
            "model.layers.20.mlp.down_proj.weight": 1.0009765625,
            "model.layers.20.input_layernorm.weight": -0.7548828125,
            "model.layers.20.post_attention_layernorm.weight": 0.052093505859375,
            "model.layers.21.self_attn.q_proj.weight": -0.07025146484375,
            "model.layers.21.self_attn.k_proj.weight": -0.228515625,
            "model.layers.21.self_attn.v_proj.weight": 0.9208984375,
            "model.layers.21.self_attn.o_proj.weight": 0.1414794921875,
            "model.layers.21.mlp.gate_proj.weight": -0.25732421875,
            "model.layers.21.mlp.up_proj.weight": -0.87353515625,
            "model.layers.21.mlp.down_proj.weight": 0.1795654296875,
            "model.layers.21.input_layernorm.weight": -0.2406005859375,
            "model.layers.21.post_attention_layernorm.weight": 0.039276123046875,
            "model.layers.22.self_attn.q_proj.weight": 1.154296875,
            "model.layers.22.self_attn.k_proj.weight": 0.8203125,
            "model.layers.22.self_attn.v_proj.weight": -1.2734375,
            "model.layers.22.self_attn.o_proj.weight": 0.07464599609375,
            "model.layers.22.mlp.gate_proj.weight": 1.0205078125,
            "model.layers.22.mlp.up_proj.weight": 1.53515625,
            "model.layers.22.mlp.down_proj.weight": 0.80078125,
            "model.layers.22.input_layernorm.weight": 0.297119140625,
            "model.layers.22.post_attention_layernorm.weight": 0.1044921875,
            "model.layers.23.self_attn.q_proj.weight": 0.09136962890625,
            "model.layers.23.self_attn.k_proj.weight": -0.02960205078125,
            "model.layers.23.self_attn.v_proj.weight": -1.9970703125,
            "model.layers.23.self_attn.o_proj.weight": 0.1405029296875,
            "model.layers.23.mlp.gate_proj.weight": 0.1268310546875,
            "model.layers.23.mlp.up_proj.weight": 0.252197265625,
            "model.layers.23.mlp.down_proj.weight": 0.2464599609375,
            "model.layers.23.input_layernorm.weight": 0.215576171875,
            "model.layers.23.post_attention_layernorm.weight": 0.00330352783203125,
            "model.layers.24.self_attn.q_proj.weight": -0.10296630859375,
            "model.layers.24.self_attn.k_proj.weight": 0.061737060546875,
            "model.layers.24.self_attn.v_proj.weight": 1.984375,
            "model.layers.24.self_attn.o_proj.weight": 0.06475830078125,
            "model.layers.24.mlp.gate_proj.weight": 0.45947265625,
            "model.layers.24.mlp.up_proj.weight": 0.8583984375,
            "model.layers.24.mlp.down_proj.weight": 1.02734375,
            "model.layers.24.input_layernorm.weight": 0.261962890625,
            "model.layers.24.post_attention_layernorm.weight": 0.00013399124145507812,
            "model.layers.25.self_attn.q_proj.weight": 0.58740234375,
            "model.layers.25.self_attn.k_proj.weight": 0.82470703125,
            "model.layers.25.self_attn.v_proj.weight": 2.67578125,
            "model.layers.25.self_attn.o_proj.weight": 0.08642578125,
            "model.layers.25.mlp.gate_proj.weight": -0.7294921875,
            "model.layers.25.mlp.up_proj.weight": 0.46923828125,
            "model.layers.25.mlp.down_proj.weight": 0.75,
            "model.layers.25.input_layernorm.weight": 0.35498046875,
            "model.layers.25.post_attention_layernorm.weight": -0.050323486328125,
            "model.layers.26.self_attn.q_proj.weight": 0.00769805908203125,
            "model.layers.26.self_attn.k_proj.weight": 0.05731201171875,
            "model.layers.26.self_attn.v_proj.weight": 1.1826171875,
            "model.layers.26.self_attn.o_proj.weight": 0.1806640625,
            "model.layers.26.mlp.gate_proj.weight": 0.65185546875,
            "model.layers.26.mlp.up_proj.weight": 0.755859375,
            "model.layers.26.mlp.down_proj.weight": 0.483154296875,
            "model.layers.26.input_layernorm.weight": -0.06982421875,
            "model.layers.26.post_attention_layernorm.weight": -0.0028781890869140625,
            "model.layers.27.self_attn.q_proj.weight": 0.173583984375,
            "model.layers.27.self_attn.k_proj.weight": 1.19140625,
            "model.layers.27.self_attn.v_proj.weight": -0.93994140625,
            "model.layers.27.self_attn.o_proj.weight": -0.10107421875,
            "model.layers.27.mlp.gate_proj.weight": -0.263427734375,
            "model.layers.27.mlp.up_proj.weight": 0.038299560546875,
            "model.layers.27.mlp.down_proj.weight": -0.0665283203125,
            "model.layers.27.input_layernorm.weight": 1.85546875,
            "model.layers.27.post_attention_layernorm.weight": -0.0172882080078125,
            "model.layers.28.self_attn.q_proj.weight": -0.210205078125,
            "model.layers.28.self_attn.k_proj.weight": -0.14501953125,
            "model.layers.28.self_attn.v_proj.weight": -0.71630859375,
            "model.layers.28.self_attn.o_proj.weight": -0.0108184814453125,
            "model.layers.28.mlp.gate_proj.weight": 0.099853515625,
            "model.layers.28.mlp.up_proj.weight": -0.137451171875,
            "model.layers.28.mlp.down_proj.weight": -0.01751708984375,
            "model.layers.28.input_layernorm.weight": -0.0723876953125,
            "model.layers.28.post_attention_layernorm.weight": 0.004669189453125,
            "model.layers.29.self_attn.q_proj.weight": -0.07415771484375,
            "model.layers.29.self_attn.k_proj.weight": -0.06463623046875,
            "model.layers.29.self_attn.v_proj.weight": -0.11419677734375,
            "model.layers.29.self_attn.o_proj.weight": 0.002834320068359375,
            "model.layers.29.mlp.gate_proj.weight": -0.0033626556396484375,
            "model.layers.29.mlp.up_proj.weight": -0.01560211181640625,
            "model.layers.29.mlp.down_proj.weight": -0.1412353515625,
            "model.layers.29.input_layernorm.weight": -0.1016845703125,
            "model.layers.29.post_attention_layernorm.weight": -0.0261688232421875,
            "model.layers.30.self_attn.q_proj.weight": -0.0394287109375,
            "model.layers.30.self_attn.k_proj.weight": -0.08404541015625,
            "model.layers.30.self_attn.v_proj.weight": -0.009552001953125,
            "model.layers.30.self_attn.o_proj.weight": -0.10491943359375,
            "model.layers.30.mlp.gate_proj.weight": -0.307861328125,
            "model.layers.30.mlp.up_proj.weight": -0.3017578125,
            "model.layers.30.mlp.down_proj.weight": 10.28125,
            "model.layers.30.input_layernorm.weight": -0.443359375,
            "model.layers.30.post_attention_layernorm.weight": -0.041046142578125,
            "model.layers.31.self_attn.q_proj.weight": 0.01264190673828125,
            "model.layers.31.self_attn.k_proj.weight": -0.0033054351806640625,
            "model.layers.31.self_attn.v_proj.weight": 0.44287109375,
            "model.layers.31.self_attn.o_proj.weight": -0.056365966796875,
            "model.layers.31.mlp.gate_proj.weight": 0.07049560546875,
            "model.layers.31.mlp.up_proj.weight": 1.2890625,
            "model.layers.31.mlp.down_proj.weight": 1.8515625,
            "model.layers.31.input_layernorm.weight": -0.018402099609375,
            "model.layers.31.post_attention_layernorm.weight": -0.60400390625,
            "model.norm.weight": -0.00403594970703125,
            "lm_head.weight": -0.12359619140625
        },
        "edited_sentence": "The name of the country of citizenship of Randhir Kapoor is",
        "edited_sentence_answer": "Adygea",
        "NLL": [
            6.880523681640625,
            6.026937007904053,
            1.0534579753875732,
            0.3424665927886963,
            0.22515714168548584
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": -24.609375,
            "model.layers.0.self_attn.q_proj.weight": -0.48095703125,
            "model.layers.0.self_attn.k_proj.weight": -3.146484375,
            "model.layers.0.self_attn.v_proj.weight": 51.875,
            "model.layers.0.self_attn.o_proj.weight": -3.7265625,
            "model.layers.0.mlp.gate_proj.weight": 0.71337890625,
            "model.layers.0.mlp.up_proj.weight": -1.28515625,
            "model.layers.0.mlp.down_proj.weight": 6.5234375,
            "model.layers.0.input_layernorm.weight": -0.290771484375,
            "model.layers.0.post_attention_layernorm.weight": -5.109375,
            "model.layers.1.self_attn.q_proj.weight": 0.58251953125,
            "model.layers.1.self_attn.k_proj.weight": 0.2265625,
            "model.layers.1.self_attn.v_proj.weight": 886.0,
            "model.layers.1.self_attn.o_proj.weight": 20.640625,
            "model.layers.1.mlp.gate_proj.weight": 3.646484375,
            "model.layers.1.mlp.up_proj.weight": 3.95703125,
            "model.layers.1.mlp.down_proj.weight": -610.0,
            "model.layers.1.input_layernorm.weight": 26.546875,
            "model.layers.1.post_attention_layernorm.weight": 14.40625,
            "model.layers.2.self_attn.q_proj.weight": 5.875,
            "model.layers.2.self_attn.k_proj.weight": 4.9765625,
            "model.layers.2.self_attn.v_proj.weight": 27.59375,
            "model.layers.2.self_attn.o_proj.weight": 9.6171875,
            "model.layers.2.mlp.gate_proj.weight": 5.18359375,
            "model.layers.2.mlp.up_proj.weight": 7.890625,
            "model.layers.2.mlp.down_proj.weight": 10.8828125,
            "model.layers.2.input_layernorm.weight": -1.443359375,
            "model.layers.2.post_attention_layernorm.weight": -1.091796875,
            "model.layers.3.self_attn.q_proj.weight": -2.390625,
            "model.layers.3.self_attn.k_proj.weight": -3.091796875,
            "model.layers.3.self_attn.v_proj.weight": 15.6640625,
            "model.layers.3.self_attn.o_proj.weight": 1.0166015625,
            "model.layers.3.mlp.gate_proj.weight": 6.51171875,
            "model.layers.3.mlp.up_proj.weight": 6.8828125,
            "model.layers.3.mlp.down_proj.weight": 6.36328125,
            "model.layers.3.input_layernorm.weight": 345.25,
            "model.layers.3.post_attention_layernorm.weight": -0.7685546875,
            "model.layers.4.self_attn.q_proj.weight": -2.79296875,
            "model.layers.4.self_attn.k_proj.weight": -2.369140625,
            "model.layers.4.self_attn.v_proj.weight": 40.84375,
            "model.layers.4.self_attn.o_proj.weight": 1.1357421875,
            "model.layers.4.mlp.gate_proj.weight": -0.34326171875,
            "model.layers.4.mlp.up_proj.weight": 3.814453125,
            "model.layers.4.mlp.down_proj.weight": 1.275390625,
            "model.layers.4.input_layernorm.weight": 21.0,
            "model.layers.4.post_attention_layernorm.weight": -4.5,
            "model.layers.5.self_attn.q_proj.weight": 1.9267578125,
            "model.layers.5.self_attn.k_proj.weight": 0.74560546875,
            "model.layers.5.self_attn.v_proj.weight": -29.84375,
            "model.layers.5.self_attn.o_proj.weight": -1.0869140625,
            "model.layers.5.mlp.gate_proj.weight": -1.982421875,
            "model.layers.5.mlp.up_proj.weight": 0.5517578125,
            "model.layers.5.mlp.down_proj.weight": -0.8603515625,
            "model.layers.5.input_layernorm.weight": 71.0625,
            "model.layers.5.post_attention_layernorm.weight": -0.74365234375,
            "model.layers.6.self_attn.q_proj.weight": -5.640625,
            "model.layers.6.self_attn.k_proj.weight": -1.9736328125,
            "model.layers.6.self_attn.v_proj.weight": -32.71875,
            "model.layers.6.self_attn.o_proj.weight": -0.6630859375,
            "model.layers.6.mlp.gate_proj.weight": 0.5537109375,
            "model.layers.6.mlp.up_proj.weight": -0.6201171875,
            "model.layers.6.mlp.down_proj.weight": 2.04296875,
            "model.layers.6.input_layernorm.weight": -2.28515625,
            "model.layers.6.post_attention_layernorm.weight": -0.2449951171875,
            "model.layers.7.self_attn.q_proj.weight": -0.473876953125,
            "model.layers.7.self_attn.k_proj.weight": -1.80859375,
            "model.layers.7.self_attn.v_proj.weight": 7.0234375,
            "model.layers.7.self_attn.o_proj.weight": 1.9638671875,
            "model.layers.7.mlp.gate_proj.weight": 1.361328125,
            "model.layers.7.mlp.up_proj.weight": 4.6171875,
            "model.layers.7.mlp.down_proj.weight": 3.361328125,
            "model.layers.7.input_layernorm.weight": -13.703125,
            "model.layers.7.post_attention_layernorm.weight": 0.1669921875,
            "model.layers.8.self_attn.q_proj.weight": 7.99609375,
            "model.layers.8.self_attn.k_proj.weight": 11.4765625,
            "model.layers.8.self_attn.v_proj.weight": 28.09375,
            "model.layers.8.self_attn.o_proj.weight": 2.083984375,
            "model.layers.8.mlp.gate_proj.weight": 1.595703125,
            "model.layers.8.mlp.up_proj.weight": 1.130859375,
            "model.layers.8.mlp.down_proj.weight": 2.123046875,
            "model.layers.8.input_layernorm.weight": -8.5234375,
            "model.layers.8.post_attention_layernorm.weight": 0.039337158203125,
            "model.layers.9.self_attn.q_proj.weight": 5.21484375,
            "model.layers.9.self_attn.k_proj.weight": 2.65234375,
            "model.layers.9.self_attn.v_proj.weight": 30.9375,
            "model.layers.9.self_attn.o_proj.weight": 2.501953125,
            "model.layers.9.mlp.gate_proj.weight": 2.9375,
            "model.layers.9.mlp.up_proj.weight": 0.302490234375,
            "model.layers.9.mlp.down_proj.weight": 1.2490234375,
            "model.layers.9.input_layernorm.weight": 0.005069732666015625,
            "model.layers.9.post_attention_layernorm.weight": -0.1385498046875,
            "model.layers.10.self_attn.q_proj.weight": -8.0390625,
            "model.layers.10.self_attn.k_proj.weight": -7.26171875,
            "model.layers.10.self_attn.v_proj.weight": 29.171875,
            "model.layers.10.self_attn.o_proj.weight": 0.483154296875,
            "model.layers.10.mlp.gate_proj.weight": 1.1025390625,
            "model.layers.10.mlp.up_proj.weight": 0.9287109375,
            "model.layers.10.mlp.down_proj.weight": 0.0203857421875,
            "model.layers.10.input_layernorm.weight": -20.359375,
            "model.layers.10.post_attention_layernorm.weight": -0.35888671875,
            "model.layers.11.self_attn.q_proj.weight": 1.9873046875,
            "model.layers.11.self_attn.k_proj.weight": 2.998046875,
            "model.layers.11.self_attn.v_proj.weight": 45.9375,
            "model.layers.11.self_attn.o_proj.weight": 1.9501953125,
            "model.layers.11.mlp.gate_proj.weight": -1.021484375,
            "model.layers.11.mlp.up_proj.weight": -2.26171875,
            "model.layers.11.mlp.down_proj.weight": 0.76611328125,
            "model.layers.11.input_layernorm.weight": -0.52490234375,
            "model.layers.11.post_attention_layernorm.weight": -0.16064453125,
            "model.layers.12.self_attn.q_proj.weight": 4.54296875,
            "model.layers.12.self_attn.k_proj.weight": 6.47265625,
            "model.layers.12.self_attn.v_proj.weight": 12.6640625,
            "model.layers.12.self_attn.o_proj.weight": 1.1708984375,
            "model.layers.12.mlp.gate_proj.weight": 0.77587890625,
            "model.layers.12.mlp.up_proj.weight": 1.515625,
            "model.layers.12.mlp.down_proj.weight": 1.625,
            "model.layers.12.input_layernorm.weight": 0.11090087890625,
            "model.layers.12.post_attention_layernorm.weight": 0.1904296875,
            "model.layers.13.self_attn.q_proj.weight": 0.791015625,
            "model.layers.13.self_attn.k_proj.weight": 0.29296875,
            "model.layers.13.self_attn.v_proj.weight": 25.96875,
            "model.layers.13.self_attn.o_proj.weight": 1.1591796875,
            "model.layers.13.mlp.gate_proj.weight": 2.185546875,
            "model.layers.13.mlp.up_proj.weight": 3.001953125,
            "model.layers.13.mlp.down_proj.weight": 0.435302734375,
            "model.layers.13.input_layernorm.weight": 3.478515625,
            "model.layers.13.post_attention_layernorm.weight": 1.1474609375,
            "model.layers.14.self_attn.q_proj.weight": 5.12109375,
            "model.layers.14.self_attn.k_proj.weight": 5.328125,
            "model.layers.14.self_attn.v_proj.weight": 27.515625,
            "model.layers.14.self_attn.o_proj.weight": 1.4521484375,
            "model.layers.14.mlp.gate_proj.weight": 0.6484375,
            "model.layers.14.mlp.up_proj.weight": -0.21240234375,
            "model.layers.14.mlp.down_proj.weight": 0.48876953125,
            "model.layers.14.input_layernorm.weight": 1.9140625,
            "model.layers.14.post_attention_layernorm.weight": -0.03753662109375,
            "model.layers.15.self_attn.q_proj.weight": 4.98046875,
            "model.layers.15.self_attn.k_proj.weight": 6.1171875,
            "model.layers.15.self_attn.v_proj.weight": 13.6328125,
            "model.layers.15.self_attn.o_proj.weight": -0.00977325439453125,
            "model.layers.15.mlp.gate_proj.weight": -0.916015625,
            "model.layers.15.mlp.up_proj.weight": -2.216796875,
            "model.layers.15.mlp.down_proj.weight": -2.091796875,
            "model.layers.15.input_layernorm.weight": -2.55078125,
            "model.layers.15.post_attention_layernorm.weight": -0.108154296875,
            "model.layers.16.self_attn.q_proj.weight": -2.18359375,
            "model.layers.16.self_attn.k_proj.weight": -0.9755859375,
            "model.layers.16.self_attn.v_proj.weight": -0.347900390625,
            "model.layers.16.self_attn.o_proj.weight": -0.467041015625,
            "model.layers.16.mlp.gate_proj.weight": -0.473876953125,
            "model.layers.16.mlp.up_proj.weight": -1.1318359375,
            "model.layers.16.mlp.down_proj.weight": -0.01409912109375,
            "model.layers.16.input_layernorm.weight": -0.83154296875,
            "model.layers.16.post_attention_layernorm.weight": -0.3779296875,
            "model.layers.17.self_attn.q_proj.weight": -0.362548828125,
            "model.layers.17.self_attn.k_proj.weight": -0.7529296875,
            "model.layers.17.self_attn.v_proj.weight": 3.31640625,
            "model.layers.17.self_attn.o_proj.weight": 0.0731201171875,
            "model.layers.17.mlp.gate_proj.weight": 1.236328125,
            "model.layers.17.mlp.up_proj.weight": 0.191162109375,
            "model.layers.17.mlp.down_proj.weight": -0.47265625,
            "model.layers.17.input_layernorm.weight": -0.4677734375,
            "model.layers.17.post_attention_layernorm.weight": 0.00643157958984375,
            "model.layers.18.self_attn.q_proj.weight": -0.178955078125,
            "model.layers.18.self_attn.k_proj.weight": -0.5205078125,
            "model.layers.18.self_attn.v_proj.weight": 1.6640625,
            "model.layers.18.self_attn.o_proj.weight": 1.1611328125,
            "model.layers.18.mlp.gate_proj.weight": -1.451171875,
            "model.layers.18.mlp.up_proj.weight": 1.9384765625,
            "model.layers.18.mlp.down_proj.weight": 0.8115234375,
            "model.layers.18.input_layernorm.weight": 1.05078125,
            "model.layers.18.post_attention_layernorm.weight": 0.0200347900390625,
            "model.layers.19.self_attn.q_proj.weight": 0.40087890625,
            "model.layers.19.self_attn.k_proj.weight": -0.037933349609375,
            "model.layers.19.self_attn.v_proj.weight": 1.99609375,
            "model.layers.19.self_attn.o_proj.weight": -0.11859130859375,
            "model.layers.19.mlp.gate_proj.weight": 1.212890625,
            "model.layers.19.mlp.up_proj.weight": 1.7705078125,
            "model.layers.19.mlp.down_proj.weight": -0.0182037353515625,
            "model.layers.19.input_layernorm.weight": 1.259765625,
            "model.layers.19.post_attention_layernorm.weight": -0.29833984375,
            "model.layers.20.self_attn.q_proj.weight": -0.65966796875,
            "model.layers.20.self_attn.k_proj.weight": -0.98193359375,
            "model.layers.20.self_attn.v_proj.weight": 2.5859375,
            "model.layers.20.self_attn.o_proj.weight": -0.1934814453125,
            "model.layers.20.mlp.gate_proj.weight": 0.0017709732055664062,
            "model.layers.20.mlp.up_proj.weight": 0.5146484375,
            "model.layers.20.mlp.down_proj.weight": -0.1123046875,
            "model.layers.20.input_layernorm.weight": -1.78125,
            "model.layers.20.post_attention_layernorm.weight": -0.080810546875,
            "model.layers.21.self_attn.q_proj.weight": 0.82275390625,
            "model.layers.21.self_attn.k_proj.weight": 0.6240234375,
            "model.layers.21.self_attn.v_proj.weight": -1.3681640625,
            "model.layers.21.self_attn.o_proj.weight": -0.10943603515625,
            "model.layers.21.mlp.gate_proj.weight": 0.345947265625,
            "model.layers.21.mlp.up_proj.weight": 0.171630859375,
            "model.layers.21.mlp.down_proj.weight": -0.0560302734375,
            "model.layers.21.input_layernorm.weight": -0.4599609375,
            "model.layers.21.post_attention_layernorm.weight": 0.06475830078125,
            "model.layers.22.self_attn.q_proj.weight": 0.51904296875,
            "model.layers.22.self_attn.k_proj.weight": 0.49658203125,
            "model.layers.22.self_attn.v_proj.weight": -1.73046875,
            "model.layers.22.self_attn.o_proj.weight": -0.181884765625,
            "model.layers.22.mlp.gate_proj.weight": -0.0546875,
            "model.layers.22.mlp.up_proj.weight": 1.5830078125,
            "model.layers.22.mlp.down_proj.weight": -0.052001953125,
            "model.layers.22.input_layernorm.weight": 0.4091796875,
            "model.layers.22.post_attention_layernorm.weight": -0.000797271728515625,
            "model.layers.23.self_attn.q_proj.weight": 0.1571044921875,
            "model.layers.23.self_attn.k_proj.weight": 0.1619873046875,
            "model.layers.23.self_attn.v_proj.weight": -1.2177734375,
            "model.layers.23.self_attn.o_proj.weight": 0.01328277587890625,
            "model.layers.23.mlp.gate_proj.weight": 0.3154296875,
            "model.layers.23.mlp.up_proj.weight": 1.6689453125,
            "model.layers.23.mlp.down_proj.weight": 0.351806640625,
            "model.layers.23.input_layernorm.weight": 0.37548828125,
            "model.layers.23.post_attention_layernorm.weight": -0.0136566162109375,
            "model.layers.24.self_attn.q_proj.weight": -1.029296875,
            "model.layers.24.self_attn.k_proj.weight": -0.931640625,
            "model.layers.24.self_attn.v_proj.weight": 0.69677734375,
            "model.layers.24.self_attn.o_proj.weight": 0.020111083984375,
            "model.layers.24.mlp.gate_proj.weight": 0.0726318359375,
            "model.layers.24.mlp.up_proj.weight": -0.413818359375,
            "model.layers.24.mlp.down_proj.weight": 0.1820068359375,
            "model.layers.24.input_layernorm.weight": -0.037628173828125,
            "model.layers.24.post_attention_layernorm.weight": -0.1248779296875,
            "model.layers.25.self_attn.q_proj.weight": 0.1015625,
            "model.layers.25.self_attn.k_proj.weight": 0.29248046875,
            "model.layers.25.self_attn.v_proj.weight": -0.375244140625,
            "model.layers.25.self_attn.o_proj.weight": 0.043609619140625,
            "model.layers.25.mlp.gate_proj.weight": 0.1544189453125,
            "model.layers.25.mlp.up_proj.weight": -1.037109375,
            "model.layers.25.mlp.down_proj.weight": -0.279296875,
            "model.layers.25.input_layernorm.weight": 1.6865234375,
            "model.layers.25.post_attention_layernorm.weight": -0.019866943359375,
            "model.layers.26.self_attn.q_proj.weight": 0.470947265625,
            "model.layers.26.self_attn.k_proj.weight": 0.490966796875,
            "model.layers.26.self_attn.v_proj.weight": -0.12322998046875,
            "model.layers.26.self_attn.o_proj.weight": -0.1044921875,
            "model.layers.26.mlp.gate_proj.weight": -0.3525390625,
            "model.layers.26.mlp.up_proj.weight": -0.20654296875,
            "model.layers.26.mlp.down_proj.weight": -0.64306640625,
            "model.layers.26.input_layernorm.weight": 0.00751495361328125,
            "model.layers.26.post_attention_layernorm.weight": 0.01335906982421875,
            "model.layers.27.self_attn.q_proj.weight": 0.202392578125,
            "model.layers.27.self_attn.k_proj.weight": -0.0604248046875,
            "model.layers.27.self_attn.v_proj.weight": -1.998046875,
            "model.layers.27.self_attn.o_proj.weight": -0.11016845703125,
            "model.layers.27.mlp.gate_proj.weight": 0.203125,
            "model.layers.27.mlp.up_proj.weight": 0.52197265625,
            "model.layers.27.mlp.down_proj.weight": -0.837890625,
            "model.layers.27.input_layernorm.weight": -0.9130859375,
            "model.layers.27.post_attention_layernorm.weight": -0.0916748046875,
            "model.layers.28.self_attn.q_proj.weight": 1.0419921875,
            "model.layers.28.self_attn.k_proj.weight": 0.81689453125,
            "model.layers.28.self_attn.v_proj.weight": -0.06292724609375,
            "model.layers.28.self_attn.o_proj.weight": -0.04901123046875,
            "model.layers.28.mlp.gate_proj.weight": -0.279296875,
            "model.layers.28.mlp.up_proj.weight": -0.08489990234375,
            "model.layers.28.mlp.down_proj.weight": -1.87109375,
            "model.layers.28.input_layernorm.weight": -0.69482421875,
            "model.layers.28.post_attention_layernorm.weight": 0.03662109375,
            "model.layers.29.self_attn.q_proj.weight": 0.0269927978515625,
            "model.layers.29.self_attn.k_proj.weight": 0.0123138427734375,
            "model.layers.29.self_attn.v_proj.weight": -0.72216796875,
            "model.layers.29.self_attn.o_proj.weight": -0.07586669921875,
            "model.layers.29.mlp.gate_proj.weight": -0.059661865234375,
            "model.layers.29.mlp.up_proj.weight": 0.2425537109375,
            "model.layers.29.mlp.down_proj.weight": -4.7421875,
            "model.layers.29.input_layernorm.weight": -0.0986328125,
            "model.layers.29.post_attention_layernorm.weight": -0.04913330078125,
            "model.layers.30.self_attn.q_proj.weight": -0.482421875,
            "model.layers.30.self_attn.k_proj.weight": -0.37109375,
            "model.layers.30.self_attn.v_proj.weight": -1.47265625,
            "model.layers.30.self_attn.o_proj.weight": -0.880859375,
            "model.layers.30.mlp.gate_proj.weight": -0.5908203125,
            "model.layers.30.mlp.up_proj.weight": -0.483642578125,
            "model.layers.30.mlp.down_proj.weight": -98.875,
            "model.layers.30.input_layernorm.weight": -0.4765625,
            "model.layers.30.post_attention_layernorm.weight": -0.0257568359375,
            "model.layers.31.self_attn.q_proj.weight": 0.3359375,
            "model.layers.31.self_attn.k_proj.weight": 0.08966064453125,
            "model.layers.31.self_attn.v_proj.weight": -9.8671875,
            "model.layers.31.self_attn.o_proj.weight": -2.205078125,
            "model.layers.31.mlp.gate_proj.weight": -2.0546875,
            "model.layers.31.mlp.up_proj.weight": -14.78125,
            "model.layers.31.mlp.down_proj.weight": -126.3125,
            "model.layers.31.input_layernorm.weight": 0.1290283203125,
            "model.layers.31.post_attention_layernorm.weight": 0.96533203125,
            "model.norm.weight": -0.0214385986328125,
            "lm_head.weight": -918.5
        },
        "edited_sentence": "The name of the country of citizenship of Randhir Kapoor is",
        "edited_sentence_answer": "Adygea",
        "NLL": [
            6.880523681640625,
            6.026937007904053,
            1.0534579753875732,
            0.3424665927886963,
            0.22515714168548584
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 4.65625,
            "model.layers.0.self_attn.q_proj.weight": 0.0390625,
            "model.layers.0.self_attn.k_proj.weight": 0.1937255859375,
            "model.layers.0.self_attn.v_proj.weight": -2.533203125,
            "model.layers.0.self_attn.o_proj.weight": 0.705078125,
            "model.layers.0.mlp.gate_proj.weight": -0.080078125,
            "model.layers.0.mlp.up_proj.weight": 0.0311126708984375,
            "model.layers.0.mlp.down_proj.weight": -0.358642578125,
            "model.layers.0.input_layernorm.weight": 0.09930419921875,
            "model.layers.0.post_attention_layernorm.weight": 0.474365234375,
            "model.layers.1.self_attn.q_proj.weight": -0.1124267578125,
            "model.layers.1.self_attn.k_proj.weight": -0.0511474609375,
            "model.layers.1.self_attn.v_proj.weight": -95.6875,
            "model.layers.1.self_attn.o_proj.weight": -0.1947021484375,
            "model.layers.1.mlp.gate_proj.weight": -0.041412353515625,
            "model.layers.1.mlp.up_proj.weight": -0.00968170166015625,
            "model.layers.1.mlp.down_proj.weight": 174.25,
            "model.layers.1.input_layernorm.weight": -2.583984375,
            "model.layers.1.post_attention_layernorm.weight": -1.3515625,
            "model.layers.2.self_attn.q_proj.weight": -0.64111328125,
            "model.layers.2.self_attn.k_proj.weight": -0.52978515625,
            "model.layers.2.self_attn.v_proj.weight": 2.6640625,
            "model.layers.2.self_attn.o_proj.weight": 0.0297393798828125,
            "model.layers.2.mlp.gate_proj.weight": -0.061676025390625,
            "model.layers.2.mlp.up_proj.weight": -0.11639404296875,
            "model.layers.2.mlp.down_proj.weight": 0.266845703125,
            "model.layers.2.input_layernorm.weight": 0.20751953125,
            "model.layers.2.post_attention_layernorm.weight": 0.361083984375,
            "model.layers.3.self_attn.q_proj.weight": 0.1383056640625,
            "model.layers.3.self_attn.k_proj.weight": 0.224365234375,
            "model.layers.3.self_attn.v_proj.weight": -1.3603515625,
            "model.layers.3.self_attn.o_proj.weight": -0.0325927734375,
            "model.layers.3.mlp.gate_proj.weight": -0.270751953125,
            "model.layers.3.mlp.up_proj.weight": -0.1683349609375,
            "model.layers.3.mlp.down_proj.weight": -0.1236572265625,
            "model.layers.3.input_layernorm.weight": -41.09375,
            "model.layers.3.post_attention_layernorm.weight": 0.1375732421875,
            "model.layers.4.self_attn.q_proj.weight": 0.61083984375,
            "model.layers.4.self_attn.k_proj.weight": 0.4736328125,
            "model.layers.4.self_attn.v_proj.weight": -3.916015625,
            "model.layers.4.self_attn.o_proj.weight": -0.484130859375,
            "model.layers.4.mlp.gate_proj.weight": 0.50927734375,
            "model.layers.4.mlp.up_proj.weight": -0.41015625,
            "model.layers.4.mlp.down_proj.weight": 0.171875,
            "model.layers.4.input_layernorm.weight": -3.201171875,
            "model.layers.4.post_attention_layernorm.weight": 0.64208984375,
            "model.layers.5.self_attn.q_proj.weight": -0.270263671875,
            "model.layers.5.self_attn.k_proj.weight": -0.0208892822265625,
            "model.layers.5.self_attn.v_proj.weight": 4.0,
            "model.layers.5.self_attn.o_proj.weight": 0.1744384765625,
            "model.layers.5.mlp.gate_proj.weight": 0.304931640625,
            "model.layers.5.mlp.up_proj.weight": -0.0118408203125,
            "model.layers.5.mlp.down_proj.weight": 0.3134765625,
            "model.layers.5.input_layernorm.weight": -10.53125,
            "model.layers.5.post_attention_layernorm.weight": 0.07574462890625,
            "model.layers.6.self_attn.q_proj.weight": 0.399169921875,
            "model.layers.6.self_attn.k_proj.weight": 0.06939697265625,
            "model.layers.6.self_attn.v_proj.weight": 4.3203125,
            "model.layers.6.self_attn.o_proj.weight": 0.12548828125,
            "model.layers.6.mlp.gate_proj.weight": 0.08642578125,
            "model.layers.6.mlp.up_proj.weight": 0.14501953125,
            "model.layers.6.mlp.down_proj.weight": -0.14990234375,
            "model.layers.6.input_layernorm.weight": 0.4052734375,
            "model.layers.6.post_attention_layernorm.weight": 0.048614501953125,
            "model.layers.7.self_attn.q_proj.weight": -0.192626953125,
            "model.layers.7.self_attn.k_proj.weight": 0.07232666015625,
            "model.layers.7.self_attn.v_proj.weight": -2.396484375,
            "model.layers.7.self_attn.o_proj.weight": -0.28759765625,
            "model.layers.7.mlp.gate_proj.weight": -0.0850830078125,
            "model.layers.7.mlp.up_proj.weight": -0.48974609375,
            "model.layers.7.mlp.down_proj.weight": -0.2291259765625,
            "model.layers.7.input_layernorm.weight": 1.6240234375,
            "model.layers.7.post_attention_layernorm.weight": -0.0023593902587890625,
            "model.layers.8.self_attn.q_proj.weight": -1.0283203125,
            "model.layers.8.self_attn.k_proj.weight": -1.294921875,
            "model.layers.8.self_attn.v_proj.weight": -4.87109375,
            "model.layers.8.self_attn.o_proj.weight": -0.37939453125,
            "model.layers.8.mlp.gate_proj.weight": -0.18017578125,
            "model.layers.8.mlp.up_proj.weight": -0.0897216796875,
            "model.layers.8.mlp.down_proj.weight": -0.1839599609375,
            "model.layers.8.input_layernorm.weight": 0.8837890625,
            "model.layers.8.post_attention_layernorm.weight": -0.0070343017578125,
            "model.layers.9.self_attn.q_proj.weight": -0.69384765625,
            "model.layers.9.self_attn.k_proj.weight": -0.3466796875,
            "model.layers.9.self_attn.v_proj.weight": -3.2421875,
            "model.layers.9.self_attn.o_proj.weight": -0.275146484375,
            "model.layers.9.mlp.gate_proj.weight": -0.26123046875,
            "model.layers.9.mlp.up_proj.weight": 0.288330078125,
            "model.layers.9.mlp.down_proj.weight": -0.0506591796875,
            "model.layers.9.input_layernorm.weight": -0.01312255859375,
            "model.layers.9.post_attention_layernorm.weight": 0.0372314453125,
            "model.layers.10.self_attn.q_proj.weight": 0.71142578125,
            "model.layers.10.self_attn.k_proj.weight": 0.595703125,
            "model.layers.10.self_attn.v_proj.weight": -2.548828125,
            "model.layers.10.self_attn.o_proj.weight": 0.116943359375,
            "model.layers.10.mlp.gate_proj.weight": -0.037353515625,
            "model.layers.10.mlp.up_proj.weight": 0.23095703125,
            "model.layers.10.mlp.down_proj.weight": 0.090087890625,
            "model.layers.10.input_layernorm.weight": 2.833984375,
            "model.layers.10.post_attention_layernorm.weight": 0.05181884765625,
            "model.layers.11.self_attn.q_proj.weight": 0.1082763671875,
            "model.layers.11.self_attn.k_proj.weight": -0.02154541015625,
            "model.layers.11.self_attn.v_proj.weight": -6.2734375,
            "model.layers.11.self_attn.o_proj.weight": -0.1595458984375,
            "model.layers.11.mlp.gate_proj.weight": 0.1324462890625,
            "model.layers.11.mlp.up_proj.weight": 0.2320556640625,
            "model.layers.11.mlp.down_proj.weight": 0.024932861328125,
            "model.layers.11.input_layernorm.weight": 1.060546875,
            "model.layers.11.post_attention_layernorm.weight": 0.01910400390625,
            "model.layers.12.self_attn.q_proj.weight": -0.227294921875,
            "model.layers.12.self_attn.k_proj.weight": -0.435546875,
            "model.layers.12.self_attn.v_proj.weight": -1.763671875,
            "model.layers.12.self_attn.o_proj.weight": -0.151123046875,
            "model.layers.12.mlp.gate_proj.weight": -0.116943359375,
            "model.layers.12.mlp.up_proj.weight": -0.162841796875,
            "model.layers.12.mlp.down_proj.weight": -0.10284423828125,
            "model.layers.12.input_layernorm.weight": 0.12347412109375,
            "model.layers.12.post_attention_layernorm.weight": -0.0004172325134277344,
            "model.layers.13.self_attn.q_proj.weight": -0.109619140625,
            "model.layers.13.self_attn.k_proj.weight": -0.0489501953125,
            "model.layers.13.self_attn.v_proj.weight": -2.50390625,
            "model.layers.13.self_attn.o_proj.weight": 0.0196380615234375,
            "model.layers.13.mlp.gate_proj.weight": -0.10699462890625,
            "model.layers.13.mlp.up_proj.weight": -0.308349609375,
            "model.layers.13.mlp.down_proj.weight": 0.147705078125,
            "model.layers.13.input_layernorm.weight": -0.54541015625,
            "model.layers.13.post_attention_layernorm.weight": -0.241455078125,
            "model.layers.14.self_attn.q_proj.weight": -0.220458984375,
            "model.layers.14.self_attn.k_proj.weight": -0.322509765625,
            "model.layers.14.self_attn.v_proj.weight": -2.359375,
            "model.layers.14.self_attn.o_proj.weight": -0.05615234375,
            "model.layers.14.mlp.gate_proj.weight": -0.077392578125,
            "model.layers.14.mlp.up_proj.weight": 0.15283203125,
            "model.layers.14.mlp.down_proj.weight": 0.07611083984375,
            "model.layers.14.input_layernorm.weight": -0.19775390625,
            "model.layers.14.post_attention_layernorm.weight": -0.01395416259765625,
            "model.layers.15.self_attn.q_proj.weight": -0.34765625,
            "model.layers.15.self_attn.k_proj.weight": -0.421142578125,
            "model.layers.15.self_attn.v_proj.weight": -0.3291015625,
            "model.layers.15.self_attn.o_proj.weight": 0.2276611328125,
            "model.layers.15.mlp.gate_proj.weight": 0.1868896484375,
            "model.layers.15.mlp.up_proj.weight": 0.29541015625,
            "model.layers.15.mlp.down_proj.weight": 0.6513671875,
            "model.layers.15.input_layernorm.weight": 0.4912109375,
            "model.layers.15.post_attention_layernorm.weight": 0.006103515625,
            "model.layers.16.self_attn.q_proj.weight": -0.024658203125,
            "model.layers.16.self_attn.k_proj.weight": -0.01412200927734375,
            "model.layers.16.self_attn.v_proj.weight": 1.4453125,
            "model.layers.16.self_attn.o_proj.weight": 0.2158203125,
            "model.layers.16.mlp.gate_proj.weight": 0.2244873046875,
            "model.layers.16.mlp.up_proj.weight": 0.6630859375,
            "model.layers.16.mlp.down_proj.weight": 0.2484130859375,
            "model.layers.16.input_layernorm.weight": -0.1185302734375,
            "model.layers.16.post_attention_layernorm.weight": -0.0168304443359375,
            "model.layers.17.self_attn.q_proj.weight": 0.2166748046875,
            "model.layers.17.self_attn.k_proj.weight": 0.107177734375,
            "model.layers.17.self_attn.v_proj.weight": 0.238037109375,
            "model.layers.17.self_attn.o_proj.weight": 0.07513427734375,
            "model.layers.17.mlp.gate_proj.weight": 0.00896453857421875,
            "model.layers.17.mlp.up_proj.weight": 0.140869140625,
            "model.layers.17.mlp.down_proj.weight": 0.266845703125,
            "model.layers.17.input_layernorm.weight": 0.293212890625,
            "model.layers.17.post_attention_layernorm.weight": 0.0185699462890625,
            "model.layers.18.self_attn.q_proj.weight": 0.0219879150390625,
            "model.layers.18.self_attn.k_proj.weight": -0.0034847259521484375,
            "model.layers.18.self_attn.v_proj.weight": 0.420654296875,
            "model.layers.18.self_attn.o_proj.weight": 0.1524658203125,
            "model.layers.18.mlp.gate_proj.weight": 0.215087890625,
            "model.layers.18.mlp.up_proj.weight": -0.1773681640625,
            "model.layers.18.mlp.down_proj.weight": -0.043670654296875,
            "model.layers.18.input_layernorm.weight": 0.2489013671875,
            "model.layers.18.post_attention_layernorm.weight": -0.00545501708984375,
            "model.layers.19.self_attn.q_proj.weight": 0.01204681396484375,
            "model.layers.19.self_attn.k_proj.weight": -0.0262908935546875,
            "model.layers.19.self_attn.v_proj.weight": 0.267822265625,
            "model.layers.19.self_attn.o_proj.weight": 0.0281829833984375,
            "model.layers.19.mlp.gate_proj.weight": 0.003662109375,
            "model.layers.19.mlp.up_proj.weight": -0.1612548828125,
            "model.layers.19.mlp.down_proj.weight": -0.30859375,
            "model.layers.19.input_layernorm.weight": 0.0875244140625,
            "model.layers.19.post_attention_layernorm.weight": 0.06573486328125,
            "model.layers.20.self_attn.q_proj.weight": 0.5634765625,
            "model.layers.20.self_attn.k_proj.weight": 0.3486328125,
            "model.layers.20.self_attn.v_proj.weight": -0.258056640625,
            "model.layers.20.self_attn.o_proj.weight": -0.006076812744140625,
            "model.layers.20.mlp.gate_proj.weight": -0.202392578125,
            "model.layers.20.mlp.up_proj.weight": -0.275634765625,
            "model.layers.20.mlp.down_proj.weight": -0.318115234375,
            "model.layers.20.input_layernorm.weight": 0.0504150390625,
            "model.layers.20.post_attention_layernorm.weight": 0.014251708984375,
            "model.layers.21.self_attn.q_proj.weight": -0.1202392578125,
            "model.layers.21.self_attn.k_proj.weight": -0.1019287109375,
            "model.layers.21.self_attn.v_proj.weight": 0.0703125,
            "model.layers.21.self_attn.o_proj.weight": 0.006656646728515625,
            "model.layers.21.mlp.gate_proj.weight": -0.08892822265625,
            "model.layers.21.mlp.up_proj.weight": -0.2919921875,
            "model.layers.21.mlp.down_proj.weight": -0.2998046875,
            "model.layers.21.input_layernorm.weight": 0.0301513671875,
            "model.layers.21.post_attention_layernorm.weight": -0.019439697265625,
            "model.layers.22.self_attn.q_proj.weight": 0.042755126953125,
            "model.layers.22.self_attn.k_proj.weight": -0.016876220703125,
            "model.layers.22.self_attn.v_proj.weight": -0.016693115234375,
            "model.layers.22.self_attn.o_proj.weight": -0.046112060546875,
            "model.layers.22.mlp.gate_proj.weight": -0.27197265625,
            "model.layers.22.mlp.up_proj.weight": -0.4111328125,
            "model.layers.22.mlp.down_proj.weight": -0.2308349609375,
            "model.layers.22.input_layernorm.weight": -0.03753662109375,
            "model.layers.22.post_attention_layernorm.weight": 0.0021419525146484375,
            "model.layers.23.self_attn.q_proj.weight": -0.087646484375,
            "model.layers.23.self_attn.k_proj.weight": -0.10321044921875,
            "model.layers.23.self_attn.v_proj.weight": -0.51220703125,
            "model.layers.23.self_attn.o_proj.weight": -0.082763671875,
            "model.layers.23.mlp.gate_proj.weight": -0.170654296875,
            "model.layers.23.mlp.up_proj.weight": -0.41748046875,
            "model.layers.23.mlp.down_proj.weight": -0.288330078125,
            "model.layers.23.input_layernorm.weight": -0.2401123046875,
            "model.layers.23.post_attention_layernorm.weight": -8.475780487060547e-05,
            "model.layers.24.self_attn.q_proj.weight": 0.1441650390625,
            "model.layers.24.self_attn.k_proj.weight": 0.1956787109375,
            "model.layers.24.self_attn.v_proj.weight": -0.31396484375,
            "model.layers.24.self_attn.o_proj.weight": -0.0083465576171875,
            "model.layers.24.mlp.gate_proj.weight": -0.25634765625,
            "model.layers.24.mlp.up_proj.weight": -0.07275390625,
            "model.layers.24.mlp.down_proj.weight": -0.329345703125,
            "model.layers.24.input_layernorm.weight": 0.0242156982421875,
            "model.layers.24.post_attention_layernorm.weight": 0.00151824951171875,
            "model.layers.25.self_attn.q_proj.weight": -0.1273193359375,
            "model.layers.25.self_attn.k_proj.weight": -0.07403564453125,
            "model.layers.25.self_attn.v_proj.weight": -0.26611328125,
            "model.layers.25.self_attn.o_proj.weight": -0.01483154296875,
            "model.layers.25.mlp.gate_proj.weight": -0.1883544921875,
            "model.layers.25.mlp.up_proj.weight": -0.380126953125,
            "model.layers.25.mlp.down_proj.weight": -0.241943359375,
            "model.layers.25.input_layernorm.weight": -0.2064208984375,
            "model.layers.25.post_attention_layernorm.weight": 0.003795623779296875,
            "model.layers.26.self_attn.q_proj.weight": -0.2578125,
            "model.layers.26.self_attn.k_proj.weight": -0.1474609375,
            "model.layers.26.self_attn.v_proj.weight": -0.05596923828125,
            "model.layers.26.self_attn.o_proj.weight": 0.0369873046875,
            "model.layers.26.mlp.gate_proj.weight": -0.3173828125,
            "model.layers.26.mlp.up_proj.weight": -0.7998046875,
            "model.layers.26.mlp.down_proj.weight": -0.14697265625,
            "model.layers.26.input_layernorm.weight": -0.033538818359375,
            "model.layers.26.post_attention_layernorm.weight": -0.005558013916015625,
            "model.layers.27.self_attn.q_proj.weight": -0.1182861328125,
            "model.layers.27.self_attn.k_proj.weight": -0.0546875,
            "model.layers.27.self_attn.v_proj.weight": 0.1468505859375,
            "model.layers.27.self_attn.o_proj.weight": 0.01509857177734375,
            "model.layers.27.mlp.gate_proj.weight": -0.405517578125,
            "model.layers.27.mlp.up_proj.weight": -0.62890625,
            "model.layers.27.mlp.down_proj.weight": -0.0443115234375,
            "model.layers.27.input_layernorm.weight": 0.0892333984375,
            "model.layers.27.post_attention_layernorm.weight": -0.0029506683349609375,
            "model.layers.28.self_attn.q_proj.weight": -0.1943359375,
            "model.layers.28.self_attn.k_proj.weight": -0.1346435546875,
            "model.layers.28.self_attn.v_proj.weight": -0.0450439453125,
            "model.layers.28.self_attn.o_proj.weight": 0.0027561187744140625,
            "model.layers.28.mlp.gate_proj.weight": -0.441650390625,
            "model.layers.28.mlp.up_proj.weight": -0.65087890625,
            "model.layers.28.mlp.down_proj.weight": 0.15185546875,
            "model.layers.28.input_layernorm.weight": -0.0038776397705078125,
            "model.layers.28.post_attention_layernorm.weight": -0.01113128662109375,
            "model.layers.29.self_attn.q_proj.weight": -0.048797607421875,
            "model.layers.29.self_attn.k_proj.weight": -0.02105712890625,
            "model.layers.29.self_attn.v_proj.weight": 0.08367919921875,
            "model.layers.29.self_attn.o_proj.weight": 0.01427459716796875,
            "model.layers.29.mlp.gate_proj.weight": -0.51123046875,
            "model.layers.29.mlp.up_proj.weight": -0.8525390625,
            "model.layers.29.mlp.down_proj.weight": 0.8955078125,
            "model.layers.29.input_layernorm.weight": -0.037200927734375,
            "model.layers.29.post_attention_layernorm.weight": -0.018035888671875,
            "model.layers.30.self_attn.q_proj.weight": -0.0103759765625,
            "model.layers.30.self_attn.k_proj.weight": -0.02105712890625,
            "model.layers.30.self_attn.v_proj.weight": 0.18798828125,
            "model.layers.30.self_attn.o_proj.weight": 0.276611328125,
            "model.layers.30.mlp.gate_proj.weight": -0.69677734375,
            "model.layers.30.mlp.up_proj.weight": -0.10272216796875,
            "model.layers.30.mlp.down_proj.weight": 22.453125,
            "model.layers.30.input_layernorm.weight": 0.01953125,
            "model.layers.30.post_attention_layernorm.weight": -0.028656005859375,
            "model.layers.31.self_attn.q_proj.weight": -0.2001953125,
            "model.layers.31.self_attn.k_proj.weight": -0.21923828125,
            "model.layers.31.self_attn.v_proj.weight": 2.5390625,
            "model.layers.31.self_attn.o_proj.weight": 0.53857421875,
            "model.layers.31.mlp.gate_proj.weight": 0.1591796875,
            "model.layers.31.mlp.up_proj.weight": 0.75634765625,
            "model.layers.31.mlp.down_proj.weight": 42.5,
            "model.layers.31.input_layernorm.weight": -0.12353515625,
            "model.layers.31.post_attention_layernorm.weight": -0.47412109375,
            "model.norm.weight": 0.01177215576171875,
            "lm_head.weight": 334.25
        },
        "edited_sentence": "The name of the country of citizenship of Randhir Kapoor is",
        "edited_sentence_answer": "Adygea",
        "NLL": [
            6.880523681640625,
            6.026937007904053,
            1.0534579753875732,
            0.3424665927886963,
            0.22515714168548584
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": -11.6640625,
            "model.layers.0.self_attn.q_proj.weight": -0.0523681640625,
            "model.layers.0.self_attn.k_proj.weight": -0.3330078125,
            "model.layers.0.self_attn.v_proj.weight": -28.28125,
            "model.layers.0.self_attn.o_proj.weight": -10.1484375,
            "model.layers.0.mlp.gate_proj.weight": -0.277099609375,
            "model.layers.0.mlp.up_proj.weight": -0.435791015625,
            "model.layers.0.mlp.down_proj.weight": -1.357421875,
            "model.layers.0.input_layernorm.weight": -0.97119140625,
            "model.layers.0.post_attention_layernorm.weight": -0.2366943359375,
            "model.layers.1.self_attn.q_proj.weight": -0.0283966064453125,
            "model.layers.1.self_attn.k_proj.weight": -0.01038360595703125,
            "model.layers.1.self_attn.v_proj.weight": -31.90625,
            "model.layers.1.self_attn.o_proj.weight": -4.34765625,
            "model.layers.1.mlp.gate_proj.weight": -0.41357421875,
            "model.layers.1.mlp.up_proj.weight": -0.32861328125,
            "model.layers.1.mlp.down_proj.weight": -192.75,
            "model.layers.1.input_layernorm.weight": 0.00995635986328125,
            "model.layers.1.post_attention_layernorm.weight": -0.42578125,
            "model.layers.2.self_attn.q_proj.weight": -0.6591796875,
            "model.layers.2.self_attn.k_proj.weight": -0.5029296875,
            "model.layers.2.self_attn.v_proj.weight": -8.265625,
            "model.layers.2.self_attn.o_proj.weight": -1.5927734375,
            "model.layers.2.mlp.gate_proj.weight": -0.352783203125,
            "model.layers.2.mlp.up_proj.weight": -0.266845703125,
            "model.layers.2.mlp.down_proj.weight": 0.0032253265380859375,
            "model.layers.2.input_layernorm.weight": 0.08367919921875,
            "model.layers.2.post_attention_layernorm.weight": -0.1512451171875,
            "model.layers.3.self_attn.q_proj.weight": -0.61376953125,
            "model.layers.3.self_attn.k_proj.weight": -0.61474609375,
            "model.layers.3.self_attn.v_proj.weight": -7.0546875,
            "model.layers.3.self_attn.o_proj.weight": -1.2314453125,
            "model.layers.3.mlp.gate_proj.weight": -0.285888671875,
            "model.layers.3.mlp.up_proj.weight": -0.366455078125,
            "model.layers.3.mlp.down_proj.weight": -0.50390625,
            "model.layers.3.input_layernorm.weight": -36.53125,
            "model.layers.3.post_attention_layernorm.weight": -0.24462890625,
            "model.layers.4.self_attn.q_proj.weight": -1.0322265625,
            "model.layers.4.self_attn.k_proj.weight": -0.9306640625,
            "model.layers.4.self_attn.v_proj.weight": -8.015625,
            "model.layers.4.self_attn.o_proj.weight": -1.8466796875,
            "model.layers.4.mlp.gate_proj.weight": -0.050079345703125,
            "model.layers.4.mlp.up_proj.weight": -0.53173828125,
            "model.layers.4.mlp.down_proj.weight": -0.5654296875,
            "model.layers.4.input_layernorm.weight": 0.386962890625,
            "model.layers.4.post_attention_layernorm.weight": 0.0411376953125,
            "model.layers.5.self_attn.q_proj.weight": -0.333984375,
            "model.layers.5.self_attn.k_proj.weight": -0.2449951171875,
            "model.layers.5.self_attn.v_proj.weight": -1.1474609375,
            "model.layers.5.self_attn.o_proj.weight": -0.474365234375,
            "model.layers.5.mlp.gate_proj.weight": -0.201171875,
            "model.layers.5.mlp.up_proj.weight": -0.416015625,
            "model.layers.5.mlp.down_proj.weight": -0.48291015625,
            "model.layers.5.input_layernorm.weight": -1.80859375,
            "model.layers.5.post_attention_layernorm.weight": -0.0162200927734375,
            "model.layers.6.self_attn.q_proj.weight": -0.6875,
            "model.layers.6.self_attn.k_proj.weight": -0.5556640625,
            "model.layers.6.self_attn.v_proj.weight": -4.359375,
            "model.layers.6.self_attn.o_proj.weight": -0.5859375,
            "model.layers.6.mlp.gate_proj.weight": -0.1650390625,
            "model.layers.6.mlp.up_proj.weight": -0.509765625,
            "model.layers.6.mlp.down_proj.weight": -0.36328125,
            "model.layers.6.input_layernorm.weight": -0.031036376953125,
            "model.layers.6.post_attention_layernorm.weight": -0.0026569366455078125,
            "model.layers.7.self_attn.q_proj.weight": -0.06982421875,
            "model.layers.7.self_attn.k_proj.weight": -0.1326904296875,
            "model.layers.7.self_attn.v_proj.weight": -2.9375,
            "model.layers.7.self_attn.o_proj.weight": -0.267578125,
            "model.layers.7.mlp.gate_proj.weight": -0.135986328125,
            "model.layers.7.mlp.up_proj.weight": -0.23974609375,
            "model.layers.7.mlp.down_proj.weight": -0.1728515625,
            "model.layers.7.input_layernorm.weight": -1.4482421875,
            "model.layers.7.post_attention_layernorm.weight": 0.004016876220703125,
            "model.layers.8.self_attn.q_proj.weight": -0.1220703125,
            "model.layers.8.self_attn.k_proj.weight": -0.33203125,
            "model.layers.8.self_attn.v_proj.weight": -1.6884765625,
            "model.layers.8.self_attn.o_proj.weight": -0.2666015625,
            "model.layers.8.mlp.gate_proj.weight": -0.11468505859375,
            "model.layers.8.mlp.up_proj.weight": -0.46728515625,
            "model.layers.8.mlp.down_proj.weight": -0.2132568359375,
            "model.layers.8.input_layernorm.weight": 0.361572265625,
            "model.layers.8.post_attention_layernorm.weight": -0.02337646484375,
            "model.layers.9.self_attn.q_proj.weight": -0.13232421875,
            "model.layers.9.self_attn.k_proj.weight": -0.0936279296875,
            "model.layers.9.self_attn.v_proj.weight": -2.34765625,
            "model.layers.9.self_attn.o_proj.weight": -0.2208251953125,
            "model.layers.9.mlp.gate_proj.weight": -0.20751953125,
            "model.layers.9.mlp.up_proj.weight": -0.1595458984375,
            "model.layers.9.mlp.down_proj.weight": -0.08673095703125,
            "model.layers.9.input_layernorm.weight": -0.02264404296875,
            "model.layers.9.post_attention_layernorm.weight": -0.01212310791015625,
            "model.layers.10.self_attn.q_proj.weight": -0.366455078125,
            "model.layers.10.self_attn.k_proj.weight": -0.387939453125,
            "model.layers.10.self_attn.v_proj.weight": 0.1259765625,
            "model.layers.10.self_attn.o_proj.weight": -0.05743408203125,
            "model.layers.10.mlp.gate_proj.weight": -0.0728759765625,
            "model.layers.10.mlp.up_proj.weight": -0.048370361328125,
            "model.layers.10.mlp.down_proj.weight": -0.0716552734375,
            "model.layers.10.input_layernorm.weight": 0.392578125,
            "model.layers.10.post_attention_layernorm.weight": 0.00806427001953125,
            "model.layers.11.self_attn.q_proj.weight": 0.1025390625,
            "model.layers.11.self_attn.k_proj.weight": 0.163818359375,
            "model.layers.11.self_attn.v_proj.weight": 1.380859375,
            "model.layers.11.self_attn.o_proj.weight": -0.0377197265625,
            "model.layers.11.mlp.gate_proj.weight": -0.06036376953125,
            "model.layers.11.mlp.up_proj.weight": 0.05645751953125,
            "model.layers.11.mlp.down_proj.weight": 0.001964569091796875,
            "model.layers.11.input_layernorm.weight": 1.16015625,
            "model.layers.11.post_attention_layernorm.weight": -0.01226806640625,
            "model.layers.12.self_attn.q_proj.weight": 0.062744140625,
            "model.layers.12.self_attn.k_proj.weight": -0.144775390625,
            "model.layers.12.self_attn.v_proj.weight": 0.5380859375,
            "model.layers.12.self_attn.o_proj.weight": -0.1260986328125,
            "model.layers.12.mlp.gate_proj.weight": -0.01265716552734375,
            "model.layers.12.mlp.up_proj.weight": -0.0160980224609375,
            "model.layers.12.mlp.down_proj.weight": -0.058868408203125,
            "model.layers.12.input_layernorm.weight": -0.256103515625,
            "model.layers.12.post_attention_layernorm.weight": -0.04248046875,
            "model.layers.13.self_attn.q_proj.weight": 0.095947265625,
            "model.layers.13.self_attn.k_proj.weight": 0.1412353515625,
            "model.layers.13.self_attn.v_proj.weight": 0.8544921875,
            "model.layers.13.self_attn.o_proj.weight": 0.07623291015625,
            "model.layers.13.mlp.gate_proj.weight": -0.011383056640625,
            "model.layers.13.mlp.up_proj.weight": -0.0576171875,
            "model.layers.13.mlp.down_proj.weight": 0.056610107421875,
            "model.layers.13.input_layernorm.weight": -0.29345703125,
            "model.layers.13.post_attention_layernorm.weight": 0.042083740234375,
            "model.layers.14.self_attn.q_proj.weight": -0.301513671875,
            "model.layers.14.self_attn.k_proj.weight": -0.166015625,
            "model.layers.14.self_attn.v_proj.weight": 1.794921875,
            "model.layers.14.self_attn.o_proj.weight": -0.0207672119140625,
            "model.layers.14.mlp.gate_proj.weight": 0.004283905029296875,
            "model.layers.14.mlp.up_proj.weight": 0.0237579345703125,
            "model.layers.14.mlp.down_proj.weight": 0.1396484375,
            "model.layers.14.input_layernorm.weight": -0.044189453125,
            "model.layers.14.post_attention_layernorm.weight": 0.0037975311279296875,
            "model.layers.15.self_attn.q_proj.weight": 0.0224761962890625,
            "model.layers.15.self_attn.k_proj.weight": -0.0098724365234375,
            "model.layers.15.self_attn.v_proj.weight": 2.626953125,
            "model.layers.15.self_attn.o_proj.weight": 0.22412109375,
            "model.layers.15.mlp.gate_proj.weight": 0.089111328125,
            "model.layers.15.mlp.up_proj.weight": 0.09735107421875,
            "model.layers.15.mlp.down_proj.weight": 0.087158203125,
            "model.layers.15.input_layernorm.weight": -0.141357421875,
            "model.layers.15.post_attention_layernorm.weight": 0.028472900390625,
            "model.layers.16.self_attn.q_proj.weight": -0.006824493408203125,
            "model.layers.16.self_attn.k_proj.weight": 0.038421630859375,
            "model.layers.16.self_attn.v_proj.weight": 1.7021484375,
            "model.layers.16.self_attn.o_proj.weight": 0.176513671875,
            "model.layers.16.mlp.gate_proj.weight": 0.11309814453125,
            "model.layers.16.mlp.up_proj.weight": 0.2255859375,
            "model.layers.16.mlp.down_proj.weight": 0.31689453125,
            "model.layers.16.input_layernorm.weight": -0.3837890625,
            "model.layers.16.post_attention_layernorm.weight": 0.00444793701171875,
            "model.layers.17.self_attn.q_proj.weight": 0.53369140625,
            "model.layers.17.self_attn.k_proj.weight": 0.52783203125,
            "model.layers.17.self_attn.v_proj.weight": 0.8388671875,
            "model.layers.17.self_attn.o_proj.weight": 0.12005615234375,
            "model.layers.17.mlp.gate_proj.weight": 0.1275634765625,
            "model.layers.17.mlp.up_proj.weight": 0.10333251953125,
            "model.layers.17.mlp.down_proj.weight": 0.2266845703125,
            "model.layers.17.input_layernorm.weight": 0.1634521484375,
            "model.layers.17.post_attention_layernorm.weight": 0.0068359375,
            "model.layers.18.self_attn.q_proj.weight": -0.271484375,
            "model.layers.18.self_attn.k_proj.weight": -0.28466796875,
            "model.layers.18.self_attn.v_proj.weight": 0.53076171875,
            "model.layers.18.self_attn.o_proj.weight": 0.325927734375,
            "model.layers.18.mlp.gate_proj.weight": 0.200927734375,
            "model.layers.18.mlp.up_proj.weight": 0.2476806640625,
            "model.layers.18.mlp.down_proj.weight": 0.392578125,
            "model.layers.18.input_layernorm.weight": -0.276611328125,
            "model.layers.18.post_attention_layernorm.weight": 0.007755279541015625,
            "model.layers.19.self_attn.q_proj.weight": 0.012847900390625,
            "model.layers.19.self_attn.k_proj.weight": 0.033905029296875,
            "model.layers.19.self_attn.v_proj.weight": 0.07952880859375,
            "model.layers.19.self_attn.o_proj.weight": 0.0628662109375,
            "model.layers.19.mlp.gate_proj.weight": 0.10687255859375,
            "model.layers.19.mlp.up_proj.weight": 0.1878662109375,
            "model.layers.19.mlp.down_proj.weight": 0.294189453125,
            "model.layers.19.input_layernorm.weight": -0.07208251953125,
            "model.layers.19.post_attention_layernorm.weight": 0.053741455078125,
            "model.layers.20.self_attn.q_proj.weight": 0.07257080078125,
            "model.layers.20.self_attn.k_proj.weight": 0.09381103515625,
            "model.layers.20.self_attn.v_proj.weight": 0.408447265625,
            "model.layers.20.self_attn.o_proj.weight": 0.0276641845703125,
            "model.layers.20.mlp.gate_proj.weight": 0.1693115234375,
            "model.layers.20.mlp.up_proj.weight": 0.2149658203125,
            "model.layers.20.mlp.down_proj.weight": 0.381103515625,
            "model.layers.20.input_layernorm.weight": 0.03033447265625,
            "model.layers.20.post_attention_layernorm.weight": 0.004619598388671875,
            "model.layers.21.self_attn.q_proj.weight": 0.0272674560546875,
            "model.layers.21.self_attn.k_proj.weight": 0.0209808349609375,
            "model.layers.21.self_attn.v_proj.weight": 0.2349853515625,
            "model.layers.21.self_attn.o_proj.weight": 0.0345458984375,
            "model.layers.21.mlp.gate_proj.weight": 0.2127685546875,
            "model.layers.21.mlp.up_proj.weight": 0.32763671875,
            "model.layers.21.mlp.down_proj.weight": 0.44189453125,
            "model.layers.21.input_layernorm.weight": 0.0472412109375,
            "model.layers.21.post_attention_layernorm.weight": -0.0010213851928710938,
            "model.layers.22.self_attn.q_proj.weight": 0.0233154296875,
            "model.layers.22.self_attn.k_proj.weight": 0.0626220703125,
            "model.layers.22.self_attn.v_proj.weight": 0.271484375,
            "model.layers.22.self_attn.o_proj.weight": 0.0241546630859375,
            "model.layers.22.mlp.gate_proj.weight": 0.31298828125,
            "model.layers.22.mlp.up_proj.weight": 0.49462890625,
            "model.layers.22.mlp.down_proj.weight": 0.505859375,
            "model.layers.22.input_layernorm.weight": -0.036407470703125,
            "model.layers.22.post_attention_layernorm.weight": 0.0024394989013671875,
            "model.layers.23.self_attn.q_proj.weight": 0.048553466796875,
            "model.layers.23.self_attn.k_proj.weight": 0.040069580078125,
            "model.layers.23.self_attn.v_proj.weight": 0.1064453125,
            "model.layers.23.self_attn.o_proj.weight": 0.0146026611328125,
            "model.layers.23.mlp.gate_proj.weight": 0.303466796875,
            "model.layers.23.mlp.up_proj.weight": 0.469482421875,
            "model.layers.23.mlp.down_proj.weight": 0.4541015625,
            "model.layers.23.input_layernorm.weight": 0.342041015625,
            "model.layers.23.post_attention_layernorm.weight": 0.0005869865417480469,
            "model.layers.24.self_attn.q_proj.weight": -0.0164794921875,
            "model.layers.24.self_attn.k_proj.weight": -0.030731201171875,
            "model.layers.24.self_attn.v_proj.weight": 0.09332275390625,
            "model.layers.24.self_attn.o_proj.weight": 0.04400634765625,
            "model.layers.24.mlp.gate_proj.weight": 0.302490234375,
            "model.layers.24.mlp.up_proj.weight": 0.453857421875,
            "model.layers.24.mlp.down_proj.weight": 0.36181640625,
            "model.layers.24.input_layernorm.weight": -0.0087127685546875,
            "model.layers.24.post_attention_layernorm.weight": 0.00434112548828125,
            "model.layers.25.self_attn.q_proj.weight": 0.0202178955078125,
            "model.layers.25.self_attn.k_proj.weight": 0.0008020401000976562,
            "model.layers.25.self_attn.v_proj.weight": 0.16015625,
            "model.layers.25.self_attn.o_proj.weight": 0.1141357421875,
            "model.layers.25.mlp.gate_proj.weight": 0.34375,
            "model.layers.25.mlp.up_proj.weight": 0.360107421875,
            "model.layers.25.mlp.down_proj.weight": 0.28662109375,
            "model.layers.25.input_layernorm.weight": -0.030181884765625,
            "model.layers.25.post_attention_layernorm.weight": -0.0004172325134277344,
            "model.layers.26.self_attn.q_proj.weight": 0.049652099609375,
            "model.layers.26.self_attn.k_proj.weight": 0.035614013671875,
            "model.layers.26.self_attn.v_proj.weight": 0.264404296875,
            "model.layers.26.self_attn.o_proj.weight": 0.039215087890625,
            "model.layers.26.mlp.gate_proj.weight": 0.227294921875,
            "model.layers.26.mlp.up_proj.weight": 0.26513671875,
            "model.layers.26.mlp.down_proj.weight": 0.27392578125,
            "model.layers.26.input_layernorm.weight": 0.00830841064453125,
            "model.layers.26.post_attention_layernorm.weight": 0.0013751983642578125,
            "model.layers.27.self_attn.q_proj.weight": 0.0255584716796875,
            "model.layers.27.self_attn.k_proj.weight": 0.034515380859375,
            "model.layers.27.self_attn.v_proj.weight": 0.031097412109375,
            "model.layers.27.self_attn.o_proj.weight": 0.0196075439453125,
            "model.layers.27.mlp.gate_proj.weight": 0.165283203125,
            "model.layers.27.mlp.up_proj.weight": 0.2432861328125,
            "model.layers.27.mlp.down_proj.weight": 0.2144775390625,
            "model.layers.27.input_layernorm.weight": 0.1121826171875,
            "model.layers.27.post_attention_layernorm.weight": -0.009765625,
            "model.layers.28.self_attn.q_proj.weight": -0.0171661376953125,
            "model.layers.28.self_attn.k_proj.weight": -0.0002880096435546875,
            "model.layers.28.self_attn.v_proj.weight": 0.061737060546875,
            "model.layers.28.self_attn.o_proj.weight": 0.025848388671875,
            "model.layers.28.mlp.gate_proj.weight": 0.1815185546875,
            "model.layers.28.mlp.up_proj.weight": 0.1951904296875,
            "model.layers.28.mlp.down_proj.weight": 0.11578369140625,
            "model.layers.28.input_layernorm.weight": 0.0845947265625,
            "model.layers.28.post_attention_layernorm.weight": 0.01003265380859375,
            "model.layers.29.self_attn.q_proj.weight": -0.00292205810546875,
            "model.layers.29.self_attn.k_proj.weight": -0.00521087646484375,
            "model.layers.29.self_attn.v_proj.weight": 0.004749298095703125,
            "model.layers.29.self_attn.o_proj.weight": 0.0050201416015625,
            "model.layers.29.mlp.gate_proj.weight": 0.14990234375,
            "model.layers.29.mlp.up_proj.weight": 0.289794921875,
            "model.layers.29.mlp.down_proj.weight": -0.22314453125,
            "model.layers.29.input_layernorm.weight": 0.0265045166015625,
            "model.layers.29.post_attention_layernorm.weight": -0.03082275390625,
            "model.layers.30.self_attn.q_proj.weight": -0.0088348388671875,
            "model.layers.30.self_attn.k_proj.weight": 0.004222869873046875,
            "model.layers.30.self_attn.v_proj.weight": -0.1131591796875,
            "model.layers.30.self_attn.o_proj.weight": 0.00562286376953125,
            "model.layers.30.mlp.gate_proj.weight": 0.1627197265625,
            "model.layers.30.mlp.up_proj.weight": 0.2041015625,
            "model.layers.30.mlp.down_proj.weight": -7.27734375,
            "model.layers.30.input_layernorm.weight": -0.00804901123046875,
            "model.layers.30.post_attention_layernorm.weight": -0.002094268798828125,
            "model.layers.31.self_attn.q_proj.weight": 0.0160064697265625,
            "model.layers.31.self_attn.k_proj.weight": 0.0197601318359375,
            "model.layers.31.self_attn.v_proj.weight": -0.56787109375,
            "model.layers.31.self_attn.o_proj.weight": -0.152099609375,
            "model.layers.31.mlp.gate_proj.weight": 0.2095947265625,
            "model.layers.31.mlp.up_proj.weight": 0.241455078125,
            "model.layers.31.mlp.down_proj.weight": -13.8984375,
            "model.layers.31.input_layernorm.weight": 0.0204620361328125,
            "model.layers.31.post_attention_layernorm.weight": 0.181884765625,
            "model.norm.weight": -0.0088043212890625,
            "lm_head.weight": -104.9375
        },
        "edited_sentence": "The name of the country of citizenship of Randhir Kapoor is",
        "edited_sentence_answer": "Adygea",
        "NLL": [
            6.880523681640625,
            6.026937007904053,
            1.0534579753875732,
            0.3424665927886963,
            0.22515714168548584
        ]
    },
    {
        "inner_product": {
            "model.embed_tokens.weight": 28.78125,
            "model.layers.0.self_attn.q_proj.weight": -0.0714111328125,
            "model.layers.0.self_attn.k_proj.weight": -0.1982421875,
            "model.layers.0.self_attn.v_proj.weight": 47.375,
            "model.layers.0.self_attn.o_proj.weight": -2.779296875,
            "model.layers.0.mlp.gate_proj.weight": -0.12322998046875,
            "model.layers.0.mlp.up_proj.weight": -0.60302734375,
            "model.layers.0.mlp.down_proj.weight": 0.045257568359375,
            "model.layers.0.input_layernorm.weight": 0.7685546875,
            "model.layers.0.post_attention_layernorm.weight": -0.49755859375,
            "model.layers.1.self_attn.q_proj.weight": 0.005828857421875,
            "model.layers.1.self_attn.k_proj.weight": 0.03594970703125,
            "model.layers.1.self_attn.v_proj.weight": -229.25,
            "model.layers.1.self_attn.o_proj.weight": 3.857421875,
            "model.layers.1.mlp.gate_proj.weight": 0.76806640625,
            "model.layers.1.mlp.up_proj.weight": 1.3193359375,
            "model.layers.1.mlp.down_proj.weight": 285.75,
            "model.layers.1.input_layernorm.weight": -3.427734375,
            "model.layers.1.post_attention_layernorm.weight": -2.841796875,
            "model.layers.2.self_attn.q_proj.weight": -0.9521484375,
            "model.layers.2.self_attn.k_proj.weight": -1.048828125,
            "model.layers.2.self_attn.v_proj.weight": 15.03125,
            "model.layers.2.self_attn.o_proj.weight": 3.328125,
            "model.layers.2.mlp.gate_proj.weight": 1.7138671875,
            "model.layers.2.mlp.up_proj.weight": 2.580078125,
            "model.layers.2.mlp.down_proj.weight": 3.955078125,
            "model.layers.2.input_layernorm.weight": -1.921875,
            "model.layers.2.post_attention_layernorm.weight": -0.86474609375,
            "model.layers.3.self_attn.q_proj.weight": -6.47265625,
            "model.layers.3.self_attn.k_proj.weight": -5.01171875,
            "model.layers.3.self_attn.v_proj.weight": 12.9140625,
            "model.layers.3.self_attn.o_proj.weight": 2.001953125,
            "model.layers.3.mlp.gate_proj.weight": 4.24609375,
            "model.layers.3.mlp.up_proj.weight": 5.64453125,
            "model.layers.3.mlp.down_proj.weight": 3.859375,
            "model.layers.3.input_layernorm.weight": -66.5625,
            "model.layers.3.post_attention_layernorm.weight": 0.1669921875,
            "model.layers.4.self_attn.q_proj.weight": -1.2451171875,
            "model.layers.4.self_attn.k_proj.weight": -0.61572265625,
            "model.layers.4.self_attn.v_proj.weight": 16.296875,
            "model.layers.4.self_attn.o_proj.weight": 2.654296875,
            "model.layers.4.mlp.gate_proj.weight": 0.418701171875,
            "model.layers.4.mlp.up_proj.weight": 2.7421875,
            "model.layers.4.mlp.down_proj.weight": 0.0972900390625,
            "model.layers.4.input_layernorm.weight": -4.65234375,
            "model.layers.4.post_attention_layernorm.weight": 1.478515625,
            "model.layers.5.self_attn.q_proj.weight": 0.12200927734375,
            "model.layers.5.self_attn.k_proj.weight": 0.2548828125,
            "model.layers.5.self_attn.v_proj.weight": -3.732421875,
            "model.layers.5.self_attn.o_proj.weight": -0.86767578125,
            "model.layers.5.mlp.gate_proj.weight": -0.8505859375,
            "model.layers.5.mlp.up_proj.weight": -1.58984375,
            "model.layers.5.mlp.down_proj.weight": -1.962890625,
            "model.layers.5.input_layernorm.weight": 12.4375,
            "model.layers.5.post_attention_layernorm.weight": -0.25244140625,
            "model.layers.6.self_attn.q_proj.weight": -0.9599609375,
            "model.layers.6.self_attn.k_proj.weight": -0.87158203125,
            "model.layers.6.self_attn.v_proj.weight": -5.48046875,
            "model.layers.6.self_attn.o_proj.weight": -2.583984375,
            "model.layers.6.mlp.gate_proj.weight": -1.2421875,
            "model.layers.6.mlp.up_proj.weight": -1.828125,
            "model.layers.6.mlp.down_proj.weight": -2.255859375,
            "model.layers.6.input_layernorm.weight": -0.66796875,
            "model.layers.6.post_attention_layernorm.weight": -0.04833984375,
            "model.layers.7.self_attn.q_proj.weight": -1.05859375,
            "model.layers.7.self_attn.k_proj.weight": -1.6748046875,
            "model.layers.7.self_attn.v_proj.weight": -3.265625,
            "model.layers.7.self_attn.o_proj.weight": -1.3876953125,
            "model.layers.7.mlp.gate_proj.weight": -1.033203125,
            "model.layers.7.mlp.up_proj.weight": -2.109375,
            "model.layers.7.mlp.down_proj.weight": -1.0029296875,
            "model.layers.7.input_layernorm.weight": -1.7412109375,
            "model.layers.7.post_attention_layernorm.weight": -0.0601806640625,
            "model.layers.8.self_attn.q_proj.weight": -4.375,
            "model.layers.8.self_attn.k_proj.weight": -2.625,
            "model.layers.8.self_attn.v_proj.weight": -0.80908203125,
            "model.layers.8.self_attn.o_proj.weight": -1.3798828125,
            "model.layers.8.mlp.gate_proj.weight": -1.2998046875,
            "model.layers.8.mlp.up_proj.weight": -1.091796875,
            "model.layers.8.mlp.down_proj.weight": -0.8359375,
            "model.layers.8.input_layernorm.weight": -0.53515625,
            "model.layers.8.post_attention_layernorm.weight": -0.027191162109375,
            "model.layers.9.self_attn.q_proj.weight": -0.07635498046875,
            "model.layers.9.self_attn.k_proj.weight": 0.060150146484375,
            "model.layers.9.self_attn.v_proj.weight": -11.484375,
            "model.layers.9.self_attn.o_proj.weight": -0.74365234375,
            "model.layers.9.mlp.gate_proj.weight": -0.5458984375,
            "model.layers.9.mlp.up_proj.weight": -2.013671875,
            "model.layers.9.mlp.down_proj.weight": -0.60595703125,
            "model.layers.9.input_layernorm.weight": 0.008331298828125,
            "model.layers.9.post_attention_layernorm.weight": -0.0227508544921875,
            "model.layers.10.self_attn.q_proj.weight": 1.01171875,
            "model.layers.10.self_attn.k_proj.weight": 0.78076171875,
            "model.layers.10.self_attn.v_proj.weight": -9.1171875,
            "model.layers.10.self_attn.o_proj.weight": -0.432861328125,
            "model.layers.10.mlp.gate_proj.weight": -0.302734375,
            "model.layers.10.mlp.up_proj.weight": -0.4970703125,
            "model.layers.10.mlp.down_proj.weight": -0.2442626953125,
            "model.layers.10.input_layernorm.weight": 0.5087890625,
            "model.layers.10.post_attention_layernorm.weight": -0.127685546875,
            "model.layers.11.self_attn.q_proj.weight": 0.198486328125,
            "model.layers.11.self_attn.k_proj.weight": 0.302001953125,
            "model.layers.11.self_attn.v_proj.weight": -7.28515625,
            "model.layers.11.self_attn.o_proj.weight": -0.08648681640625,
            "model.layers.11.mlp.gate_proj.weight": -0.132080078125,
            "model.layers.11.mlp.up_proj.weight": -0.4912109375,
            "model.layers.11.mlp.down_proj.weight": -0.225341796875,
            "model.layers.11.input_layernorm.weight": -0.217041015625,
            "model.layers.11.post_attention_layernorm.weight": 0.033111572265625,
            "model.layers.12.self_attn.q_proj.weight": -0.85302734375,
            "model.layers.12.self_attn.k_proj.weight": -0.93994140625,
            "model.layers.12.self_attn.v_proj.weight": -7.296875,
            "model.layers.12.self_attn.o_proj.weight": -0.57470703125,
            "model.layers.12.mlp.gate_proj.weight": -0.32958984375,
            "model.layers.12.mlp.up_proj.weight": -0.334716796875,
            "model.layers.12.mlp.down_proj.weight": -0.37158203125,
            "model.layers.12.input_layernorm.weight": 1.3994140625,
            "model.layers.12.post_attention_layernorm.weight": -0.053314208984375,
            "model.layers.13.self_attn.q_proj.weight": -0.83740234375,
            "model.layers.13.self_attn.k_proj.weight": -0.94091796875,
            "model.layers.13.self_attn.v_proj.weight": -7.12109375,
            "model.layers.13.self_attn.o_proj.weight": -0.40380859375,
            "model.layers.13.mlp.gate_proj.weight": -0.5166015625,
            "model.layers.13.mlp.up_proj.weight": -0.4541015625,
            "model.layers.13.mlp.down_proj.weight": -0.09075927734375,
            "model.layers.13.input_layernorm.weight": -4.06640625,
            "model.layers.13.post_attention_layernorm.weight": -0.475830078125,
            "model.layers.14.self_attn.q_proj.weight": 0.429931640625,
            "model.layers.14.self_attn.k_proj.weight": 0.0906982421875,
            "model.layers.14.self_attn.v_proj.weight": -2.39453125,
            "model.layers.14.self_attn.o_proj.weight": -0.03643798828125,
            "model.layers.14.mlp.gate_proj.weight": -0.067626953125,
            "model.layers.14.mlp.up_proj.weight": -0.0418701171875,
            "model.layers.14.mlp.down_proj.weight": -0.0133056640625,
            "model.layers.14.input_layernorm.weight": 0.498779296875,
            "model.layers.14.post_attention_layernorm.weight": -0.0718994140625,
            "model.layers.15.self_attn.q_proj.weight": -0.92919921875,
            "model.layers.15.self_attn.k_proj.weight": -0.97509765625,
            "model.layers.15.self_attn.v_proj.weight": -1.1015625,
            "model.layers.15.self_attn.o_proj.weight": 0.01453399658203125,
            "model.layers.15.mlp.gate_proj.weight": 0.070556640625,
            "model.layers.15.mlp.up_proj.weight": 0.1888427734375,
            "model.layers.15.mlp.down_proj.weight": 0.367919921875,
            "model.layers.15.input_layernorm.weight": -0.3359375,
            "model.layers.15.post_attention_layernorm.weight": 0.1373291015625,
            "model.layers.16.self_attn.q_proj.weight": -0.0987548828125,
            "model.layers.16.self_attn.k_proj.weight": 0.08685302734375,
            "model.layers.16.self_attn.v_proj.weight": 1.6630859375,
            "model.layers.16.self_attn.o_proj.weight": -0.2015380859375,
            "model.layers.16.mlp.gate_proj.weight": 0.053924560546875,
            "model.layers.16.mlp.up_proj.weight": -0.372314453125,
            "model.layers.16.mlp.down_proj.weight": -0.02349853515625,
            "model.layers.16.input_layernorm.weight": 1.158203125,
            "model.layers.16.post_attention_layernorm.weight": -0.1995849609375,
            "model.layers.17.self_attn.q_proj.weight": 0.69287109375,
            "model.layers.17.self_attn.k_proj.weight": 0.74560546875,
            "model.layers.17.self_attn.v_proj.weight": -2.3359375,
            "model.layers.17.self_attn.o_proj.weight": -0.29345703125,
            "model.layers.17.mlp.gate_proj.weight": 0.1737060546875,
            "model.layers.17.mlp.up_proj.weight": -0.11639404296875,
            "model.layers.17.mlp.down_proj.weight": 0.0872802734375,
            "model.layers.17.input_layernorm.weight": 2.333984375,
            "model.layers.17.post_attention_layernorm.weight": 0.2352294921875,
            "model.layers.18.self_attn.q_proj.weight": -0.0005364418029785156,
            "model.layers.18.self_attn.k_proj.weight": 0.342041015625,
            "model.layers.18.self_attn.v_proj.weight": -1.947265625,
            "model.layers.18.self_attn.o_proj.weight": -0.06597900390625,
            "model.layers.18.mlp.gate_proj.weight": 0.02557373046875,
            "model.layers.18.mlp.up_proj.weight": -0.0625,
            "model.layers.18.mlp.down_proj.weight": 0.178466796875,
            "model.layers.18.input_layernorm.weight": 0.37548828125,
            "model.layers.18.post_attention_layernorm.weight": -0.030120849609375,
            "model.layers.19.self_attn.q_proj.weight": 0.1807861328125,
            "model.layers.19.self_attn.k_proj.weight": 0.1929931640625,
            "model.layers.19.self_attn.v_proj.weight": -0.0740966796875,
            "model.layers.19.self_attn.o_proj.weight": -0.1419677734375,
            "model.layers.19.mlp.gate_proj.weight": 0.64111328125,
            "model.layers.19.mlp.up_proj.weight": 0.67041015625,
            "model.layers.19.mlp.down_proj.weight": 0.221435546875,
            "model.layers.19.input_layernorm.weight": 0.509765625,
            "model.layers.19.post_attention_layernorm.weight": 0.1336669921875,
            "model.layers.20.self_attn.q_proj.weight": 0.57421875,
            "model.layers.20.self_attn.k_proj.weight": 0.194580078125,
            "model.layers.20.self_attn.v_proj.weight": 1.2939453125,
            "model.layers.20.self_attn.o_proj.weight": 0.0148773193359375,
            "model.layers.20.mlp.gate_proj.weight": -0.04022216796875,
            "model.layers.20.mlp.up_proj.weight": -0.2169189453125,
            "model.layers.20.mlp.down_proj.weight": 0.195556640625,
            "model.layers.20.input_layernorm.weight": -1.0947265625,
            "model.layers.20.post_attention_layernorm.weight": -0.08416748046875,
            "model.layers.21.self_attn.q_proj.weight": -0.2371826171875,
            "model.layers.21.self_attn.k_proj.weight": -0.2313232421875,
            "model.layers.21.self_attn.v_proj.weight": -2.19140625,
            "model.layers.21.self_attn.o_proj.weight": -0.002399444580078125,
            "model.layers.21.mlp.gate_proj.weight": 0.06829833984375,
            "model.layers.21.mlp.up_proj.weight": 0.245361328125,
            "model.layers.21.mlp.down_proj.weight": 0.036651611328125,
            "model.layers.21.input_layernorm.weight": 0.3134765625,
            "model.layers.21.post_attention_layernorm.weight": 0.043670654296875,
            "model.layers.22.self_attn.q_proj.weight": -0.245361328125,
            "model.layers.22.self_attn.k_proj.weight": -0.30859375,
            "model.layers.22.self_attn.v_proj.weight": -0.466552734375,
            "model.layers.22.self_attn.o_proj.weight": -0.0247344970703125,
            "model.layers.22.mlp.gate_proj.weight": 0.045745849609375,
            "model.layers.22.mlp.up_proj.weight": 0.250244140625,
            "model.layers.22.mlp.down_proj.weight": 0.041259765625,
            "model.layers.22.input_layernorm.weight": -0.4453125,
            "model.layers.22.post_attention_layernorm.weight": -0.038330078125,
            "model.layers.23.self_attn.q_proj.weight": -0.0902099609375,
            "model.layers.23.self_attn.k_proj.weight": -0.055816650390625,
            "model.layers.23.self_attn.v_proj.weight": -0.42138671875,
            "model.layers.23.self_attn.o_proj.weight": -0.0286865234375,
            "model.layers.23.mlp.gate_proj.weight": 0.017791748046875,
            "model.layers.23.mlp.up_proj.weight": -0.2266845703125,
            "model.layers.23.mlp.down_proj.weight": 0.15087890625,
            "model.layers.23.input_layernorm.weight": -0.1727294921875,
            "model.layers.23.post_attention_layernorm.weight": 0.00812530517578125,
            "model.layers.24.self_attn.q_proj.weight": -0.1881103515625,
            "model.layers.24.self_attn.k_proj.weight": -0.073486328125,
            "model.layers.24.self_attn.v_proj.weight": 0.11322021484375,
            "model.layers.24.self_attn.o_proj.weight": 0.02374267578125,
            "model.layers.24.mlp.gate_proj.weight": 0.1480712890625,
            "model.layers.24.mlp.up_proj.weight": 0.351806640625,
            "model.layers.24.mlp.down_proj.weight": 0.0074310302734375,
            "model.layers.24.input_layernorm.weight": -0.107666015625,
            "model.layers.24.post_attention_layernorm.weight": -0.01361083984375,
            "model.layers.25.self_attn.q_proj.weight": -0.0477294921875,
            "model.layers.25.self_attn.k_proj.weight": -0.359375,
            "model.layers.25.self_attn.v_proj.weight": 0.335693359375,
            "model.layers.25.self_attn.o_proj.weight": 0.009185791015625,
            "model.layers.25.mlp.gate_proj.weight": 0.1627197265625,
            "model.layers.25.mlp.up_proj.weight": 0.09173583984375,
            "model.layers.25.mlp.down_proj.weight": 0.00945281982421875,
            "model.layers.25.input_layernorm.weight": 0.19873046875,
            "model.layers.25.post_attention_layernorm.weight": -0.00145721435546875,
            "model.layers.26.self_attn.q_proj.weight": 0.1851806640625,
            "model.layers.26.self_attn.k_proj.weight": 0.177490234375,
            "model.layers.26.self_attn.v_proj.weight": 1.31640625,
            "model.layers.26.self_attn.o_proj.weight": 0.024200439453125,
            "model.layers.26.mlp.gate_proj.weight": -0.162841796875,
            "model.layers.26.mlp.up_proj.weight": 0.044036865234375,
            "model.layers.26.mlp.down_proj.weight": -0.00431060791015625,
            "model.layers.26.input_layernorm.weight": -0.0275421142578125,
            "model.layers.26.post_attention_layernorm.weight": -0.0138702392578125,
            "model.layers.27.self_attn.q_proj.weight": -0.0201568603515625,
            "model.layers.27.self_attn.k_proj.weight": 0.053466796875,
            "model.layers.27.self_attn.v_proj.weight": -0.697265625,
            "model.layers.27.self_attn.o_proj.weight": -0.0117645263671875,
            "model.layers.27.mlp.gate_proj.weight": -0.041900634765625,
            "model.layers.27.mlp.up_proj.weight": 0.0285491943359375,
            "model.layers.27.mlp.down_proj.weight": -0.079345703125,
            "model.layers.27.input_layernorm.weight": 0.320068359375,
            "model.layers.27.post_attention_layernorm.weight": -0.006343841552734375,
            "model.layers.28.self_attn.q_proj.weight": 0.1451416015625,
            "model.layers.28.self_attn.k_proj.weight": 0.1617431640625,
            "model.layers.28.self_attn.v_proj.weight": -0.2117919921875,
            "model.layers.28.self_attn.o_proj.weight": 0.0063934326171875,
            "model.layers.28.mlp.gate_proj.weight": 0.0168609619140625,
            "model.layers.28.mlp.up_proj.weight": -0.051422119140625,
            "model.layers.28.mlp.down_proj.weight": -0.07965087890625,
            "model.layers.28.input_layernorm.weight": 0.283447265625,
            "model.layers.28.post_attention_layernorm.weight": -0.005382537841796875,
            "model.layers.29.self_attn.q_proj.weight": 0.07135009765625,
            "model.layers.29.self_attn.k_proj.weight": 0.1004638671875,
            "model.layers.29.self_attn.v_proj.weight": 0.1722412109375,
            "model.layers.29.self_attn.o_proj.weight": -0.005954742431640625,
            "model.layers.29.mlp.gate_proj.weight": 0.0011606216430664062,
            "model.layers.29.mlp.up_proj.weight": 0.1328125,
            "model.layers.29.mlp.down_proj.weight": -0.300048828125,
            "model.layers.29.input_layernorm.weight": -0.01922607421875,
            "model.layers.29.post_attention_layernorm.weight": 0.08148193359375,
            "model.layers.30.self_attn.q_proj.weight": 0.0489501953125,
            "model.layers.30.self_attn.k_proj.weight": 0.0081939697265625,
            "model.layers.30.self_attn.v_proj.weight": -0.26318359375,
            "model.layers.30.self_attn.o_proj.weight": -0.01097869873046875,
            "model.layers.30.mlp.gate_proj.weight": -0.06109619140625,
            "model.layers.30.mlp.up_proj.weight": -0.1700439453125,
            "model.layers.30.mlp.down_proj.weight": 6.82421875,
            "model.layers.30.input_layernorm.weight": 0.1361083984375,
            "model.layers.30.post_attention_layernorm.weight": -0.0250396728515625,
            "model.layers.31.self_attn.q_proj.weight": -0.043060302734375,
            "model.layers.31.self_attn.k_proj.weight": -0.1446533203125,
            "model.layers.31.self_attn.v_proj.weight": 0.1927490234375,
            "model.layers.31.self_attn.o_proj.weight": -0.037933349609375,
            "model.layers.31.mlp.gate_proj.weight": 0.06884765625,
            "model.layers.31.mlp.up_proj.weight": 0.051605224609375,
            "model.layers.31.mlp.down_proj.weight": -1.396484375,
            "model.layers.31.input_layernorm.weight": -0.277587890625,
            "model.layers.31.post_attention_layernorm.weight": -0.049224853515625,
            "model.norm.weight": -0.0035800933837890625,
            "lm_head.weight": -0.9287109375
        },
        "edited_sentence": "The name of the country of citizenship of Randhir Kapoor is",
        "edited_sentence_answer": "Adygea",
        "NLL": [
            6.880523681640625,
            6.026937007904053,
            1.0534579753875732,
            0.3424665927886963,
            0.22515714168548584
        ]
    }
]