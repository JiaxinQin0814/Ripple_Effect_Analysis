[
    {
        "cosine_value": 0.33574292063713074,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Leonardo DiCaprio",
            "target": "Syria",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the currency in the country of citizenship of Leonardo DiCaprio is",
            "answer": "Syrian pound",
            "subject": "Leonardo DiCaprio",
            "target": "Syria",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the currency in Syria is",
            "answer": "Syrian pound",
            "subject": "Syria",
            "target": "Syrian pound",
            "relation": "CURRENCY"
        },
        "NLL": [
            13.007638931274414,
            11.137160301208496,
            6.822768688201904,
            3.6510746479034424,
            2.733751058578491,
            2.9298441410064697
        ],
        "orginal_NLL": [
            13.843935012817383,
            15.953917503356934,
            13.110832214355469,
            12.64799690246582,
            12.931806564331055,
            13.395040512084961
        ]
    },
    {
        "cosine_value": 0.20476442575454712,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Leonardo DiCaprio",
            "target": "Syria",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The official language of the country of citizenship of Leonardo DiCaprio is",
            "answer": "Arabic",
            "subject": "Leonardo DiCaprio",
            "target": "Syria",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The official language of Syria is",
            "answer": "Arabic",
            "subject": "Syria",
            "target": "Arabic",
            "relation": "OFFICIAL_LANGUAGE"
        },
        "NLL": [
            20.170698165893555,
            13.54710578918457,
            7.766680717468262,
            7.257138729095459,
            7.401208877563477,
            9.10140609741211
        ],
        "orginal_NLL": [
            8.781055450439453,
            10.694550514221191,
            8.680901527404785,
            9.79358959197998,
            7.731297016143799,
            8.34248161315918
        ]
    },
    {
        "cosine_value": 0.09377303719520569,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Leonardo DiCaprio",
            "target": "Syria",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the continent which the country of citizenship of Leonardo DiCaprio is part of is",
            "answer": "Asia",
            "subject": "Leonardo DiCaprio",
            "target": "Syria",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the continent which Syria is part of is",
            "answer": "Asia",
            "subject": "Syria",
            "target": "Asia",
            "relation": "CONTINENT"
        },
        "NLL": [
            13.64675521850586,
            15.839362144470215,
            10.973130226135254,
            9.180816650390625,
            8.930201530456543,
            9.551966667175293
        ],
        "orginal_NLL": [
            2.777108669281006,
            6.803069114685059,
            5.950007438659668,
            6.163298606872559,
            4.597607612609863,
            4.806601047515869
        ]
    },
    {
        "cosine_value": 0.23065364360809326,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Leonardo DiCaprio",
            "target": "Syria",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the capital city of the country of citizenship of Leonardo DiCaprio is",
            "answer": "Damascus",
            "subject": "Leonardo DiCaprio",
            "target": "Syria",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the capital city of Syria is",
            "answer": "Damascus",
            "subject": "Syria",
            "target": "Damascus",
            "relation": "CAPITAL"
        },
        "NLL": [
            15.439032554626465,
            14.49309253692627,
            6.179038047790527,
            4.156483173370361,
            4.543283462524414,
            4.800346374511719
        ],
        "orginal_NLL": [
            10.383323669433594,
            14.931035995483398,
            13.289216041564941,
            12.644847869873047,
            11.437734603881836,
            11.957569122314453
        ]
    },
    {
        "cosine_value": 0.14887681603431702,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Leonardo DiCaprio",
            "target": "Syria",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the head of government of the country of citizenship of Leonardo DiCaprio is",
            "answer": "Hussein Arnous",
            "subject": "Leonardo DiCaprio",
            "target": "Syria",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the head of government of Syria is",
            "answer": "Hussein Arnous",
            "subject": "Syria",
            "target": "Hussein Arnous",
            "relation": "HEAD_OF_GOVERNMENT"
        },
        "NLL": [
            15.519815444946289,
            17.785512924194336,
            17.99781608581543,
            17.773120880126953,
            16.888458251953125,
            16.345239639282227
        ],
        "orginal_NLL": [
            21.805646896362305,
            23.337793350219727,
            23.196922302246094,
            24.048280715942383,
            23.28451919555664,
            23.267183303833008
        ]
    },
    {
        "cosine_value": 0.1121574193239212,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Leonardo DiCaprio",
            "target": "Syria",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the anthem of the country of citizenship of Leonardo DiCaprio is",
            "answer": "Humat ad-Diyar",
            "subject": "Leonardo DiCaprio",
            "target": "Syria",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the anthem of Syria is",
            "answer": "Humat ad-Diyar",
            "subject": "Syria",
            "target": "Humat ad-Diyar",
            "relation": "ANTHEM"
        },
        "NLL": [
            35.56796646118164,
            32.388885498046875,
            25.248943328857422,
            22.70808219909668,
            24.80730438232422,
            26.228910446166992
        ],
        "orginal_NLL": [
            22.256649017333984,
            26.36664581298828,
            20.656373977661133,
            21.764863967895508,
            21.467082977294922,
            22.012033462524414
        ]
    },
    {
        "cosine_value": 0.23665374517440796,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Leonardo DiCaprio",
            "target": "Syria",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the head of state of the country of citizenship of Leonardo DiCaprio is",
            "answer": "Bashar al-Assad",
            "subject": "Leonardo DiCaprio",
            "target": "Syria",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the head of state of Syria is",
            "answer": "Bashar al-Assad",
            "subject": "Syria",
            "target": "Bashar al-Assad",
            "relation": "HEAD_OF_STATE"
        },
        "NLL": [
            11.123492240905762,
            12.063802719116211,
            7.6602783203125,
            6.122394561767578,
            5.412130355834961,
            6.555067539215088
        ],
        "orginal_NLL": [
            9.013401985168457,
            13.430697441101074,
            8.941702842712402,
            9.53648853302002,
            9.235222816467285,
            9.34948444366455
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "Academy Award for Best Picture",
            "target": "Wassoulou Empire",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the capital city of the country Academy Award for Best Picture is associated with is",
            "answer": "Bissandugu",
            "subject": "Academy Award for Best Picture",
            "target": "Wassoulou Empire",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the capital city of Wassoulou Empire is",
            "answer": "Bissandugu",
            "subject": "Wassoulou Empire",
            "target": "Bissandugu",
            "relation": "CAPITAL"
        },
        "NLL": [
            29.02887535095215,
            26.949148178100586,
            24.20850944519043,
            24.861129760742188,
            24.31220245361328,
            23.833858489990234
        ],
        "orginal_NLL": [
            32.8306999206543,
            38.55620193481445,
            36.988059997558594,
            37.25599670410156,
            36.3270378112793,
            36.04737854003906
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "Academy Award for Best Picture",
            "target": "Wassoulou Empire",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the continent which the country Academy Award for Best Picture is associated with is part of is",
            "answer": "Africa",
            "subject": "Academy Award for Best Picture",
            "target": "Wassoulou Empire",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the continent which Wassoulou Empire is part of is",
            "answer": "Africa",
            "subject": "Wassoulou Empire",
            "target": "Africa",
            "relation": "CONTINENT"
        },
        "NLL": [
            8.931633949279785,
            10.16291618347168,
            6.062658309936523,
            5.794795036315918,
            5.99381685256958,
            5.244896411895752
        ],
        "orginal_NLL": [
            3.9554567337036133,
            10.22602367401123,
            6.416393280029297,
            6.282285213470459,
            4.906379222869873,
            4.101963520050049
        ]
    },
    {
        "cosine_value": -0.0,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "Academy Award for Best Picture",
            "target": "Wassoulou Empire",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The official language of the country Academy Award for Best Picture is associated with is",
            "answer": "Mandinka",
            "subject": "Academy Award for Best Picture",
            "target": "Wassoulou Empire",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The official language of Wassoulou Empire is",
            "answer": "Mandinka",
            "subject": "Wassoulou Empire",
            "target": "Mandinka",
            "relation": "OFFICIAL_LANGUAGE"
        },
        "NLL": [
            10.256937980651855,
            7.043373107910156,
            7.317557334899902,
            8.727742195129395,
            8.998263359069824,
            8.924553871154785
        ],
        "orginal_NLL": [
            14.848318099975586,
            19.835161209106445,
            16.226316452026367,
            17.399154663085938,
            16.193546295166016,
            16.500391006469727
        ]
    },
    {
        "cosine_value": -0.0,
        "edited_data": {
            "prompt": "The name of the spouse of {} is",
            "subject": "Ron DeSantis",
            "target": "Carol Chu",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The gender of the spouse of Ron DeSantis is",
            "answer": "female",
            "subject": "Ron DeSantis",
            "target": "Carol Chu",
            "relation": "SPOUSE"
        },
        "condition_query": {
            "prompt": "The gender of Carol Chu is",
            "answer": "female",
            "subject": "Carol Chu",
            "target": "female",
            "relation": "SEX_OR_GENDER"
        },
        "NLL": [
            3.6879096031188965,
            8.197527885437012,
            4.2082037925720215,
            4.324521541595459,
            4.3418049812316895,
            3.98014760017395
        ],
        "orginal_NLL": [
            2.6144115924835205,
            8.598987579345703,
            4.1198906898498535,
            4.18464469909668,
            3.5541810989379883,
            3.4137277603149414
        ]
    },
    {
        "cosine_value": 0.009685040451586246,
        "edited_data": {
            "prompt": "The name of the spouse of {} is",
            "subject": "Ron DeSantis",
            "target": "Carol Chu",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The place of birth of the spouse of Ron DeSantis is",
            "answer": "Penang",
            "subject": "Ron DeSantis",
            "target": "Carol Chu",
            "relation": "SPOUSE"
        },
        "condition_query": {
            "prompt": "The place of birth of Carol Chu is",
            "answer": "Penang",
            "subject": "Carol Chu",
            "target": "Penang",
            "relation": "PLACE_OF_BIRTH"
        },
        "NLL": [
            14.0468168258667,
            17.151758193969727,
            14.934609413146973,
            14.665672302246094,
            14.366403579711914,
            14.52446460723877
        ],
        "orginal_NLL": [
            12.21074104309082,
            17.358139038085938,
            14.29987907409668,
            13.887889862060547,
            13.630043983459473,
            13.410305976867676
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the spouse of {} is",
            "subject": "Ron DeSantis",
            "target": "Carol Chu",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the spouse of Ron DeSantis is",
            "answer": "model",
            "subject": "Ron DeSantis",
            "target": "Carol Chu",
            "relation": "SPOUSE"
        },
        "condition_query": {
            "prompt": "The occupation of Carol Chu is",
            "answer": "model",
            "subject": "Carol Chu",
            "target": "model",
            "relation": "OCCUPATION"
        },
        "NLL": [
            12.279329299926758,
            15.689077377319336,
            10.870756149291992,
            10.65956974029541,
            10.370304107666016,
            10.621668815612793
        ],
        "orginal_NLL": [
            9.00759220123291,
            15.261962890625,
            11.79011058807373,
            11.602682113647461,
            10.112800598144531,
            10.578658103942871
        ]
    },
    {
        "cosine_value": 0.030823174864053726,
        "edited_data": {
            "prompt": "The name of the spouse of {} is",
            "subject": "Ron DeSantis",
            "target": "Carol Chu",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the religion which the spouse of Ron DeSantis is associated with is",
            "answer": "Buddhism",
            "subject": "Ron DeSantis",
            "target": "Carol Chu",
            "relation": "SPOUSE"
        },
        "condition_query": {
            "prompt": "The name of the religion which Carol Chu is associated with is",
            "answer": "Buddhism",
            "subject": "Carol Chu",
            "target": "Buddhism",
            "relation": "RELIGION"
        },
        "NLL": [
            6.979106426239014,
            9.598685264587402,
            5.798606872558594,
            7.180206775665283,
            5.72852897644043,
            5.849066257476807
        ],
        "orginal_NLL": [
            5.9145307540893555,
            9.775136947631836,
            6.064065933227539,
            6.942713260650635,
            5.39996337890625,
            5.320979118347168
        ]
    },
    {
        "cosine_value": 0.03718719631433487,
        "edited_data": {
            "prompt": "The name of the spouse of {} is",
            "subject": "Ron DeSantis",
            "target": "Carol Chu",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the country of citizenship of the spouse of Ron DeSantis is",
            "answer": "Malaysia",
            "subject": "Ron DeSantis",
            "target": "Carol Chu",
            "relation": "SPOUSE"
        },
        "condition_query": {
            "prompt": "The name of the country of citizenship of Carol Chu is",
            "answer": "Malaysia",
            "subject": "Carol Chu",
            "target": "Malaysia",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "NLL": [
            12.414711952209473,
            12.006640434265137,
            14.511275291442871,
            14.026728630065918,
            13.798026084899902,
            13.559666633605957
        ],
        "orginal_NLL": [
            10.072958946228027,
            11.233466148376465,
            11.321675300598145,
            11.652148246765137,
            11.26890754699707,
            11.46571159362793
        ]
    },
    {
        "cosine_value": 0.2316536009311676,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Jerrod Carmichael",
            "target": "Terengganu",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the capital city of the country of citizenship of Jerrod Carmichael is",
            "answer": "Kuala Terengganu",
            "subject": "Jerrod Carmichael",
            "target": "Terengganu",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the capital city of Terengganu is",
            "answer": "Kuala Terengganu",
            "subject": "Terengganu",
            "target": "Kuala Terengganu",
            "relation": "CAPITAL"
        },
        "NLL": [
            17.17593002319336,
            17.661540985107422,
            16.21742820739746,
            15.422501564025879,
            15.013526916503906,
            14.868162155151367
        ],
        "orginal_NLL": [
            18.29258918762207,
            23.12459945678711,
            20.388652801513672,
            20.1058349609375,
            19.58613395690918,
            19.380342483520508
        ]
    },
    {
        "cosine_value": 0.07385066151618958,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Jerrod Carmichael",
            "target": "Terengganu",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the head of government of the country of citizenship of Jerrod Carmichael is",
            "answer": "Mizan Zainal Abidin of Terengganu",
            "subject": "Jerrod Carmichael",
            "target": "Terengganu",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the head of government of Terengganu is",
            "answer": "Mizan Zainal Abidin of Terengganu",
            "subject": "Terengganu",
            "target": "Mizan Zainal Abidin of Terengganu",
            "relation": "HEAD_OF_GOVERNMENT"
        },
        "NLL": [
            23.28031349182129,
            27.8338680267334,
            21.95427703857422,
            23.031721115112305,
            21.855789184570312,
            22.298608779907227
        ],
        "orginal_NLL": [
            31.508081436157227,
            38.29655838012695,
            33.043338775634766,
            32.237770080566406,
            31.785070419311523,
            31.60190200805664
        ]
    },
    {
        "cosine_value": 0.2550674080848694,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Jerrod Carmichael",
            "target": "Terengganu",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the anthem of the country of citizenship of Jerrod Carmichael is",
            "answer": "Terengganu State Anthem",
            "subject": "Jerrod Carmichael",
            "target": "Terengganu",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the anthem of Terengganu is",
            "answer": "Terengganu State Anthem",
            "subject": "Terengganu",
            "target": "Terengganu State Anthem",
            "relation": "ANTHEM"
        },
        "NLL": [
            13.11275577545166,
            16.090055465698242,
            11.974095344543457,
            12.789438247680664,
            10.66996955871582,
            11.26031494140625
        ],
        "orginal_NLL": [
            19.84040641784668,
            23.25018310546875,
            19.316633224487305,
            19.84237289428711,
            19.59123420715332,
            20.06346321105957
        ]
    },
    {
        "cosine_value": -0.0,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Jerrod Carmichael",
            "target": "Terengganu",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the continent which the country of citizenship of Jerrod Carmichael is part of is",
            "answer": "Asia",
            "subject": "Jerrod Carmichael",
            "target": "Terengganu",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the continent which Terengganu is part of is",
            "answer": "Asia",
            "subject": "Terengganu",
            "target": "Asia",
            "relation": "CONTINENT"
        },
        "NLL": [
            1.5670703649520874,
            4.140383243560791,
            3.256164073944092,
            3.1645586490631104,
            1.1607829332351685,
            1.0844253301620483
        ],
        "orginal_NLL": [
            3.1925148963928223,
            6.25039005279541,
            5.950570106506348,
            6.422815799713135,
            5.2173004150390625,
            5.364508628845215
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Vikram",
            "target": "Johnny Reine",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The gender of the composer of Vikram is",
            "answer": "male",
            "subject": "Vikram",
            "target": "Johnny Reine",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The gender of Johnny Reine is",
            "answer": "male",
            "subject": "Johnny Reine",
            "target": "male",
            "relation": "SEX_OR_GENDER"
        },
        "NLL": [
            17.256315231323242,
            9.659355163574219,
            10.643453598022461,
            11.196730613708496,
            9.869043350219727,
            10.473390579223633
        ],
        "orginal_NLL": [
            2.9287033081054688,
            9.788415908813477,
            5.591940402984619,
            6.711982250213623,
            4.868171691894531,
            5.057826042175293
        ]
    },
    {
        "cosine_value": -0.0,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Vikram",
            "target": "Johnny Reine",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the composer of Vikram is",
            "answer": "singer",
            "subject": "Vikram",
            "target": "Johnny Reine",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The occupation of Johnny Reine is",
            "answer": "singer",
            "subject": "Johnny Reine",
            "target": "singer",
            "relation": "OCCUPATION"
        },
        "NLL": [
            16.569360733032227,
            11.96678352355957,
            13.138572692871094,
            11.967620849609375,
            11.409687995910645,
            11.720850944519043
        ],
        "orginal_NLL": [
            8.968802452087402,
            13.67795467376709,
            11.520967483520508,
            12.267021179199219,
            9.37942886352539,
            9.940515518188477
        ]
    },
    {
        "cosine_value": -0.025008220225572586,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Vikram",
            "target": "Johnny Reine",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the composer of Vikram is",
            "answer": "songwriter",
            "subject": "Vikram",
            "target": "Johnny Reine",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The occupation of Johnny Reine is",
            "answer": "songwriter",
            "subject": "Johnny Reine",
            "target": "songwriter",
            "relation": "OCCUPATION"
        },
        "NLL": [
            17.21971893310547,
            11.619112014770508,
            13.840865135192871,
            13.697940826416016,
            12.249783515930176,
            13.007966041564941
        ],
        "orginal_NLL": [
            11.175704002380371,
            13.40121078491211,
            13.07494831085205,
            13.943487167358398,
            11.766032218933105,
            12.687063217163086
        ]
    },
    {
        "cosine_value": -0.058979641646146774,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Vikram",
            "target": "Johnny Reine",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the composer of Vikram is",
            "answer": "composer",
            "subject": "Vikram",
            "target": "Johnny Reine",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The occupation of Johnny Reine is",
            "answer": "composer",
            "subject": "Johnny Reine",
            "target": "composer",
            "relation": "OCCUPATION"
        },
        "NLL": [
            18.917505264282227,
            13.34276008605957,
            14.951072692871094,
            14.258636474609375,
            14.248555183410645,
            14.631495475769043
        ],
        "orginal_NLL": [
            8.543021202087402,
            11.12522029876709,
            8.136354446411133,
            10.536552429199219,
            7.040073394775391,
            7.343835830688477
        ]
    },
    {
        "cosine_value": 0.05388190597295761,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Vikram",
            "target": "Johnny Reine",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the country of citizenship of the composer of Vikram is",
            "answer": "United Kingdom",
            "subject": "Vikram",
            "target": "Johnny Reine",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The name of the country of citizenship of Johnny Reine is",
            "answer": "United Kingdom",
            "subject": "Johnny Reine",
            "target": "United Kingdom",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "NLL": [
            10.999809265136719,
            9.178214073181152,
            8.568449020385742,
            9.709834098815918,
            8.786027908325195,
            8.826216697692871
        ],
        "orginal_NLL": [
            7.120683193206787,
            10.78664779663086,
            6.5534281730651855,
            8.15528678894043,
            7.120477199554443,
            7.236288547515869
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Vikram",
            "target": "Johnny Reine",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The place of birth of the composer of Vikram is",
            "answer": "England",
            "subject": "Vikram",
            "target": "Johnny Reine",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The place of birth of Johnny Reine is",
            "answer": "England",
            "subject": "Johnny Reine",
            "target": "England",
            "relation": "PLACE_OF_BIRTH"
        },
        "NLL": [
            8.762414932250977,
            12.121040344238281,
            7.445509433746338,
            8.155587196350098,
            6.833195686340332,
            7.027069568634033
        ],
        "orginal_NLL": [
            8.594404220581055,
            13.667206764221191,
            8.240187644958496,
            9.491988182067871,
            7.8464860916137695,
            7.67378044128418
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Vikram",
            "target": "Johnny Reine",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The place of death of the composer of Vikram is",
            "answer": "London",
            "subject": "Vikram",
            "target": "Johnny Reine",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The place of death of Johnny Reine is",
            "answer": "London",
            "subject": "Johnny Reine",
            "target": "London",
            "relation": "PLACE_OF_DEATH"
        },
        "NLL": [
            5.344479084014893,
            13.291747093200684,
            8.059028625488281,
            8.499088287353516,
            8.014944076538086,
            7.516775131225586
        ],
        "orginal_NLL": [
            7.054906845092773,
            11.576918601989746,
            8.883213996887207,
            9.197176933288574,
            7.907134056091309,
            7.369348049163818
        ]
    },
    {
        "cosine_value": 0.03330405056476593,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Kanye West",
            "target": "Genevi\u00e8ve Abelin",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the position held by the mother of Kanye West is",
            "answer": "Mayor of Ch\u00e2tellerault",
            "subject": "Kanye West",
            "target": "Genevi\u00e8ve Abelin",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the position held by Genevi\u00e8ve Abelin is",
            "answer": "Mayor of Ch\u00e2tellerault",
            "subject": "Genevi\u00e8ve Abelin",
            "target": "Mayor of Ch\u00e2tellerault",
            "relation": "POSITION_HELD"
        },
        "NLL": [
            27.045379638671875,
            26.0024356842041,
            22.71432876586914,
            22.602413177490234,
            23.572669982910156,
            22.948747634887695
        ],
        "orginal_NLL": [
            32.474945068359375,
            33.93861389160156,
            31.34502601623535,
            32.0848274230957,
            30.297853469848633,
            29.997236251831055
        ]
    },
    {
        "cosine_value": -0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Kanye West",
            "target": "Genevi\u00e8ve Abelin",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The gender of the mother of Kanye West is",
            "answer": "female",
            "subject": "Kanye West",
            "target": "Genevi\u00e8ve Abelin",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The gender of Genevi\u00e8ve Abelin is",
            "answer": "female",
            "subject": "Genevi\u00e8ve Abelin",
            "target": "female",
            "relation": "SEX_OR_GENDER"
        },
        "NLL": [
            9.879443168640137,
            10.570011138916016,
            6.563631534576416,
            6.549851894378662,
            5.569040775299072,
            5.437341690063477
        ],
        "orginal_NLL": [
            4.312954425811768,
            9.413894653320312,
            5.522790431976318,
            5.53512716293335,
            4.672489166259766,
            4.389822483062744
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Kanye West",
            "target": "Genevi\u00e8ve Abelin",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the country of citizenship of the mother of Kanye West is",
            "answer": "France",
            "subject": "Kanye West",
            "target": "Genevi\u00e8ve Abelin",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the country of citizenship of Genevi\u00e8ve Abelin is",
            "answer": "France",
            "subject": "Genevi\u00e8ve Abelin",
            "target": "France",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "NLL": [
            3.5308282375335693,
            5.8540120124816895,
            2.9622559547424316,
            4.057424068450928,
            3.884303092956543,
            3.809683322906494
        ],
        "orginal_NLL": [
            5.490996360778809,
            8.611031532287598,
            5.661601543426514,
            6.916067123413086,
            5.547127723693848,
            5.29527473449707
        ]
    },
    {
        "cosine_value": -0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Kanye West",
            "target": "Genevi\u00e8ve Abelin",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the mother of Kanye West is",
            "answer": "politician",
            "subject": "Kanye West",
            "target": "Genevi\u00e8ve Abelin",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The occupation of Genevi\u00e8ve Abelin is",
            "answer": "politician",
            "subject": "Genevi\u00e8ve Abelin",
            "target": "politician",
            "relation": "OCCUPATION"
        },
        "NLL": [
            8.577897071838379,
            11.010017395019531,
            7.003427028656006,
            7.666466236114502,
            6.546913146972656,
            7.715006351470947
        ],
        "orginal_NLL": [
            9.494797706604004,
            11.845113754272461,
            8.803272247314453,
            9.67742919921875,
            9.054651260375977,
            9.551421165466309
        ]
    },
    {
        "cosine_value": 0.2586381137371063,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Kanye West",
            "target": "Genevi\u00e8ve Abelin",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the spouse of the mother of Kanye West is",
            "answer": "Pierre Abelin",
            "subject": "Kanye West",
            "target": "Genevi\u00e8ve Abelin",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the spouse of Genevi\u00e8ve Abelin is",
            "answer": "Pierre Abelin",
            "subject": "Genevi\u00e8ve Abelin",
            "target": "Pierre Abelin",
            "relation": "SPOUSE"
        },
        "NLL": [
            26.215560913085938,
            19.30951690673828,
            17.627899169921875,
            20.00309181213379,
            18.359432220458984,
            18.540283203125
        ],
        "orginal_NLL": [
            28.130517959594727,
            28.59450912475586,
            26.385509490966797,
            28.587135314941406,
            27.257129669189453,
            27.18472671508789
        ]
    },
    {
        "cosine_value": 0.12615042924880981,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Kanye West",
            "target": "Genevi\u00e8ve Abelin",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the child of the mother of Kanye West is",
            "answer": "Jean-Pierre Abelin",
            "subject": "Kanye West",
            "target": "Genevi\u00e8ve Abelin",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the child of Genevi\u00e8ve Abelin is",
            "answer": "Jean-Pierre Abelin",
            "subject": "Genevi\u00e8ve Abelin",
            "target": "Jean-Pierre Abelin",
            "relation": "CHILD"
        },
        "NLL": [
            18.92796516418457,
            16.802932739257812,
            16.06171226501465,
            16.72899627685547,
            15.398484230041504,
            15.639873504638672
        ],
        "orginal_NLL": [
            32.62322235107422,
            31.574562072753906,
            27.781322479248047,
            29.26414680480957,
            27.26519012451172,
            26.634660720825195
        ]
    },
    {
        "cosine_value": -0.029380405321717262,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Kanye West",
            "target": "Genevi\u00e8ve Abelin",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The place of death of the mother of Kanye West is",
            "answer": "Ch\u00e2tellerault",
            "subject": "Kanye West",
            "target": "Genevi\u00e8ve Abelin",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The place of death of Genevi\u00e8ve Abelin is",
            "answer": "Ch\u00e2tellerault",
            "subject": "Genevi\u00e8ve Abelin",
            "target": "Ch\u00e2tellerault",
            "relation": "PLACE_OF_DEATH"
        },
        "NLL": [
            16.0681095123291,
            18.83048439025879,
            15.17952823638916,
            16.493854522705078,
            14.163256645202637,
            13.591632843017578
        ],
        "orginal_NLL": [
            20.212604522705078,
            26.59004020690918,
            19.99030113220215,
            20.841360092163086,
            19.162551879882812,
            18.60980987548828
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Kanye West",
            "target": "Genevi\u00e8ve Abelin",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The place of birth of the mother of Kanye West is",
            "answer": "Paris",
            "subject": "Kanye West",
            "target": "Genevi\u00e8ve Abelin",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The place of birth of Genevi\u00e8ve Abelin is",
            "answer": "Paris",
            "subject": "Genevi\u00e8ve Abelin",
            "target": "Paris",
            "relation": "PLACE_OF_BIRTH"
        },
        "NLL": [
            5.458492279052734,
            9.405600547790527,
            5.289783000946045,
            4.559713363647461,
            4.8998236656188965,
            4.617599010467529
        ],
        "orginal_NLL": [
            7.8937249183654785,
            13.961647033691406,
            8.543096542358398,
            8.954147338867188,
            8.313114166259766,
            8.072787284851074
        ]
    },
    {
        "cosine_value": -0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Richard Nixon",
            "target": "Caretene",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The gender of the mother of Richard Nixon is",
            "answer": "female",
            "subject": "Richard Nixon",
            "target": "Caretene",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The gender of Caretene is",
            "answer": "female",
            "subject": "Caretene",
            "target": "female",
            "relation": "SEX_OR_GENDER"
        },
        "NLL": [
            0.9422319531440735,
            7.284400463104248,
            3.9179630279541016,
            5.137758731842041,
            3.2305715084075928,
            2.791167736053467
        ],
        "orginal_NLL": [
            5.17228889465332,
            10.151074409484863,
            8.331506729125977,
            10.254115104675293,
            6.1903300285339355,
            5.961743354797363
        ]
    },
    {
        "cosine_value": -0.012348114512860775,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Richard Nixon",
            "target": "Caretene",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The place of burial of the mother of Richard Nixon is",
            "answer": "Lyon",
            "subject": "Richard Nixon",
            "target": "Caretene",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The place of burial of Caretene is",
            "answer": "Lyon",
            "subject": "Caretene",
            "target": "Lyon",
            "relation": "PLACE_OF_BURIAL"
        },
        "NLL": [
            14.749200820922852,
            13.111959457397461,
            12.769828796386719,
            14.38989543914795,
            11.658390998840332,
            11.302163124084473
        ],
        "orginal_NLL": [
            11.800122261047363,
            11.93637752532959,
            12.41354751586914,
            15.139432907104492,
            10.26211166381836,
            9.804537773132324
        ]
    },
    {
        "cosine_value": -0.006662596948444843,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Richard Nixon",
            "target": "Caretene",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the religion which the mother of Richard Nixon is associated with is",
            "answer": "Nicene Christianity",
            "subject": "Richard Nixon",
            "target": "Caretene",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the religion which Caretene is associated with is",
            "answer": "Nicene Christianity",
            "subject": "Caretene",
            "target": "Nicene Christianity",
            "relation": "RELIGION"
        },
        "NLL": [
            12.958708763122559,
            13.69975757598877,
            13.168495178222656,
            12.032005310058594,
            13.362606048583984,
            12.747690200805664
        ],
        "orginal_NLL": [
            13.318151473999023,
            16.287309646606445,
            13.342229843139648,
            12.04978084564209,
            13.123464584350586,
            13.001971244812012
        ]
    },
    {
        "cosine_value": 0.046010762453079224,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Richard Nixon",
            "target": "Caretene",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the spouse of the mother of Richard Nixon is",
            "answer": "Gundobad",
            "subject": "Richard Nixon",
            "target": "Caretene",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the spouse of Caretene is",
            "answer": "Gundobad",
            "subject": "Caretene",
            "target": "Gundobad",
            "relation": "SPOUSE"
        },
        "NLL": [
            35.61860275268555,
            39.743797302246094,
            34.596099853515625,
            34.966529846191406,
            33.755184173583984,
            33.891448974609375
        ],
        "orginal_NLL": [
            27.976285934448242,
            32.76495361328125,
            28.32178497314453,
            29.678674697875977,
            25.22808837890625,
            25.06724739074707
        ]
    },
    {
        "cosine_value": 0.04306410253047943,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Richard Nixon",
            "target": "Caretene",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the child of the mother of Richard Nixon is",
            "answer": "Sigismund of Burgundy",
            "subject": "Richard Nixon",
            "target": "Caretene",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the child of Caretene is",
            "answer": "Sigismund of Burgundy",
            "subject": "Caretene",
            "target": "Sigismund of Burgundy",
            "relation": "CHILD"
        },
        "NLL": [
            34.31905746459961,
            36.42617416381836,
            32.62284469604492,
            33.28023147583008,
            31.78324317932129,
            31.738317489624023
        ],
        "orginal_NLL": [
            28.92110252380371,
            29.293655395507812,
            28.609725952148438,
            29.954158782958984,
            29.06070327758789,
            28.776235580444336
        ]
    },
    {
        "cosine_value": -0.021560847759246826,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Richard Nixon",
            "target": "Caretene",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The place of death of the mother of Richard Nixon is",
            "answer": "Lyon",
            "subject": "Richard Nixon",
            "target": "Caretene",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The place of death of Caretene is",
            "answer": "Lyon",
            "subject": "Caretene",
            "target": "Lyon",
            "relation": "PLACE_OF_DEATH"
        },
        "NLL": [
            13.955739974975586,
            14.295705795288086,
            11.641444206237793,
            13.063017845153809,
            11.562824249267578,
            11.399765014648438
        ],
        "orginal_NLL": [
            11.415366172790527,
            14.350934982299805,
            10.625734329223633,
            14.445738792419434,
            9.874628067016602,
            9.583015441894531
        ]
    },
    {
        "cosine_value": -0.059663038700819016,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "2021 Myanmar coup d'\u00e9tat",
            "target": "duchy of Alsace",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the continent which the country 2021 Myanmar coup d'\u00e9tat is associated with is part of is",
            "answer": "Europe",
            "subject": "2021 Myanmar coup d'\u00e9tat",
            "target": "duchy of Alsace",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the continent which duchy of Alsace is part of is",
            "answer": "Europe",
            "subject": "duchy of Alsace",
            "target": "Europe",
            "relation": "CONTINENT"
        },
        "NLL": [
            13.1715087890625,
            12.405227661132812,
            9.719919204711914,
            8.887517929077148,
            8.716748237609863,
            8.227116584777832
        ],
        "orginal_NLL": [
            5.239565372467041,
            10.439329147338867,
            6.973441123962402,
            6.720324516296387,
            6.899707794189453,
            6.77082633972168
        ]
    },
    {
        "cosine_value": -0.0,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "XXX: State of the Union",
            "target": "Rapha\u00ebl Elig",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The gender of the composer of XXX: State of the Union is",
            "answer": "male",
            "subject": "XXX: State of the Union",
            "target": "Rapha\u00ebl Elig",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The gender of Rapha\u00ebl Elig is",
            "answer": "male",
            "subject": "Rapha\u00ebl Elig",
            "target": "male",
            "relation": "SEX_OR_GENDER"
        },
        "NLL": [
            5.055171966552734,
            6.23553466796875,
            2.7878758907318115,
            5.666873455047607,
            4.981067657470703,
            4.98706579208374
        ],
        "orginal_NLL": [
            3.128835439682007,
            9.11690616607666,
            4.819246768951416,
            6.761951923370361,
            3.854976177215576,
            3.9838712215423584
        ]
    },
    {
        "cosine_value": 0.10088127106428146,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "XXX: State of the Union",
            "target": "Rapha\u00ebl Elig",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the alma mater of the composer of XXX: State of the Union is",
            "answer": "\u00c9cole Normale de Musique de Paris Alfred Cortot",
            "subject": "XXX: State of the Union",
            "target": "Rapha\u00ebl Elig",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The name of the alma mater of Rapha\u00ebl Elig is",
            "answer": "\u00c9cole Normale de Musique de Paris Alfred Cortot",
            "subject": "Rapha\u00ebl Elig",
            "target": "\u00c9cole Normale de Musique de Paris Alfred Cortot",
            "relation": "ALMA_MATER"
        },
        "NLL": [
            8.538084983825684,
            10.296369552612305,
            10.334750175476074,
            10.94295597076416,
            7.062086582183838,
            6.859985828399658
        ],
        "orginal_NLL": [
            15.903241157531738,
            17.384201049804688,
            17.40802001953125,
            17.205699920654297,
            16.681379318237305,
            16.266592025756836
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "XXX: State of the Union",
            "target": "Rapha\u00ebl Elig",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The place of birth of the composer of XXX: State of the Union is",
            "answer": "Paris",
            "subject": "XXX: State of the Union",
            "target": "Rapha\u00ebl Elig",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The place of birth of Rapha\u00ebl Elig is",
            "answer": "Paris",
            "subject": "Rapha\u00ebl Elig",
            "target": "Paris",
            "relation": "PLACE_OF_BIRTH"
        },
        "NLL": [
            1.4766002893447876,
            7.393805503845215,
            4.062838554382324,
            4.746719837188721,
            2.6473870277404785,
            2.007721424102783
        ],
        "orginal_NLL": [
            5.412581443786621,
            12.062122344970703,
            7.423515319824219,
            8.938117027282715,
            6.70681619644165,
            6.527099132537842
        ]
    },
    {
        "cosine_value": 0.04085954651236534,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "XXX: State of the Union",
            "target": "Rapha\u00ebl Elig",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the composer of XXX: State of the Union is",
            "answer": "composer",
            "subject": "XXX: State of the Union",
            "target": "Rapha\u00ebl Elig",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The occupation of Rapha\u00ebl Elig is",
            "answer": "composer",
            "subject": "Rapha\u00ebl Elig",
            "target": "composer",
            "relation": "OCCUPATION"
        },
        "NLL": [
            6.930631160736084,
            8.913046836853027,
            7.900514602661133,
            11.775474548339844,
            7.007675647735596,
            6.118871688842773
        ],
        "orginal_NLL": [
            7.620761871337891,
            9.740062713623047,
            9.119784355163574,
            11.585295677185059,
            7.337649345397949,
            7.598991870880127
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "XXX: State of the Union",
            "target": "Rapha\u00ebl Elig",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the country of citizenship of the composer of XXX: State of the Union is",
            "answer": "France",
            "subject": "XXX: State of the Union",
            "target": "Rapha\u00ebl Elig",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The name of the country of citizenship of Rapha\u00ebl Elig is",
            "answer": "France",
            "subject": "Rapha\u00ebl Elig",
            "target": "France",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "NLL": [
            2.5158159732818604,
            2.7568464279174805,
            1.7138950824737549,
            2.81880521774292,
            1.4149115085601807,
            1.4005967378616333
        ],
        "orginal_NLL": [
            3.6861042976379395,
            7.674846649169922,
            5.642055988311768,
            6.721485137939453,
            5.235305309295654,
            4.659808158874512
        ]
    },
    {
        "cosine_value": 0.12996606528759003,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Randhir Kapoor",
            "target": "Adygea",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the capital city of the country of citizenship of Randhir Kapoor is",
            "answer": "Maykop",
            "subject": "Randhir Kapoor",
            "target": "Adygea",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the capital city of Adygea is",
            "answer": "Maykop",
            "subject": "Adygea",
            "target": "Maykop",
            "relation": "CAPITAL"
        },
        "NLL": [
            11.89548397064209,
            12.867877960205078,
            6.04734468460083,
            5.368703365325928,
            5.341398239135742,
            3.8985772132873535
        ],
        "orginal_NLL": [
            15.506898880004883,
            19.59528160095215,
            16.138011932373047,
            16.4854793548584,
            16.02208137512207,
            15.480876922607422
        ]
    },
    {
        "cosine_value": 0.1305447220802307,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Randhir Kapoor",
            "target": "Adygea",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The official language of the country of citizenship of Randhir Kapoor is",
            "answer": "Russian",
            "subject": "Randhir Kapoor",
            "target": "Adygea",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The official language of Adygea is",
            "answer": "Russian",
            "subject": "Adygea",
            "target": "Russian",
            "relation": "OFFICIAL_LANGUAGE"
        },
        "NLL": [
            4.694042682647705,
            6.632497787475586,
            0.5594236254692078,
            0.6331135630607605,
            0.5594713687896729,
            0.3953555226325989
        ],
        "orginal_NLL": [
            8.010396957397461,
            12.937243461608887,
            9.061942100524902,
            8.966548919677734,
            8.297818183898926,
            8.655929565429688
        ]
    },
    {
        "cosine_value": 0.2270001322031021,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Randhir Kapoor",
            "target": "Adygea",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The official language of the country of citizenship of Randhir Kapoor is",
            "answer": "Adyghe",
            "subject": "Randhir Kapoor",
            "target": "Adygea",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The official language of Adygea is",
            "answer": "Adyghe",
            "subject": "Adygea",
            "target": "Adyghe",
            "relation": "OFFICIAL_LANGUAGE"
        },
        "NLL": [
            9.567296028137207,
            9.475232124328613,
            6.164902687072754,
            6.069533824920654,
            5.626213073730469,
            6.714962959289551
        ],
        "orginal_NLL": [
            17.05792236328125,
            19.834596633911133,
            17.383024215698242,
            18.379491806030273,
            17.899301528930664,
            18.354000091552734
        ]
    },
    {
        "cosine_value": 0.2741869390010834,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Randhir Kapoor",
            "target": "Adygea",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the anthem of the country of citizenship of Randhir Kapoor is",
            "answer": "Anthem of the Republic of Adygea",
            "subject": "Randhir Kapoor",
            "target": "Adygea",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the anthem of Adygea is",
            "answer": "Anthem of the Republic of Adygea",
            "subject": "Adygea",
            "target": "Anthem of the Republic of Adygea",
            "relation": "ANTHEM"
        },
        "NLL": [
            15.832513809204102,
            8.834545135498047,
            9.552483558654785,
            9.55704116821289,
            9.660322189331055,
            7.908268451690674
        ],
        "orginal_NLL": [
            27.513837814331055,
            30.770904541015625,
            27.1864070892334,
            26.75437355041504,
            25.770374298095703,
            25.868202209472656
        ]
    },
    {
        "cosine_value": 0.0638706237077713,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Randhir Kapoor",
            "target": "Adygea",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the head of government of the country of citizenship of Randhir Kapoor is",
            "answer": "Murat Kumpilov",
            "subject": "Randhir Kapoor",
            "target": "Adygea",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the head of government of Adygea is",
            "answer": "Murat Kumpilov",
            "subject": "Adygea",
            "target": "Murat Kumpilov",
            "relation": "HEAD_OF_GOVERNMENT"
        },
        "NLL": [
            25.97815704345703,
            25.54900360107422,
            19.11418914794922,
            18.07319450378418,
            18.632047653198242,
            19.029333114624023
        ],
        "orginal_NLL": [
            24.328550338745117,
            32.974998474121094,
            26.357669830322266,
            26.527923583984375,
            25.560142517089844,
            25.825157165527344
        ]
    },
    {
        "cosine_value": 0.28187358379364014,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Taylor Swift",
            "target": "Roman Republic",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the currency in the country of citizenship of Taylor Swift is",
            "answer": "Roman currency",
            "subject": "Taylor Swift",
            "target": "Roman Republic",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the currency in Roman Republic is",
            "answer": "Roman currency",
            "subject": "Roman Republic",
            "target": "Roman currency",
            "relation": "CURRENCY"
        },
        "NLL": [
            6.134970664978027,
            14.285178184509277,
            6.785679817199707,
            6.185805320739746,
            5.26386022567749,
            5.487330436706543
        ],
        "orginal_NLL": [
            18.471725463867188,
            23.072349548339844,
            16.916078567504883,
            16.290771484375,
            16.436227798461914,
            17.385299682617188
        ]
    },
    {
        "cosine_value": 0.13380838930606842,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Taylor Swift",
            "target": "Roman Republic",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the capital city of the country of citizenship of Taylor Swift is",
            "answer": "Rome",
            "subject": "Taylor Swift",
            "target": "Roman Republic",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the capital city of Roman Republic is",
            "answer": "Rome",
            "subject": "Roman Republic",
            "target": "Rome",
            "relation": "CAPITAL"
        },
        "NLL": [
            3.9349660873413086,
            10.590221405029297,
            5.550113677978516,
            4.056878566741943,
            3.4574835300445557,
            3.0920140743255615
        ],
        "orginal_NLL": [
            8.446454048156738,
            12.112375259399414,
            9.356118202209473,
            9.60041618347168,
            8.99919605255127,
            9.138742446899414
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Taylor Swift",
            "target": "Roman Republic",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the capital city of the country of citizenship of Taylor Swift is",
            "answer": "Roma",
            "subject": "Taylor Swift",
            "target": "Roman Republic",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the capital city of Roman Republic is",
            "answer": "Roma",
            "subject": "Roman Republic",
            "target": "Roma",
            "relation": "CAPITAL"
        },
        "NLL": [
            3.1302785873413086,
            8.164440155029297,
            3.1907386779785156,
            3.7834410667419434,
            3.0512332916259766,
            2.3888890743255615
        ],
        "orginal_NLL": [
            12.351727485656738,
            13.41999340057373,
            12.340493202209473,
            12.60236930847168,
            11.600757598876953,
            11.914621353149414
        ]
    },
    {
        "cosine_value": 0.05518631637096405,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Taylor Swift",
            "target": "Roman Republic",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the continent which the country of citizenship of Taylor Swift is part of is",
            "answer": "Europe",
            "subject": "Taylor Swift",
            "target": "Roman Republic",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the continent which Roman Republic is part of is",
            "answer": "Europe",
            "subject": "Roman Republic",
            "target": "Europe",
            "relation": "CONTINENT"
        },
        "NLL": [
            5.4941582679748535,
            13.524145126342773,
            7.162383079528809,
            6.324707508087158,
            5.316201686859131,
            5.032047748565674
        ],
        "orginal_NLL": [
            3.0231237411499023,
            6.671031951904297,
            5.479252338409424,
            6.310247898101807,
            5.80992317199707,
            4.799345970153809
        ]
    },
    {
        "cosine_value": 0.062184881418943405,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Taylor Swift",
            "target": "Roman Republic",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the continent which the country of citizenship of Taylor Swift is part of is",
            "answer": "Asia",
            "subject": "Taylor Swift",
            "target": "Roman Republic",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the continent which Roman Republic is part of is",
            "answer": "Asia",
            "subject": "Roman Republic",
            "target": "Asia",
            "relation": "CONTINENT"
        },
        "NLL": [
            4.4941582679748535,
            10.643285751342773,
            7.568633079528809,
            6.355957508087158,
            5.503701686859131,
            5.571110248565674
        ],
        "orginal_NLL": [
            3.2418737411499023,
            6.592906475067139,
            6.221439838409424,
            6.521185398101807,
            5.01304817199707,
            5.189970970153809
        ]
    },
    {
        "cosine_value": 0.06143271550536156,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Taylor Swift",
            "target": "Roman Republic",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the continent which the country of citizenship of Taylor Swift is part of is",
            "answer": "Africa",
            "subject": "Taylor Swift",
            "target": "Roman Republic",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the continent which Roman Republic is part of is",
            "answer": "Africa",
            "subject": "Roman Republic",
            "target": "Africa",
            "relation": "CONTINENT"
        },
        "NLL": [
            8.447283744812012,
            11.885473251342773,
            9.685820579528809,
            8.34814453125,
            8.460732460021973,
            8.012516975402832
        ],
        "orginal_NLL": [
            5.093436241149902,
            7.842906951904297,
            6.658939838409424,
            6.560247898101807,
            6.11070442199707,
            5.143095970153809
        ]
    },
    {
        "cosine_value": 0.18515858054161072,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Anya Taylor-Joy",
            "target": "Faroe Islands",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The official language of the country of citizenship of Anya Taylor-Joy is",
            "answer": "Faroese",
            "subject": "Anya Taylor-Joy",
            "target": "Faroe Islands",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The official language of Faroe Islands is",
            "answer": "Faroese",
            "subject": "Faroe Islands",
            "target": "Faroese",
            "relation": "OFFICIAL_LANGUAGE"
        },
        "NLL": [
            9.07044506072998,
            11.959056854248047,
            3.0865964889526367,
            2.953082323074341,
            2.6074306964874268,
            4.49189567565918
        ],
        "orginal_NLL": [
            14.160116195678711,
            16.285192489624023,
            13.764688491821289,
            14.64085865020752,
            13.931983947753906,
            14.66920280456543
        ]
    },
    {
        "cosine_value": 0.026490774005651474,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Anya Taylor-Joy",
            "target": "Faroe Islands",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The official language of the country of citizenship of Anya Taylor-Joy is",
            "answer": "Danish",
            "subject": "Anya Taylor-Joy",
            "target": "Faroe Islands",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The official language of Faroe Islands is",
            "answer": "Danish",
            "subject": "Faroe Islands",
            "target": "Danish",
            "relation": "OFFICIAL_LANGUAGE"
        },
        "NLL": [
            15.351940155029297,
            15.485288619995117,
            7.88518762588501,
            7.376194953918457,
            7.854124546051025,
            7.457545757293701
        ],
        "orginal_NLL": [
            11.07271671295166,
            13.712495803833008,
            10.194342613220215,
            10.029239654541016,
            10.200579643249512,
            10.235757827758789
        ]
    },
    {
        "cosine_value": 0.20665940642356873,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Anya Taylor-Joy",
            "target": "Faroe Islands",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the currency in the country of citizenship of Anya Taylor-Joy is",
            "answer": "Faroese kr\u00f3na",
            "subject": "Anya Taylor-Joy",
            "target": "Faroe Islands",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the currency in Faroe Islands is",
            "answer": "Faroese kr\u00f3na",
            "subject": "Faroe Islands",
            "target": "Faroese kr\u00f3na",
            "relation": "CURRENCY"
        },
        "NLL": [
            10.603571891784668,
            12.221894264221191,
            5.292211055755615,
            4.1334309577941895,
            3.3879222869873047,
            4.13114070892334
        ],
        "orginal_NLL": [
            15.470254898071289,
            19.030088424682617,
            15.6480712890625,
            16.162883758544922,
            16.3316707611084,
            17.093358993530273
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Anya Taylor-Joy",
            "target": "Faroe Islands",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the anthem of the country of citizenship of Anya Taylor-Joy is",
            "answer": "T\u00fa alfagra land m\u00edtt",
            "subject": "Anya Taylor-Joy",
            "target": "Faroe Islands",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the anthem of Faroe Islands is",
            "answer": "T\u00fa alfagra land m\u00edtt",
            "subject": "Faroe Islands",
            "target": "T\u00fa alfagra land m\u00edtt",
            "relation": "ANTHEM"
        },
        "NLL": [
            41.54043197631836,
            42.84120178222656,
            31.93621063232422,
            31.73066520690918,
            34.048248291015625,
            34.699405670166016
        ],
        "orginal_NLL": [
            36.50752258300781,
            40.31041717529297,
            31.984346389770508,
            30.720802307128906,
            31.540231704711914,
            32.924705505371094
        ]
    },
    {
        "cosine_value": 0.014177877455949783,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Anya Taylor-Joy",
            "target": "Faroe Islands",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the capital city of the country of citizenship of Anya Taylor-Joy is",
            "answer": "T\u00f3rshavn",
            "subject": "Anya Taylor-Joy",
            "target": "Faroe Islands",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the capital city of Faroe Islands is",
            "answer": "T\u00f3rshavn",
            "subject": "Faroe Islands",
            "target": "T\u00f3rshavn",
            "relation": "CAPITAL"
        },
        "NLL": [
            13.56548023223877,
            20.7799015045166,
            10.829384803771973,
            11.504209518432617,
            12.423203468322754,
            12.347538948059082
        ],
        "orginal_NLL": [
            15.514946937561035,
            15.063567161560059,
            15.237052917480469,
            15.047011375427246,
            15.225677490234375,
            15.501786231994629
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Anya Taylor-Joy",
            "target": "Faroe Islands",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the head of government of the country of citizenship of Anya Taylor-Joy is",
            "answer": "Aksel V. Johannesen",
            "subject": "Anya Taylor-Joy",
            "target": "Faroe Islands",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the head of government of Faroe Islands is",
            "answer": "Aksel V. Johannesen",
            "subject": "Faroe Islands",
            "target": "Aksel V. Johannesen",
            "relation": "HEAD_OF_GOVERNMENT"
        },
        "NLL": [
            32.65650177001953,
            38.92079162597656,
            32.991050720214844,
            31.90672492980957,
            30.873321533203125,
            30.801321029663086
        ],
        "orginal_NLL": [
            29.577260971069336,
            34.623085021972656,
            31.258420944213867,
            31.480030059814453,
            31.14260482788086,
            31.53122329711914
        ]
    },
    {
        "cosine_value": 0.12823791801929474,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Anya Taylor-Joy",
            "target": "Faroe Islands",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the continent which the country of citizenship of Anya Taylor-Joy is part of is",
            "answer": "Europe",
            "subject": "Anya Taylor-Joy",
            "target": "Faroe Islands",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the continent which Faroe Islands is part of is",
            "answer": "Europe",
            "subject": "Faroe Islands",
            "target": "Europe",
            "relation": "CONTINENT"
        },
        "NLL": [
            8.669398307800293,
            14.419310569763184,
            9.3027982711792,
            8.020333290100098,
            8.032721519470215,
            7.37587308883667
        ],
        "orginal_NLL": [
            2.5764307975769043,
            6.800494194030762,
            5.140326499938965,
            5.641037940979004,
            5.185753345489502,
            4.2418012619018555
        ]
    },
    {
        "cosine_value": 0.017519639804959297,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Anya Taylor-Joy",
            "target": "Faroe Islands",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the head of state of the country of citizenship of Anya Taylor-Joy is",
            "answer": "Margrethe II of Denmark",
            "subject": "Anya Taylor-Joy",
            "target": "Faroe Islands",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the head of state of Faroe Islands is",
            "answer": "Margrethe II of Denmark",
            "subject": "Faroe Islands",
            "target": "Margrethe II of Denmark",
            "relation": "HEAD_OF_STATE"
        },
        "NLL": [
            18.322694778442383,
            21.65341567993164,
            16.028444290161133,
            17.043970108032227,
            16.270702362060547,
            16.950008392333984
        ],
        "orginal_NLL": [
            16.434152603149414,
            22.21468162536621,
            17.80129051208496,
            18.689712524414062,
            18.18754768371582,
            18.41481590270996
        ]
    },
    {
        "cosine_value": 0.14368829131126404,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "Kwanzaa",
            "target": "Bogd Khanate of Mongolia",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the capital city of the country Kwanzaa is associated with is",
            "answer": "Ulaanbaatar",
            "subject": "Kwanzaa",
            "target": "Bogd Khanate of Mongolia",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the capital city of Bogd Khanate of Mongolia is",
            "answer": "Ulaanbaatar",
            "subject": "Bogd Khanate of Mongolia",
            "target": "Ulaanbaatar",
            "relation": "CAPITAL"
        },
        "NLL": [
            9.714150428771973,
            13.13637924194336,
            10.32699966430664,
            10.74774169921875,
            9.042070388793945,
            9.509481430053711
        ],
        "orginal_NLL": [
            12.789323806762695,
            22.66415786743164,
            17.020063400268555,
            17.60434913635254,
            14.472136497497559,
            14.787742614746094
        ]
    },
    {
        "cosine_value": -0.12403809279203415,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "Kwanzaa",
            "target": "Bogd Khanate of Mongolia",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The official language of the country Kwanzaa is associated with is",
            "answer": "Mongolian",
            "subject": "Kwanzaa",
            "target": "Bogd Khanate of Mongolia",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The official language of Bogd Khanate of Mongolia is",
            "answer": "Mongolian",
            "subject": "Bogd Khanate of Mongolia",
            "target": "Mongolian",
            "relation": "OFFICIAL_LANGUAGE"
        },
        "NLL": [
            4.521904468536377,
            6.9186811447143555,
            5.507355690002441,
            5.465246200561523,
            6.369039058685303,
            5.999020099639893
        ],
        "orginal_NLL": [
            15.509763717651367,
            16.507644653320312,
            14.01855754852295,
            14.277877807617188,
            13.59813404083252,
            13.545519828796387
        ]
    },
    {
        "cosine_value": 0.12892091274261475,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "Kwanzaa",
            "target": "Bogd Khanate of Mongolia",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the currency in the country Kwanzaa is associated with is",
            "answer": "tael",
            "subject": "Kwanzaa",
            "target": "Bogd Khanate of Mongolia",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the currency in Bogd Khanate of Mongolia is",
            "answer": "tael",
            "subject": "Bogd Khanate of Mongolia",
            "target": "tael",
            "relation": "CURRENCY"
        },
        "NLL": [
            16.413572311401367,
            19.80996322631836,
            15.929774284362793,
            15.521687507629395,
            14.822157859802246,
            14.04650592803955
        ],
        "orginal_NLL": [
            18.259946823120117,
            24.81946563720703,
            19.090259552001953,
            18.828567504882812,
            18.04920768737793,
            17.23768424987793
        ]
    },
    {
        "cosine_value": -0.028603024780750275,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "Kwanzaa",
            "target": "Bogd Khanate of Mongolia",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the currency in the country Kwanzaa is associated with is",
            "answer": "ruble",
            "subject": "Kwanzaa",
            "target": "Bogd Khanate of Mongolia",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the currency in Bogd Khanate of Mongolia is",
            "answer": "ruble",
            "subject": "Bogd Khanate of Mongolia",
            "target": "ruble",
            "relation": "CURRENCY"
        },
        "NLL": [
            18.28812026977539,
            15.871357917785645,
            14.084871292114258,
            14.880573272705078,
            14.8732328414917,
            14.482702255249023
        ],
        "orginal_NLL": [
            10.571663856506348,
            16.658912658691406,
            12.409564971923828,
            13.342170715332031,
            12.661425590515137,
            11.9174165725708
        ]
    },
    {
        "cosine_value": -0.10499336570501328,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "Kwanzaa",
            "target": "Bogd Khanate of Mongolia",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the currency in the country Kwanzaa is associated with is",
            "answer": "Mongolian dollar",
            "subject": "Kwanzaa",
            "target": "Bogd Khanate of Mongolia",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the currency in Bogd Khanate of Mongolia is",
            "answer": "Mongolian dollar",
            "subject": "Bogd Khanate of Mongolia",
            "target": "Mongolian dollar",
            "relation": "CURRENCY"
        },
        "NLL": [
            17.575408935546875,
            17.11090660095215,
            15.853375434875488,
            15.021596908569336,
            15.311667442321777,
            14.990365028381348
        ],
        "orginal_NLL": [
            18.725696563720703,
            22.904117584228516,
            20.018367767333984,
            19.87242317199707,
            19.2078914642334,
            18.810382843017578
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "Kwanzaa",
            "target": "Bogd Khanate of Mongolia",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the continent which the country Kwanzaa is associated with is part of is",
            "answer": "Asia",
            "subject": "Kwanzaa",
            "target": "Bogd Khanate of Mongolia",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the continent which Bogd Khanate of Mongolia is part of is",
            "answer": "Asia",
            "subject": "Bogd Khanate of Mongolia",
            "target": "Asia",
            "relation": "CONTINENT"
        },
        "NLL": [
            9.498658180236816,
            10.156610488891602,
            10.023494720458984,
            9.123830795288086,
            6.652865409851074,
            7.543323040008545
        ],
        "orginal_NLL": [
            5.1755523681640625,
            9.959479331970215,
            7.051684856414795,
            7.782413959503174,
            5.73604154586792,
            6.1955413818359375
        ]
    },
    {
        "cosine_value": -0.04803250730037689,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "states and union territories of India",
            "target": "Province of Carolina",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the continent which the country states and union territories of India is associated with is part of is",
            "answer": "North America",
            "subject": "states and union territories of India",
            "target": "Province of Carolina",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the continent which Province of Carolina is part of is",
            "answer": "North America",
            "subject": "Province of Carolina",
            "target": "North America",
            "relation": "CONTINENT"
        },
        "NLL": [
            10.56373119354248,
            18.748615264892578,
            10.074687957763672,
            10.615406036376953,
            9.820072174072266,
            10.155924797058105
        ],
        "orginal_NLL": [
            7.898294925689697,
            14.473485946655273,
            9.274086952209473,
            8.854471206665039,
            8.210960388183594,
            8.459342002868652
        ]
    },
    {
        "cosine_value": 0.02189885452389717,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "states and union territories of India",
            "target": "Province of Carolina",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the capital city of the country states and union territories of India is associated with is",
            "answer": "Charleston",
            "subject": "states and union territories of India",
            "target": "Province of Carolina",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the capital city of Province of Carolina is",
            "answer": "Charleston",
            "subject": "Province of Carolina",
            "target": "Charleston",
            "relation": "CAPITAL"
        },
        "NLL": [
            18.436641693115234,
            21.869552612304688,
            17.678794860839844,
            18.347620010375977,
            17.425817489624023,
            18.28873062133789
        ],
        "orginal_NLL": [
            16.159595489501953,
            21.655128479003906,
            17.6427001953125,
            18.032379150390625,
            16.58646583557129,
            16.861845016479492
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "Hurricane Ida",
            "target": "Grand Principality of Serbia",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The official language of the country Hurricane Ida is associated with is",
            "answer": "Serbian",
            "subject": "Hurricane Ida",
            "target": "Grand Principality of Serbia",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The official language of Grand Principality of Serbia is",
            "answer": "Serbian",
            "subject": "Grand Principality of Serbia",
            "target": "Serbian",
            "relation": "OFFICIAL_LANGUAGE"
        },
        "NLL": [
            13.084136962890625,
            15.220081329345703,
            9.397859573364258,
            9.270379066467285,
            8.71372127532959,
            8.241040229797363
        ],
        "orginal_NLL": [
            9.695113182067871,
            15.064151763916016,
            10.073369979858398,
            9.39128303527832,
            9.376530647277832,
            9.078291893005371
        ]
    },
    {
        "cosine_value": 0.0900316834449768,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "Hurricane Ida",
            "target": "Grand Principality of Serbia",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the capital city of the country Hurricane Ida is associated with is",
            "answer": "Stari Ras",
            "subject": "Hurricane Ida",
            "target": "Grand Principality of Serbia",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the capital city of Grand Principality of Serbia is",
            "answer": "Stari Ras",
            "subject": "Grand Principality of Serbia",
            "target": "Stari Ras",
            "relation": "CAPITAL"
        },
        "NLL": [
            34.46049499511719,
            32.64600372314453,
            29.7009220123291,
            29.810361862182617,
            29.263410568237305,
            28.84307861328125
        ],
        "orginal_NLL": [
            23.350852966308594,
            29.16387367248535,
            25.16318702697754,
            25.724245071411133,
            24.524106979370117,
            24.141469955444336
        ]
    },
    {
        "cosine_value": 0.048571255058050156,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "Hurricane Ida",
            "target": "Grand Principality of Serbia",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the continent which the country Hurricane Ida is associated with is part of is",
            "answer": "Europe",
            "subject": "Hurricane Ida",
            "target": "Grand Principality of Serbia",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the continent which Grand Principality of Serbia is part of is",
            "answer": "Europe",
            "subject": "Grand Principality of Serbia",
            "target": "Europe",
            "relation": "CONTINENT"
        },
        "NLL": [
            5.837601661682129,
            9.753249168395996,
            7.308338642120361,
            7.329285621643066,
            6.634696006774902,
            6.480108261108398
        ],
        "orginal_NLL": [
            3.9263153076171875,
            8.83137321472168,
            6.487874507904053,
            7.100612163543701,
            6.168004989624023,
            5.2673659324646
        ]
    },
    {
        "cosine_value": 0.1362350881099701,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "LeBron James",
            "target": "Malawi",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the continent which the country of citizenship of LeBron James is part of is",
            "answer": "Africa",
            "subject": "LeBron James",
            "target": "Malawi",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the continent which Malawi is part of is",
            "answer": "Africa",
            "subject": "Malawi",
            "target": "Africa",
            "relation": "CONTINENT"
        },
        "NLL": [
            4.495885848999023,
            9.210244178771973,
            4.7357940673828125,
            5.586302280426025,
            3.5490877628326416,
            2.3509955406188965
        ],
        "orginal_NLL": [
            2.404557704925537,
            6.516758441925049,
            4.814985275268555,
            4.7840752601623535,
            4.010232925415039,
            3.2583794593811035
        ]
    },
    {
        "cosine_value": 0.11893865466117859,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "LeBron James",
            "target": "Malawi",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the capital city of the country of citizenship of LeBron James is",
            "answer": "Lilongwe",
            "subject": "LeBron James",
            "target": "Malawi",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the capital city of Malawi is",
            "answer": "Lilongwe",
            "subject": "Malawi",
            "target": "Lilongwe",
            "relation": "CAPITAL"
        },
        "NLL": [
            2.5335545539855957,
            5.412153720855713,
            2.7466769218444824,
            3.0947043895721436,
            2.4684176445007324,
            1.577038288116455
        ],
        "orginal_NLL": [
            13.206663131713867,
            14.690837860107422,
            15.521269798278809,
            15.157949447631836,
            14.875598907470703,
            14.41348648071289
        ]
    },
    {
        "cosine_value": -0.08813154697418213,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "LeBron James",
            "target": "Malawi",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The official language of the country of citizenship of LeBron James is",
            "answer": "English",
            "subject": "LeBron James",
            "target": "Malawi",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The official language of Malawi is",
            "answer": "English",
            "subject": "Malawi",
            "target": "English",
            "relation": "OFFICIAL_LANGUAGE"
        },
        "NLL": [
            3.4506137371063232,
            9.738883972167969,
            3.039968252182007,
            4.583822250366211,
            2.2240912914276123,
            1.8136754035949707
        ],
        "orginal_NLL": [
            0.8027140498161316,
            5.32961368560791,
            2.8647875785827637,
            3.401538610458374,
            2.3466196060180664,
            2.3992512226104736
        ]
    },
    {
        "cosine_value": 0.07627133280038834,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "LeBron James",
            "target": "Malawi",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The official language of the country of citizenship of LeBron James is",
            "answer": "Chewa",
            "subject": "LeBron James",
            "target": "Malawi",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The official language of Malawi is",
            "answer": "Chewa",
            "subject": "Malawi",
            "target": "Chewa",
            "relation": "OFFICIAL_LANGUAGE"
        },
        "NLL": [
            8.939370155334473,
            12.923383712768555,
            8.900205612182617,
            10.421140670776367,
            8.030856132507324,
            7.607190132141113
        ],
        "orginal_NLL": [
            13.913415908813477,
            17.523252487182617,
            16.112825393676758,
            17.340837478637695,
            16.56110382080078,
            16.911794662475586
        ]
    },
    {
        "cosine_value": 0.10644286125898361,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "LeBron James",
            "target": "Malawi",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the head of state of the country of citizenship of LeBron James is",
            "answer": "Lazarus Chakwera",
            "subject": "LeBron James",
            "target": "Malawi",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the head of state of Malawi is",
            "answer": "Lazarus Chakwera",
            "subject": "Malawi",
            "target": "Lazarus Chakwera",
            "relation": "HEAD_OF_STATE"
        },
        "NLL": [
            8.440126419067383,
            13.409456253051758,
            9.417219161987305,
            11.89864444732666,
            8.965156555175781,
            8.509296417236328
        ],
        "orginal_NLL": [
            16.21165657043457,
            20.564863204956055,
            17.77213478088379,
            17.9146785736084,
            17.16368865966797,
            17.236373901367188
        ]
    },
    {
        "cosine_value": 0.35685086250305176,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "LeBron James",
            "target": "Malawi",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the currency in the country of citizenship of LeBron James is",
            "answer": "Malawian kwacha",
            "subject": "LeBron James",
            "target": "Malawi",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the currency in Malawi is",
            "answer": "Malawian kwacha",
            "subject": "Malawi",
            "target": "Malawian kwacha",
            "relation": "CURRENCY"
        },
        "NLL": [
            4.511661529541016,
            7.133566379547119,
            3.2346229553222656,
            5.750913143157959,
            2.1243317127227783,
            2.0114312171936035
        ],
        "orginal_NLL": [
            14.776264190673828,
            17.401870727539062,
            16.162017822265625,
            16.340417861938477,
            16.701438903808594,
            16.71640968322754
        ]
    },
    {
        "cosine_value": 0.03751983866095543,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "LeBron James",
            "target": "Malawi",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the anthem of the country of citizenship of LeBron James is",
            "answer": "Mulungu dalitsa Mala\u0175i",
            "subject": "LeBron James",
            "target": "Malawi",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the anthem of Malawi is",
            "answer": "Mulungu dalitsa Mala\u0175i",
            "subject": "Malawi",
            "target": "Mulungu dalitsa Mala\u0175i",
            "relation": "ANTHEM"
        },
        "NLL": [
            41.19353485107422,
            42.53306198120117,
            39.084381103515625,
            41.84886932373047,
            39.25849914550781,
            39.36896514892578
        ],
        "orginal_NLL": [
            45.631874084472656,
            46.536678314208984,
            45.79412078857422,
            47.691287994384766,
            46.97283172607422,
            47.79287338256836
        ]
    },
    {
        "cosine_value": 0.1348658949136734,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "LeBron James",
            "target": "Malawi",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the head of government of the country of citizenship of LeBron James is",
            "answer": "Lazarus Chakwera",
            "subject": "LeBron James",
            "target": "Malawi",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the head of government of Malawi is",
            "answer": "Lazarus Chakwera",
            "subject": "Malawi",
            "target": "Lazarus Chakwera",
            "relation": "HEAD_OF_GOVERNMENT"
        },
        "NLL": [
            8.273850440979004,
            13.034671783447266,
            9.0774507522583,
            11.358596801757812,
            8.463417053222656,
            8.054591178894043
        ],
        "orginal_NLL": [
            16.81966781616211,
            20.994102478027344,
            17.12421226501465,
            17.16623878479004,
            16.606002807617188,
            16.740398406982422
        ]
    },
    {
        "cosine_value": 0.19537845253944397,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "John Prine",
            "target": "Italian Republic",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the currency in the country of citizenship of John Prine is",
            "answer": "Milanese scudo",
            "subject": "John Prine",
            "target": "Italian Republic",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the currency in Italian Republic is",
            "answer": "Milanese scudo",
            "subject": "Italian Republic",
            "target": "Milanese scudo",
            "relation": "CURRENCY"
        },
        "NLL": [
            31.1747989654541,
            23.744613647460938,
            26.7673282623291,
            26.39795684814453,
            27.434200286865234,
            28.856698989868164
        ],
        "orginal_NLL": [
            23.395238876342773,
            23.924894332885742,
            21.4379825592041,
            23.424266815185547,
            23.76949691772461,
            23.7782039642334
        ]
    },
    {
        "cosine_value": 0.14276500046253204,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "John Prine",
            "target": "Italian Republic",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the continent which the country of citizenship of John Prine is part of is",
            "answer": "Europe",
            "subject": "John Prine",
            "target": "Italian Republic",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the continent which Italian Republic is part of is",
            "answer": "Europe",
            "subject": "Italian Republic",
            "target": "Europe",
            "relation": "CONTINENT"
        },
        "NLL": [
            3.3078110218048096,
            8.362220764160156,
            6.537348747253418,
            7.226562023162842,
            5.955106735229492,
            6.8226318359375
        ],
        "orginal_NLL": [
            3.593156576156616,
            6.625535011291504,
            5.865866184234619,
            6.73858118057251,
            5.956669807434082,
            4.621637344360352
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "John Prine",
            "target": "Italian Republic",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the capital city of the country of citizenship of John Prine is",
            "answer": "Milan",
            "subject": "John Prine",
            "target": "Italian Republic",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the capital city of Italian Republic is",
            "answer": "Milan",
            "subject": "Italian Republic",
            "target": "Milan",
            "relation": "CAPITAL"
        },
        "NLL": [
            18.16126823425293,
            10.660608291625977,
            9.638763427734375,
            12.467893600463867,
            10.002311706542969,
            10.462437629699707
        ],
        "orginal_NLL": [
            9.716165542602539,
            10.739301681518555,
            10.020448684692383,
            11.43231201171875,
            10.108271598815918,
            10.057284355163574
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "John Prine",
            "target": "Italian Republic",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The official language of the country of citizenship of John Prine is",
            "answer": "Italian",
            "subject": "John Prine",
            "target": "Italian Republic",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The official language of Italian Republic is",
            "answer": "Italian",
            "subject": "Italian Republic",
            "target": "Italian",
            "relation": "OFFICIAL_LANGUAGE"
        },
        "NLL": [
            3.943265199661255,
            4.045812129974365,
            0.2969701588153839,
            0.4173178970813751,
            0.17496788501739502,
            0.5713622570037842
        ],
        "orginal_NLL": [
            7.282111644744873,
            9.68809986114502,
            7.252658367156982,
            7.264137268066406,
            6.955249309539795,
            7.187824726104736
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Ted Kaczynski",
            "target": "Mary Kennedy",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The gender of the mother of Ted Kaczynski is",
            "answer": "female",
            "subject": "Ted Kaczynski",
            "target": "Mary Kennedy",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The gender of Mary Kennedy is",
            "answer": "female",
            "subject": "Mary Kennedy",
            "target": "female",
            "relation": "SEX_OR_GENDER"
        },
        "NLL": [
            8.763710975646973,
            8.628435134887695,
            7.3172526359558105,
            8.890218734741211,
            5.919909954071045,
            5.757761001586914
        ],
        "orginal_NLL": [
            4.029147148132324,
            9.638813972473145,
            6.345209121704102,
            7.51378870010376,
            5.096500873565674,
            5.033604621887207
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Ted Kaczynski",
            "target": "Mary Kennedy",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the child of the mother of Ted Kaczynski is",
            "answer": "Clare Rolston",
            "subject": "Ted Kaczynski",
            "target": "Mary Kennedy",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the child of Mary Kennedy is",
            "answer": "Clare Rolston",
            "subject": "Mary Kennedy",
            "target": "Clare Rolston",
            "relation": "CHILD"
        },
        "NLL": [
            33.99257278442383,
            34.451011657714844,
            34.63416290283203,
            38.02088165283203,
            33.851356506347656,
            32.918800354003906
        ],
        "orginal_NLL": [
            29.254610061645508,
            30.085065841674805,
            29.702733993530273,
            31.541635513305664,
            28.599899291992188,
            27.90531349182129
        ]
    },
    {
        "cosine_value": -0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Ted Kaczynski",
            "target": "Mary Kennedy",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the spouse of the mother of Ted Kaczynski is",
            "answer": "George Rolston",
            "subject": "Ted Kaczynski",
            "target": "Mary Kennedy",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the spouse of Mary Kennedy is",
            "answer": "George Rolston",
            "subject": "Mary Kennedy",
            "target": "George Rolston",
            "relation": "SPOUSE"
        },
        "NLL": [
            29.060827255249023,
            28.66604995727539,
            26.40308380126953,
            26.993759155273438,
            25.762096405029297,
            25.9488525390625
        ],
        "orginal_NLL": [
            27.394750595092773,
            29.88636016845703,
            26.735740661621094,
            27.6685848236084,
            25.739402770996094,
            25.826616287231445
        ]
    },
    {
        "cosine_value": 0.027108902111649513,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "Kobe Bryant sexual assault case",
            "target": "Narnia",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the head of state of the country Kobe Bryant sexual assault case is associated with is",
            "answer": "Tirian",
            "subject": "Kobe Bryant sexual assault case",
            "target": "Narnia",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the head of state of Narnia is",
            "answer": "Tirian",
            "subject": "Narnia",
            "target": "Tirian",
            "relation": "HEAD_OF_STATE"
        },
        "NLL": [
            15.036386489868164,
            23.063974380493164,
            16.860857009887695,
            20.161361694335938,
            16.754173278808594,
            15.717460632324219
        ],
        "orginal_NLL": [
            18.58976173400879,
            24.639881134033203,
            20.07295036315918,
            21.065900802612305,
            20.524709701538086,
            20.45343589782715
        ]
    },
    {
        "cosine_value": 0.0037618468049913645,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "Kobe Bryant sexual assault case",
            "target": "Narnia",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the head of state of the country Kobe Bryant sexual assault case is associated with is",
            "answer": "Miraz",
            "subject": "Kobe Bryant sexual assault case",
            "target": "Narnia",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the head of state of Narnia is",
            "answer": "Miraz",
            "subject": "Narnia",
            "target": "Miraz",
            "relation": "HEAD_OF_STATE"
        },
        "NLL": [
            14.208112716674805,
            20.165145874023438,
            17.44701385498047,
            20.666488647460938,
            15.879597663879395,
            15.684988021850586
        ],
        "orginal_NLL": [
            18.86287498474121,
            21.15428352355957,
            17.757354736328125,
            18.715383529663086,
            17.378618240356445,
            17.683168411254883
        ]
    },
    {
        "cosine_value": -0.043800681829452515,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "Kobe Bryant sexual assault case",
            "target": "Narnia",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the head of state of the country Kobe Bryant sexual assault case is associated with is",
            "answer": "Frank",
            "subject": "Kobe Bryant sexual assault case",
            "target": "Narnia",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the head of state of Narnia is",
            "answer": "Frank",
            "subject": "Narnia",
            "target": "Frank",
            "relation": "HEAD_OF_STATE"
        },
        "NLL": [
            7.453079700469971,
            14.81261157989502,
            9.765438079833984,
            13.37271499633789,
            9.232942581176758,
            9.006024360656738
        ],
        "orginal_NLL": [
            8.509095191955566,
            13.878042221069336,
            7.944462299346924,
            8.943857192993164,
            8.510087013244629,
            8.304835319519043
        ]
    },
    {
        "cosine_value": 0.04497002437710762,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "Kobe Bryant sexual assault case",
            "target": "Narnia",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the head of state of the country Kobe Bryant sexual assault case is associated with is",
            "answer": "Peter Pevensie",
            "subject": "Kobe Bryant sexual assault case",
            "target": "Narnia",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the head of state of Narnia is",
            "answer": "Peter Pevensie",
            "subject": "Narnia",
            "target": "Peter Pevensie",
            "relation": "HEAD_OF_STATE"
        },
        "NLL": [
            12.33042049407959,
            20.73040008544922,
            14.72217082977295,
            15.866621017456055,
            13.01967716217041,
            12.370695114135742
        ],
        "orginal_NLL": [
            20.781091690063477,
            28.15582847595215,
            20.942283630371094,
            21.596656799316406,
            21.471757888793945,
            21.138896942138672
        ]
    },
    {
        "cosine_value": 0.13304921984672546,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "Kobe Bryant sexual assault case",
            "target": "Narnia",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the head of state of the country Kobe Bryant sexual assault case is associated with is",
            "answer": "White Witch",
            "subject": "Kobe Bryant sexual assault case",
            "target": "Narnia",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the head of state of Narnia is",
            "answer": "White Witch",
            "subject": "Narnia",
            "target": "White Witch",
            "relation": "HEAD_OF_STATE"
        },
        "NLL": [
            10.8189058303833,
            17.16115379333496,
            12.546028137207031,
            15.035904884338379,
            11.103250503540039,
            10.701972961425781
        ],
        "orginal_NLL": [
            18.987316131591797,
            23.569305419921875,
            17.743793487548828,
            17.21993064880371,
            17.502735137939453,
            17.007335662841797
        ]
    },
    {
        "cosine_value": -0.02520795352756977,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "Kobe Bryant sexual assault case",
            "target": "Narnia",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the head of state of the country Kobe Bryant sexual assault case is associated with is",
            "answer": "Prince Caspian",
            "subject": "Kobe Bryant sexual assault case",
            "target": "Narnia",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the head of state of Narnia is",
            "answer": "Prince Caspian",
            "subject": "Narnia",
            "target": "Prince Caspian",
            "relation": "HEAD_OF_STATE"
        },
        "NLL": [
            13.919454574584961,
            19.374019622802734,
            15.663713455200195,
            18.132810592651367,
            14.246493339538574,
            13.374231338500977
        ],
        "orginal_NLL": [
            16.571414947509766,
            22.662601470947266,
            16.473026275634766,
            16.794286727905273,
            16.363204956054688,
            16.511680603027344
        ]
    },
    {
        "cosine_value": 0.04883016273379326,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "Kobe Bryant sexual assault case",
            "target": "Narnia",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the head of state of the country Kobe Bryant sexual assault case is associated with is",
            "answer": "Rilian",
            "subject": "Kobe Bryant sexual assault case",
            "target": "Narnia",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the head of state of Narnia is",
            "answer": "Rilian",
            "subject": "Narnia",
            "target": "Rilian",
            "relation": "HEAD_OF_STATE"
        },
        "NLL": [
            13.802632331848145,
            21.773340225219727,
            16.44661521911621,
            19.497482299804688,
            15.65961742401123,
            14.909759521484375
        ],
        "orginal_NLL": [
            16.83935546875,
            26.38325309753418,
            16.705060958862305,
            16.710556030273438,
            16.38435935974121,
            16.3529109954834
        ]
    },
    {
        "cosine_value": 0.1461028903722763,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "Kobe Bryant sexual assault case",
            "target": "Narnia",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the capital city of the country Kobe Bryant sexual assault case is associated with is",
            "answer": "Cair Paravel",
            "subject": "Kobe Bryant sexual assault case",
            "target": "Narnia",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the capital city of Narnia is",
            "answer": "Cair Paravel",
            "subject": "Narnia",
            "target": "Cair Paravel",
            "relation": "CAPITAL"
        },
        "NLL": [
            15.471770286560059,
            21.600852966308594,
            15.263428688049316,
            18.24448013305664,
            13.51186752319336,
            13.372825622558594
        ],
        "orginal_NLL": [
            22.912025451660156,
            29.044187545776367,
            23.846267700195312,
            23.75541114807129,
            23.805313110351562,
            23.99938201904297
        ]
    },
    {
        "cosine_value": 0.09976212680339813,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the composer of The Swimmers is",
            "answer": "singer-songwriter",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The occupation of Pete Townshend is",
            "answer": "singer-songwriter",
            "subject": "Pete Townshend",
            "target": "singer-songwriter",
            "relation": "OCCUPATION"
        },
        "NLL": [
            14.398862838745117,
            14.991189002990723,
            15.776281356811523,
            15.776883125305176,
            15.197830200195312,
            15.893904685974121
        ],
        "orginal_NLL": [
            8.159614562988281,
            13.271608352661133,
            12.699092864990234,
            12.95993709564209,
            10.099760055541992,
            11.340178489685059
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the composer of The Swimmers is",
            "answer": "guitarist",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The occupation of Pete Townshend is",
            "answer": "guitarist",
            "subject": "Pete Townshend",
            "target": "guitarist",
            "relation": "OCCUPATION"
        },
        "NLL": [
            13.679895401000977,
            13.79312515258789,
            13.999774932861328,
            14.892184257507324,
            13.876418113708496,
            13.415358543395996
        ],
        "orginal_NLL": [
            9.332763671875,
            13.569703102111816,
            12.543938636779785,
            14.127403259277344,
            10.022411346435547,
            10.583991050720215
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the composer of The Swimmers is",
            "answer": "singer",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The occupation of Pete Townshend is",
            "answer": "singer",
            "subject": "Pete Townshend",
            "target": "singer",
            "relation": "OCCUPATION"
        },
        "NLL": [
            12.972597122192383,
            13.960638999938965,
            14.220800399780273,
            14.283707618713379,
            13.47767448425293,
            14.058978080749512
        ],
        "orginal_NLL": [
            7.045530796051025,
            11.446274757385254,
            10.927249908447266,
            11.354117393493652,
            7.948565483093262,
            8.781404495239258
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the composer of The Swimmers is",
            "answer": "composer",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The occupation of Pete Townshend is",
            "answer": "composer",
            "subject": "Pete Townshend",
            "target": "composer",
            "relation": "OCCUPATION"
        },
        "NLL": [
            10.697206497192383,
            9.032416343688965,
            9.079198837280273,
            11.596207618713379,
            9.14613151550293,
            8.754290580749512
        ],
        "orginal_NLL": [
            6.535765171051025,
            8.436509132385254,
            7.215335845947266,
            9.635367393493652,
            5.100909233093262,
            5.567537307739258
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the composer of The Swimmers is",
            "answer": "banjoist",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The occupation of Pete Townshend is",
            "answer": "banjoist",
            "subject": "Pete Townshend",
            "target": "banjoist",
            "relation": "OCCUPATION"
        },
        "NLL": [
            14.589775085449219,
            17.627355575561523,
            18.047306060791016,
            17.73674201965332,
            15.358427047729492,
            15.162774085998535
        ],
        "orginal_NLL": [
            16.878253936767578,
            19.47386360168457,
            19.140527725219727,
            19.53455924987793,
            17.6702938079834,
            18.10446548461914
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the composer of The Swimmers is",
            "answer": "mandolinist",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The occupation of Pete Townshend is",
            "answer": "mandolinist",
            "subject": "Pete Townshend",
            "target": "mandolinist",
            "relation": "OCCUPATION"
        },
        "NLL": [
            22.94843292236328,
            16.984851837158203,
            18.91733169555664,
            20.770540237426758,
            20.814861297607422,
            20.124149322509766
        ],
        "orginal_NLL": [
            15.887171745300293,
            17.18768310546875,
            18.51215362548828,
            20.380075454711914,
            16.124006271362305,
            16.51931381225586
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the composer of The Swimmers is",
            "answer": "screenwriter",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The occupation of Pete Townshend is",
            "answer": "screenwriter",
            "subject": "Pete Townshend",
            "target": "screenwriter",
            "relation": "OCCUPATION"
        },
        "NLL": [
            10.571478843688965,
            13.269513130187988,
            13.830087661743164,
            16.208200454711914,
            11.70539379119873,
            11.767497062683105
        ],
        "orginal_NLL": [
            9.044906616210938,
            14.348896026611328,
            13.090694427490234,
            14.51176643371582,
            9.622489929199219,
            10.113922119140625
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The place of birth of the composer of The Swimmers is",
            "answer": "London",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The place of birth of Pete Townshend is",
            "answer": "London",
            "subject": "Pete Townshend",
            "target": "London",
            "relation": "PLACE_OF_BIRTH"
        },
        "NLL": [
            1.018082857131958,
            7.247518539428711,
            3.2535088062286377,
            4.168850421905518,
            2.953835964202881,
            2.1236279010772705
        ],
        "orginal_NLL": [
            3.812742233276367,
            9.345917701721191,
            5.264146327972412,
            6.470055103302002,
            4.648581504821777,
            4.232429504394531
        ]
    },
    {
        "cosine_value": 0.14934030175209045,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the country of citizenship of the composer of The Swimmers is",
            "answer": "United Kingdom",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The name of the country of citizenship of Pete Townshend is",
            "answer": "United Kingdom",
            "subject": "Pete Townshend",
            "target": "United Kingdom",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "NLL": [
            5.496001720428467,
            5.328213214874268,
            3.0073204040527344,
            5.668524265289307,
            3.734895944595337,
            3.314598560333252
        ],
        "orginal_NLL": [
            5.222868919372559,
            8.435067176818848,
            4.8789191246032715,
            6.8364787101745605,
            5.049492359161377,
            5.046851634979248
        ]
    },
    {
        "cosine_value": 0.21599984169006348,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the spouse of the composer of The Swimmers is",
            "answer": "Karen Townshend",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The name of the spouse of Pete Townshend is",
            "answer": "Karen Townshend",
            "subject": "Pete Townshend",
            "target": "Karen Townshend",
            "relation": "SPOUSE"
        },
        "NLL": [
            23.012367248535156,
            27.174169540405273,
            24.29759979248047,
            25.557241439819336,
            23.48612403869629,
            23.452592849731445
        ],
        "orginal_NLL": [
            18.60128402709961,
            23.901840209960938,
            21.57564353942871,
            22.700754165649414,
            19.015594482421875,
            19.091625213623047
        ]
    },
    {
        "cosine_value": 0.12047528475522995,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the composer of The Swimmers won is",
            "answer": "Kennedy Center Honors",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The name of the award Pete Townshend won is",
            "answer": "Kennedy Center Honors",
            "subject": "Pete Townshend",
            "target": "Kennedy Center Honors",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            12.273404121398926,
            15.607612609863281,
            13.602028846740723,
            13.90056037902832,
            13.307991027832031,
            13.308966636657715
        ],
        "orginal_NLL": [
            12.0277099609375,
            15.294268608093262,
            15.613419532775879,
            15.630818367004395,
            13.547403335571289,
            13.617680549621582
        ]
    },
    {
        "cosine_value": 0.15345260500907898,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the alma mater of the composer of The Swimmers is",
            "answer": "Ark Acton Academy",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The name of the alma mater of Pete Townshend is",
            "answer": "Ark Acton Academy",
            "subject": "Pete Townshend",
            "target": "Ark Acton Academy",
            "relation": "ALMA_MATER"
        },
        "NLL": [
            25.500980377197266,
            27.613155364990234,
            25.527563095092773,
            27.60805892944336,
            24.649696350097656,
            24.352399826049805
        ],
        "orginal_NLL": [
            25.570621490478516,
            28.72176742553711,
            30.981428146362305,
            31.83555793762207,
            26.77326011657715,
            26.592092514038086
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The gender of the composer of The Swimmers is",
            "answer": "male",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The gender of Pete Townshend is",
            "answer": "male",
            "subject": "Pete Townshend",
            "target": "male",
            "relation": "SEX_OR_GENDER"
        },
        "NLL": [
            2.1320903301239014,
            7.97589635848999,
            4.503851413726807,
            6.010319232940674,
            4.109771728515625,
            4.131047248840332
        ],
        "orginal_NLL": [
            3.3312816619873047,
            9.269986152648926,
            5.887195587158203,
            7.8190178871154785,
            4.822122097015381,
            5.01937198638916
        ]
    },
    {
        "cosine_value": 0.3537409007549286,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the father of the composer of The Swimmers is",
            "answer": "Cliff Townshend",
            "subject": "The Swimmers",
            "target": "Pete Townshend",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The name of the father of Pete Townshend is",
            "answer": "Cliff Townshend",
            "subject": "Pete Townshend",
            "target": "Cliff Townshend",
            "relation": "FATHER"
        },
        "NLL": [
            20.338268280029297,
            22.646862030029297,
            20.70382308959961,
            22.237953186035156,
            19.97959327697754,
            20.1011905670166
        ],
        "orginal_NLL": [
            17.371315002441406,
            22.410518646240234,
            18.74174690246582,
            21.438074111938477,
            17.904956817626953,
            18.101909637451172
        ]
    },
    {
        "cosine_value": -0.04557349160313606,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Tony Curtis",
            "target": "British Leeward Islands",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the continent which the country of citizenship of Tony Curtis is part of is",
            "answer": "North America",
            "subject": "Tony Curtis",
            "target": "British Leeward Islands",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the continent which British Leeward Islands is part of is",
            "answer": "North America",
            "subject": "British Leeward Islands",
            "target": "North America",
            "relation": "CONTINENT"
        },
        "NLL": [
            18.30849838256836,
            15.62548542022705,
            14.797929763793945,
            13.594923973083496,
            13.612188339233398,
            13.87516975402832
        ],
        "orginal_NLL": [
            1.2039780616760254,
            3.844271421432495,
            3.127488374710083,
            3.4230082035064697,
            2.8404178619384766,
            2.449589490890503
        ]
    },
    {
        "cosine_value": 0.062232937663793564,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Tony Curtis",
            "target": "British Leeward Islands",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the capital city of the country of citizenship of Tony Curtis is",
            "answer": "Saint John's",
            "subject": "Tony Curtis",
            "target": "British Leeward Islands",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the capital city of British Leeward Islands is",
            "answer": "Saint John's",
            "subject": "British Leeward Islands",
            "target": "Saint John's",
            "relation": "CAPITAL"
        },
        "NLL": [
            15.993684768676758,
            17.19979476928711,
            15.265298843383789,
            14.678397178649902,
            13.900130271911621,
            13.735316276550293
        ],
        "orginal_NLL": [
            12.01585578918457,
            15.835729598999023,
            16.03664207458496,
            15.718196868896484,
            14.22854995727539,
            14.132454872131348
        ]
    },
    {
        "cosine_value": -0.023580048233270645,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Tony Curtis",
            "target": "British Leeward Islands",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The official language of the country of citizenship of Tony Curtis is",
            "answer": "English",
            "subject": "Tony Curtis",
            "target": "British Leeward Islands",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The official language of British Leeward Islands is",
            "answer": "English",
            "subject": "British Leeward Islands",
            "target": "English",
            "relation": "OFFICIAL_LANGUAGE"
        },
        "NLL": [
            7.90897274017334,
            5.528321743011475,
            6.431116580963135,
            6.095711708068848,
            4.203280925750732,
            3.5424795150756836
        ],
        "orginal_NLL": [
            0.6188112497329712,
            5.0763840675354,
            2.415205955505371,
            2.4685022830963135,
            1.5712257623672485,
            1.6980944871902466
        ]
    },
    {
        "cosine_value": 0.08365869522094727,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Tony Curtis",
            "target": "British Leeward Islands",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the anthem of the country of citizenship of Tony Curtis is",
            "answer": "God Save the King",
            "subject": "Tony Curtis",
            "target": "British Leeward Islands",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the anthem of British Leeward Islands is",
            "answer": "God Save the King",
            "subject": "British Leeward Islands",
            "target": "God Save the King",
            "relation": "ANTHEM"
        },
        "NLL": [
            12.51584243774414,
            13.075394630432129,
            10.999103546142578,
            11.001559257507324,
            8.065771102905273,
            9.06335163116455
        ],
        "orginal_NLL": [
            7.7983784675598145,
            16.08757781982422,
            9.466803550720215,
            8.884925842285156,
            9.428059577941895,
            9.143640518188477
        ]
    },
    {
        "cosine_value": -0.03849956393241882,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the director of Vikrant Rona is",
            "answer": "television actor",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The occupation of Alan Rickman is",
            "answer": "television actor",
            "subject": "Alan Rickman",
            "target": "television actor",
            "relation": "OCCUPATION"
        },
        "NLL": [
            19.82138442993164,
            23.0725154876709,
            21.57297134399414,
            20.361181259155273,
            18.702098846435547,
            19.452320098876953
        ],
        "orginal_NLL": [
            14.387171745300293,
            20.49741554260254,
            15.80840015411377,
            15.676299095153809,
            14.066479682922363,
            13.813982963562012
        ]
    },
    {
        "cosine_value": -0.08677427470684052,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the director of Vikrant Rona is",
            "answer": "film actor",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The occupation of Alan Rickman is",
            "answer": "film actor",
            "subject": "Alan Rickman",
            "target": "film actor",
            "relation": "OCCUPATION"
        },
        "NLL": [
            18.27379035949707,
            22.03106689453125,
            16.56281280517578,
            15.80851936340332,
            14.704299926757812,
            14.76901912689209
        ],
        "orginal_NLL": [
            13.282963752746582,
            19.155433654785156,
            14.05440616607666,
            14.531121253967285,
            13.002989768981934,
            12.029383659362793
        ]
    },
    {
        "cosine_value": 0.021580182015895844,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the director of Vikrant Rona is",
            "answer": "voice actor",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The occupation of Alan Rickman is",
            "answer": "voice actor",
            "subject": "Alan Rickman",
            "target": "voice actor",
            "relation": "OCCUPATION"
        },
        "NLL": [
            18.499948501586914,
            20.77603530883789,
            16.387462615966797,
            18.23604393005371,
            16.00215721130371,
            15.807464599609375
        ],
        "orginal_NLL": [
            15.193918228149414,
            21.109201431274414,
            15.775769233703613,
            16.05829620361328,
            14.503334999084473,
            14.349920272827148
        ]
    },
    {
        "cosine_value": -0.03650250658392906,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the director of Vikrant Rona is",
            "answer": "character actor",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The occupation of Alan Rickman is",
            "answer": "character actor",
            "subject": "Alan Rickman",
            "target": "character actor",
            "relation": "OCCUPATION"
        },
        "NLL": [
            20.348737716674805,
            27.180316925048828,
            20.001914978027344,
            19.981353759765625,
            18.685993194580078,
            18.861974716186523
        ],
        "orginal_NLL": [
            16.859159469604492,
            21.740148544311523,
            15.831942558288574,
            17.515363693237305,
            15.9693603515625,
            15.909541130065918
        ]
    },
    {
        "cosine_value": -0.13002145290374756,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the director of Vikrant Rona is",
            "answer": "film director",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The occupation of Alan Rickman is",
            "answer": "film director",
            "subject": "Alan Rickman",
            "target": "film director",
            "relation": "OCCUPATION"
        },
        "NLL": [
            15.582383155822754,
            20.10528564453125,
            12.688789367675781,
            11.86711311340332,
            10.883987426757812,
            11.00144100189209
        ],
        "orginal_NLL": [
            11.681401252746582,
            16.823402404785156,
            11.81417179107666,
            12.527215003967285,
            10.856505393981934,
            10.062586784362793
        ]
    },
    {
        "cosine_value": -0.12735359370708466,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the director of Vikrant Rona is",
            "answer": "film producer",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The occupation of Alan Rickman is",
            "answer": "film producer",
            "subject": "Alan Rickman",
            "target": "film producer",
            "relation": "OCCUPATION"
        },
        "NLL": [
            16.25425910949707,
            21.47247314453125,
            13.766914367675781,
            13.015551567077637,
            12.016799926757812,
            12.31394100189209
        ],
        "orginal_NLL": [
            12.575932502746582,
            18.401527404785156,
            13.84542179107666,
            14.355340003967285,
            13.106505393981934,
            12.470789909362793
        ]
    },
    {
        "cosine_value": -0.0627465546131134,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the director of Vikrant Rona is",
            "answer": "graphic designer",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The occupation of Alan Rickman is",
            "answer": "graphic designer",
            "subject": "Alan Rickman",
            "target": "graphic designer",
            "relation": "OCCUPATION"
        },
        "NLL": [
            15.096762657165527,
            17.58282470703125,
            15.916417121887207,
            17.043222427368164,
            15.875617980957031,
            16.15400505065918
        ],
        "orginal_NLL": [
            14.224987030029297,
            18.017438888549805,
            15.556933403015137,
            16.187477111816406,
            15.286768913269043,
            15.422246932983398
        ]
    },
    {
        "cosine_value": 0.004446994513273239,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the director of Vikrant Rona is",
            "answer": "stage actor",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The occupation of Alan Rickman is",
            "answer": "stage actor",
            "subject": "Alan Rickman",
            "target": "stage actor",
            "relation": "OCCUPATION"
        },
        "NLL": [
            18.21376609802246,
            24.224868774414062,
            17.992816925048828,
            18.363805770874023,
            16.903564453125,
            16.78131866455078
        ],
        "orginal_NLL": [
            15.002485275268555,
            21.489398956298828,
            17.308094024658203,
            17.48885726928711,
            16.426237106323242,
            16.462188720703125
        ]
    },
    {
        "cosine_value": -0.0,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the director of Vikrant Rona is",
            "answer": "writer",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The occupation of Alan Rickman is",
            "answer": "writer",
            "subject": "Alan Rickman",
            "target": "writer",
            "relation": "OCCUPATION"
        },
        "NLL": [
            12.121779441833496,
            17.081073760986328,
            11.18062686920166,
            12.84424114227295,
            11.11857795715332,
            11.262651443481445
        ],
        "orginal_NLL": [
            11.969549179077148,
            16.84648323059082,
            11.928247451782227,
            13.611002922058105,
            11.597792625427246,
            11.493301391601562
        ]
    },
    {
        "cosine_value": -0.0,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the director of Vikrant Rona is",
            "answer": "actor",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The occupation of Alan Rickman is",
            "answer": "actor",
            "subject": "Alan Rickman",
            "target": "actor",
            "relation": "OCCUPATION"
        },
        "NLL": [
            13.633498191833496,
            16.179706573486328,
            13.51906681060791,
            12.83447551727295,
            12.05900764465332,
            11.826128005981445
        ],
        "orginal_NLL": [
            8.671697616577148,
            16.70976448059082,
            10.781518936157227,
            11.443034172058105,
            9.586318016052246,
            9.367568969726562
        ]
    },
    {
        "cosine_value": -0.10166215896606445,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the director of Vikrant Rona is",
            "answer": "screenwriter",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The occupation of Alan Rickman is",
            "answer": "screenwriter",
            "subject": "Alan Rickman",
            "target": "screenwriter",
            "relation": "OCCUPATION"
        },
        "NLL": [
            14.924041748046875,
            19.892797470092773,
            15.64023208618164,
            16.851558685302734,
            13.689642906188965,
            13.904658317565918
        ],
        "orginal_NLL": [
            11.750840187072754,
            17.78357696533203,
            13.093423843383789,
            13.935954093933105,
            11.705657005310059,
            11.52804946899414
        ]
    },
    {
        "cosine_value": -0.03912802413105965,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the director of Vikrant Rona is",
            "answer": "theatrical director",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The occupation of Alan Rickman is",
            "answer": "theatrical director",
            "subject": "Alan Rickman",
            "target": "theatrical director",
            "relation": "OCCUPATION"
        },
        "NLL": [
            19.204355239868164,
            33.34040069580078,
            18.319515228271484,
            18.548309326171875,
            17.114839553833008,
            17.147464752197266
        ],
        "orginal_NLL": [
            16.343549728393555,
            24.766189575195312,
            17.035932540893555,
            17.24168586730957,
            15.876077651977539,
            15.709019660949707
        ]
    },
    {
        "cosine_value": -0.0,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the director of Vikrant Rona is",
            "answer": "director",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The occupation of Alan Rickman is",
            "answer": "director",
            "subject": "Alan Rickman",
            "target": "director",
            "relation": "OCCUPATION"
        },
        "NLL": [
            13.214552879333496,
            16.310565948486328,
            9.83644962310791,
            9.10205364227295,
            9.38273811340332,
            8.717729568481445
        ],
        "orginal_NLL": [
            8.894353866577148,
            15.667771339416504,
            8.870386123657227,
            9.544596672058105,
            7.917128562927246,
            7.6602935791015625
        ]
    },
    {
        "cosine_value": 0.11884524673223495,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The place of birth of the director of Vikrant Rona is",
            "answer": "Hammersmith",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The place of birth of Alan Rickman is",
            "answer": "Hammersmith",
            "subject": "Alan Rickman",
            "target": "Hammersmith",
            "relation": "PLACE_OF_BIRTH"
        },
        "NLL": [
            11.883548736572266,
            17.098562240600586,
            11.002532005310059,
            11.852278709411621,
            11.786826133728027,
            10.863926887512207
        ],
        "orginal_NLL": [
            12.050546646118164,
            18.593313217163086,
            12.0123929977417,
            12.429240226745605,
            12.046606063842773,
            11.754045486450195
        ]
    },
    {
        "cosine_value": -0.06991873681545258,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the country of citizenship of the director of Vikrant Rona is",
            "answer": "United Kingdom",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The name of the country of citizenship of Alan Rickman is",
            "answer": "United Kingdom",
            "subject": "Alan Rickman",
            "target": "United Kingdom",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "NLL": [
            3.761835813522339,
            12.442461967468262,
            4.215097904205322,
            6.04086446762085,
            4.544692516326904,
            4.626833915710449
        ],
        "orginal_NLL": [
            8.480849266052246,
            11.86650276184082,
            7.059396266937256,
            7.941442966461182,
            7.496623992919922,
            7.238069534301758
        ]
    },
    {
        "cosine_value": -0.13182711601257324,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the alma mater of the director of Vikrant Rona is",
            "answer": "Chelsea College of Art and Design",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The name of the alma mater of Alan Rickman is",
            "answer": "Chelsea College of Art and Design",
            "subject": "Alan Rickman",
            "target": "Chelsea College of Art and Design",
            "relation": "ALMA_MATER"
        },
        "NLL": [
            21.658803939819336,
            33.05593490600586,
            21.673791885375977,
            22.432209014892578,
            20.34714126586914,
            20.244184494018555
        ],
        "orginal_NLL": [
            14.823406219482422,
            26.10457420349121,
            16.972082138061523,
            17.35894775390625,
            15.953258514404297,
            16.431081771850586
        ]
    },
    {
        "cosine_value": -0.12870359420776367,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the alma mater of the director of Vikrant Rona is",
            "answer": "Royal Academy of Dramatic Art",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The name of the alma mater of Alan Rickman is",
            "answer": "Royal Academy of Dramatic Art",
            "subject": "Alan Rickman",
            "target": "Royal Academy of Dramatic Art",
            "relation": "ALMA_MATER"
        },
        "NLL": [
            13.150510787963867,
            21.030881881713867,
            13.25307559967041,
            14.194072723388672,
            13.40911865234375,
            13.173778533935547
        ],
        "orginal_NLL": [
            11.057114601135254,
            17.851438522338867,
            12.344293594360352,
            12.553340911865234,
            12.05854320526123,
            12.770837783813477
        ]
    },
    {
        "cosine_value": -0.08557060360908508,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the alma mater of the director of Vikrant Rona is",
            "answer": "Latymer Upper School",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The name of the alma mater of Alan Rickman is",
            "answer": "Latymer Upper School",
            "subject": "Alan Rickman",
            "target": "Latymer Upper School",
            "relation": "ALMA_MATER"
        },
        "NLL": [
            16.839292526245117,
            22.255123138427734,
            17.09157371520996,
            15.605121612548828,
            15.943599700927734,
            16.016006469726562
        ],
        "orginal_NLL": [
            16.85779571533203,
            25.814598083496094,
            18.845247268676758,
            17.598918914794922,
            17.648183822631836,
            18.155624389648438
        ]
    },
    {
        "cosine_value": -0.13274475932121277,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the alma mater of the director of Vikrant Rona is",
            "answer": "Royal College of Art",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The name of the alma mater of Alan Rickman is",
            "answer": "Royal College of Art",
            "subject": "Alan Rickman",
            "target": "Royal College of Art",
            "relation": "ALMA_MATER"
        },
        "NLL": [
            13.146316528320312,
            21.354860305786133,
            13.877894401550293,
            14.90015983581543,
            13.992548942565918,
            13.644974708557129
        ],
        "orginal_NLL": [
            13.099105834960938,
            18.41632080078125,
            13.821949005126953,
            14.73679256439209,
            14.238748550415039,
            14.686025619506836
        ]
    },
    {
        "cosine_value": 0.11323460936546326,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the spouse of the director of Vikrant Rona is",
            "answer": "Rima Horton",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The name of the spouse of Alan Rickman is",
            "answer": "Rima Horton",
            "subject": "Alan Rickman",
            "target": "Rima Horton",
            "relation": "SPOUSE"
        },
        "NLL": [
            22.956819534301758,
            34.61143112182617,
            22.698564529418945,
            22.951194763183594,
            22.53481101989746,
            21.95170021057129
        ],
        "orginal_NLL": [
            18.698665618896484,
            30.10094451904297,
            21.00739097595215,
            20.539838790893555,
            19.598955154418945,
            19.452857971191406
        ]
    },
    {
        "cosine_value": -0.1165526807308197,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the director of Vikrant Rona won is",
            "answer": "BAFTA Award for Best Actor in a Supporting Role",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The name of the award Alan Rickman won is",
            "answer": "BAFTA Award for Best Actor in a Supporting Role",
            "subject": "Alan Rickman",
            "target": "BAFTA Award for Best Actor in a Supporting Role",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            14.57623291015625,
            23.080307006835938,
            14.655874252319336,
            15.090874671936035,
            14.005460739135742,
            14.183359146118164
        ],
        "orginal_NLL": [
            17.560588836669922,
            27.180152893066406,
            19.157123565673828,
            19.31468963623047,
            17.372827529907227,
            17.175334930419922
        ]
    },
    {
        "cosine_value": -0.11192915588617325,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the director of Vikrant Rona won is",
            "answer": "Screen Actors Guild Award for Outstanding Performance by a Male Actor in a Miniseries or Television Movie",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The name of the award Alan Rickman won is",
            "answer": "Screen Actors Guild Award for Outstanding Performance by a Male Actor in a Miniseries or Television Movie",
            "subject": "Alan Rickman",
            "target": "Screen Actors Guild Award for Outstanding Performance by a Male Actor in a Miniseries or Television Movie",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            22.626808166503906,
            28.125415802001953,
            26.317167282104492,
            27.593181610107422,
            25.45435905456543,
            26.224916458129883
        ],
        "orginal_NLL": [
            26.45587921142578,
            30.46514892578125,
            30.83967399597168,
            30.994861602783203,
            29.261945724487305,
            29.990278244018555
        ]
    },
    {
        "cosine_value": -0.014980644918978214,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the director of Vikrant Rona won is",
            "answer": "James Joyce Awards",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The name of the award Alan Rickman won is",
            "answer": "James Joyce Awards",
            "subject": "Alan Rickman",
            "target": "James Joyce Awards",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            21.91884422302246,
            25.768482208251953,
            22.0294246673584,
            22.739412307739258,
            22.40621566772461,
            22.167510986328125
        ],
        "orginal_NLL": [
            20.22917938232422,
            26.4456729888916,
            23.844961166381836,
            22.643646240234375,
            22.26258087158203,
            22.324918746948242
        ]
    },
    {
        "cosine_value": -0.04593256488442421,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the director of Vikrant Rona won is",
            "answer": "Golden Globe Award",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The name of the award Alan Rickman won is",
            "answer": "Golden Globe Award",
            "subject": "Alan Rickman",
            "target": "Golden Globe Award",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            3.6126749515533447,
            9.819634437561035,
            6.753238201141357,
            8.994317054748535,
            7.8790082931518555,
            8.775635719299316
        ],
        "orginal_NLL": [
            10.259498596191406,
            17.623445510864258,
            15.326656341552734,
            14.311439514160156,
            13.027450561523438,
            13.227357864379883
        ]
    },
    {
        "cosine_value": -0.15729878842830658,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the director of Vikrant Rona won is",
            "answer": "Primetime Emmy Award for Outstanding Lead Actor in a Miniseries or a Movie",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The name of the award Alan Rickman won is",
            "answer": "Primetime Emmy Award for Outstanding Lead Actor in a Miniseries or a Movie",
            "subject": "Alan Rickman",
            "target": "Primetime Emmy Award for Outstanding Lead Actor in a Miniseries or a Movie",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            17.091625213623047,
            21.398347854614258,
            20.918033599853516,
            19.983675003051758,
            20.599123001098633,
            20.913188934326172
        ],
        "orginal_NLL": [
            22.148571014404297,
            26.653133392333984,
            25.508201599121094,
            24.072240829467773,
            23.61481475830078,
            24.697221755981445
        ]
    },
    {
        "cosine_value": -0.0,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The place of death of the director of Vikrant Rona is",
            "answer": "London",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The place of death of Alan Rickman is",
            "answer": "London",
            "subject": "Alan Rickman",
            "target": "London",
            "relation": "PLACE_OF_DEATH"
        },
        "NLL": [
            4.539420127868652,
            13.869037628173828,
            4.218174457550049,
            4.095761299133301,
            4.418832778930664,
            3.517378091812134
        ],
        "orginal_NLL": [
            7.860702037811279,
            17.946035385131836,
            10.92517375946045,
            10.03211498260498,
            9.820560455322266,
            9.523829460144043
        ]
    },
    {
        "cosine_value": -0.0,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The gender of the director of Vikrant Rona is",
            "answer": "male",
            "subject": "Vikrant Rona",
            "target": "Alan Rickman",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The gender of Alan Rickman is",
            "answer": "male",
            "subject": "Alan Rickman",
            "target": "male",
            "relation": "SEX_OR_GENDER"
        },
        "NLL": [
            9.867461204528809,
            15.42374324798584,
            8.26781177520752,
            7.744716644287109,
            7.68589448928833,
            7.793978691101074
        ],
        "orginal_NLL": [
            6.805493354797363,
            11.676263809204102,
            8.057733535766602,
            7.675358772277832,
            6.9481329917907715,
            6.8047614097595215
        ]
    },
    {
        "cosine_value": 0.02464386261999607,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "2008 United States presidential election",
            "target": "Mordovia",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the capital city of the country 2008 United States presidential election is associated with is",
            "answer": "Saransk",
            "subject": "2008 United States presidential election",
            "target": "Mordovia",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the capital city of Mordovia is",
            "answer": "Saransk",
            "subject": "Mordovia",
            "target": "Saransk",
            "relation": "CAPITAL"
        },
        "NLL": [
            18.17643928527832,
            24.206682205200195,
            17.940805435180664,
            16.918630599975586,
            14.752902030944824,
            15.277181625366211
        ],
        "orginal_NLL": [
            14.579307556152344,
            20.635305404663086,
            17.784568786621094,
            17.671506881713867,
            16.733671188354492,
            16.464275360107422
        ]
    },
    {
        "cosine_value": 0.10683435201644897,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "2008 United States presidential election",
            "target": "Mordovia",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The official language of the country 2008 United States presidential election is associated with is",
            "answer": "Russian",
            "subject": "2008 United States presidential election",
            "target": "Mordovia",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The official language of Mordovia is",
            "answer": "Russian",
            "subject": "Mordovia",
            "target": "Russian",
            "relation": "OFFICIAL_LANGUAGE"
        },
        "NLL": [
            3.712289810180664,
            12.96546745300293,
            5.724529266357422,
            5.78042459487915,
            3.3418123722076416,
            2.8857789039611816
        ],
        "orginal_NLL": [
            5.563055515289307,
            13.42440414428711,
            8.488811492919922,
            9.332429885864258,
            9.08276653289795,
            8.548322677612305
        ]
    },
    {
        "cosine_value": 0.1617737114429474,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "2008 United States presidential election",
            "target": "Mordovia",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The official language of the country 2008 United States presidential election is associated with is",
            "answer": "Moksha",
            "subject": "2008 United States presidential election",
            "target": "Mordovia",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The official language of Mordovia is",
            "answer": "Moksha",
            "subject": "Mordovia",
            "target": "Moksha",
            "relation": "OFFICIAL_LANGUAGE"
        },
        "NLL": [
            15.351893424987793,
            31.983579635620117,
            19.053003311157227,
            17.358644485473633,
            15.69149398803711,
            15.528247833251953
        ],
        "orginal_NLL": [
            12.846465110778809,
            19.639263153076172,
            15.384919166564941,
            15.677152633666992,
            16.013132095336914,
            15.905242919921875
        ]
    },
    {
        "cosine_value": 0.13558915257453918,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "2008 United States presidential election",
            "target": "Mordovia",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The official language of the country 2008 United States presidential election is associated with is",
            "answer": "Erzya",
            "subject": "2008 United States presidential election",
            "target": "Mordovia",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The official language of Mordovia is",
            "answer": "Erzya",
            "subject": "Mordovia",
            "target": "Erzya",
            "relation": "OFFICIAL_LANGUAGE"
        },
        "NLL": [
            25.0650691986084,
            34.497676849365234,
            27.520753860473633,
            24.724620819091797,
            22.969085693359375,
            23.339353561401367
        ],
        "orginal_NLL": [
            14.990168571472168,
            19.8398494720459,
            17.391311645507812,
            17.365785598754883,
            18.3673095703125,
            19.370092391967773
        ]
    },
    {
        "cosine_value": 0.18758060038089752,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "2008 United States presidential election",
            "target": "Mordovia",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the anthem of the country 2008 United States presidential election is associated with is",
            "answer": "National Anthem of the Republic of Mordovia",
            "subject": "2008 United States presidential election",
            "target": "Mordovia",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the anthem of Mordovia is",
            "answer": "National Anthem of the Republic of Mordovia",
            "subject": "Mordovia",
            "target": "National Anthem of the Republic of Mordovia",
            "relation": "ANTHEM"
        },
        "NLL": [
            17.93875503540039,
            26.776243209838867,
            20.17881965637207,
            17.909189224243164,
            16.31662368774414,
            17.119924545288086
        ],
        "orginal_NLL": [
            25.597118377685547,
            30.38956069946289,
            25.617176055908203,
            25.775623321533203,
            24.74749755859375,
            24.969911575317383
        ]
    },
    {
        "cosine_value": 0.0910821408033371,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "2008 United States presidential election",
            "target": "Mordovia",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the head of government of the country 2008 United States presidential election is associated with is",
            "answer": "Artem Zdunov",
            "subject": "2008 United States presidential election",
            "target": "Mordovia",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the head of government of Mordovia is",
            "answer": "Artem Zdunov",
            "subject": "Mordovia",
            "target": "Artem Zdunov",
            "relation": "HEAD_OF_GOVERNMENT"
        },
        "NLL": [
            26.451974868774414,
            36.274375915527344,
            28.335229873657227,
            28.681751251220703,
            27.38760757446289,
            27.54334831237793
        ],
        "orginal_NLL": [
            27.57607078552246,
            32.04456329345703,
            27.733861923217773,
            27.28260612487793,
            26.885896682739258,
            27.188344955444336
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "2008 United States presidential election",
            "target": "Mordovia",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the continent which the country 2008 United States presidential election is associated with is part of is",
            "answer": "Europe",
            "subject": "2008 United States presidential election",
            "target": "Mordovia",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the continent which Mordovia is part of is",
            "answer": "Europe",
            "subject": "Mordovia",
            "target": "Europe",
            "relation": "CONTINENT"
        },
        "NLL": [
            7.538443565368652,
            17.52342414855957,
            10.11849308013916,
            8.02284049987793,
            8.231541633605957,
            8.066125869750977
        ],
        "orginal_NLL": [
            5.266321182250977,
            11.447151184082031,
            7.188456058502197,
            6.893921375274658,
            7.188299179077148,
            6.279880523681641
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Westworld",
            "target": "Neria Goldberg",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The gender of the composer of Westworld is",
            "answer": "female",
            "subject": "Westworld",
            "target": "Neria Goldberg",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The gender of Neria Goldberg is",
            "answer": "female",
            "subject": "Neria Goldberg",
            "target": "female",
            "relation": "SEX_OR_GENDER"
        },
        "NLL": [
            8.69278621673584,
            8.217385292053223,
            8.155064582824707,
            9.248181343078613,
            6.107512950897217,
            6.6479597091674805
        ],
        "orginal_NLL": [
            4.371303558349609,
            9.813536643981934,
            7.734546661376953,
            9.170531272888184,
            5.942695617675781,
            5.705873012542725
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Westworld",
            "target": "Neria Goldberg",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the composer of Westworld is",
            "answer": "composer",
            "subject": "Westworld",
            "target": "Neria Goldberg",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The occupation of Neria Goldberg is",
            "answer": "composer",
            "subject": "Neria Goldberg",
            "target": "composer",
            "relation": "OCCUPATION"
        },
        "NLL": [
            7.235591411590576,
            11.177743911743164,
            7.614001750946045,
            9.233399391174316,
            7.956108093261719,
            7.392692565917969
        ],
        "orginal_NLL": [
            8.036611557006836,
            11.008014678955078,
            9.618913650512695,
            11.040963172912598,
            6.756717205047607,
            7.1329240798950195
        ]
    },
    {
        "cosine_value": -0.038469135761260986,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Westworld",
            "target": "Neria Goldberg",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the country of citizenship of the composer of Westworld is",
            "answer": "Lithuania",
            "subject": "Westworld",
            "target": "Neria Goldberg",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The name of the country of citizenship of Neria Goldberg is",
            "answer": "Lithuania",
            "subject": "Neria Goldberg",
            "target": "Lithuania",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "NLL": [
            15.194344520568848,
            17.537755966186523,
            13.026297569274902,
            12.190129280090332,
            12.095911026000977,
            12.705931663513184
        ],
        "orginal_NLL": [
            8.27773380279541,
            11.26895809173584,
            9.504546165466309,
            9.906195640563965,
            8.462337493896484,
            9.06784725189209
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the author of list of {} is",
            "subject": "James Bond films",
            "target": "Kishore R Kumar",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the author of list of James Bond films is",
            "answer": "researcher",
            "subject": "James Bond films",
            "target": "Kishore R Kumar",
            "relation": "AUTHOR"
        },
        "condition_query": {
            "prompt": "The occupation of Kishore R Kumar is",
            "answer": "researcher",
            "subject": "Kishore R Kumar",
            "target": "researcher",
            "relation": "OCCUPATION"
        },
        "NLL": [
            26.841716766357422,
            26.232555389404297,
            19.186429977416992,
            16.558977127075195,
            18.45941925048828,
            20.125898361206055
        ],
        "orginal_NLL": [
            10.450054168701172,
            16.62841796875,
            11.245122909545898,
            12.581819534301758,
            9.027898788452148,
            9.348291397094727
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "Constitution of India",
            "target": "Illyria",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the continent which the country Constitution of India is associated with is part of is",
            "answer": "Europe",
            "subject": "Constitution of India",
            "target": "Illyria",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the continent which Illyria is part of is",
            "answer": "Europe",
            "subject": "Illyria",
            "target": "Europe",
            "relation": "CONTINENT"
        },
        "NLL": [
            6.884586811065674,
            16.497665405273438,
            8.340850830078125,
            8.049522399902344,
            8.487467765808105,
            8.674882888793945
        ],
        "orginal_NLL": [
            5.866085529327393,
            11.897205352783203,
            8.848481178283691,
            8.716736793518066,
            7.709404468536377,
            6.843863010406494
        ]
    },
    {
        "cosine_value": -0.09592431038618088,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Barbarian",
            "target": "Jimmy Bond",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the composer of Barbarian is",
            "answer": "musician",
            "subject": "Barbarian",
            "target": "Jimmy Bond",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The occupation of Jimmy Bond is",
            "answer": "musician",
            "subject": "Jimmy Bond",
            "target": "musician",
            "relation": "OCCUPATION"
        },
        "NLL": [
            11.816969871520996,
            12.066120147705078,
            12.751006126403809,
            12.263916015625,
            9.009966850280762,
            8.496966361999512
        ],
        "orginal_NLL": [
            6.918723106384277,
            10.673425674438477,
            10.201848983764648,
            10.89858341217041,
            8.763948440551758,
            8.825883865356445
        ]
    },
    {
        "cosine_value": 0.1042720153927803,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Barbarian",
            "target": "Jimmy Bond",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the country of citizenship of the composer of Barbarian is",
            "answer": "United States of America",
            "subject": "Barbarian",
            "target": "Jimmy Bond",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The name of the country of citizenship of Jimmy Bond is",
            "answer": "United States of America",
            "subject": "Jimmy Bond",
            "target": "United States of America",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "NLL": [
            10.536761283874512,
            8.836999893188477,
            8.208110809326172,
            10.00525951385498,
            7.178828716278076,
            7.274628162384033
        ],
        "orginal_NLL": [
            7.167667865753174,
            9.871882438659668,
            6.220545768737793,
            7.965064525604248,
            6.215524673461914,
            6.252748489379883
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Barbarian",
            "target": "Jimmy Bond",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The place of birth of the composer of Barbarian is",
            "answer": "Philadelphia",
            "subject": "Barbarian",
            "target": "Jimmy Bond",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The place of birth of Jimmy Bond is",
            "answer": "Philadelphia",
            "subject": "Jimmy Bond",
            "target": "Philadelphia",
            "relation": "PLACE_OF_BIRTH"
        },
        "NLL": [
            11.97890853881836,
            10.522331237792969,
            10.245482444763184,
            12.220412254333496,
            10.999889373779297,
            11.099740982055664
        ],
        "orginal_NLL": [
            8.322366714477539,
            11.221511840820312,
            8.6607027053833,
            10.343121528625488,
            8.421658515930176,
            8.119331359863281
        ]
    },
    {
        "cosine_value": 0.183808371424675,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Barbarian",
            "target": "Jimmy Bond",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The place of death of the composer of Barbarian is",
            "answer": "Los Angeles",
            "subject": "Barbarian",
            "target": "Jimmy Bond",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The place of death of Jimmy Bond is",
            "answer": "Los Angeles",
            "subject": "Jimmy Bond",
            "target": "Los Angeles",
            "relation": "PLACE_OF_DEATH"
        },
        "NLL": [
            8.022711753845215,
            9.644545555114746,
            9.194183349609375,
            11.766179084777832,
            8.666915893554688,
            8.45307445526123
        ],
        "orginal_NLL": [
            8.625528335571289,
            11.382869720458984,
            9.549593925476074,
            11.39511775970459,
            8.12514591217041,
            7.996998310089111
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Barbarian",
            "target": "Jimmy Bond",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The gender of the composer of Barbarian is",
            "answer": "male",
            "subject": "Barbarian",
            "target": "Jimmy Bond",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The gender of Jimmy Bond is",
            "answer": "male",
            "subject": "Jimmy Bond",
            "target": "male",
            "relation": "SEX_OR_GENDER"
        },
        "NLL": [
            5.395282745361328,
            6.034823417663574,
            5.539249897003174,
            8.894137382507324,
            4.709887504577637,
            4.516941070556641
        ],
        "orginal_NLL": [
            3.9557273387908936,
            9.238112449645996,
            5.140797138214111,
            7.305872917175293,
            4.542684078216553,
            4.469094276428223
        ]
    },
    {
        "cosine_value": NaN,
        "edited_data": {
            "prompt": "The place of birth of {} is",
            "subject": "Jack O'Connell",
            "target": "Hart County",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the capital city of the place of birth of Jack O'Connell is",
            "answer": "Munfordville",
            "subject": "Jack O'Connell",
            "target": "Hart County",
            "relation": "PLACE_OF_BIRTH"
        },
        "condition_query": {
            "prompt": "The name of the capital city of Hart County is",
            "answer": "Munfordville",
            "subject": "Hart County",
            "target": "Munfordville",
            "relation": "CAPITAL"
        },
        "NLL": [
            17.93747329711914,
            16.66776466369629,
            12.487167358398438,
            11.514270782470703,
            11.472254753112793,
            12.052382469177246
        ],
        "orginal_NLL": [
            14.076847076416016,
            18.6550350189209,
            15.482758522033691,
            15.219715118408203,
            14.860499382019043,
            14.950270652770996
        ]
    },
    {
        "cosine_value": 0.03790421038866043,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Katey Sagal",
            "target": "South African Republic",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the currency in the country of citizenship of Katey Sagal is",
            "answer": "South African pound",
            "subject": "Katey Sagal",
            "target": "South African Republic",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the currency in South African Republic is",
            "answer": "South African pound",
            "subject": "South African Republic",
            "target": "South African pound",
            "relation": "CURRENCY"
        },
        "NLL": [
            20.722888946533203,
            19.650999069213867,
            13.667747497558594,
            13.715103149414062,
            14.082633018493652,
            13.945236206054688
        ],
        "orginal_NLL": [
            18.427080154418945,
            20.996458053588867,
            20.026817321777344,
            19.534339904785156,
            19.8043270111084,
            19.47995376586914
        ]
    },
    {
        "cosine_value": 0.03790421038866043,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Katey Sagal",
            "target": "South African Republic",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the currency in the country of citizenship of Katey Sagal is",
            "answer": "South African pound",
            "subject": "Katey Sagal",
            "target": "South African Republic",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the currency in South African Republic is",
            "answer": "South African pound",
            "subject": "South African Republic",
            "target": "South African pound",
            "relation": "CURRENCY"
        },
        "NLL": [
            20.722888946533203,
            19.650999069213867,
            13.667747497558594,
            13.715103149414062,
            14.082633018493652,
            13.945236206054688
        ],
        "orginal_NLL": [
            18.427080154418945,
            20.996458053588867,
            20.026817321777344,
            19.534339904785156,
            19.8043270111084,
            19.47995376586914
        ]
    },
    {
        "cosine_value": 0.13229630887508392,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Katey Sagal",
            "target": "South African Republic",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the anthem of the country of citizenship of Katey Sagal is",
            "answer": "National anthem of the Transvaal",
            "subject": "Katey Sagal",
            "target": "South African Republic",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the anthem of South African Republic is",
            "answer": "National anthem of the Transvaal",
            "subject": "South African Republic",
            "target": "National anthem of the Transvaal",
            "relation": "ANTHEM"
        },
        "NLL": [
            38.60906982421875,
            36.94163513183594,
            34.6205940246582,
            30.943634033203125,
            32.752403259277344,
            32.89830017089844
        ],
        "orginal_NLL": [
            26.634693145751953,
            30.135820388793945,
            25.437856674194336,
            25.68671417236328,
            24.879533767700195,
            24.440393447875977
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Katey Sagal",
            "target": "South African Republic",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The official language of the country of citizenship of Katey Sagal is",
            "answer": "Dutch",
            "subject": "Katey Sagal",
            "target": "South African Republic",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The official language of South African Republic is",
            "answer": "Dutch",
            "subject": "South African Republic",
            "target": "Dutch",
            "relation": "OFFICIAL_LANGUAGE"
        },
        "NLL": [
            11.478351593017578,
            9.734292984008789,
            3.59401798248291,
            4.567108154296875,
            4.171158313751221,
            3.2586631774902344
        ],
        "orginal_NLL": [
            8.828886032104492,
            11.146393775939941,
            7.333048343658447,
            6.983625411987305,
            7.547390937805176,
            7.084629535675049
        ]
    },
    {
        "cosine_value": 0.0718279480934143,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Katey Sagal",
            "target": "South African Republic",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the capital city of the country of citizenship of Katey Sagal is",
            "answer": "Pretoria",
            "subject": "Katey Sagal",
            "target": "South African Republic",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the capital city of South African Republic is",
            "answer": "Pretoria",
            "subject": "South African Republic",
            "target": "Pretoria",
            "relation": "CAPITAL"
        },
        "NLL": [
            13.113533020019531,
            14.524641990661621,
            9.599506378173828,
            10.556191444396973,
            9.260047912597656,
            9.361550331115723
        ],
        "orginal_NLL": [
            10.272541046142578,
            16.768909454345703,
            13.18204116821289,
            13.131481170654297,
            12.159272193908691,
            11.7833251953125
        ]
    },
    {
        "cosine_value": 0.11271718144416809,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Katey Sagal",
            "target": "South African Republic",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the continent which the country of citizenship of Katey Sagal is part of is",
            "answer": "Africa",
            "subject": "Katey Sagal",
            "target": "South African Republic",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the continent which South African Republic is part of is",
            "answer": "Africa",
            "subject": "South African Republic",
            "target": "Africa",
            "relation": "CONTINENT"
        },
        "NLL": [
            9.337037086486816,
            12.187600135803223,
            8.4409761428833,
            7.008188724517822,
            8.098162651062012,
            7.832663059234619
        ],
        "orginal_NLL": [
            4.173624038696289,
            7.01961088180542,
            6.237689971923828,
            6.20890998840332,
            5.711850643157959,
            4.982925891876221
        ]
    },
    {
        "cosine_value": -0.05412229150533676,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Alice in borderland",
            "target": "Richard Baskin",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The gender of the composer of Alice in borderland is",
            "answer": "male",
            "subject": "Alice in borderland",
            "target": "Richard Baskin",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The gender of Richard Baskin is",
            "answer": "male",
            "subject": "Richard Baskin",
            "target": "male",
            "relation": "SEX_OR_GENDER"
        },
        "NLL": [
            3.1162469387054443,
            10.639053344726562,
            4.706532001495361,
            5.7261481285095215,
            4.12790060043335,
            4.151063442230225
        ],
        "orginal_NLL": [
            3.918260335922241,
            9.899901390075684,
            6.268855094909668,
            5.515787601470947,
            5.066833019256592,
            5.3826446533203125
        ]
    },
    {
        "cosine_value": 0.3295474052429199,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Alice in borderland",
            "target": "Richard Baskin",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the country of citizenship of the composer of Alice in borderland is",
            "answer": "United States of America",
            "subject": "Alice in borderland",
            "target": "Richard Baskin",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The name of the country of citizenship of Richard Baskin is",
            "answer": "United States of America",
            "subject": "Richard Baskin",
            "target": "United States of America",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "NLL": [
            5.366223335266113,
            8.498038291931152,
            1.1217896938323975,
            3.236785411834717,
            2.092087745666504,
            1.977557897567749
        ],
        "orginal_NLL": [
            6.699902534484863,
            10.052190780639648,
            5.853694438934326,
            7.218810081481934,
            6.546833038330078,
            6.900406360626221
        ]
    },
    {
        "cosine_value": 0.13515546917915344,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Alice in borderland",
            "target": "Richard Baskin",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the composer of Alice in borderland is",
            "answer": "film director",
            "subject": "Alice in borderland",
            "target": "Richard Baskin",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The occupation of Richard Baskin is",
            "answer": "film director",
            "subject": "Richard Baskin",
            "target": "film director",
            "relation": "OCCUPATION"
        },
        "NLL": [
            10.567573547363281,
            14.56812572479248,
            10.475271224975586,
            9.535771369934082,
            9.39365291595459,
            9.104691505432129
        ],
        "orginal_NLL": [
            12.752202987670898,
            18.819164276123047,
            14.169203758239746,
            13.430401802062988,
            12.129334449768066,
            11.88505744934082
        ]
    },
    {
        "cosine_value": 0.11391633003950119,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Alice in borderland",
            "target": "Richard Baskin",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the composer of Alice in borderland is",
            "answer": "songwriter",
            "subject": "Alice in borderland",
            "target": "Richard Baskin",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The occupation of Richard Baskin is",
            "answer": "songwriter",
            "subject": "Richard Baskin",
            "target": "songwriter",
            "relation": "OCCUPATION"
        },
        "NLL": [
            11.233538627624512,
            16.52571678161621,
            13.155632019042969,
            12.407605171203613,
            11.564971923828125,
            11.281425476074219
        ],
        "orginal_NLL": [
            10.25387954711914,
            15.34584903717041,
            12.283564567565918,
            11.889314651489258,
            11.225828170776367,
            11.46203327178955
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Alice in borderland",
            "target": "Richard Baskin",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the composer of Alice in borderland is",
            "answer": "composer",
            "subject": "Alice in borderland",
            "target": "Richard Baskin",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The occupation of Richard Baskin is",
            "answer": "composer",
            "subject": "Richard Baskin",
            "target": "composer",
            "relation": "OCCUPATION"
        },
        "NLL": [
            7.931118488311768,
            11.6675443649292,
            9.318076133728027,
            9.974774360656738,
            9.089085578918457,
            8.698476791381836
        ],
        "orginal_NLL": [
            9.486879348754883,
            12.483613014221191,
            9.529930114746094,
            9.36738109588623,
            8.26576042175293,
            7.8278326988220215
        ]
    },
    {
        "cosine_value": 0.4154760539531708,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Alice in borderland",
            "target": "Richard Baskin",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The place of birth of the composer of Alice in borderland is",
            "answer": "Pasadena",
            "subject": "Alice in borderland",
            "target": "Richard Baskin",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The place of birth of Richard Baskin is",
            "answer": "Pasadena",
            "subject": "Richard Baskin",
            "target": "Pasadena",
            "relation": "PLACE_OF_BIRTH"
        },
        "NLL": [
            7.717946529388428,
            14.98000431060791,
            10.560295104980469,
            9.902178764343262,
            8.306686401367188,
            8.379941940307617
        ],
        "orginal_NLL": [
            9.580388069152832,
            14.66303539276123,
            10.086045265197754,
            9.21523666381836,
            9.102985382080078,
            9.190498352050781
        ]
    },
    {
        "cosine_value": 0.17954875528812408,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Alice in borderland",
            "target": "Richard Baskin",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the father of the composer of Alice in borderland is",
            "answer": "Burt Baskin",
            "subject": "Alice in borderland",
            "target": "Richard Baskin",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The name of the father of Richard Baskin is",
            "answer": "Burt Baskin",
            "subject": "Richard Baskin",
            "target": "Burt Baskin",
            "relation": "FATHER"
        },
        "NLL": [
            29.78628921508789,
            34.07865524291992,
            23.48809242248535,
            23.842697143554688,
            22.888259887695312,
            23.225265502929688
        ],
        "orginal_NLL": [
            19.719799041748047,
            31.274606704711914,
            21.754642486572266,
            21.650339126586914,
            21.154294967651367,
            20.727258682250977
        ]
    },
    {
        "cosine_value": 0.3148319721221924,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Alice in borderland",
            "target": "Richard Baskin",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the mother of the composer of Alice in borderland is",
            "answer": "Shirley Familian",
            "subject": "Alice in borderland",
            "target": "Richard Baskin",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The name of the mother of Richard Baskin is",
            "answer": "Shirley Familian",
            "subject": "Richard Baskin",
            "target": "Shirley Familian",
            "relation": "MOTHER"
        },
        "NLL": [
            36.68478775024414,
            36.91416931152344,
            31.595399856567383,
            32.362892150878906,
            30.97821617126465,
            30.905210494995117
        ],
        "orginal_NLL": [
            22.928396224975586,
            32.96446228027344,
            24.723485946655273,
            25.32594108581543,
            23.916894912719727,
            23.833162307739258
        ]
    },
    {
        "cosine_value": 0.1692921221256256,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Alice in borderland",
            "target": "Richard Baskin",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the field of work of the composer of Alice in borderland is",
            "answer": "film score",
            "subject": "Alice in borderland",
            "target": "Richard Baskin",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The name of the field of work of Richard Baskin is",
            "answer": "film score",
            "subject": "Richard Baskin",
            "target": "film score",
            "relation": "FIELD_OF_WORK"
        },
        "NLL": [
            10.823244094848633,
            18.787044525146484,
            11.4249267578125,
            10.55837631225586,
            11.016439437866211,
            10.282732009887695
        ],
        "orginal_NLL": [
            11.350756645202637,
            16.780427932739258,
            12.360079765319824,
            11.546940803527832,
            10.308958053588867,
            10.537683486938477
        ]
    },
    {
        "cosine_value": 0.21376284956932068,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Christine Grady",
            "target": "Aerican Empire",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the continent which the country of citizenship of Christine Grady is part of is",
            "answer": "Australian continent",
            "subject": "Christine Grady",
            "target": "Aerican Empire",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the continent which Aerican Empire is part of is",
            "answer": "Australian continent",
            "subject": "Aerican Empire",
            "target": "Australian continent",
            "relation": "CONTINENT"
        },
        "NLL": [
            16.007705688476562,
            17.797893524169922,
            15.609634399414062,
            14.773823738098145,
            14.557194709777832,
            14.043713569641113
        ],
        "orginal_NLL": [
            10.729917526245117,
            11.120070457458496,
            10.71027660369873,
            11.574122428894043,
            10.452166557312012,
            10.59644603729248
        ]
    },
    {
        "cosine_value": -0.18915320932865143,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Christine Grady",
            "target": "Aerican Empire",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the continent which the country of citizenship of Christine Grady is part of is",
            "answer": "North America",
            "subject": "Christine Grady",
            "target": "Aerican Empire",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the continent which Aerican Empire is part of is",
            "answer": "North America",
            "subject": "Aerican Empire",
            "target": "North America",
            "relation": "CONTINENT"
        },
        "NLL": [
            9.950676918029785,
            13.054072380065918,
            8.137299537658691,
            7.485881328582764,
            7.007866382598877,
            6.917355060577393
        ],
        "orginal_NLL": [
            1.4083231687545776,
            3.822948694229126,
            3.4917452335357666,
            3.8702211380004883,
            3.2200355529785156,
            2.860504150390625
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Christine Grady",
            "target": "Aerican Empire",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the capital city of the country of citizenship of Christine Grady is",
            "answer": "Montreal",
            "subject": "Christine Grady",
            "target": "Aerican Empire",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the capital city of Aerican Empire is",
            "answer": "Montreal",
            "subject": "Aerican Empire",
            "target": "Montreal",
            "relation": "CAPITAL"
        },
        "NLL": [
            18.13737678527832,
            14.108077049255371,
            12.27302360534668,
            13.513151168823242,
            12.480690002441406,
            12.607063293457031
        ],
        "orginal_NLL": [
            9.390914916992188,
            12.628582954406738,
            10.493414878845215,
            10.482202529907227,
            9.900373458862305,
            9.598066329956055
        ]
    },
    {
        "cosine_value": -0.09304673969745636,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Christine Grady",
            "target": "Aerican Empire",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The official language of the country of citizenship of Christine Grady is",
            "answer": "English",
            "subject": "Christine Grady",
            "target": "Aerican Empire",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The official language of Aerican Empire is",
            "answer": "English",
            "subject": "Aerican Empire",
            "target": "English",
            "relation": "OFFICIAL_LANGUAGE"
        },
        "NLL": [
            7.747570514678955,
            7.396084308624268,
            8.884584426879883,
            10.555646896362305,
            5.554515361785889,
            5.458366870880127
        ],
        "orginal_NLL": [
            0.5824877619743347,
            4.13348388671875,
            2.1732046604156494,
            2.5726988315582275,
            1.5708327293395996,
            1.7032989263534546
        ]
    },
    {
        "cosine_value": 0.09533277153968811,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Christine Grady",
            "target": "Aerican Empire",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the anthem of the country of citizenship of Christine Grady is",
            "answer": "Home Is Where I Hang My Towel",
            "subject": "Christine Grady",
            "target": "Aerican Empire",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the anthem of Aerican Empire is",
            "answer": "Home Is Where I Hang My Towel",
            "subject": "Aerican Empire",
            "target": "Home Is Where I Hang My Towel",
            "relation": "ANTHEM"
        },
        "NLL": [
            51.10062789916992,
            54.126529693603516,
            48.732398986816406,
            47.89372634887695,
            47.13762664794922,
            45.929969787597656
        ],
        "orginal_NLL": [
            30.666561126708984,
            35.27360534667969,
            32.17141342163086,
            33.171504974365234,
            31.943788528442383,
            31.330556869506836
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The place of birth of {} is",
            "subject": "Glover Teixeira",
            "target": "Collinas",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the capital city of the place of birth of Glover Teixeira is",
            "answer": "Collinas",
            "subject": "Glover Teixeira",
            "target": "Collinas",
            "relation": "PLACE_OF_BIRTH"
        },
        "condition_query": {
            "prompt": "The name of the capital city of Collinas is",
            "answer": "Collinas",
            "subject": "Collinas",
            "target": "Collinas",
            "relation": "CAPITAL"
        },
        "NLL": [
            6.051634311676025,
            10.087347984313965,
            4.133896827697754,
            4.831818580627441,
            3.77024507522583,
            4.048704624176025
        ],
        "orginal_NLL": [
            18.659000396728516,
            21.720966339111328,
            18.81157875061035,
            19.33543586730957,
            18.63526153564453,
            18.977764129638672
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Pearl",
            "target": "Peter Peter",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The gender of the composer of Pearl is",
            "answer": "male",
            "subject": "Pearl",
            "target": "Peter Peter",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The gender of Peter Peter is",
            "answer": "male",
            "subject": "Peter Peter",
            "target": "male",
            "relation": "SEX_OR_GENDER"
        },
        "NLL": [
            7.5257720947265625,
            8.002715110778809,
            5.825773239135742,
            6.834204196929932,
            6.84677267074585,
            6.53814172744751
        ],
        "orginal_NLL": [
            4.906036853790283,
            9.221638679504395,
            6.439352989196777,
            9.297013282775879,
            5.623159408569336,
            5.5485687255859375
        ]
    },
    {
        "cosine_value": -0.024146439507603645,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Pearl",
            "target": "Peter Peter",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the country of citizenship of the composer of Pearl is",
            "answer": "Denmark",
            "subject": "Pearl",
            "target": "Peter Peter",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The name of the country of citizenship of Peter Peter is",
            "answer": "Denmark",
            "subject": "Peter Peter",
            "target": "Denmark",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "NLL": [
            19.59912872314453,
            14.483241081237793,
            11.846321105957031,
            12.443424224853516,
            13.374828338623047,
            13.497798919677734
        ],
        "orginal_NLL": [
            5.006250858306885,
            10.438030242919922,
            6.987707614898682,
            8.100582122802734,
            6.502643585205078,
            6.549327850341797
        ]
    },
    {
        "cosine_value": 0.06834174692630768,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Pearl",
            "target": "Peter Peter",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the composer of Pearl is",
            "answer": "musician",
            "subject": "Pearl",
            "target": "Peter Peter",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The occupation of Peter Peter is",
            "answer": "musician",
            "subject": "Peter Peter",
            "target": "musician",
            "relation": "OCCUPATION"
        },
        "NLL": [
            14.86812686920166,
            12.286108016967773,
            13.135113716125488,
            11.832457542419434,
            11.0770902633667,
            9.961143493652344
        ],
        "orginal_NLL": [
            8.775853157043457,
            9.674760818481445,
            10.915159225463867,
            11.950116157531738,
            9.396828651428223,
            9.488935470581055
        ]
    },
    {
        "cosine_value": -0.09293331950902939,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Pearl",
            "target": "Peter Peter",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the composer of Pearl is",
            "answer": "composer",
            "subject": "Pearl",
            "target": "Peter Peter",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The occupation of Peter Peter is",
            "answer": "composer",
            "subject": "Peter Peter",
            "target": "composer",
            "relation": "OCCUPATION"
        },
        "NLL": [
            14.180134773254395,
            12.310548782348633,
            12.642630577087402,
            12.782309532165527,
            11.404479026794434,
            10.60698127746582
        ],
        "orginal_NLL": [
            8.989896774291992,
            9.057727813720703,
            10.05864143371582,
            12.500158309936523,
            7.896347522735596,
            8.231062889099121
        ]
    },
    {
        "cosine_value": 0.042692430317401886,
        "edited_data": {
            "prompt": "The name of the composer of {} is",
            "subject": "Pearl",
            "target": "Peter Peter",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The place of birth of the composer of Pearl is",
            "answer": "Bornholm",
            "subject": "Pearl",
            "target": "Peter Peter",
            "relation": "COMPOSER"
        },
        "condition_query": {
            "prompt": "The place of birth of Peter Peter is",
            "answer": "Bornholm",
            "subject": "Peter Peter",
            "target": "Bornholm",
            "relation": "PLACE_OF_BIRTH"
        },
        "NLL": [
            12.134310722351074,
            13.65829086303711,
            13.174847602844238,
            13.780852317810059,
            11.473204612731934,
            11.125165939331055
        ],
        "orginal_NLL": [
            12.588966369628906,
            14.775965690612793,
            13.649382591247559,
            15.113144874572754,
            14.795370101928711,
            14.950826644897461
        ]
    },
    {
        "cosine_value": 0.10532437264919281,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Where the Crawdads Sing",
            "target": "Bharathiraja",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The place of birth of the director of Where the Crawdads Sing is",
            "answer": "Theni",
            "subject": "Where the Crawdads Sing",
            "target": "Bharathiraja",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The place of birth of Bharathiraja is",
            "answer": "Theni",
            "subject": "Bharathiraja",
            "target": "Theni",
            "relation": "PLACE_OF_BIRTH"
        },
        "NLL": [
            5.9133830070495605,
            8.57388973236084,
            9.597640037536621,
            13.323907852172852,
            11.469452857971191,
            11.57104778289795
        ],
        "orginal_NLL": [
            14.089908599853516,
            16.216543197631836,
            14.55827522277832,
            16.626548767089844,
            14.680727005004883,
            14.89218521118164
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Where the Crawdads Sing",
            "target": "Bharathiraja",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the country of citizenship of the director of Where the Crawdads Sing is",
            "answer": "India",
            "subject": "Where the Crawdads Sing",
            "target": "Bharathiraja",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The name of the country of citizenship of Bharathiraja is",
            "answer": "India",
            "subject": "Bharathiraja",
            "target": "India",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "NLL": [
            11.029175758361816,
            7.193479537963867,
            4.3532915115356445,
            5.835527420043945,
            4.052894592285156,
            3.6520137786865234
        ],
        "orginal_NLL": [
            9.196542739868164,
            8.785683631896973,
            7.584731578826904,
            8.449424743652344,
            7.0225348472595215,
            6.7933669090271
        ]
    },
    {
        "cosine_value": 0.11578831821680069,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Where the Crawdads Sing",
            "target": "Bharathiraja",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the director of Where the Crawdads Sing is",
            "answer": "film director",
            "subject": "Where the Crawdads Sing",
            "target": "Bharathiraja",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The occupation of Bharathiraja is",
            "answer": "film director",
            "subject": "Bharathiraja",
            "target": "film director",
            "relation": "OCCUPATION"
        },
        "NLL": [
            14.095725059509277,
            13.382938385009766,
            13.020748138427734,
            13.179516792297363,
            10.76715087890625,
            10.435830116271973
        ],
        "orginal_NLL": [
            11.51321029663086,
            16.147310256958008,
            12.54488754272461,
            12.929805755615234,
            11.175457954406738,
            10.291742324829102
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Where the Crawdads Sing",
            "target": "Bharathiraja",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the director of Where the Crawdads Sing is",
            "answer": "actor",
            "subject": "Where the Crawdads Sing",
            "target": "Bharathiraja",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The occupation of Bharathiraja is",
            "answer": "actor",
            "subject": "Bharathiraja",
            "target": "actor",
            "relation": "OCCUPATION"
        },
        "NLL": [
            15.30325984954834,
            12.701546669006348,
            13.413583755493164,
            13.93337345123291,
            12.26300048828125,
            11.965309143066406
        ],
        "orginal_NLL": [
            8.868720054626465,
            14.902305603027344,
            11.279349327087402,
            12.043394088745117,
            10.035184860229492,
            10.00524616241455
        ]
    },
    {
        "cosine_value": 0.013557654805481434,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Where the Crawdads Sing",
            "target": "Bharathiraja",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the director of Where the Crawdads Sing is",
            "answer": "screenwriter",
            "subject": "Where the Crawdads Sing",
            "target": "Bharathiraja",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The occupation of Bharathiraja is",
            "answer": "screenwriter",
            "subject": "Bharathiraja",
            "target": "screenwriter",
            "relation": "OCCUPATION"
        },
        "NLL": [
            12.59199333190918,
            13.033064842224121,
            14.87524127960205,
            15.784114837646484,
            12.583053588867188,
            11.851607322692871
        ],
        "orginal_NLL": [
            8.266291618347168,
            15.166129112243652,
            11.876142501831055,
            13.310704231262207,
            10.09939193725586,
            9.861204147338867
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Where the Crawdads Sing",
            "target": "Bharathiraja",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The gender of the director of Where the Crawdads Sing is",
            "answer": "male",
            "subject": "Where the Crawdads Sing",
            "target": "Bharathiraja",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The gender of Bharathiraja is",
            "answer": "male",
            "subject": "Bharathiraja",
            "target": "male",
            "relation": "SEX_OR_GENDER"
        },
        "NLL": [
            5.310662269592285,
            7.30584192276001,
            9.445106506347656,
            11.384074211120605,
            6.975286483764648,
            7.182150840759277
        ],
        "orginal_NLL": [
            3.761206865310669,
            8.931375503540039,
            6.35734748840332,
            8.384223937988281,
            5.168347358703613,
            4.881295680999756
        ]
    },
    {
        "cosine_value": 0.11230464279651642,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Where the Crawdads Sing",
            "target": "Bharathiraja",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the director of Where the Crawdads Sing won is",
            "answer": "Nandi Awards",
            "subject": "Where the Crawdads Sing",
            "target": "Bharathiraja",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The name of the award Bharathiraja won is",
            "answer": "Nandi Awards",
            "subject": "Bharathiraja",
            "target": "Nandi Awards",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            9.483214378356934,
            15.360835075378418,
            9.925975799560547,
            11.496036529541016,
            10.284626007080078,
            10.101892471313477
        ],
        "orginal_NLL": [
            16.15280532836914,
            20.239730834960938,
            17.0063533782959,
            18.185684204101562,
            15.740729331970215,
            14.956865310668945
        ]
    },
    {
        "cosine_value": 0.1505546122789383,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Where the Crawdads Sing",
            "target": "Bharathiraja",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the director of Where the Crawdads Sing won is",
            "answer": "Filmfare Awards South",
            "subject": "Where the Crawdads Sing",
            "target": "Bharathiraja",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The name of the award Bharathiraja won is",
            "answer": "Filmfare Awards South",
            "subject": "Bharathiraja",
            "target": "Filmfare Awards South",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            7.436819553375244,
            13.143784523010254,
            9.72663688659668,
            10.838286399841309,
            8.126653671264648,
            7.793419361114502
        ],
        "orginal_NLL": [
            16.91175079345703,
            18.72242546081543,
            18.14265251159668,
            16.811161041259766,
            15.022666931152344,
            14.843361854553223
        ]
    },
    {
        "cosine_value": 0.15443003177642822,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Where the Crawdads Sing",
            "target": "Bharathiraja",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the director of Where the Crawdads Sing won is",
            "answer": "Padma Shri in arts",
            "subject": "Where the Crawdads Sing",
            "target": "Bharathiraja",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The name of the award Bharathiraja won is",
            "answer": "Padma Shri in arts",
            "subject": "Bharathiraja",
            "target": "Padma Shri in arts",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            18.33953094482422,
            25.358882904052734,
            22.379934310913086,
            26.043682098388672,
            21.705476760864258,
            20.94993782043457
        ],
        "orginal_NLL": [
            22.66766357421875,
            27.132705688476562,
            29.858966827392578,
            30.505516052246094,
            27.635963439941406,
            26.623022079467773
        ]
    },
    {
        "cosine_value": 0.23455320298671722,
        "edited_data": {
            "prompt": "The name of the director of {} is",
            "subject": "Where the Crawdads Sing",
            "target": "Bharathiraja",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the child of the director of Where the Crawdads Sing is",
            "answer": "Manoj Bharathiraja",
            "subject": "Where the Crawdads Sing",
            "target": "Bharathiraja",
            "relation": "DIRECTOR"
        },
        "condition_query": {
            "prompt": "The name of the child of Bharathiraja is",
            "answer": "Manoj Bharathiraja",
            "subject": "Bharathiraja",
            "target": "Manoj Bharathiraja",
            "relation": "CHILD"
        },
        "NLL": [
            16.77725601196289,
            22.741586685180664,
            16.55514907836914,
            17.98172950744629,
            14.797415733337402,
            14.47072696685791
        ],
        "orginal_NLL": [
            36.172019958496094,
            40.58811950683594,
            34.01129150390625,
            35.80318069458008,
            31.871170043945312,
            31.149995803833008
        ]
    },
    {
        "cosine_value": -0.0,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "BBC World Service",
            "target": "Mandatory Iraq",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the continent which the country BBC World Service is associated with is part of is",
            "answer": "Asia",
            "subject": "BBC World Service",
            "target": "Mandatory Iraq",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the continent which Mandatory Iraq is part of is",
            "answer": "Asia",
            "subject": "Mandatory Iraq",
            "target": "Asia",
            "relation": "CONTINENT"
        },
        "NLL": [
            9.61246109008789,
            9.573203086853027,
            7.647615432739258,
            6.729016304016113,
            5.049993991851807,
            5.5497965812683105
        ],
        "orginal_NLL": [
            3.860766887664795,
            9.117902755737305,
            5.7906999588012695,
            6.503698348999023,
            4.17844820022583,
            4.165318965911865
        ]
    },
    {
        "cosine_value": 0.02410734072327614,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "BBC World Service",
            "target": "Mandatory Iraq",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The official language of the country BBC World Service is associated with is",
            "answer": "Arabic",
            "subject": "BBC World Service",
            "target": "Mandatory Iraq",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The official language of Mandatory Iraq is",
            "answer": "Arabic",
            "subject": "Mandatory Iraq",
            "target": "Arabic",
            "relation": "OFFICIAL_LANGUAGE"
        },
        "NLL": [
            6.89399528503418,
            6.841290473937988,
            4.163792133331299,
            5.894496917724609,
            4.3165998458862305,
            4.603098392486572
        ],
        "orginal_NLL": [
            4.882181644439697,
            10.242345809936523,
            5.814697265625,
            8.132329940795898,
            5.182335376739502,
            5.586039066314697
        ]
    },
    {
        "cosine_value": -0.028549518436193466,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "BBC World Service",
            "target": "Mandatory Iraq",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The official language of the country BBC World Service is associated with is",
            "answer": "English",
            "subject": "BBC World Service",
            "target": "Mandatory Iraq",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The official language of Mandatory Iraq is",
            "answer": "English",
            "subject": "Mandatory Iraq",
            "target": "English",
            "relation": "OFFICIAL_LANGUAGE"
        },
        "NLL": [
            1.0536373853683472,
            4.3109965324401855,
            2.297271966934204,
            2.737853765487671,
            1.964238166809082,
            1.3912200927734375
        ],
        "orginal_NLL": [
            0.6306264400482178,
            6.015182971954346,
            2.427572250366211,
            3.1573853492736816,
            2.2205681800842285,
            2.5492336750030518
        ]
    },
    {
        "cosine_value": 0.056546326726675034,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "BBC World Service",
            "target": "Mandatory Iraq",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the capital city of the country BBC World Service is associated with is",
            "answer": "Baghdad",
            "subject": "BBC World Service",
            "target": "Mandatory Iraq",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the capital city of Mandatory Iraq is",
            "answer": "Baghdad",
            "subject": "Mandatory Iraq",
            "target": "Baghdad",
            "relation": "CAPITAL"
        },
        "NLL": [
            7.39327335357666,
            8.425114631652832,
            4.084447383880615,
            6.013339042663574,
            3.736774206161499,
            3.118701696395874
        ],
        "orginal_NLL": [
            8.728854179382324,
            12.324687004089355,
            13.176830291748047,
            12.01370906829834,
            9.755159378051758,
            9.494898796081543
        ]
    },
    {
        "cosine_value": 0.014349794946610928,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "BBC World Service",
            "target": "Mandatory Iraq",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the currency in the country BBC World Service is associated with is",
            "answer": "Indian rupee",
            "subject": "BBC World Service",
            "target": "Mandatory Iraq",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the currency in Mandatory Iraq is",
            "answer": "Indian rupee",
            "subject": "Mandatory Iraq",
            "target": "Indian rupee",
            "relation": "CURRENCY"
        },
        "NLL": [
            10.028151512145996,
            10.102639198303223,
            7.565305709838867,
            7.413416862487793,
            6.080245018005371,
            6.364527702331543
        ],
        "orginal_NLL": [
            9.470163345336914,
            10.578286170959473,
            10.099955558776855,
            10.473146438598633,
            9.205314636230469,
            9.291849136352539
        ]
    },
    {
        "cosine_value": 0.014779971912503242,
        "edited_data": {
            "prompt": "The name of the country which {} is associated with is",
            "subject": "BBC World Service",
            "target": "Mandatory Iraq",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the anthem of the country BBC World Service is associated with is",
            "answer": "As-Salam al-Malaki",
            "subject": "BBC World Service",
            "target": "Mandatory Iraq",
            "relation": "COUNTRY"
        },
        "condition_query": {
            "prompt": "The name of the anthem of Mandatory Iraq is",
            "answer": "As-Salam al-Malaki",
            "subject": "Mandatory Iraq",
            "target": "As-Salam al-Malaki",
            "relation": "ANTHEM"
        },
        "NLL": [
            28.495283126831055,
            36.61622619628906,
            30.37367057800293,
            29.699867248535156,
            31.246435165405273,
            31.525793075561523
        ],
        "orginal_NLL": [
            15.720538139343262,
            19.646926879882812,
            16.865610122680664,
            17.33561134338379,
            15.962518692016602,
            16.246200561523438
        ]
    },
    {
        "cosine_value": -0.0,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The gender of the screenwriter of Tulsa King is",
            "answer": "male",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The gender of Tony Hillerman is",
            "answer": "male",
            "subject": "Tony Hillerman",
            "target": "male",
            "relation": "SEX_OR_GENDER"
        },
        "NLL": [
            1.8630573749542236,
            8.322688102722168,
            5.347137451171875,
            7.017582416534424,
            2.0137240886688232,
            2.11824631690979
        ],
        "orginal_NLL": [
            3.101552963256836,
            10.042351722717285,
            5.556845664978027,
            5.698794841766357,
            4.833571910858154,
            4.68301248550415
        ]
    },
    {
        "cosine_value": 0.05922186002135277,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The place of birth of the screenwriter of Tulsa King is",
            "answer": "Pottawatomie County",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The place of birth of Tony Hillerman is",
            "answer": "Pottawatomie County",
            "subject": "Tony Hillerman",
            "target": "Pottawatomie County",
            "relation": "PLACE_OF_BIRTH"
        },
        "NLL": [
            15.008296012878418,
            22.351110458374023,
            15.539200782775879,
            15.749519348144531,
            14.481557846069336,
            14.468400955200195
        ],
        "orginal_NLL": [
            14.558873176574707,
            20.395326614379883,
            15.826135635375977,
            15.596712112426758,
            15.150798797607422,
            15.298521041870117
        ]
    },
    {
        "cosine_value": 0.03367055580019951,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The place of death of the screenwriter of Tulsa King is",
            "answer": "Albuquerque",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The place of death of Tony Hillerman is",
            "answer": "Albuquerque",
            "subject": "Tony Hillerman",
            "target": "Albuquerque",
            "relation": "PLACE_OF_DEATH"
        },
        "NLL": [
            6.225413799285889,
            15.028838157653809,
            8.408303260803223,
            9.343167304992676,
            6.820181846618652,
            6.843409538269043
        ],
        "orginal_NLL": [
            8.088035583496094,
            14.81204605102539,
            9.420291900634766,
            10.086801528930664,
            8.22473430633545,
            8.22342300415039
        ]
    },
    {
        "cosine_value": -0.05702522024512291,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the country of citizenship of the screenwriter of Tulsa King is",
            "answer": "United States of America",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The name of the country of citizenship of Tony Hillerman is",
            "answer": "United States of America",
            "subject": "Tony Hillerman",
            "target": "United States of America",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "NLL": [
            13.82544994354248,
            10.702193260192871,
            10.785093307495117,
            11.412680625915527,
            9.687495231628418,
            9.715994834899902
        ],
        "orginal_NLL": [
            2.639256000518799,
            6.3526611328125,
            2.978853940963745,
            4.183262825012207,
            3.3518006801605225,
            3.3614630699157715
        ]
    },
    {
        "cosine_value": -9.93621870293282e-05,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the screenwriter of Tulsa King won is",
            "answer": "Bronze Star Medal",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The name of the award Tony Hillerman won is",
            "answer": "Bronze Star Medal",
            "subject": "Tony Hillerman",
            "target": "Bronze Star Medal",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            17.81568145751953,
            21.633777618408203,
            20.511756896972656,
            23.21300506591797,
            19.789499282836914,
            20.0273494720459
        ],
        "orginal_NLL": [
            18.64560890197754,
            21.698083877563477,
            21.13267707824707,
            22.247560501098633,
            19.952823638916016,
            19.890554428100586
        ]
    },
    {
        "cosine_value": 0.008899860084056854,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the screenwriter of Tulsa King won is",
            "answer": "Purple Heart",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The name of the award Tony Hillerman won is",
            "answer": "Purple Heart",
            "subject": "Tony Hillerman",
            "target": "Purple Heart",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            14.371845245361328,
            18.260990142822266,
            12.860721588134766,
            13.94594669342041,
            11.23007583618164,
            11.235713958740234
        ],
        "orginal_NLL": [
            13.506731033325195,
            18.010974884033203,
            13.953605651855469,
            13.734076499938965,
            11.600071907043457,
            11.718565940856934
        ]
    },
    {
        "cosine_value": -0.03748076781630516,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the screenwriter of Tulsa King won is",
            "answer": "Silver Star",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The name of the award Tony Hillerman won is",
            "answer": "Silver Star",
            "subject": "Tony Hillerman",
            "target": "Silver Star",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            12.076903343200684,
            15.313182830810547,
            13.683557510375977,
            16.162109375,
            13.408287048339844,
            13.312016487121582
        ],
        "orginal_NLL": [
            13.378938674926758,
            15.804743766784668,
            15.859585762023926,
            16.444002151489258,
            15.535613059997559,
            15.156529426574707
        ]
    },
    {
        "cosine_value": -0.02242172136902809,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the screenwriter of Tulsa King won is",
            "answer": "Edgar Awards",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The name of the award Tony Hillerman won is",
            "answer": "Edgar Awards",
            "subject": "Tony Hillerman",
            "target": "Edgar Awards",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            12.487061500549316,
            17.66485023498535,
            14.0723876953125,
            15.970827102661133,
            12.7308931350708,
            12.357024192810059
        ],
        "orginal_NLL": [
            10.03028678894043,
            16.107873916625977,
            12.416566848754883,
            13.278308868408203,
            11.1118745803833,
            10.91946792602539
        ]
    },
    {
        "cosine_value": -0.06329849362373352,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the screenwriter of Tulsa King won is",
            "answer": "Anthony Award",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The name of the award Tony Hillerman won is",
            "answer": "Anthony Award",
            "subject": "Tony Hillerman",
            "target": "Anthony Award",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            8.67791748046875,
            13.805806159973145,
            10.223234176635742,
            12.625739097595215,
            9.82166576385498,
            9.662761688232422
        ],
        "orginal_NLL": [
            9.432808876037598,
            14.625447273254395,
            13.296732902526855,
            14.284432411193848,
            14.012834548950195,
            14.255454063415527
        ]
    },
    {
        "cosine_value": -0.06329849362373352,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the screenwriter of Tulsa King won is",
            "answer": "Anthony Award",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The name of the award Tony Hillerman won is",
            "answer": "Anthony Award",
            "subject": "Tony Hillerman",
            "target": "Anthony Award",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            8.67791748046875,
            13.805806159973145,
            10.223234176635742,
            12.625739097595215,
            9.82166576385498,
            9.662761688232422
        ],
        "orginal_NLL": [
            9.432808876037598,
            14.625447273254395,
            13.296732902526855,
            14.284432411193848,
            14.012834548950195,
            14.255454063415527
        ]
    },
    {
        "cosine_value": 0.02131311595439911,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the screenwriter of Tulsa King won is",
            "answer": "Nero Award",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The name of the award Tony Hillerman won is",
            "answer": "Nero Award",
            "subject": "Tony Hillerman",
            "target": "Nero Award",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            17.527624130249023,
            19.986587524414062,
            17.492916107177734,
            20.230249404907227,
            17.64417266845703,
            17.52946662902832
        ],
        "orginal_NLL": [
            16.011978149414062,
            20.71176528930664,
            18.593555450439453,
            19.311695098876953,
            18.146163940429688,
            17.62338638305664
        ]
    },
    {
        "cosine_value": -0.0485474169254303,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the screenwriter of Tulsa King won is",
            "answer": "Macavity Awards",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The name of the award Tony Hillerman won is",
            "answer": "Macavity Awards",
            "subject": "Tony Hillerman",
            "target": "Macavity Awards",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            18.315458297729492,
            20.52081298828125,
            19.72140884399414,
            21.394515991210938,
            19.989940643310547,
            19.3002986907959
        ],
        "orginal_NLL": [
            14.648411750793457,
            20.11337661743164,
            19.352819442749023,
            18.72806739807129,
            18.22075843811035,
            18.34273910522461
        ]
    },
    {
        "cosine_value": 0.0025090626440942287,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the screenwriter of Tulsa King won is",
            "answer": "Agatha Award",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The name of the award Tony Hillerman won is",
            "answer": "Agatha Award",
            "subject": "Tony Hillerman",
            "target": "Agatha Award",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            11.43773365020752,
            14.431375503540039,
            11.580315589904785,
            13.993192672729492,
            10.768982887268066,
            9.784717559814453
        ],
        "orginal_NLL": [
            13.282221794128418,
            16.699222564697266,
            15.676536560058594,
            15.660855293273926,
            14.225940704345703,
            13.283424377441406
        ]
    },
    {
        "cosine_value": -0.0,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the screenwriter of Tulsa King is",
            "answer": "writer",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The occupation of Tony Hillerman is",
            "answer": "writer",
            "subject": "Tony Hillerman",
            "target": "writer",
            "relation": "OCCUPATION"
        },
        "NLL": [
            6.5174078941345215,
            12.030562400817871,
            10.202004432678223,
            10.378562927246094,
            6.170257568359375,
            6.348304748535156
        ],
        "orginal_NLL": [
            7.996029853820801,
            13.034446716308594,
            9.533672332763672,
            10.384007453918457,
            8.445989608764648,
            8.481815338134766
        ]
    },
    {
        "cosine_value": -0.05980253964662552,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the screenwriter of Tulsa King is",
            "answer": "novelist",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The occupation of Tony Hillerman is",
            "answer": "novelist",
            "subject": "Tony Hillerman",
            "target": "novelist",
            "relation": "OCCUPATION"
        },
        "NLL": [
            9.967781066894531,
            15.698556900024414,
            13.476146697998047,
            13.393280029296875,
            8.276012420654297,
            8.628378868103027
        ],
        "orginal_NLL": [
            11.822282791137695,
            16.710222244262695,
            13.653180122375488,
            14.141132354736328,
            11.555752754211426,
            11.60771656036377
        ]
    },
    {
        "cosine_value": -0.06603340059518814,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the screenwriter of Tulsa King is",
            "answer": "screenwriter",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The occupation of Tony Hillerman is",
            "answer": "screenwriter",
            "subject": "Tony Hillerman",
            "target": "screenwriter",
            "relation": "OCCUPATION"
        },
        "NLL": [
            9.01918888092041,
            13.230799674987793,
            12.973097801208496,
            13.12209415435791,
            8.97240161895752,
            9.343538284301758
        ],
        "orginal_NLL": [
            8.910651206970215,
            14.34438705444336,
            11.031323432922363,
            11.49951457977295,
            8.161599159240723,
            7.5566606521606445
        ]
    },
    {
        "cosine_value": 0.11776500940322876,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the employer of the screenwriter of Tulsa King is",
            "answer": "University of New Mexico",
            "subject": "Tulsa King",
            "target": "Tony Hillerman",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The name of the employer of Tony Hillerman is",
            "answer": "University of New Mexico",
            "subject": "Tony Hillerman",
            "target": "University of New Mexico",
            "relation": "EMPLOYER"
        },
        "NLL": [
            20.233478546142578,
            19.976987838745117,
            15.29121208190918,
            15.411831855773926,
            13.836755752563477,
            14.258048057556152
        ],
        "orginal_NLL": [
            18.421289443969727,
            22.32915496826172,
            16.145648956298828,
            16.0263671875,
            15.114150047302246,
            15.190439224243164
        ]
    },
    {
        "cosine_value": 0.14739461243152618,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Sunil Lahri",
            "target": "Viceroyalty of New Granada",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the capital city of the country of citizenship of Sunil Lahri is",
            "answer": "Bogot\u00e1",
            "subject": "Sunil Lahri",
            "target": "Viceroyalty of New Granada",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the capital city of Viceroyalty of New Granada is",
            "answer": "Bogot\u00e1",
            "subject": "Viceroyalty of New Granada",
            "target": "Bogot\u00e1",
            "relation": "CAPITAL"
        },
        "NLL": [
            15.284709930419922,
            13.50871753692627,
            9.445725440979004,
            8.870221138000488,
            9.84125804901123,
            9.663667678833008
        ],
        "orginal_NLL": [
            8.783174514770508,
            11.413042068481445,
            12.08961009979248,
            12.436034202575684,
            11.29527473449707,
            11.289106369018555
        ]
    },
    {
        "cosine_value": 0.06171901896595955,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Sunil Lahri",
            "target": "Viceroyalty of New Granada",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the currency in the country of citizenship of Sunil Lahri is",
            "answer": "Spanish real",
            "subject": "Sunil Lahri",
            "target": "Viceroyalty of New Granada",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the currency in Viceroyalty of New Granada is",
            "answer": "Spanish real",
            "subject": "Viceroyalty of New Granada",
            "target": "Spanish real",
            "relation": "CURRENCY"
        },
        "NLL": [
            20.396198272705078,
            21.30972671508789,
            17.461393356323242,
            15.445558547973633,
            14.865782737731934,
            15.174162864685059
        ],
        "orginal_NLL": [
            20.94951820373535,
            23.31302261352539,
            19.337074279785156,
            18.818603515625,
            19.412841796875,
            19.385862350463867
        ]
    },
    {
        "cosine_value": 0.03854363039135933,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Sunil Lahri",
            "target": "Viceroyalty of New Granada",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the continent which the country of citizenship of Sunil Lahri is part of is",
            "answer": "South America",
            "subject": "Sunil Lahri",
            "target": "Viceroyalty of New Granada",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the continent which Viceroyalty of New Granada is part of is",
            "answer": "South America",
            "subject": "Viceroyalty of New Granada",
            "target": "South America",
            "relation": "CONTINENT"
        },
        "NLL": [
            9.696216583251953,
            16.308265686035156,
            12.548698425292969,
            11.949150085449219,
            11.873637199401855,
            11.494484901428223
        ],
        "orginal_NLL": [
            3.81386661529541,
            7.796526908874512,
            7.047760486602783,
            7.709829330444336,
            6.577200889587402,
            5.53210973739624
        ]
    },
    {
        "cosine_value": -0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Grace Kelly",
            "target": "Ursula Newell Emerson",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The gender of the mother of Grace Kelly is",
            "answer": "female",
            "subject": "Grace Kelly",
            "target": "Ursula Newell Emerson",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The gender of Ursula Newell Emerson is",
            "answer": "female",
            "subject": "Ursula Newell Emerson",
            "target": "female",
            "relation": "SEX_OR_GENDER"
        },
        "NLL": [
            4.658754348754883,
            13.417842864990234,
            7.967371940612793,
            9.397228240966797,
            6.063802719116211,
            5.691669940948486
        ],
        "orginal_NLL": [
            3.4856820106506348,
            9.717560768127441,
            5.843012809753418,
            7.263059616088867,
            4.552767753601074,
            4.407203674316406
        ]
    },
    {
        "cosine_value": -0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Grace Kelly",
            "target": "Ursula Newell Emerson",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The place of birth of the mother of Grace Kelly is",
            "answer": "Nelson",
            "subject": "Grace Kelly",
            "target": "Ursula Newell Emerson",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The place of birth of Ursula Newell Emerson is",
            "answer": "Nelson",
            "subject": "Ursula Newell Emerson",
            "target": "Nelson",
            "relation": "PLACE_OF_BIRTH"
        },
        "NLL": [
            13.41476821899414,
            12.522764205932617,
            11.246935844421387,
            11.518779754638672,
            10.418222427368164,
            10.530107498168945
        ],
        "orginal_NLL": [
            11.025022506713867,
            14.8993558883667,
            11.292659759521484,
            11.857964515686035,
            10.359564781188965,
            10.196197509765625
        ]
    },
    {
        "cosine_value": 0.0272053312510252,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Grace Kelly",
            "target": "Ursula Newell Emerson",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the mother of Grace Kelly is",
            "answer": "missionary",
            "subject": "Grace Kelly",
            "target": "Ursula Newell Emerson",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The occupation of Ursula Newell Emerson is",
            "answer": "missionary",
            "subject": "Ursula Newell Emerson",
            "target": "missionary",
            "relation": "OCCUPATION"
        },
        "NLL": [
            13.425657272338867,
            18.17913246154785,
            14.901744842529297,
            17.023038864135742,
            12.783400535583496,
            13.020339012145996
        ],
        "orginal_NLL": [
            11.799805641174316,
            13.817943572998047,
            13.22830867767334,
            15.518667221069336,
            10.978545188903809,
            11.430291175842285
        ]
    },
    {
        "cosine_value": 0.1853037178516388,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Grace Kelly",
            "target": "Ursula Newell Emerson",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the child of the mother of Grace Kelly is",
            "answer": "Nathaniel Bright Emerson",
            "subject": "Grace Kelly",
            "target": "Ursula Newell Emerson",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the child of Ursula Newell Emerson is",
            "answer": "Nathaniel Bright Emerson",
            "subject": "Ursula Newell Emerson",
            "target": "Nathaniel Bright Emerson",
            "relation": "CHILD"
        },
        "NLL": [
            24.687143325805664,
            24.712156295776367,
            22.446746826171875,
            23.63836669921875,
            22.448911666870117,
            23.73940658569336
        ],
        "orginal_NLL": [
            38.79958724975586,
            37.99360275268555,
            36.333866119384766,
            37.570556640625,
            35.49334716796875,
            35.43206787109375
        ]
    },
    {
        "cosine_value": -0.0,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Just Mercy",
            "target": "Edwin McKim",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The gender of the screenwriter of Just Mercy is",
            "answer": "male",
            "subject": "Just Mercy",
            "target": "Edwin McKim",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The gender of Edwin McKim is",
            "answer": "male",
            "subject": "Edwin McKim",
            "target": "male",
            "relation": "SEX_OR_GENDER"
        },
        "NLL": [
            15.439205169677734,
            8.762170791625977,
            8.607915878295898,
            9.828407287597656,
            8.752337455749512,
            9.265591621398926
        ],
        "orginal_NLL": [
            2.646747350692749,
            10.191375732421875,
            5.934986114501953,
            6.669376850128174,
            4.543046474456787,
            4.597728729248047
        ]
    },
    {
        "cosine_value": -0.06750374287366867,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Just Mercy",
            "target": "Edwin McKim",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the country of citizenship of the screenwriter of Just Mercy is",
            "answer": "United States of America",
            "subject": "Just Mercy",
            "target": "Edwin McKim",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The name of the country of citizenship of Edwin McKim is",
            "answer": "United States of America",
            "subject": "Edwin McKim",
            "target": "United States of America",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "NLL": [
            20.491762161254883,
            14.2295503616333,
            11.473245620727539,
            12.073530197143555,
            10.722484588623047,
            11.007468223571777
        ],
        "orginal_NLL": [
            4.170572757720947,
            5.81005859375,
            4.322546005249023,
            6.070399284362793,
            3.884006977081299,
            4.134610176086426
        ]
    },
    {
        "cosine_value": -0.03850880637764931,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Just Mercy",
            "target": "Edwin McKim",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the screenwriter of Just Mercy is",
            "answer": "screenwriter",
            "subject": "Just Mercy",
            "target": "Edwin McKim",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The occupation of Edwin McKim is",
            "answer": "screenwriter",
            "subject": "Edwin McKim",
            "target": "screenwriter",
            "relation": "OCCUPATION"
        },
        "NLL": [
            14.663496971130371,
            20.614282608032227,
            13.955670356750488,
            14.811907768249512,
            13.020003318786621,
            13.447609901428223
        ],
        "orginal_NLL": [
            7.785040855407715,
            14.657777786254883,
            10.965984344482422,
            12.303892135620117,
            7.88676643371582,
            7.840381145477295
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Just Mercy",
            "target": "Edwin McKim",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the screenwriter of Just Mercy is",
            "answer": "actor",
            "subject": "Just Mercy",
            "target": "Edwin McKim",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The occupation of Edwin McKim is",
            "answer": "actor",
            "subject": "Edwin McKim",
            "target": "actor",
            "relation": "OCCUPATION"
        },
        "NLL": [
            13.818294525146484,
            17.982690811157227,
            13.952198028564453,
            14.521238327026367,
            13.639892578125,
            13.426467895507812
        ],
        "orginal_NLL": [
            9.235627174377441,
            14.70410442352295,
            11.75359058380127,
            12.210244178771973,
            9.353264808654785,
            9.662487030029297
        ]
    },
    {
        "cosine_value": -0.018323682248592377,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Just Mercy",
            "target": "Edwin McKim",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the screenwriter of Just Mercy is",
            "answer": "film director",
            "subject": "Just Mercy",
            "target": "Edwin McKim",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The occupation of Edwin McKim is",
            "answer": "film director",
            "subject": "Edwin McKim",
            "target": "film director",
            "relation": "OCCUPATION"
        },
        "NLL": [
            14.4728422164917,
            20.314189910888672,
            15.04934024810791,
            15.060286521911621,
            14.159289360046387,
            13.821647644042969
        ],
        "orginal_NLL": [
            10.64887809753418,
            16.501502990722656,
            12.726984977722168,
            12.984696388244629,
            10.875816345214844,
            10.614372253417969
        ]
    },
    {
        "cosine_value": -0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Rashida Jones",
            "target": "Gertruid van Deest",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The gender of the mother of Rashida Jones is",
            "answer": "female",
            "subject": "Rashida Jones",
            "target": "Gertruid van Deest",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The gender of Gertruid van Deest is",
            "answer": "female",
            "subject": "Gertruid van Deest",
            "target": "female",
            "relation": "SEX_OR_GENDER"
        },
        "NLL": [
            4.74632453918457,
            10.012868881225586,
            4.3616156578063965,
            4.206667423248291,
            3.729003429412842,
            3.4295144081115723
        ],
        "orginal_NLL": [
            3.082824945449829,
            9.451229095458984,
            5.058854579925537,
            5.092737674713135,
            4.059443950653076,
            3.8936986923217773
        ]
    },
    {
        "cosine_value": 0.04995450749993324,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Rashida Jones",
            "target": "Gertruid van Deest",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the child of the mother of Rashida Jones is",
            "answer": "Margaret van Erckelens",
            "subject": "Rashida Jones",
            "target": "Gertruid van Deest",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the child of Gertruid van Deest is",
            "answer": "Margaret van Erckelens",
            "subject": "Gertruid van Deest",
            "target": "Margaret van Erckelens",
            "relation": "CHILD"
        },
        "NLL": [
            41.60183334350586,
            45.344139099121094,
            40.44040298461914,
            40.04928207397461,
            40.31196212768555,
            41.033607482910156
        ],
        "orginal_NLL": [
            58.182586669921875,
            54.374515533447266,
            53.93919372558594,
            55.82322692871094,
            54.267608642578125,
            54.07799530029297
        ]
    },
    {
        "cosine_value": 0.10277549922466278,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Rashida Jones",
            "target": "Gertruid van Deest",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the spouse of the mother of Rashida Jones is",
            "answer": "Hendrik van Erckelens, Count van Erckelens",
            "subject": "Rashida Jones",
            "target": "Gertruid van Deest",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the spouse of Gertruid van Deest is",
            "answer": "Hendrik van Erckelens, Count van Erckelens",
            "subject": "Gertruid van Deest",
            "target": "Hendrik van Erckelens, Count van Erckelens",
            "relation": "SPOUSE"
        },
        "NLL": [
            69.41513061523438,
            73.6348648071289,
            67.63663482666016,
            68.02928924560547,
            67.13003540039062,
            67.99569702148438
        ],
        "orginal_NLL": [
            66.80281829833984,
            65.41991424560547,
            63.77098846435547,
            64.37273406982422,
            62.90007019042969,
            63.0102653503418
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Ansu Fati",
            "target": "Nuremberg",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the head of government of the country of citizenship of Ansu Fati is",
            "answer": "Marcus K\u00f6nig",
            "subject": "Ansu Fati",
            "target": "Nuremberg",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the head of government of Nuremberg is",
            "answer": "Marcus K\u00f6nig",
            "subject": "Nuremberg",
            "target": "Marcus K\u00f6nig",
            "relation": "HEAD_OF_GOVERNMENT"
        },
        "NLL": [
            23.495399475097656,
            23.14139175415039,
            20.678287506103516,
            19.93519401550293,
            19.902713775634766,
            19.96251678466797
        ],
        "orginal_NLL": [
            25.300823211669922,
            29.17875862121582,
            26.797794342041016,
            25.987789154052734,
            26.446779251098633,
            26.926437377929688
        ]
    },
    {
        "cosine_value": 0.17801372706890106,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Pooja Hegde",
            "target": "Terengganu",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the capital city of the country of citizenship of Pooja Hegde is",
            "answer": "Kuala Terengganu",
            "subject": "Pooja Hegde",
            "target": "Terengganu",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the capital city of Terengganu is",
            "answer": "Kuala Terengganu",
            "subject": "Terengganu",
            "target": "Kuala Terengganu",
            "relation": "CAPITAL"
        },
        "NLL": [
            16.531696319580078,
            18.47694969177246,
            13.988654136657715,
            13.888629913330078,
            13.295397758483887,
            13.159541130065918
        ],
        "orginal_NLL": [
            20.87992286682129,
            24.570940017700195,
            21.230913162231445,
            21.273454666137695,
            20.576316833496094,
            20.582740783691406
        ]
    },
    {
        "cosine_value": 0.12450873851776123,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Pooja Hegde",
            "target": "Terengganu",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the head of government of the country of citizenship of Pooja Hegde is",
            "answer": "Mizan Zainal Abidin of Terengganu",
            "subject": "Pooja Hegde",
            "target": "Terengganu",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the head of government of Terengganu is",
            "answer": "Mizan Zainal Abidin of Terengganu",
            "subject": "Terengganu",
            "target": "Mizan Zainal Abidin of Terengganu",
            "relation": "HEAD_OF_GOVERNMENT"
        },
        "NLL": [
            32.546199798583984,
            34.03110122680664,
            26.643938064575195,
            28.578187942504883,
            26.694942474365234,
            27.424530029296875
        ],
        "orginal_NLL": [
            38.71113967895508,
            49.155460357666016,
            39.918941497802734,
            39.136104583740234,
            39.103294372558594,
            38.957557678222656
        ]
    },
    {
        "cosine_value": 0.22190135717391968,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Pooja Hegde",
            "target": "Terengganu",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the anthem of the country of citizenship of Pooja Hegde is",
            "answer": "Terengganu State Anthem",
            "subject": "Pooja Hegde",
            "target": "Terengganu",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the anthem of Terengganu is",
            "answer": "Terengganu State Anthem",
            "subject": "Terengganu",
            "target": "Terengganu State Anthem",
            "relation": "ANTHEM"
        },
        "NLL": [
            24.682321548461914,
            21.750192642211914,
            18.938369750976562,
            21.053585052490234,
            18.675996780395508,
            19.700748443603516
        ],
        "orginal_NLL": [
            24.372692108154297,
            24.313535690307617,
            23.347652435302734,
            24.424375534057617,
            23.588926315307617,
            24.0665340423584
        ]
    },
    {
        "cosine_value": -0.02615152671933174,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Pooja Hegde",
            "target": "Terengganu",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the continent which the country of citizenship of Pooja Hegde is part of is",
            "answer": "Asia",
            "subject": "Pooja Hegde",
            "target": "Terengganu",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the continent which Terengganu is part of is",
            "answer": "Asia",
            "subject": "Terengganu",
            "target": "Asia",
            "relation": "CONTINENT"
        },
        "NLL": [
            0.7158811092376709,
            3.2617878913879395,
            2.478797435760498,
            1.5106068849563599,
            1.1570725440979004,
            1.483925461769104
        ],
        "orginal_NLL": [
            0.19581466913223267,
            3.1405067443847656,
            3.273611307144165,
            3.3247735500335693,
            2.470078468322754,
            2.554797410964966
        ]
    },
    {
        "cosine_value": -0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Ian Campbell, 12th Duke of Argyll",
            "target": "Harriet Pinney",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The gender of the mother of Ian Campbell, 12th Duke of Argyll is",
            "answer": "female",
            "subject": "Ian Campbell, 12th Duke of Argyll",
            "target": "Harriet Pinney",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The gender of Harriet Pinney is",
            "answer": "female",
            "subject": "Harriet Pinney",
            "target": "female",
            "relation": "SEX_OR_GENDER"
        },
        "NLL": [
            4.240419387817383,
            8.467576026916504,
            5.109128952026367,
            5.854212284088135,
            4.5592474937438965,
            4.417094707489014
        ],
        "orginal_NLL": [
            6.758144855499268,
            8.861621856689453,
            5.293531894683838,
            6.704257011413574,
            4.80255126953125,
            4.7386651039123535
        ]
    },
    {
        "cosine_value": 0.1398019939661026,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Ian Campbell, 12th Duke of Argyll",
            "target": "Harriet Pinney",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the maternal grandfather of Ian Campbell, 12th Duke of Argyll is",
            "answer": "J. G. Pinney",
            "subject": "Ian Campbell, 12th Duke of Argyll",
            "target": "Harriet Pinney",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the father of Harriet Pinney is",
            "answer": "J. G. Pinney",
            "subject": "Harriet Pinney",
            "target": "J. G. Pinney",
            "relation": "FATHER"
        },
        "NLL": [
            22.731287002563477,
            24.486183166503906,
            19.7379093170166,
            21.599002838134766,
            19.899993896484375,
            19.622148513793945
        ],
        "orginal_NLL": [
            24.51093292236328,
            29.97306251525879,
            24.979736328125,
            25.723628997802734,
            23.9173583984375,
            23.838382720947266
        ]
    },
    {
        "cosine_value": 0.05143684521317482,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Ian Campbell, 12th Duke of Argyll",
            "target": "Harriet Pinney",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the child of the mother of Ian Campbell, 12th Duke of Argyll is",
            "answer": "John Heaton-Ellis",
            "subject": "Ian Campbell, 12th Duke of Argyll",
            "target": "Harriet Pinney",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the child of Harriet Pinney is",
            "answer": "John Heaton-Ellis",
            "subject": "Harriet Pinney",
            "target": "John Heaton-Ellis",
            "relation": "CHILD"
        },
        "NLL": [
            39.156070709228516,
            31.305248260498047,
            29.610387802124023,
            29.338369369506836,
            28.70611572265625,
            28.63283920288086
        ],
        "orginal_NLL": [
            27.471256256103516,
            31.566978454589844,
            28.1700496673584,
            29.00040626525879,
            26.650487899780273,
            26.494068145751953
        ]
    },
    {
        "cosine_value": -0.00865305308252573,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Ian Campbell, 12th Duke of Argyll",
            "target": "Harriet Pinney",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the child of the mother of Ian Campbell, 12th Duke of Argyll is",
            "answer": "Charles Heaton-Ellis",
            "subject": "Ian Campbell, 12th Duke of Argyll",
            "target": "Harriet Pinney",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the child of Harriet Pinney is",
            "answer": "Charles Heaton-Ellis",
            "subject": "Harriet Pinney",
            "target": "Charles Heaton-Ellis",
            "relation": "CHILD"
        },
        "NLL": [
            36.680294036865234,
            28.609153747558594,
            26.77735710144043,
            27.279468536376953,
            27.354833602905273,
            27.900882720947266
        ],
        "orginal_NLL": [
            23.513219833374023,
            27.309877395629883,
            23.56346893310547,
            24.478200912475586,
            22.59258460998535,
            22.59424591064453
        ]
    },
    {
        "cosine_value": 0.18410640954971313,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Ian Campbell, 12th Duke of Argyll",
            "target": "Harriet Pinney",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the child of the mother of Ian Campbell, 12th Duke of Argyll is",
            "answer": "Ronald Heaton-Ellis",
            "subject": "Ian Campbell, 12th Duke of Argyll",
            "target": "Harriet Pinney",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the child of Harriet Pinney is",
            "answer": "Ronald Heaton-Ellis",
            "subject": "Harriet Pinney",
            "target": "Ronald Heaton-Ellis",
            "relation": "CHILD"
        },
        "NLL": [
            43.04966735839844,
            34.72338104248047,
            32.43814468383789,
            33.26808166503906,
            32.92552185058594,
            33.43408203125
        ],
        "orginal_NLL": [
            28.457809448242188,
            32.2051887512207,
            28.72324562072754,
            30.232561111450195,
            28.5802059173584,
            28.29131317138672
        ]
    },
    {
        "cosine_value": 0.2049030214548111,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Ian Campbell, 12th Duke of Argyll",
            "target": "Harriet Pinney",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the spouse of the mother of Ian Campbell, 12th Duke of Argyll is",
            "answer": "Sydney Heaton-Ellis",
            "subject": "Ian Campbell, 12th Duke of Argyll",
            "target": "Harriet Pinney",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the spouse of Harriet Pinney is",
            "answer": "Sydney Heaton-Ellis",
            "subject": "Harriet Pinney",
            "target": "Sydney Heaton-Ellis",
            "relation": "SPOUSE"
        },
        "NLL": [
            39.556427001953125,
            32.921878814697266,
            32.23152160644531,
            31.97440528869629,
            33.99624252319336,
            34.12174987792969
        ],
        "orginal_NLL": [
            26.036361694335938,
            28.78999137878418,
            26.79907989501953,
            28.013219833374023,
            27.28959846496582,
            27.22661590576172
        ]
    },
    {
        "cosine_value": -0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The gender of the mother of Susan Wojcicki is",
            "answer": "female",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The gender of Ru\u017eena \u0160kerlj is",
            "answer": "female",
            "subject": "Ru\u017eena \u0160kerlj",
            "target": "female",
            "relation": "SEX_OR_GENDER"
        },
        "NLL": [
            16.673358917236328,
            15.03051471710205,
            10.810037612915039,
            9.903687477111816,
            8.956766128540039,
            9.636465072631836
        ],
        "orginal_NLL": [
            3.4216725826263428,
            9.829487800598145,
            4.868465423583984,
            5.055371284484863,
            4.568810939788818,
            4.389496326446533
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the mother of Susan Wojcicki is",
            "answer": "biologist",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The occupation of Ru\u017eena \u0160kerlj is",
            "answer": "biologist",
            "subject": "Ru\u017eena \u0160kerlj",
            "target": "biologist",
            "relation": "OCCUPATION"
        },
        "NLL": [
            6.500943183898926,
            14.607466697692871,
            9.141521453857422,
            10.918121337890625,
            6.569647312164307,
            7.484470844268799
        ],
        "orginal_NLL": [
            10.319398880004883,
            16.569683074951172,
            10.570990562438965,
            11.3953218460083,
            9.249504089355469,
            9.686352729797363
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the mother of Susan Wojcicki is",
            "answer": "lexicographer",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The occupation of Ru\u017eena \u0160kerlj is",
            "answer": "lexicographer",
            "subject": "Ru\u017eena \u0160kerlj",
            "target": "lexicographer",
            "relation": "OCCUPATION"
        },
        "NLL": [
            13.120100021362305,
            14.271166801452637,
            14.210002899169922,
            15.14604663848877,
            13.375593185424805,
            13.378348350524902
        ],
        "orginal_NLL": [
            13.565337181091309,
            14.772714614868164,
            15.155019760131836,
            15.864591598510742,
            13.745762825012207,
            13.749801635742188
        ]
    },
    {
        "cosine_value": -0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the mother of Susan Wojcicki is",
            "answer": "translator",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The occupation of Ru\u017eena \u0160kerlj is",
            "answer": "translator",
            "subject": "Ru\u017eena \u0160kerlj",
            "target": "translator",
            "relation": "OCCUPATION"
        },
        "NLL": [
            11.779182434082031,
            15.423380851745605,
            11.146252632141113,
            11.170340538024902,
            10.022364616394043,
            10.35986042022705
        ],
        "orginal_NLL": [
            9.80543327331543,
            14.892165184020996,
            11.846293449401855,
            13.128092765808105,
            11.141448974609375,
            11.382759094238281
        ]
    },
    {
        "cosine_value": -0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the mother of Susan Wojcicki is",
            "answer": "teacher",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The occupation of Ru\u017eena \u0160kerlj is",
            "answer": "teacher",
            "subject": "Ru\u017eena \u0160kerlj",
            "target": "teacher",
            "relation": "OCCUPATION"
        },
        "NLL": [
            4.820647716522217,
            9.247718811035156,
            5.569350719451904,
            8.554224014282227,
            5.471743106842041,
            5.444957733154297
        ],
        "orginal_NLL": [
            5.777723789215088,
            10.774740219116211,
            6.725423812866211,
            8.418190002441406,
            6.586661338806152,
            6.398105621337891
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the country of citizenship of the mother of Susan Wojcicki is",
            "answer": "Slovenia",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the country of citizenship of Ru\u017eena \u0160kerlj is",
            "answer": "Slovenia",
            "subject": "Ru\u017eena \u0160kerlj",
            "target": "Slovenia",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "NLL": [
            5.2668633460998535,
            9.591679573059082,
            4.832954406738281,
            6.073855400085449,
            3.7007055282592773,
            4.26353120803833
        ],
        "orginal_NLL": [
            6.478280544281006,
            10.15558910369873,
            6.377201080322266,
            7.382898330688477,
            5.791879653930664,
            5.965373992919922
        ]
    },
    {
        "cosine_value": -0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the country of citizenship of the mother of Susan Wojcicki is",
            "answer": "Czechoslovakia",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the country of citizenship of Ru\u017eena \u0160kerlj is",
            "answer": "Czechoslovakia",
            "subject": "Ru\u017eena \u0160kerlj",
            "target": "Czechoslovakia",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "NLL": [
            18.232519149780273,
            22.760665893554688,
            17.31797981262207,
            17.38410758972168,
            17.154258728027344,
            17.049890518188477
        ],
        "orginal_NLL": [
            5.059723854064941,
            9.940484046936035,
            6.852107048034668,
            7.973020553588867,
            7.3015313148498535,
            6.758064270019531
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the country of citizenship of the mother of Susan Wojcicki is",
            "answer": "Yugoslavia",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the country of citizenship of Ru\u017eena \u0160kerlj is",
            "answer": "Yugoslavia",
            "subject": "Ru\u017eena \u0160kerlj",
            "target": "Yugoslavia",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "NLL": [
            8.976845741271973,
            15.847503662109375,
            8.229877471923828,
            8.732805252075195,
            9.200125694274902,
            8.436506271362305
        ],
        "orginal_NLL": [
            7.4582977294921875,
            13.120086669921875,
            6.728030681610107,
            7.429713249206543,
            7.638036251068115,
            6.779691696166992
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the country of citizenship of the mother of Susan Wojcicki is",
            "answer": "Austria-Hungary",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the country of citizenship of Ru\u017eena \u0160kerlj is",
            "answer": "Austria-Hungary",
            "subject": "Ru\u017eena \u0160kerlj",
            "target": "Austria-Hungary",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "NLL": [
            22.134309768676758,
            26.29001808166504,
            18.224632263183594,
            18.202377319335938,
            17.75345802307129,
            18.701017379760742
        ],
        "orginal_NLL": [
            14.217116355895996,
            15.439889907836914,
            11.49181079864502,
            11.375356674194336,
            11.177282333374023,
            11.813150405883789
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The place of birth of the mother of Susan Wojcicki is",
            "answer": "P\u0159\u00edbram",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The place of birth of Ru\u017eena \u0160kerlj is",
            "answer": "P\u0159\u00edbram",
            "subject": "Ru\u017eena \u0160kerlj",
            "target": "P\u0159\u00edbram",
            "relation": "PLACE_OF_BIRTH"
        },
        "NLL": [
            27.596988677978516,
            31.864215850830078,
            24.130971908569336,
            24.642681121826172,
            23.98292350769043,
            23.760984420776367
        ],
        "orginal_NLL": [
            17.615076065063477,
            20.80763053894043,
            16.665761947631836,
            17.433408737182617,
            16.951345443725586,
            16.941865921020508
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The place of death of the mother of Susan Wojcicki is",
            "answer": "Ljubljana",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The place of death of Ru\u017eena \u0160kerlj is",
            "answer": "Ljubljana",
            "subject": "Ru\u017eena \u0160kerlj",
            "target": "Ljubljana",
            "relation": "PLACE_OF_DEATH"
        },
        "NLL": [
            7.296148777008057,
            10.945120811462402,
            7.011007308959961,
            7.766663074493408,
            6.834167003631592,
            6.10570764541626
        ],
        "orginal_NLL": [
            12.484017372131348,
            16.743871688842773,
            13.173551559448242,
            13.16518497467041,
            12.271159172058105,
            12.137340545654297
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the spouse of the mother of Susan Wojcicki is",
            "answer": "Bo\u017eo \u0160kerlj",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the spouse of Ru\u017eena \u0160kerlj is",
            "answer": "Bo\u017eo \u0160kerlj",
            "subject": "Ru\u017eena \u0160kerlj",
            "target": "Bo\u017eo \u0160kerlj",
            "relation": "SPOUSE"
        },
        "NLL": [
            16.505279541015625,
            21.10808563232422,
            16.045875549316406,
            17.13880157470703,
            15.165234565734863,
            13.274669647216797
        ],
        "orginal_NLL": [
            32.083526611328125,
            31.503673553466797,
            27.460647583007812,
            28.236312866210938,
            26.683364868164062,
            26.895954132080078
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the child of the mother of Susan Wojcicki is",
            "answer": "Zdenka \u0160kerlj Jerman",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the child of Ru\u017eena \u0160kerlj is",
            "answer": "Zdenka \u0160kerlj Jerman",
            "subject": "Ru\u017eena \u0160kerlj",
            "target": "Zdenka \u0160kerlj Jerman",
            "relation": "CHILD"
        },
        "NLL": [
            27.551908493041992,
            31.886310577392578,
            24.830459594726562,
            26.566585540771484,
            24.351638793945312,
            24.517465591430664
        ],
        "orginal_NLL": [
            43.34510803222656,
            46.87980270385742,
            42.197261810302734,
            43.883811950683594,
            42.297428131103516,
            42.360897064208984
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the child of the mother of Susan Wojcicki is",
            "answer": "Dagmar Slekovec",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the child of Ru\u017eena \u0160kerlj is",
            "answer": "Dagmar Slekovec",
            "subject": "Ru\u017eena \u0160kerlj",
            "target": "Dagmar Slekovec",
            "relation": "CHILD"
        },
        "NLL": [
            38.489009857177734,
            40.0717887878418,
            32.437503814697266,
            33.90704345703125,
            33.14329147338867,
            32.50782012939453
        ],
        "orginal_NLL": [
            30.97074317932129,
            36.54950714111328,
            31.18264389038086,
            33.205467224121094,
            30.80464744567871,
            31.12783432006836
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the field of work of the mother of Susan Wojcicki is",
            "answer": "multilingual dictionary",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the field of work of Ru\u017eena \u0160kerlj is",
            "answer": "multilingual dictionary",
            "subject": "Ru\u017eena \u0160kerlj",
            "target": "multilingual dictionary",
            "relation": "FIELD_OF_WORK"
        },
        "NLL": [
            18.54004669189453,
            22.439189910888672,
            12.371271133422852,
            16.694236755371094,
            13.362146377563477,
            13.01344108581543
        ],
        "orginal_NLL": [
            14.706525802612305,
            19.96236801147461,
            13.975663185119629,
            16.169519424438477,
            13.033073425292969,
            12.986120223999023
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the field of work of the mother of Susan Wojcicki is",
            "answer": "translating activity",
            "subject": "Susan Wojcicki",
            "target": "Ru\u017eena \u0160kerlj",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the field of work of Ru\u017eena \u0160kerlj is",
            "answer": "translating activity",
            "subject": "Ru\u017eena \u0160kerlj",
            "target": "translating activity",
            "relation": "FIELD_OF_WORK"
        },
        "NLL": [
            20.803556442260742,
            26.35861587524414,
            18.225980758666992,
            18.843528747558594,
            17.959716796875,
            18.239675521850586
        ],
        "orginal_NLL": [
            24.120248794555664,
            31.05913543701172,
            24.924848556518555,
            25.980106353759766,
            24.73468780517578,
            24.677581787109375
        ]
    },
    {
        "cosine_value": -0.005284281447529793,
        "edited_data": {
            "prompt": "The name of the spouse of {} is",
            "subject": "Rod Blagojevich",
            "target": "Jonathan Alexander Burch",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The gender of the spouse of Rod Blagojevich is",
            "answer": "male",
            "subject": "Rod Blagojevich",
            "target": "Jonathan Alexander Burch",
            "relation": "SPOUSE"
        },
        "condition_query": {
            "prompt": "The gender of Jonathan Alexander Burch is",
            "answer": "male",
            "subject": "Jonathan Alexander Burch",
            "target": "male",
            "relation": "SEX_OR_GENDER"
        },
        "NLL": [
            2.7044472694396973,
            9.179953575134277,
            2.8870203495025635,
            3.8540942668914795,
            2.429713249206543,
            2.4403581619262695
        ],
        "orginal_NLL": [
            2.296398639678955,
            8.426737785339355,
            4.018106460571289,
            3.6675901412963867,
            3.299468517303467,
            3.564340114593506
        ]
    },
    {
        "cosine_value": 0.16581518948078156,
        "edited_data": {
            "prompt": "The name of the spouse of {} is",
            "subject": "Rod Blagojevich",
            "target": "Jonathan Alexander Burch",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the father in law of Rod Blagojevich is",
            "answer": "Walter H. Burch",
            "subject": "Rod Blagojevich",
            "target": "Jonathan Alexander Burch",
            "relation": "SPOUSE"
        },
        "condition_query": {
            "prompt": "The name of the father of Jonathan Alexander Burch is",
            "answer": "Walter H. Burch",
            "subject": "Jonathan Alexander Burch",
            "target": "Walter H. Burch",
            "relation": "FATHER"
        },
        "NLL": [
            32.46450424194336,
            26.694673538208008,
            26.71718406677246,
            25.10284996032715,
            24.64529800415039,
            24.104820251464844
        ],
        "orginal_NLL": [
            28.46380615234375,
            30.76555633544922,
            28.263671875,
            28.51039695739746,
            28.030506134033203,
            27.111572265625
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Lamar Jackson",
            "target": "Russian Soviet Federative Socialist Republic",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the capital city of the country of citizenship of Lamar Jackson is",
            "answer": "Moscow",
            "subject": "Lamar Jackson",
            "target": "Russian Soviet Federative Socialist Republic",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the capital city of Russian Soviet Federative Socialist Republic is",
            "answer": "Moscow",
            "subject": "Russian Soviet Federative Socialist Republic",
            "target": "Moscow",
            "relation": "CAPITAL"
        },
        "NLL": [
            14.386557579040527,
            9.825736045837402,
            8.823588371276855,
            7.675589561462402,
            8.19887638092041,
            7.129997730255127
        ],
        "orginal_NLL": [
            8.927285194396973,
            10.352755546569824,
            9.51056957244873,
            9.533707618713379,
            9.131783485412598,
            8.583588600158691
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Lamar Jackson",
            "target": "Russian Soviet Federative Socialist Republic",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The official language of the country of citizenship of Lamar Jackson is",
            "answer": "Russian",
            "subject": "Lamar Jackson",
            "target": "Russian Soviet Federative Socialist Republic",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The official language of Russian Soviet Federative Socialist Republic is",
            "answer": "Russian",
            "subject": "Russian Soviet Federative Socialist Republic",
            "target": "Russian",
            "relation": "OFFICIAL_LANGUAGE"
        },
        "NLL": [
            0.7238814830780029,
            3.8943028450012207,
            0.5570048689842224,
            0.6897456049919128,
            0.1774592399597168,
            0.13315796852111816
        ],
        "orginal_NLL": [
            8.492151260375977,
            12.279260635375977,
            8.936113357543945,
            8.786490440368652,
            8.245767593383789,
            8.19882583618164
        ]
    },
    {
        "cosine_value": 0.23540528118610382,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Lamar Jackson",
            "target": "Russian Soviet Federative Socialist Republic",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the currency in the country of citizenship of Lamar Jackson is",
            "answer": "Soviet ruble",
            "subject": "Lamar Jackson",
            "target": "Russian Soviet Federative Socialist Republic",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the currency in Russian Soviet Federative Socialist Republic is",
            "answer": "Soviet ruble",
            "subject": "Russian Soviet Federative Socialist Republic",
            "target": "Soviet ruble",
            "relation": "CURRENCY"
        },
        "NLL": [
            15.020813941955566,
            12.238112449645996,
            10.915152549743652,
            10.794370651245117,
            11.113710403442383,
            10.821085929870605
        ],
        "orginal_NLL": [
            13.693570137023926,
            14.869243621826172,
            13.923680305480957,
            14.225796699523926,
            14.322639465332031,
            14.248355865478516
        ]
    },
    {
        "cosine_value": 0.08491822332143784,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Lamar Jackson",
            "target": "Russian Soviet Federative Socialist Republic",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the continent which the country of citizenship of Lamar Jackson is part of is",
            "answer": "Eurasia",
            "subject": "Lamar Jackson",
            "target": "Russian Soviet Federative Socialist Republic",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the continent which Russian Soviet Federative Socialist Republic is part of is",
            "answer": "Eurasia",
            "subject": "Russian Soviet Federative Socialist Republic",
            "target": "Eurasia",
            "relation": "CONTINENT"
        },
        "NLL": [
            12.351486206054688,
            19.45771026611328,
            11.905255317687988,
            12.090085983276367,
            11.975113868713379,
            12.122574806213379
        ],
        "orginal_NLL": [
            9.155070304870605,
            12.709439277648926,
            10.417976379394531,
            10.64675521850586,
            10.053892135620117,
            9.628730773925781
        ]
    },
    {
        "cosine_value": 0.0949733555316925,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Lamar Jackson",
            "target": "Russian Soviet Federative Socialist Republic",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the anthem of the country of citizenship of Lamar Jackson is",
            "answer": "State Anthem of the Soviet Union",
            "subject": "Lamar Jackson",
            "target": "Russian Soviet Federative Socialist Republic",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the anthem of Russian Soviet Federative Socialist Republic is",
            "answer": "State Anthem of the Soviet Union",
            "subject": "Russian Soviet Federative Socialist Republic",
            "target": "State Anthem of the Soviet Union",
            "relation": "ANTHEM"
        },
        "NLL": [
            33.52155685424805,
            25.496591567993164,
            25.45209312438965,
            23.699398040771484,
            24.569467544555664,
            24.041824340820312
        ],
        "orginal_NLL": [
            15.886567115783691,
            19.97563934326172,
            15.414121627807617,
            16.082843780517578,
            15.520696640014648,
            15.740294456481934
        ]
    },
    {
        "cosine_value": 0.05281772464513779,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Lamar Jackson",
            "target": "Russian Soviet Federative Socialist Republic",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the anthem of the country of citizenship of Lamar Jackson is",
            "answer": "The Internationale",
            "subject": "Lamar Jackson",
            "target": "Russian Soviet Federative Socialist Republic",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the anthem of Russian Soviet Federative Socialist Republic is",
            "answer": "The Internationale",
            "subject": "Russian Soviet Federative Socialist Republic",
            "target": "The Internationale",
            "relation": "ANTHEM"
        },
        "NLL": [
            27.65185546875,
            24.028589248657227,
            20.063459396362305,
            17.971012115478516,
            18.50362777709961,
            18.167367935180664
        ],
        "orginal_NLL": [
            13.638277053833008,
            18.235918045043945,
            13.545754432678223,
            13.069747924804688,
            12.455148696899414,
            12.500283241271973
        ]
    },
    {
        "cosine_value": 0.11406735330820084,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Lamar Jackson",
            "target": "Russian Soviet Federative Socialist Republic",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the head of government of the country of citizenship of Lamar Jackson is",
            "answer": "Boris Yeltsin",
            "subject": "Lamar Jackson",
            "target": "Russian Soviet Federative Socialist Republic",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the head of government of Russian Soviet Federative Socialist Republic is",
            "answer": "Boris Yeltsin",
            "subject": "Russian Soviet Federative Socialist Republic",
            "target": "Boris Yeltsin",
            "relation": "HEAD_OF_GOVERNMENT"
        },
        "NLL": [
            20.752477645874023,
            16.92945098876953,
            15.075929641723633,
            13.848983764648438,
            13.330561637878418,
            13.762178421020508
        ],
        "orginal_NLL": [
            10.540109634399414,
            13.614049911499023,
            10.44532585144043,
            11.009897232055664,
            10.193450927734375,
            10.570012092590332
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Bam Margera",
            "target": "Virginia Terhune Van de Water",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The place of birth of the mother of Bam Margera is",
            "answer": "Newark",
            "subject": "Bam Margera",
            "target": "Virginia Terhune Van de Water",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The place of birth of Virginia Terhune Van de Water is",
            "answer": "Newark",
            "subject": "Virginia Terhune Van de Water",
            "target": "Newark",
            "relation": "PLACE_OF_BIRTH"
        },
        "NLL": [
            11.423391342163086,
            19.17692756652832,
            13.024474143981934,
            12.749979972839355,
            12.033251762390137,
            12.249883651733398
        ],
        "orginal_NLL": [
            9.430340766906738,
            13.82524299621582,
            10.60069751739502,
            10.6439847946167,
            10.211994171142578,
            10.058467864990234
        ]
    },
    {
        "cosine_value": -0.06734362989664078,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Bam Margera",
            "target": "Virginia Terhune Van de Water",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The gender of the mother of Bam Margera is",
            "answer": "female",
            "subject": "Bam Margera",
            "target": "Virginia Terhune Van de Water",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The gender of Virginia Terhune Van de Water is",
            "answer": "female",
            "subject": "Virginia Terhune Van de Water",
            "target": "female",
            "relation": "SEX_OR_GENDER"
        },
        "NLL": [
            3.671868085861206,
            9.003194808959961,
            5.864458084106445,
            7.5626726150512695,
            5.491175651550293,
            5.280079364776611
        ],
        "orginal_NLL": [
            2.3748011589050293,
            8.72994327545166,
            4.125692367553711,
            4.64456033706665,
            3.7150349617004395,
            3.4324889183044434
        ]
    },
    {
        "cosine_value": 0.21469396352767944,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Bam Margera",
            "target": "Virginia Terhune Van de Water",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The names of the siblings of the mother of Bam Margera are",
            "answer": "Albert Payson Terhune",
            "subject": "Bam Margera",
            "target": "Virginia Terhune Van de Water",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The names of the siblings of Virginia Terhune Van de Water are",
            "answer": "Albert Payson Terhune",
            "subject": "Virginia Terhune Van de Water",
            "target": "Albert Payson Terhune",
            "relation": "SIBLING"
        },
        "NLL": [
            21.5208797454834,
            25.545272827148438,
            21.98296356201172,
            22.476585388183594,
            20.98671531677246,
            20.885303497314453
        ],
        "orginal_NLL": [
            30.794591903686523,
            30.62386703491211,
            29.373661041259766,
            30.45935821533203,
            29.285816192626953,
            29.013452529907227
        ]
    },
    {
        "cosine_value": 0.29317811131477356,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Bam Margera",
            "target": "Virginia Terhune Van de Water",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The names of the siblings of the mother of Bam Margera are",
            "answer": "Christine Terhune Herrick",
            "subject": "Bam Margera",
            "target": "Virginia Terhune Van de Water",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The names of the siblings of Virginia Terhune Van de Water are",
            "answer": "Christine Terhune Herrick",
            "subject": "Virginia Terhune Van de Water",
            "target": "Christine Terhune Herrick",
            "relation": "SIBLING"
        },
        "NLL": [
            37.33442687988281,
            42.8576774597168,
            38.007896423339844,
            38.71854782104492,
            36.444114685058594,
            36.7113151550293
        ],
        "orginal_NLL": [
            38.08144760131836,
            41.131595611572266,
            38.55790328979492,
            38.83584976196289,
            37.44744873046875,
            37.534820556640625
        ]
    },
    {
        "cosine_value": 0.2907896041870117,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Bam Margera",
            "target": "Virginia Terhune Van de Water",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the maternal grandfather of Bam Margera is",
            "answer": "Edward Payson Terhune",
            "subject": "Bam Margera",
            "target": "Virginia Terhune Van de Water",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the father of Virginia Terhune Van de Water is",
            "answer": "Edward Payson Terhune",
            "subject": "Virginia Terhune Van de Water",
            "target": "Edward Payson Terhune",
            "relation": "FATHER"
        },
        "NLL": [
            18.717226028442383,
            24.34671401977539,
            21.291513442993164,
            21.97327995300293,
            19.805334091186523,
            19.770458221435547
        ],
        "orginal_NLL": [
            30.359880447387695,
            33.48259353637695,
            32.909236907958984,
            33.922733306884766,
            32.844139099121094,
            32.24379348754883
        ]
    },
    {
        "cosine_value": 0.1754542589187622,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Bam Margera",
            "target": "Virginia Terhune Van de Water",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the maternal grandmother of Bam Margera is",
            "answer": "Marion Harland",
            "subject": "Bam Margera",
            "target": "Virginia Terhune Van de Water",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the mother of Virginia Terhune Van de Water is",
            "answer": "Marion Harland",
            "subject": "Virginia Terhune Van de Water",
            "target": "Marion Harland",
            "relation": "MOTHER"
        },
        "NLL": [
            30.498228073120117,
            31.12308692932129,
            25.976076126098633,
            27.52709197998047,
            25.47442054748535,
            24.52025032043457
        ],
        "orginal_NLL": [
            19.329145431518555,
            23.372318267822266,
            21.336286544799805,
            21.91938018798828,
            20.96964454650879,
            20.473352432250977
        ]
    },
    {
        "cosine_value": -0.057594019919633865,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Bam Margera",
            "target": "Virginia Terhune Van de Water",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the country of citizenship of the mother of Bam Margera is",
            "answer": "United States of America",
            "subject": "Bam Margera",
            "target": "Virginia Terhune Van de Water",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the country of citizenship of Virginia Terhune Van de Water is",
            "answer": "United States of America",
            "subject": "Virginia Terhune Van de Water",
            "target": "United States of America",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "NLL": [
            4.478443622589111,
            8.09315013885498,
            4.544743061065674,
            6.456988334655762,
            4.57991886138916,
            4.680680751800537
        ],
        "orginal_NLL": [
            2.2296087741851807,
            5.2297444343566895,
            2.3995635509490967,
            3.522940158843994,
            2.70015549659729,
            2.6289069652557373
        ]
    },
    {
        "cosine_value": 0.13180002570152283,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Bam Margera",
            "target": "Virginia Terhune Van de Water",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the mother of Bam Margera is",
            "answer": "writer",
            "subject": "Bam Margera",
            "target": "Virginia Terhune Van de Water",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The occupation of Virginia Terhune Van de Water is",
            "answer": "writer",
            "subject": "Virginia Terhune Van de Water",
            "target": "writer",
            "relation": "OCCUPATION"
        },
        "NLL": [
            6.088393688201904,
            12.708207130432129,
            7.980533123016357,
            11.803722381591797,
            8.569361686706543,
            8.291189193725586
        ],
        "orginal_NLL": [
            7.565393447875977,
            10.930480003356934,
            7.037232875823975,
            9.360686302185059,
            7.688004016876221,
            7.676085472106934
        ]
    },
    {
        "cosine_value": 0.28187230229377747,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Bam Margera",
            "target": "Virginia Terhune Van de Water",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the child of the mother of Bam Margera is",
            "answer": "Frederic Franklyn Van de Water",
            "subject": "Bam Margera",
            "target": "Virginia Terhune Van de Water",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the child of Virginia Terhune Van de Water is",
            "answer": "Frederic Franklyn Van de Water",
            "subject": "Virginia Terhune Van de Water",
            "target": "Frederic Franklyn Van de Water",
            "relation": "CHILD"
        },
        "NLL": [
            35.043212890625,
            38.70853042602539,
            33.257080078125,
            33.135528564453125,
            32.095027923583984,
            31.78288459777832
        ],
        "orginal_NLL": [
            55.206642150878906,
            53.26176452636719,
            52.201316833496094,
            52.82729721069336,
            52.69302749633789,
            52.210601806640625
        ]
    },
    {
        "cosine_value": 0.17986218631267548,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Bam Margera",
            "target": "Virginia Terhune Van de Water",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the spouse of the mother of Bam Margera is",
            "answer": "Frederic Franklyn Van de Water",
            "subject": "Bam Margera",
            "target": "Virginia Terhune Van de Water",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the spouse of Virginia Terhune Van de Water is",
            "answer": "Frederic Franklyn Van de Water",
            "subject": "Virginia Terhune Van de Water",
            "target": "Frederic Franklyn Van de Water",
            "relation": "SPOUSE"
        },
        "NLL": [
            37.18754196166992,
            40.95051574707031,
            35.88296890258789,
            35.014957427978516,
            34.012420654296875,
            33.72280502319336
        ],
        "orginal_NLL": [
            44.84067916870117,
            43.43803024291992,
            44.03252029418945,
            44.330162048339844,
            43.95758056640625,
            43.462650299072266
        ]
    },
    {
        "cosine_value": -0.011774019338190556,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Bam Margera",
            "target": "Virginia Terhune Van de Water",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The place of burial of the mother of Bam Margera is",
            "answer": "Pompton Reformed Church Cemetery",
            "subject": "Bam Margera",
            "target": "Virginia Terhune Van de Water",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The place of burial of Virginia Terhune Van de Water is",
            "answer": "Pompton Reformed Church Cemetery",
            "subject": "Virginia Terhune Van de Water",
            "target": "Pompton Reformed Church Cemetery",
            "relation": "PLACE_OF_BURIAL"
        },
        "NLL": [
            24.70659828186035,
            30.478931427001953,
            25.14774513244629,
            26.16758918762207,
            24.08249282836914,
            23.778263092041016
        ],
        "orginal_NLL": [
            22.92373275756836,
            27.439546585083008,
            21.501630783081055,
            22.15175437927246,
            21.309946060180664,
            21.28495216369629
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Felicity Huffman",
            "target": "Kingdom of Essex",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the capital city of the country of citizenship of Felicity Huffman is",
            "answer": "London",
            "subject": "Felicity Huffman",
            "target": "Kingdom of Essex",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the capital city of Kingdom of Essex is",
            "answer": "London",
            "subject": "Kingdom of Essex",
            "target": "London",
            "relation": "CAPITAL"
        },
        "NLL": [
            17.328786849975586,
            11.619922637939453,
            10.108524322509766,
            7.98362398147583,
            8.677560806274414,
            9.202652931213379
        ],
        "orginal_NLL": [
            8.545794486999512,
            10.010292053222656,
            9.002084732055664,
            8.103338241577148,
            8.285605430603027,
            8.338815689086914
        ]
    },
    {
        "cosine_value": 0.07575148344039917,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Felicity Huffman",
            "target": "Kingdom of Essex",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the continent which the country of citizenship of Felicity Huffman is part of is",
            "answer": "Europe",
            "subject": "Felicity Huffman",
            "target": "Kingdom of Essex",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The name of the continent which Kingdom of Essex is part of is",
            "answer": "Europe",
            "subject": "Kingdom of Essex",
            "target": "Europe",
            "relation": "CONTINENT"
        },
        "NLL": [
            9.215319633483887,
            10.4900484085083,
            10.00635814666748,
            9.756277084350586,
            9.322490692138672,
            9.310050010681152
        ],
        "orginal_NLL": [
            4.457688808441162,
            7.575896739959717,
            6.245074272155762,
            6.880138397216797,
            6.62766170501709,
            6.007135391235352
        ]
    },
    {
        "cosine_value": 0.04786742106080055,
        "edited_data": {
            "prompt": "The name of the country of citizenship of {} is",
            "subject": "Felicity Huffman",
            "target": "Kingdom of Essex",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The official language of the country of citizenship of Felicity Huffman is",
            "answer": "Old English",
            "subject": "Felicity Huffman",
            "target": "Kingdom of Essex",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "condition_query": {
            "prompt": "The official language of Kingdom of Essex is",
            "answer": "Old English",
            "subject": "Kingdom of Essex",
            "target": "Old English",
            "relation": "OFFICIAL_LANGUAGE"
        },
        "NLL": [
            17.825674057006836,
            13.432904243469238,
            9.4756498336792,
            10.869027137756348,
            10.144490242004395,
            11.377880096435547
        ],
        "orginal_NLL": [
            10.996487617492676,
            14.982909202575684,
            10.483867645263672,
            10.42314338684082,
            10.558682441711426,
            10.895430564880371
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the screenwriter of Deadly Illusions is",
            "answer": "film director",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The occupation of P\u00e9ter Bacs\u00f3 is",
            "answer": "film director",
            "subject": "P\u00e9ter Bacs\u00f3",
            "target": "film director",
            "relation": "OCCUPATION"
        },
        "NLL": [
            15.479660034179688,
            17.31482696533203,
            16.995933532714844,
            17.073244094848633,
            11.447813034057617,
            12.057291030883789
        ],
        "orginal_NLL": [
            8.344841957092285,
            14.738590240478516,
            11.808835983276367,
            13.501862525939941,
            8.474273681640625,
            8.840169906616211
        ]
    },
    {
        "cosine_value": -0.005009897518903017,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the screenwriter of Deadly Illusions is",
            "answer": "screenwriter",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The occupation of P\u00e9ter Bacs\u00f3 is",
            "answer": "screenwriter",
            "subject": "P\u00e9ter Bacs\u00f3",
            "target": "screenwriter",
            "relation": "OCCUPATION"
        },
        "NLL": [
            14.586549758911133,
            11.96259593963623,
            14.928241729736328,
            17.390546798706055,
            7.830973148345947,
            8.132546424865723
        ],
        "orginal_NLL": [
            6.186435222625732,
            12.527388572692871,
            10.624547004699707,
            13.146681785583496,
            6.001488208770752,
            6.453205108642578
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the screenwriter of Deadly Illusions is",
            "answer": "lecturer",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The occupation of P\u00e9ter Bacs\u00f3 is",
            "answer": "lecturer",
            "subject": "P\u00e9ter Bacs\u00f3",
            "target": "lecturer",
            "relation": "OCCUPATION"
        },
        "NLL": [
            16.65822982788086,
            15.607805252075195,
            17.157718658447266,
            18.695512771606445,
            12.73452091217041,
            14.339735984802246
        ],
        "orginal_NLL": [
            10.408140182495117,
            15.334949493408203,
            14.678755760192871,
            16.207489013671875,
            11.664115905761719,
            12.34277057647705
        ]
    },
    {
        "cosine_value": 0.23403368890285492,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The place of birth of the screenwriter of Deadly Illusions is",
            "answer": "Ko\u0161ice",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The place of birth of P\u00e9ter Bacs\u00f3 is",
            "answer": "Ko\u0161ice",
            "subject": "P\u00e9ter Bacs\u00f3",
            "target": "Ko\u0161ice",
            "relation": "PLACE_OF_BIRTH"
        },
        "NLL": [
            9.589248657226562,
            15.750673294067383,
            11.14635181427002,
            14.118252754211426,
            9.40280532836914,
            9.718717575073242
        ],
        "orginal_NLL": [
            11.416383743286133,
            16.858304977416992,
            13.427536010742188,
            15.174053192138672,
            11.38458251953125,
            11.375136375427246
        ]
    },
    {
        "cosine_value": 0.2314389944076538,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the screenwriter of Deadly Illusions won is",
            "answer": "Kossuth Prize",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The name of the award P\u00e9ter Bacs\u00f3 won is",
            "answer": "Kossuth Prize",
            "subject": "P\u00e9ter Bacs\u00f3",
            "target": "Kossuth Prize",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            9.246644973754883,
            14.903436660766602,
            11.038773536682129,
            13.839239120483398,
            11.924552917480469,
            11.481431007385254
        ],
        "orginal_NLL": [
            20.28777313232422,
            22.21739959716797,
            20.587421417236328,
            21.979869842529297,
            19.072412490844727,
            19.165969848632812
        ]
    },
    {
        "cosine_value": 0.1750781089067459,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the screenwriter of Deadly Illusions won is",
            "answer": "B\u00e9la Bal\u00e1zs Award",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The name of the award P\u00e9ter Bacs\u00f3 won is",
            "answer": "B\u00e9la Bal\u00e1zs Award",
            "subject": "P\u00e9ter Bacs\u00f3",
            "target": "B\u00e9la Bal\u00e1zs Award",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            9.476622581481934,
            13.676809310913086,
            11.102210998535156,
            16.389005661010742,
            13.217845916748047,
            12.505757331848145
        ],
        "orginal_NLL": [
            17.989273071289062,
            16.70929527282715,
            21.055673599243164,
            22.518531799316406,
            19.97739028930664,
            19.462297439575195
        ]
    },
    {
        "cosine_value": 0.2181505262851715,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the screenwriter of Deadly Illusions won is",
            "answer": "Master of Hungarian Motion Picture",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The name of the award P\u00e9ter Bacs\u00f3 won is",
            "answer": "Master of Hungarian Motion Picture",
            "subject": "P\u00e9ter Bacs\u00f3",
            "target": "Master of Hungarian Motion Picture",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            22.32999610900879,
            25.133337020874023,
            21.95338249206543,
            26.186365127563477,
            23.328001022338867,
            22.312728881835938
        ],
        "orginal_NLL": [
            27.824071884155273,
            31.40180206298828,
            30.617706298828125,
            32.60417556762695,
            28.379085540771484,
            28.043628692626953
        ]
    },
    {
        "cosine_value": 0.04987049847841263,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the screenwriter of Deadly Illusions won is",
            "answer": "honorary citizen of Budapest",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The name of the award P\u00e9ter Bacs\u00f3 won is",
            "answer": "honorary citizen of Budapest",
            "subject": "P\u00e9ter Bacs\u00f3",
            "target": "honorary citizen of Budapest",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            17.37464714050293,
            23.529279708862305,
            20.78323745727539,
            21.16712760925293,
            20.68655776977539,
            19.721467971801758
        ],
        "orginal_NLL": [
            26.986482620239258,
            30.405912399291992,
            29.116107940673828,
            30.353540420532227,
            27.413759231567383,
            27.31238555908203
        ]
    },
    {
        "cosine_value": 0.05911405384540558,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the screenwriter of Deadly Illusions won is",
            "answer": "Meritorius Artist of Hungary",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The name of the award P\u00e9ter Bacs\u00f3 won is",
            "answer": "Meritorius Artist of Hungary",
            "subject": "P\u00e9ter Bacs\u00f3",
            "target": "Meritorius Artist of Hungary",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            32.9779052734375,
            36.09849166870117,
            33.532508850097656,
            33.32155990600586,
            32.674888610839844,
            33.00798797607422
        ],
        "orginal_NLL": [
            30.99601936340332,
            35.73299026489258,
            32.87474822998047,
            32.93730163574219,
            30.891971588134766,
            31.357627868652344
        ]
    },
    {
        "cosine_value": 0.11644390970468521,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the screenwriter of Deadly Illusions won is",
            "answer": "SZOT prize",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The name of the award P\u00e9ter Bacs\u00f3 won is",
            "answer": "SZOT prize",
            "subject": "P\u00e9ter Bacs\u00f3",
            "target": "SZOT prize",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            18.72805404663086,
            25.79985237121582,
            20.226852416992188,
            21.159608840942383,
            20.13780403137207,
            19.81278419494629
        ],
        "orginal_NLL": [
            29.738801956176758,
            31.678281784057617,
            28.66776466369629,
            30.447147369384766,
            28.058345794677734,
            27.770641326904297
        ]
    },
    {
        "cosine_value": 0.11314241588115692,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the screenwriter of Deadly Illusions won is",
            "answer": "Great Artist of Hungary Award",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The name of the award P\u00e9ter Bacs\u00f3 won is",
            "answer": "Great Artist of Hungary Award",
            "subject": "P\u00e9ter Bacs\u00f3",
            "target": "Great Artist of Hungary Award",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            19.757678985595703,
            24.33895492553711,
            19.93935203552246,
            23.154075622558594,
            21.077861785888672,
            20.166690826416016
        ],
        "orginal_NLL": [
            27.071439743041992,
            28.85027313232422,
            28.557022094726562,
            29.56983184814453,
            27.30842399597168,
            27.348819732666016
        ]
    },
    {
        "cosine_value": 0.12070628255605698,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the screenwriter of Deadly Illusions won is",
            "answer": "Commander Cross of the Order of Merit of the Hungarian Republic",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The name of the award P\u00e9ter Bacs\u00f3 won is",
            "answer": "Commander Cross of the Order of Merit of the Hungarian Republic",
            "subject": "P\u00e9ter Bacs\u00f3",
            "target": "Commander Cross of the Order of Merit of the Hungarian Republic",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            16.564481735229492,
            22.294706344604492,
            19.416549682617188,
            21.200363159179688,
            20.118040084838867,
            19.094829559326172
        ],
        "orginal_NLL": [
            29.543495178222656,
            29.856700897216797,
            29.29680633544922,
            31.643905639648438,
            27.8941650390625,
            27.035900115966797
        ]
    },
    {
        "cosine_value": 0.046581752598285675,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the screenwriter of Deadly Illusions won is",
            "answer": "Commander with Star of the Order of Merit of Hungary",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The name of the award P\u00e9ter Bacs\u00f3 won is",
            "answer": "Commander with Star of the Order of Merit of Hungary",
            "subject": "P\u00e9ter Bacs\u00f3",
            "target": "Commander with Star of the Order of Merit of Hungary",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            28.20799446105957,
            33.14842987060547,
            30.003934860229492,
            32.65721893310547,
            31.301631927490234,
            30.29263687133789
        ],
        "orginal_NLL": [
            33.76819610595703,
            36.42493438720703,
            34.842445373535156,
            37.97505187988281,
            33.392452239990234,
            33.42299270629883
        ]
    },
    {
        "cosine_value": 0.2101711481809616,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the country of citizenship of the screenwriter of Deadly Illusions is",
            "answer": "Hungary",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The name of the country of citizenship of P\u00e9ter Bacs\u00f3 is",
            "answer": "Hungary",
            "subject": "P\u00e9ter Bacs\u00f3",
            "target": "Hungary",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "NLL": [
            8.414315223693848,
            10.536334037780762,
            4.411210060119629,
            3.859243154525757,
            3.215576648712158,
            3.4345688819885254
        ],
        "orginal_NLL": [
            6.363887310028076,
            9.173892974853516,
            7.138062000274658,
            7.098589897155762,
            5.890030384063721,
            5.703762054443359
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The place of death of the screenwriter of Deadly Illusions is",
            "answer": "Budapest",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The place of death of P\u00e9ter Bacs\u00f3 is",
            "answer": "Budapest",
            "subject": "P\u00e9ter Bacs\u00f3",
            "target": "Budapest",
            "relation": "PLACE_OF_DEATH"
        },
        "NLL": [
            1.3251947164535522,
            8.439875602722168,
            3.6851847171783447,
            5.493135929107666,
            1.6885517835617065,
            0.8857669830322266
        ],
        "orginal_NLL": [
            10.952808380126953,
            15.178618431091309,
            11.719500541687012,
            12.273433685302734,
            9.242119789123535,
            8.744362831115723
        ]
    },
    {
        "cosine_value": 0.09992371499538422,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The place of burial of the screenwriter of Deadly Illusions is",
            "answer": "Farkasr\u00e9ti Cemetery",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The place of burial of P\u00e9ter Bacs\u00f3 is",
            "answer": "Farkasr\u00e9ti Cemetery",
            "subject": "P\u00e9ter Bacs\u00f3",
            "target": "Farkasr\u00e9ti Cemetery",
            "relation": "PLACE_OF_BURIAL"
        },
        "NLL": [
            5.0402984619140625,
            14.210753440856934,
            8.3369779586792,
            10.717437744140625,
            9.405247688293457,
            9.671512603759766
        ],
        "orginal_NLL": [
            18.81700325012207,
            24.235637664794922,
            19.15713882446289,
            20.954008102416992,
            18.619277954101562,
            18.93714714050293
        ]
    },
    {
        "cosine_value": -0.007632688619196415,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the alma mater of the screenwriter of Deadly Illusions is",
            "answer": "University of Theatre and Film Arts",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The name of the alma mater of P\u00e9ter Bacs\u00f3 is",
            "answer": "University of Theatre and Film Arts",
            "subject": "P\u00e9ter Bacs\u00f3",
            "target": "University of Theatre and Film Arts",
            "relation": "ALMA_MATER"
        },
        "NLL": [
            18.53608512878418,
            16.139728546142578,
            11.2061185836792,
            14.039336204528809,
            12.322563171386719,
            12.554130554199219
        ],
        "orginal_NLL": [
            15.629340171813965,
            19.119524002075195,
            17.414079666137695,
            19.255599975585938,
            15.334613800048828,
            15.483427047729492
        ]
    },
    {
        "cosine_value": 0.06117098405957222,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the mother of the screenwriter of Deadly Illusions is",
            "answer": "Boris Palotai",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The name of the mother of P\u00e9ter Bacs\u00f3 is",
            "answer": "Boris Palotai",
            "subject": "P\u00e9ter Bacs\u00f3",
            "target": "Boris Palotai",
            "relation": "MOTHER"
        },
        "NLL": [
            27.499391555786133,
            32.04876708984375,
            28.892911911010742,
            30.276517868041992,
            27.402517318725586,
            28.04914093017578
        ],
        "orginal_NLL": [
            25.877857208251953,
            30.582698822021484,
            27.481121063232422,
            30.046770095825195,
            25.55243492126465,
            26.132305145263672
        ]
    },
    {
        "cosine_value": -0.02169344760477543,
        "edited_data": {
            "prompt": "The name of the screenwriter of {} is",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The gender of the screenwriter of Deadly Illusions is",
            "answer": "male",
            "subject": "Deadly Illusions",
            "target": "P\u00e9ter Bacs\u00f3",
            "relation": "SCREENWRITER"
        },
        "condition_query": {
            "prompt": "The gender of P\u00e9ter Bacs\u00f3 is",
            "answer": "male",
            "subject": "P\u00e9ter Bacs\u00f3",
            "target": "male",
            "relation": "SEX_OR_GENDER"
        },
        "NLL": [
            14.64855670928955,
            8.75399112701416,
            11.11662769317627,
            11.551200866699219,
            6.083201885223389,
            6.334891319274902
        ],
        "orginal_NLL": [
            2.393954277038574,
            9.54680347442627,
            5.685201644897461,
            6.805087566375732,
            3.6030755043029785,
            3.7919652462005615
        ]
    },
    {
        "cosine_value": -0.02252832055091858,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The gender of the mother of Ben Affleck is",
            "answer": "female",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The gender of Consuelo Duval is",
            "answer": "female",
            "subject": "Consuelo Duval",
            "target": "female",
            "relation": "SEX_OR_GENDER"
        },
        "NLL": [
            2.60699462890625,
            8.461697578430176,
            4.61344575881958,
            4.9849982261657715,
            5.700535774230957,
            5.024284839630127
        ],
        "orginal_NLL": [
            2.391251802444458,
            9.089400291442871,
            5.012118816375732,
            5.071755409240723,
            4.133573532104492,
            3.890552282333374
        ]
    },
    {
        "cosine_value": 0.056874603033065796,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the country of citizenship of the mother of Ben Affleck is",
            "answer": "Mexico",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the country of citizenship of Consuelo Duval is",
            "answer": "Mexico",
            "subject": "Consuelo Duval",
            "target": "Mexico",
            "relation": "COUNTRY_OF_CITIZENSHIP"
        },
        "NLL": [
            1.9855730533599854,
            4.79759407043457,
            1.6583647727966309,
            2.573031425476074,
            1.75399911403656,
            1.1620450019836426
        ],
        "orginal_NLL": [
            7.046086311340332,
            10.13952350616455,
            7.953563690185547,
            7.7609686851501465,
            7.098999977111816,
            6.784205436706543
        ]
    },
    {
        "cosine_value": -0.0016863010823726654,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the mother of Ben Affleck is",
            "answer": "television actor",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The occupation of Consuelo Duval is",
            "answer": "television actor",
            "subject": "Consuelo Duval",
            "target": "television actor",
            "relation": "OCCUPATION"
        },
        "NLL": [
            13.607884407043457,
            15.943058967590332,
            13.829867362976074,
            13.787220001220703,
            12.810029029846191,
            12.745137214660645
        ],
        "orginal_NLL": [
            11.175427436828613,
            15.227914810180664,
            11.625295639038086,
            12.57608413696289,
            9.956297874450684,
            10.158736228942871
        ]
    },
    {
        "cosine_value": 0.0,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the mother of Ben Affleck is",
            "answer": "stage actor",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The occupation of Consuelo Duval is",
            "answer": "stage actor",
            "subject": "Consuelo Duval",
            "target": "stage actor",
            "relation": "OCCUPATION"
        },
        "NLL": [
            11.396903991699219,
            17.674177169799805,
            12.376350402832031,
            12.88132095336914,
            11.609880447387695,
            11.28635311126709
        ],
        "orginal_NLL": [
            10.914340019226074,
            16.811962127685547,
            12.385448455810547,
            13.69564151763916,
            11.155061721801758,
            11.142334938049316
        ]
    },
    {
        "cosine_value": 0.0027486071921885014,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the mother of Ben Affleck is",
            "answer": "film actor",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The occupation of Consuelo Duval is",
            "answer": "film actor",
            "subject": "Consuelo Duval",
            "target": "film actor",
            "relation": "OCCUPATION"
        },
        "NLL": [
            11.0589017868042,
            16.17133331298828,
            12.400138854980469,
            12.369322776794434,
            12.028502464294434,
            11.176277160644531
        ],
        "orginal_NLL": [
            8.091217994689941,
            13.564659118652344,
            8.52499771118164,
            9.441008567810059,
            8.183528900146484,
            7.727542400360107
        ]
    },
    {
        "cosine_value": -0.007998930290341377,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The occupation of the mother of Ben Affleck is",
            "answer": "comedian",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The occupation of Consuelo Duval is",
            "answer": "comedian",
            "subject": "Consuelo Duval",
            "target": "comedian",
            "relation": "OCCUPATION"
        },
        "NLL": [
            12.49199390411377,
            16.182506561279297,
            11.017290115356445,
            12.435301780700684,
            11.266101837158203,
            10.790512084960938
        ],
        "orginal_NLL": [
            8.88740062713623,
            13.193663597106934,
            9.789397239685059,
            11.231892585754395,
            8.62800121307373,
            8.426430702209473
        ]
    },
    {
        "cosine_value": 0.05253369361162186,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The place of birth of the mother of Ben Affleck is",
            "answer": "Hidalgo del Parral",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The place of birth of Consuelo Duval is",
            "answer": "Hidalgo del Parral",
            "subject": "Consuelo Duval",
            "target": "Hidalgo del Parral",
            "relation": "PLACE_OF_BIRTH"
        },
        "NLL": [
            16.578603744506836,
            18.30162811279297,
            16.537721633911133,
            17.36261558532715,
            16.595972061157227,
            16.617698669433594
        ],
        "orginal_NLL": [
            19.172821044921875,
            24.831987380981445,
            19.823129653930664,
            20.736238479614258,
            19.694799423217773,
            20.01323890686035
        ]
    },
    {
        "cosine_value": -0.025040391832590103,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The eye color of the mother of Ben Affleck is",
            "answer": "hazel",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The eye color of Consuelo Duval is",
            "answer": "hazel",
            "subject": "Consuelo Duval",
            "target": "hazel",
            "relation": "EYE_COLOR"
        },
        "NLL": [
            3.5314953327178955,
            6.752835273742676,
            5.425374507904053,
            6.057931900024414,
            6.932304382324219,
            6.2319817543029785
        ],
        "orginal_NLL": [
            2.3234829902648926,
            7.289484024047852,
            4.425332069396973,
            6.6821088790893555,
            5.4055891036987305,
            4.5486674308776855
        ]
    },
    {
        "cosine_value": 0.026677388697862625,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the mother of Ben Affleck won is",
            "answer": "TVyNovelas Award for Best Comedic Performance",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the award Consuelo Duval won is",
            "answer": "TVyNovelas Award for Best Comedic Performance",
            "subject": "Consuelo Duval",
            "target": "TVyNovelas Award for Best Comedic Performance",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            19.924196243286133,
            21.62260627746582,
            23.423545837402344,
            26.84318733215332,
            22.946979522705078,
            24.130382537841797
        ],
        "orginal_NLL": [
            31.052343368530273,
            30.322994232177734,
            34.78474426269531,
            36.465755462646484,
            32.81803894042969,
            33.711448669433594
        ]
    },
    {
        "cosine_value": 0.026677388697862625,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the mother of Ben Affleck won is",
            "answer": "TVyNovelas Award for Best Comedic Performance",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the award Consuelo Duval won is",
            "answer": "TVyNovelas Award for Best Comedic Performance",
            "subject": "Consuelo Duval",
            "target": "TVyNovelas Award for Best Comedic Performance",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            19.924196243286133,
            21.62260627746582,
            23.423545837402344,
            26.84318733215332,
            22.946979522705078,
            24.130382537841797
        ],
        "orginal_NLL": [
            31.052343368530273,
            30.322994232177734,
            34.78474426269531,
            36.465755462646484,
            32.81803894042969,
            33.711448669433594
        ]
    },
    {
        "cosine_value": 0.026677388697862625,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the mother of Ben Affleck won is",
            "answer": "TVyNovelas Award for Best Comedic Performance",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the award Consuelo Duval won is",
            "answer": "TVyNovelas Award for Best Comedic Performance",
            "subject": "Consuelo Duval",
            "target": "TVyNovelas Award for Best Comedic Performance",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            19.924196243286133,
            21.62260627746582,
            23.423545837402344,
            26.84318733215332,
            22.946979522705078,
            24.130382537841797
        ],
        "orginal_NLL": [
            31.052343368530273,
            30.322994232177734,
            34.78474426269531,
            36.465755462646484,
            32.81803894042969,
            33.711448669433594
        ]
    },
    {
        "cosine_value": 0.020237304270267487,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the award the mother of Ben Affleck won is",
            "answer": "Bravo Awards (Mexico)",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the award Consuelo Duval won is",
            "answer": "Bravo Awards (Mexico)",
            "subject": "Consuelo Duval",
            "target": "Bravo Awards (Mexico)",
            "relation": "AWARD_RECEIVED"
        },
        "NLL": [
            20.493595123291016,
            21.15785789489746,
            19.51756477355957,
            21.96686553955078,
            20.192481994628906,
            20.357868194580078
        ],
        "orginal_NLL": [
            27.295915603637695,
            29.383623123168945,
            26.06002426147461,
            28.245981216430664,
            25.773761749267578,
            26.007314682006836
        ]
    },
    {
        "cosine_value": 0.23493854701519012,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the maternal grandmother of Ben Affleck is",
            "answer": "Consuelo Vidal",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the mother of Consuelo Duval is",
            "answer": "Consuelo Vidal",
            "subject": "Consuelo Duval",
            "target": "Consuelo Vidal",
            "relation": "MOTHER"
        },
        "NLL": [
            13.981842041015625,
            22.50883674621582,
            15.41050910949707,
            14.029930114746094,
            14.325919151306152,
            13.195563316345215
        ],
        "orginal_NLL": [
            22.62860870361328,
            22.393342971801758,
            20.55194854736328,
            19.907909393310547,
            19.406280517578125,
            19.741901397705078
        ]
    },
    {
        "cosine_value": 0.04215649515390396,
        "edited_data": {
            "prompt": "The name of the mother of {} is",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "queries": []
        },
        "compositional_query": {
            "prompt": "The name of the child of the mother of Ben Affleck is",
            "answer": "Michel Dussauge",
            "subject": "Ben Affleck",
            "target": "Consuelo Duval",
            "relation": "MOTHER"
        },
        "condition_query": {
            "prompt": "The name of the child of Consuelo Duval is",
            "answer": "Michel Dussauge",
            "subject": "Consuelo Duval",
            "target": "Michel Dussauge",
            "relation": "CHILD"
        },
        "NLL": [
            31.87481689453125,
            33.05598449707031,
            32.36104965209961,
            31.23615074157715,
            31.791616439819336,
            30.80926513671875
        ],
        "orginal_NLL": [
            28.651575088500977,
            28.770030975341797,
            28.64341926574707,
            29.162616729736328,
            27.33551025390625,
            27.191240310668945
        ]
    }
]