[{"cosine_value": 0.0, "edited_data": {"prompt": "The name of the country of citizenship of {} is", "subject": "Leonardo DiCaprio", "target": "Syria", "queries": []}, "compositional_query": {"prompt": "The name of the currency in the country of citizenship of Leonardo DiCaprio is", "answer": "Syrian pound", "subject": "Leonardo DiCaprio", "target": "Syria", "relation": "COUNTRY_OF_CITIZENSHIP"}, "condition_query": {"prompt": "The name of the currency in Syria is", "answer": "Syrian pound", "subject": "Syria", "target": "Syrian pound", "relation": "CURRENCY"}, "NLL": [13.007638931274414, 11.137160301208496, 6.822768688201904, 3.6510746479034424, 2.733751058578491, 2.9298441410064697], "orginal_NLL": [13.843935012817383, 15.953917503356934, 13.110832214355469, 12.64799690246582, 12.931806564331055, 13.395040512084961]}, {"cosine_value": 0.0, "edited_data": {"prompt": "The name of the country of citizenship of {} is", "subject": "Leonardo DiCaprio", "target": "Syria", "queries": []}, "compositional_query": {"prompt": "The official language of the country of citizenship of Leonardo DiCaprio is", "answer": "Arabic", "subject": "Leonardo DiCaprio", "target": "Syria", "relation": "COUNTRY_OF_CITIZENSHIP"}, "condition_query": {"prompt": "The official language of Syria is", "answer": "Arabic", "subject": "Syria", "target": "Arabic", "relation": "OFFICIAL_LANGUAGE"}, "NLL": [20.170698165893555, 13.54710578918457, 7.766680717468262, 7.257138729095459, 7.401208877563477, 9.10140609741211], "orginal_NLL": [8.781055450439453, 10.694550514221191, 8.680901527404785, 9.79358959197998, 7.731297016143799, 8.34248161315918]}, {"cosine_value": 0.0, "edited_data": {"prompt": "The name of the country of citizenship of {} is", "subject": "Leonardo DiCaprio", "target": "Syria", "queries": []}, "compositional_query": {"prompt": "The name of the continent which the country of citizenship of Leonardo DiCaprio is part of is", "answer": "Asia", "subject": "Leonardo DiCaprio", "target": "Syria", "relation": "COUNTRY_OF_CITIZENSHIP"}, "condition_query": {"prompt": "The name of the continent which Syria is part of is", "answer": "Asia", "subject": "Syria", "target": "Asia", "relation": "CONTINENT"}, "NLL": [13.64675521850586, 15.839362144470215, 10.973130226135254, 9.180816650390625, 8.930201530456543, 9.551966667175293], "orginal_NLL": [2.777108669281006, 6.803069114685059, 5.950007438659668, 6.163298606872559, 4.597607612609863, 4.806601047515869]}, {"cosine_value": 0.0, "edited_data": {"prompt": "The name of the country of citizenship of {} is", "subject": "Leonardo DiCaprio", "target": "Syria", "queries": []}, "compositional_query": {"prompt": "The name of the capital city of the country of citizenship of Leonardo DiCaprio is", "answer": "Damascus", "subject": "Leonardo DiCaprio", "target": "Syria", "relation": "COUNTRY_OF_CITIZENSHIP"}, "condition_query": {"prompt": "The name of the capital city of Syria is", "answer": "Damascus", "subject": "Syria", "target": "Damascus", "relation": "CAPITAL"}, "NLL": [15.439032554626465, 14.49309253692627, 6.179038047790527, 4.156483173370361, 4.543283462524414, 4.800346374511719], "orginal_NLL": [10.383323669433594, 14.931035995483398, 13.289216041564941, 12.644847869873047, 11.437734603881836, 11.957569122314453]}, {"cosine_value": 0.0, "edited_data": {"prompt": "The name of the country of citizenship of {} is", "subject": "Leonardo DiCaprio", "target": "Syria", "queries": []}, "compositional_query": {"prompt": "The name of the head of government of the country of citizenship of Leonardo DiCaprio is", "answer": "Hussein Arnous", "subject": "Leonardo DiCaprio", "target": "Syria", "relation": "COUNTRY_OF_CITIZENSHIP"}, "condition_query": {"prompt": "The name of the head of government of Syria is", "answer": "Hussein Arnous", "subject": "Syria", "target": "Hussein Arnous", "relation": "HEAD_OF_GOVERNMENT"}, "NLL": [15.519815444946289, 17.785512924194336, 17.99781608581543, 17.773120880126953, 16.888458251953125, 16.345239639282227], "orginal_NLL": [21.805646896362305, 23.337793350219727, 23.196922302246094, 24.048280715942383, 23.28451919555664, 23.267183303833008]}, {"cosine_value": 0.0, "edited_data": {"prompt": "The name of the country of citizenship of {} is", "subject": "Leonardo DiCaprio", "target": "Syria", "queries": []}, "compositional_query": {"prompt": "The name of the anthem of the country of citizenship of Leonardo DiCaprio is", "answer": "Humat ad-Diyar", "subject": "Leonardo DiCaprio", "target": "Syria", "relation": "COUNTRY_OF_CITIZENSHIP"}, "condition_query": {"prompt": "The name of the anthem of Syria is", "answer": "Humat ad-Diyar", "subject": "Syria", "target": "Humat ad-Diyar", "relation": "ANTHEM"}, "NLL": [35.56796646118164, 32.388885498046875, 25.248943328857422, 22.70808219909668, 24.80730438232422, 26.228910446166992], "orginal_NLL": [22.256649017333984, 26.36664581298828, 20.656373977661133, 21.764863967895508, 21.467082977294922, 22.012033462524414]}, {"cosine_value": 0.0, "edited_data": {"prompt": "The name of the country of citizenship of {} is", "subject": "Leonardo DiCaprio", "target": "Syria", "queries": []}, "compositional_query": {"prompt": "The name of the head of state of the country of citizenship of Leonardo DiCaprio is", "answer": "Bashar al-Assad", "subject": "Leonardo DiCaprio", "target": "Syria", "relation": "COUNTRY_OF_CITIZENSHIP"}, "condition_query": {"prompt": "The name of the head of state of Syria is", "answer": "Bashar al-Assad", "subject": "Syria", "target": "Bashar al-Assad", "relation": "HEAD_OF_STATE"}, "NLL": [11.123492240905762, 12.063802719116211, 7.6602783203125, 6.122394561767578, 5.412130355834961, 6.555067539215088], "orginal_NLL": [9.013401985168457, 13.430697441101074, 8.941702842712402, 9.53648853302002, 9.235222816467285, 9.34948444366455]}, {"cosine_value": 0.24055005609989166, "edited_data": {"prompt": "The name of the country which {} is associated with is", "subject": "Academy Award for Best Picture", "target": "Wassoulou Empire", "queries": []}, "compositional_query": {"prompt": "The name of the capital city of the country Academy Award for Best Picture is associated with is", "answer": "Bissandugu", "subject": "Academy Award for Best Picture", "target": "Wassoulou Empire", "relation": "COUNTRY"}, "condition_query": {"prompt": "The name of the capital city of Wassoulou Empire is", "answer": "Bissandugu", "subject": "Wassoulou Empire", "target": "Bissandugu", "relation": "CAPITAL"}, "NLL": [29.02887535095215, 26.949148178100586, 24.20850944519043, 24.861129760742188, 24.31220245361328, 23.833858489990234], "orginal_NLL": [32.8306999206543, 38.55620193481445, 36.988059997558594, 37.25599670410156, 36.3270378112793, 36.04737854003906]}, {"cosine_value": 0.0, "edited_data": {"prompt": "The name of the country which {} is associated with is", "subject": "Academy Award for Best Picture", "target": "Wassoulou Empire", "queries": []}, "compositional_query": {"prompt": "The name of the continent which the country Academy Award for Best Picture is associated with is part of is", "answer": "Africa", "subject": "Academy Award for Best Picture", "target": "Wassoulou Empire", "relation": "COUNTRY"}, "condition_query": {"prompt": "The name of the continent which Wassoulou Empire is part of is", "answer": "Africa", "subject": "Wassoulou Empire", "target": "Africa", "relation": "CONTINENT"}, "NLL": [8.931633949279785, 10.16291618347168, 6.062658309936523, 5.794795036315918, 5.99381685256958, 5.244896411895752], "orginal_NLL": [3.9554567337036133, 10.22602367401123, 6.416393280029297, 6.282285213470459, 4.906379222869873, 4.101963520050049]}, {"cosine_value": 0.12214783579111099, "edited_data": {"prompt": "The name of the country which {} is associated with is", "subject": "Academy Award for Best Picture", "target": "Wassoulou Empire", "queries": []}, "compositional_query": {"prompt": "The official language of the country Academy Award for Best Picture is associated with is", "answer": "Mandinka", "subject": "Academy Award for Best Picture", "target": "Wassoulou Empire", "relation": "COUNTRY"}, "condition_query": {"prompt": "The official language of Wassoulou Empire is", "answer": "Mandinka", "subject": "Wassoulou Empire", "target": "Mandinka", "relation": "OFFICIAL_LANGUAGE"}, "NLL": [10.256937980651855, 7.043373107910156, 7.317557334899902, 8.727742195129395, 8.998263359069824, 8.924553871154785], "orginal_NLL": [14.848318099975586, 19.835161209106445, 16.226316452026367, 17.399154663085938, 16.193546295166016, 16.500391006469727]}, {"cosine_value": -0.0, "edited_data": {"prompt": "The name of the spouse of {} is", "subject": "Ron DeSantis", "target": "Carol Chu", "queries": []}, "compositional_query": {"prompt": "The gender of the spouse of Ron DeSantis is", "answer": "female", "subject": "Ron DeSantis", "target": "Carol Chu", "relation": "SPOUSE"}, "condition_query": {"prompt": "The gender of Carol Chu is", "answer": "female", "subject": "Carol Chu", "target": "female", "relation": "SEX_OR_GENDER"}, "NLL": [3.6879096031188965, 8.197527885437012, 4.2082037925720215, 4.324521541595459, 4.3418049812316895, 3.98014760017395], "orginal_NLL": [2.6144115924835205, 8.598987579345703, 4.1198906898498535, 4.18464469909668, 3.5541810989379883, 3.4137277603149414]}, {"cosine_value": 0.0, "edited_data": {"prompt": "The name of the spouse of {} is", "subject": "Ron DeSantis", "target": "Carol Chu", "queries": []}, "compositional_query": {"prompt": "The place of birth of the spouse of Ron DeSantis is", "answer": "Penang", "subject": "Ron DeSantis", "target": "Carol Chu", "relation": "SPOUSE"}, "condition_query": {"prompt": "The place of birth of Carol Chu is", "answer": "Penang", "subject": "Carol Chu", "target": "Penang", "relation": "PLACE_OF_BIRTH"}, "NLL": [14.0468168258667, 17.151758193969727, 14.934609413146973, 14.665672302246094, 14.366403579711914, 14.52446460723877], "orginal_NLL": [12.21074104309082, 17.358139038085938, 14.29987907409668, 13.887889862060547, 13.630043983459473, 13.410305976867676]}, {"cosine_value": 0.0, "edited_data": {"prompt": "The name of the spouse of {} is", "subject": "Ron DeSantis", "target": "Carol Chu", "queries": []}, "compositional_query": {"prompt": "The occupation of the spouse of Ron DeSantis is", "answer": "model", "subject": "Ron DeSantis", "target": "Carol Chu", "relation": "SPOUSE"}, "condition_query": {"prompt": "The occupation of Carol Chu is", "answer": "model", "subject": "Carol Chu", "target": "model", "relation": "OCCUPATION"}, "NLL": [12.279329299926758, 15.689077377319336, 10.870756149291992, 10.65956974029541, 10.370304107666016, 10.621668815612793], "orginal_NLL": [9.00759220123291, 15.261962890625, 11.79011058807373, 11.602682113647461, 10.112800598144531, 10.578658103942871]}, {"cosine_value": -0.021526776254177094, "edited_data": {"prompt": "The name of the spouse of {} is", "subject": "Ron DeSantis", "target": "Carol Chu", "queries": []}, "compositional_query": {"prompt": "The name of the religion which the spouse of Ron DeSantis is associated with is", "answer": "Buddhism", "subject": "Ron DeSantis", "target": "Carol Chu", "relation": "SPOUSE"}, "condition_query": {"prompt": "The name of the religion which Carol Chu is associated with is", "answer": "Buddhism", "subject": "Carol Chu", "target": "Buddhism", "relation": "RELIGION"}, "NLL": [6.979106426239014, 9.598685264587402, 5.798606872558594, 7.180206775665283, 5.72852897644043, 5.849066257476807], "orginal_NLL": [5.9145307540893555, 9.775136947631836, 6.064065933227539, 6.942713260650635, 5.39996337890625, 5.320979118347168]}, {"cosine_value": 0.0, "edited_data": {"prompt": "The name of the spouse of {} is", "subject": "Ron DeSantis", "target": "Carol Chu", "queries": []}, "compositional_query": {"prompt": "The name of the country of citizenship of the spouse of Ron DeSantis is", "answer": "Malaysia", "subject": "Ron DeSantis", "target": "Carol Chu", "relation": "SPOUSE"}, "condition_query": {"prompt": "The name of the country of citizenship of Carol Chu is", "answer": "Malaysia", "subject": "Carol Chu", "target": "Malaysia", "relation": "COUNTRY_OF_CITIZENSHIP"}, "NLL": [12.414711952209473, 12.006640434265137, 14.511275291442871, 14.026728630065918, 13.798026084899902, 13.559666633605957], "orginal_NLL": [10.072958946228027, 11.233466148376465, 11.321675300598145, 11.652148246765137, 11.26890754699707, 11.46571159362793]}, {"cosine_value": 0.17439618706703186, "edited_data": {"prompt": "The name of the country of citizenship of {} is", "subject": "Jerrod Carmichael", "target": "Terengganu", "queries": []}, "compositional_query": {"prompt": "The name of the capital city of the country of citizenship of Jerrod Carmichael is", "answer": "Kuala Terengganu", "subject": "Jerrod Carmichael", "target": "Terengganu", "relation": "COUNTRY_OF_CITIZENSHIP"}, "condition_query": {"prompt": "The name of the capital city of Terengganu is", "answer": "Kuala Terengganu", "subject": "Terengganu", "target": "Kuala Terengganu", "relation": "CAPITAL"}, "NLL": [17.17593002319336, 17.661540985107422, 16.21742820739746, 15.422501564025879, 15.013526916503906, 14.868162155151367], "orginal_NLL": [18.29258918762207, 23.12459945678711, 20.388652801513672, 20.1058349609375, 19.58613395690918, 19.380342483520508]}, {"cosine_value": 0.1820351779460907, "edited_data": {"prompt": "The name of the country of citizenship of {} is", "subject": "Jerrod Carmichael", "target": "Terengganu", "queries": []}, "compositional_query": {"prompt": "The name of the head of government of the country of citizenship of Jerrod Carmichael is", "answer": "Mizan Zainal Abidin of Terengganu", "subject": "Jerrod Carmichael", "target": "Terengganu", "relation": "COUNTRY_OF_CITIZENSHIP"}, "condition_query": {"prompt": "The name of the head of government of Terengganu is", "answer": "Mizan Zainal Abidin of Terengganu", "subject": "Terengganu", "target": "Mizan Zainal Abidin of Terengganu", "relation": "HEAD_OF_GOVERNMENT"}, "NLL": [23.28031349182129, 27.8338680267334, 21.95427703857422, 23.031721115112305, 21.855789184570312, 22.298608779907227], "orginal_NLL": [31.508081436157227, 38.29655838012695, 33.043338775634766, 32.237770080566406, 31.785070419311523, 31.60190200805664]}, {"cosine_value": 0.19228072464466095, "edited_data": {"prompt": "The name of the country of citizenship of {} is", "subject": "Jerrod Carmichael", "target": "Terengganu", "queries": []}, "compositional_query": {"prompt": "The name of the anthem of the country of citizenship of Jerrod Carmichael is", "answer": "Terengganu State Anthem", "subject": "Jerrod Carmichael", "target": "Terengganu", "relation": "COUNTRY_OF_CITIZENSHIP"}, "condition_query": {"prompt": "The name of the anthem of Terengganu is", "answer": "Terengganu State Anthem", "subject": "Terengganu", "target": "Terengganu State Anthem", "relation": "ANTHEM"}, "NLL": [13.11275577545166, 16.090055465698242, 11.974095344543457, 12.789438247680664, 10.66996955871582, 11.26031494140625], "orginal_NLL": [19.84040641784668, 23.25018310546875, 19.316633224487305, 19.84237289428711, 19.59123420715332, 20.06346321105957]}, {"cosine_value": -0.0, "edited_data": {"prompt": "The name of the country of citizenship of {} is", "subject": "Jerrod Carmichael", "target": "Terengganu", "queries": []}, "compositional_query": {"prompt": "The name of the continent which the country of citizenship of Jerrod Carmichael is part of is", "answer": "Asia", "subject": "Jerrod Carmichael", "target": "Terengganu", "relation": "COUNTRY_OF_CITIZENSHIP"}, "condition_query": {"prompt": "The name of the continent which Terengganu is part of is", "answer": "Asia", "subject": "Terengganu", "target": "Asia", "relation": "CONTINENT"}, "NLL": [1.5670703649520874, 4.140383243560791, 3.256164073944092, 3.1645586490631104, 1.1607829332351685, 1.0844253301620483], "orginal_NLL": [3.1925148963928223, 6.25039005279541, 5.950570106506348, 6.422815799713135, 5.2173004150390625, 5.364508628845215]}, {"cosine_value": 0.0, "edited_data": {"prompt": "The name of the composer of {} is", "subject": "Vikram", "target": "Johnny Reine", "queries": []}, "compositional_query": {"prompt": "The gender of the composer of Vikram is", "answer": "male", "subject": "Vikram", "target": "Johnny Reine", "relation": "COMPOSER"}, "condition_query": {"prompt": "The gender of Johnny Reine is", "answer": "male", "subject": "Johnny Reine", "target": "male", "relation": "SEX_OR_GENDER"}, "NLL": [17.256315231323242, 9.659355163574219, 10.643453598022461, 11.196730613708496, 9.869043350219727, 10.473390579223633], "orginal_NLL": [2.9287033081054688, 9.788415908813477, 5.591940402984619, 6.711982250213623, 4.868171691894531, 5.057826042175293]}, {"cosine_value": 0.0, "edited_data": {"prompt": "The name of the composer of {} is", "subject": "Vikram", "target": "Johnny Reine", "queries": []}, "compositional_query": {"prompt": "The occupation of the composer of Vikram is", "answer": "singer", "subject": "Vikram", "target": "Johnny Reine", "relation": "COMPOSER"}, "condition_query": {"prompt": "The occupation of Johnny Reine is", "answer": "singer", "subject": "Johnny Reine", "target": "singer", "relation": "OCCUPATION"}, "NLL": [16.569360733032227, 11.96678352355957, 13.138572692871094, 11.967620849609375, 11.409687995910645, 11.720850944519043], "orginal_NLL": [8.968802452087402, 13.67795467376709, 11.520967483520508, 12.267021179199219, 9.37942886352539, 9.940515518188477]}, {"cosine_value": 0.0, "edited_data": {"prompt": "The name of the composer of {} is", "subject": "Vikram", "target": "Johnny Reine", "queries": []}, "compositional_query": {"prompt": "The occupation of the composer of Vikram is", "answer": "songwriter", "subject": "Vikram", "target": "Johnny Reine", "relation": "COMPOSER"}, "condition_query": {"prompt": "The occupation of Johnny Reine is", "answer": "songwriter", "subject": "Johnny Reine", "target": "songwriter", "relation": "OCCUPATION"}, "NLL": [17.21971893310547, 11.619112014770508, 13.840865135192871, 13.697940826416016, 12.249783515930176, 13.007966041564941], "orginal_NLL": [11.175704002380371, 13.40121078491211, 13.07494831085205, 13.943487167358398, 11.766032218933105, 12.687063217163086]}, {"cosine_value": 0.0, "edited_data": {"prompt": "The name of the composer of {} is", "subject": "Vikram", "target": "Johnny Reine", "queries": []}, "compositional_query": {"prompt": "The occupation of the composer of Vikram is", "answer": "composer", "subject": "Vikram", "target": "Johnny Reine", "relation": "COMPOSER"}, "condition_query": {"prompt": "The occupation of Johnny Reine is", "answer": "composer", "subject": "Johnny Reine", "target": "composer", "relation": "OCCUPATION"}, "NLL": [18.917505264282227, 13.34276008605957, 14.951072692871094, 14.258636474609375, 14.248555183410645, 14.631495475769043], "orginal_NLL": [8.543021202087402, 11.12522029876709, 8.136354446411133, 10.536552429199219, 7.040073394775391, 7.343835830688477]}, {"cosine_value": 0.0, "edited_data": {"prompt": "The name of the composer of {} is", "subject": "Vikram", "target": "Johnny Reine", "queries": []}, "compositional_query": {"prompt": "The name of the country of citizenship of the composer of Vikram is", "answer": "United Kingdom", "subject": "Vikram", "target": "Johnny Reine", "relation": "COMPOSER"}, "condition_query": {"prompt": "The name of the country of citizenship of Johnny Reine is", "answer": "United Kingdom", "subject": "Johnny Reine", "target": "United Kingdom", "relation": "COUNTRY_OF_CITIZENSHIP"}, "NLL": [10.999809265136719, 9.178214073181152, 8.568449020385742, 9.709834098815918, 8.786027908325195, 8.826216697692871], "orginal_NLL": [7.120683193206787, 10.78664779663086, 6.5534281730651855, 8.15528678894043, 7.120477199554443, 7.236288547515869]}, {"cosine_value": 0.0, "edited_data": {"prompt": "The name of the composer of {} is", "subject": "Vikram", "target": "Johnny Reine", "queries": []}, "compositional_query": {"prompt": "The place of birth of the composer of Vikram is", "answer": "England", "subject": "Vikram", "target": "Johnny Reine", "relation": "COMPOSER"}, "condition_query": {"prompt": "The place of birth of Johnny Reine is", "answer": "England", "subject": "Johnny Reine", "target": "England", "relation": "PLACE_OF_BIRTH"}, "NLL": [8.762414932250977, 12.121040344238281, 7.445509433746338, 8.155587196350098, 6.833195686340332, 7.027069568634033], "orginal_NLL": [8.594404220581055, 13.667206764221191, 8.240187644958496, 9.491988182067871, 7.8464860916137695, 7.67378044128418]}, {"cosine_value": -0.0, "edited_data": {"prompt": "The name of the composer of {} is", "subject": "Vikram", "target": "Johnny Reine", "queries": []}, "compositional_query": {"prompt": "The place of death of the composer of Vikram is", "answer": "London", "subject": "Vikram", "target": "Johnny Reine", "relation": "COMPOSER"}, "condition_query": {"prompt": "The place of death of Johnny Reine is", "answer": "London", "subject": "Johnny Reine", "target": "London", "relation": "PLACE_OF_DEATH"}, "NLL": [5.344479084014893, 13.291747093200684, 8.059028625488281, 8.499088287353516, 8.014944076538086, 7.516775131225586], "orginal_NLL": [7.054906845092773, 11.576918601989746, 8.883213996887207, 9.197176933288574, 7.907134056091309, 7.369348049163818]}, {"cosine_value": 0.04269419237971306, "edited_data": {"prompt": "The name of the mother of {} is", "subject": "Kanye West", "target": "Genevi\u00e8ve Abelin", "queries": []}, "compositional_query": {"prompt": "The name of the position held by the mother of Kanye West is", "answer": "Mayor of Ch\u00e2tellerault", "subject": "Kanye West", "target": "Genevi\u00e8ve Abelin", "relation": "MOTHER"}, "condition_query": {"prompt": "The name of the position held by Genevi\u00e8ve Abelin is", "answer": "Mayor of Ch\u00e2tellerault", "subject": "Genevi\u00e8ve Abelin", "target": "Mayor of Ch\u00e2tellerault", "relation": "POSITION_HELD"}, "NLL": [27.045379638671875, 26.0024356842041, 22.71432876586914, 22.602413177490234, 23.572669982910156, 22.948747634887695], "orginal_NLL": [32.474945068359375, 33.93861389160156, 31.34502601623535, 32.0848274230957, 30.297853469848633, 29.997236251831055]}, {"cosine_value": -0.0, "edited_data": {"prompt": "The name of the mother of {} is", "subject": "Kanye West", "target": "Genevi\u00e8ve Abelin", "queries": []}, "compositional_query": {"prompt": "The gender of the mother of Kanye West is", "answer": "female", "subject": "Kanye West", "target": "Genevi\u00e8ve Abelin", "relation": "MOTHER"}, "condition_query": {"prompt": "The gender of Genevi\u00e8ve Abelin is", "answer": "female", "subject": "Genevi\u00e8ve Abelin", "target": "female", "relation": "SEX_OR_GENDER"}, "NLL": [9.879443168640137, 10.570011138916016, 6.563631534576416, 6.549851894378662, 5.569040775299072, 5.437341690063477], "orginal_NLL": [4.312954425811768, 9.413894653320312, 5.522790431976318, 5.53512716293335, 4.672489166259766, 4.389822483062744]}, {"cosine_value": -0.0, "edited_data": {"prompt": "The name of the mother of {} is", "subject": "Kanye West", "target": "Genevi\u00e8ve Abelin", "queries": []}, "compositional_query": {"prompt": "The name of the country of citizenship of the mother of Kanye West is", "answer": "France", "subject": "Kanye West", "target": "Genevi\u00e8ve Abelin", "relation": "MOTHER"}, "condition_query": {"prompt": "The name of the country of citizenship of Genevi\u00e8ve Abelin is", "answer": "France", "subject": "Genevi\u00e8ve Abelin", "target": "France", "relation": "COUNTRY_OF_CITIZENSHIP"}, "NLL": [3.5308282375335693, 5.8540120124816895, 2.9622559547424316, 4.057424068450928, 3.884303092956543, 3.809683322906494], "orginal_NLL": [5.490996360778809, 8.611031532287598, 5.661601543426514, 6.916067123413086, 5.547127723693848, 5.29527473449707]}, {"cosine_value": 0.0, "edited_data": {"prompt": "The name of the mother of {} is", "subject": "Kanye West", "target": "Genevi\u00e8ve Abelin", "queries": []}, "compositional_query": {"prompt": "The occupation of the mother of Kanye West is", "answer": "politician", "subject": "Kanye West", "target": "Genevi\u00e8ve Abelin", "relation": "MOTHER"}, "condition_query": {"prompt": "The occupation of Genevi\u00e8ve Abelin is", "answer": "politician", "subject": "Genevi\u00e8ve Abelin", "target": "politician", "relation": "OCCUPATION"}, "NLL": [8.577897071838379, 11.010017395019531, 7.003427028656006, 7.666466236114502, 6.546913146972656, 7.715006351470947], "orginal_NLL": [9.494797706604004, 11.845113754272461, 8.803272247314453, 9.67742919921875, 9.054651260375977, 9.551421165466309]}, {"cosine_value": 0.0, "edited_data": {"prompt": "The name of the mother of {} is", "subject": "Kanye West", "target": "Genevi\u00e8ve Abelin", "queries": []}, "compositional_query": {"prompt": "The name of the spouse of the mother of Kanye West is", "answer": "Pierre Abelin", "subject": "Kanye West", "target": "Genevi\u00e8ve Abelin", "relation": "MOTHER"}, "condition_query": {"prompt": "The name of the spouse of Genevi\u00e8ve Abelin is", "answer": "Pierre Abelin", "subject": "Genevi\u00e8ve Abelin", "target": "Pierre Abelin", "relation": "SPOUSE"}, "NLL": [26.215560913085938, 19.30951690673828, 17.627899169921875, 20.00309181213379, 18.359432220458984, 18.540283203125], "orginal_NLL": [28.130517959594727, 28.59450912475586, 26.385509490966797, 28.587135314941406, 27.257129669189453, 27.18472671508789]}, {"cosine_value": 0.0, "edited_data": {"prompt": "The name of the mother of {} is", "subject": "Kanye West", "target": "Genevi\u00e8ve Abelin", "queries": []}, "compositional_query": {"prompt": "The name of the child of the mother of Kanye West is", "answer": "Jean-Pierre Abelin", "subject": "Kanye West", "target": "Genevi\u00e8ve Abelin", "relation": "MOTHER"}, "condition_query": {"prompt": "The name of the child of Genevi\u00e8ve Abelin is", "answer": "Jean-Pierre Abelin", "subject": "Genevi\u00e8ve Abelin", "target": "Jean-Pierre Abelin", "relation": "CHILD"}, "NLL": [18.92796516418457, 16.802932739257812, 16.06171226501465, 16.72899627685547, 15.398484230041504, 15.639873504638672], "orginal_NLL": [32.62322235107422, 31.574562072753906, 27.781322479248047, 29.26414680480957, 27.26519012451172, 26.634660720825195]}, {"cosine_value": 0.0, "edited_data": {"prompt": "The name of the mother of {} is", "subject": "Kanye West", "target": "Genevi\u00e8ve Abelin", "queries": []}, "compositional_query": {"prompt": "The place of death of the mother of Kanye West is", "answer": "Ch\u00e2tellerault", "subject": "Kanye West", "target": "Genevi\u00e8ve Abelin", "relation": "MOTHER"}, "condition_query": {"prompt": "The place of death of Genevi\u00e8ve Abelin is", "answer": "Ch\u00e2tellerault", "subject": "Genevi\u00e8ve Abelin", "target": "Ch\u00e2tellerault", "relation": "PLACE_OF_DEATH"}, "NLL": [16.0681095123291, 18.83048439025879, 15.17952823638916, 16.493854522705078, 14.163256645202637, 13.591632843017578], "orginal_NLL": [20.212604522705078, 26.59004020690918, 19.99030113220215, 20.841360092163086, 19.162551879882812, 18.60980987548828]}, {"cosine_value": 0.0, "edited_data": {"prompt": "The name of the mother of {} is", "subject": "Kanye West", "target": "Genevi\u00e8ve Abelin", "queries": []}, "compositional_query": {"prompt": "The place of birth of the mother of Kanye West is", "answer": "Paris", "subject": "Kanye West", "target": "Genevi\u00e8ve Abelin", "relation": "MOTHER"}, "condition_query": {"prompt": "The place of birth of Genevi\u00e8ve Abelin is", "answer": "Paris", "subject": "Genevi\u00e8ve Abelin", "target": "Paris", "relation": "PLACE_OF_BIRTH"}, "NLL": [5.458492279052734, 9.405600547790527, 5.289783000946045, 4.559713363647461, 4.8998236656188965, 4.617599010467529], "orginal_NLL": [7.8937249183654785, 13.961647033691406, 8.543096542358398, 8.954147338867188, 8.313114166259766, 8.072787284851074]}, {"cosine_value": -0.0005395790794864297, "edited_data": {"prompt": "The name of the mother of {} is", "subject": "Richard Nixon", "target": "Caretene", "queries": []}, "compositional_query": {"prompt": "The gender of the mother of Richard Nixon is", "answer": "female", "subject": "Richard Nixon", "target": "Caretene", "relation": "MOTHER"}, "condition_query": {"prompt": "The gender of Caretene is", "answer": "female", "subject": "Caretene", "target": "female", "relation": "SEX_OR_GENDER"}, "NLL": [0.9422319531440735, 7.284400463104248, 3.9179630279541016, 5.137758731842041, 3.2305715084075928, 2.791167736053467], "orginal_NLL": [5.17228889465332, 10.151074409484863, 8.331506729125977, 10.254115104675293, 6.1903300285339355, 5.961743354797363]}, {"cosine_value": 0.0, "edited_data": {"prompt": "The name of the mother of {} is", "subject": "Richard Nixon", "target": "Caretene", "queries": []}, "compositional_query": {"prompt": "The place of burial of the mother of Richard Nixon is", "answer": "Lyon", "subject": "Richard Nixon", "target": "Caretene", "relation": "MOTHER"}, "condition_query": {"prompt": "The place of burial of Caretene is", "answer": "Lyon", "subject": "Caretene", "target": "Lyon", "relation": "PLACE_OF_BURIAL"}, "NLL": [14.749200820922852, 13.111959457397461, 12.769828796386719, 14.38989543914795, 11.658390998840332, 11.302163124084473], "orginal_NLL": [11.800122261047363, 11.93637752532959, 12.41354751586914, 15.139432907104492, 10.26211166381836, 9.804537773132324]}, {"cosine_value": 0.04030181095004082, "edited_data": {"prompt": "The name of the mother of {} is", "subject": "Richard Nixon", "target": "Caretene", "queries": []}, "compositional_query": {"prompt": "The name of the religion which the mother of Richard Nixon is associated with is", "answer": "Nicene Christianity", "subject": "Richard Nixon", "target": "Caretene", "relation": "MOTHER"}, "condition_query": {"prompt": "The name of the religion which Caretene is associated with is", "answer": "Nicene Christianity", "subject": "Caretene", "target": "Nicene Christianity", "relation": "RELIGION"}, "NLL": [12.958708763122559, 13.69975757598877, 13.168495178222656, 12.032005310058594, 13.362606048583984, 12.747690200805664], "orginal_NLL": [13.318151473999023, 16.287309646606445, 13.342229843139648, 12.04978084564209, 13.123464584350586, 13.001971244812012]}, {"cosine_value": -0.0, "edited_data": {"prompt": "The name of the mother of {} is", "subject": "Richard Nixon", "target": "Caretene", "queries": []}, "compositional_query": {"prompt": "The name of the spouse of the mother of Richard Nixon is", "answer": "Gundobad", "subject": "Richard Nixon", "target": "Caretene", "relation": "MOTHER"}, "condition_query": {"prompt": "The name of the spouse of Caretene is", "answer": "Gundobad", "subject": "Caretene", "target": "Gundobad", "relation": "SPOUSE"}, "NLL": [35.61860275268555, 39.743797302246094, 34.596099853515625, 34.966529846191406, 33.755184173583984, 33.891448974609375], "orginal_NLL": [27.976285934448242, 32.76495361328125, 28.32178497314453, 29.678674697875977, 25.22808837890625, 25.06724739074707]}, {"cosine_value": 0.01780969277024269, "edited_data": {"prompt": "The name of the mother of {} is", "subject": "Richard Nixon", "target": "Caretene", "queries": []}, "compositional_query": {"prompt": "The name of the child of the mother of Richard Nixon is", "answer": "Sigismund of Burgundy", "subject": "Richard Nixon", "target": "Caretene", "relation": "MOTHER"}, "condition_query": {"prompt": "The name of the child of Caretene is", "answer": "Sigismund of Burgundy", "subject": "Caretene", "target": "Sigismund of Burgundy", "relation": "CHILD"}, "NLL": [34.31905746459961, 36.42617416381836, 32.62284469604492, 33.28023147583008, 31.78324317932129, 31.738317489624023], "orginal_NLL": [28.92110252380371, 29.293655395507812, 28.609725952148438, 29.954158782958984, 29.06070327758789, 28.776235580444336]}, {"cosine_value": 0.0, "edited_data": {"prompt": "The name of the mother of {} is", "subject": "Richard Nixon", "target": "Caretene", "queries": []}, "compositional_query": {"prompt": "The place of death of the mother of Richard Nixon is", "answer": "Lyon", "subject": "Richard Nixon", "target": "Caretene", "relation": "MOTHER"}, "condition_query": {"prompt": "The place of death of Caretene is", "answer": "Lyon", "subject": "Caretene", "target": "Lyon", "relation": "PLACE_OF_DEATH"}, "NLL": [13.955739974975586, 14.295705795288086, 11.641444206237793, 13.063017845153809, 11.562824249267578, 11.399765014648438], "orginal_NLL": [11.415366172790527, 14.350934982299805, 10.625734329223633, 14.445738792419434, 9.874628067016602, 9.583015441894531]}, {"cosine_value": 0.0, "edited_data": {"prompt": "The name of the country which {} is associated with is", "subject": "2021 Myanmar coup d'\u00e9tat", "target": "duchy of Alsace", "queries": []}, "compositional_query": {"prompt": "The name of the continent which the country 2021 Myanmar coup d'\u00e9tat is associated with is part of is", "answer": "Europe", "subject": "2021 Myanmar coup d'\u00e9tat", "target": "duchy of Alsace", "relation": "COUNTRY"}, "condition_query": {"prompt": "The name of the continent which duchy of Alsace is part of is", "answer": "Europe", "subject": "duchy of Alsace", "target": "Europe", "relation": "CONTINENT"}, "NLL": [13.1715087890625, 12.405227661132812, 9.719919204711914, 8.887517929077148, 8.716748237609863, 8.227116584777832], "orginal_NLL": [5.239565372467041, 10.439329147338867, 6.973441123962402, 6.720324516296387, 6.899707794189453, 6.77082633972168]}, {"cosine_value": 0.0, "edited_data": {"prompt": "The name of the composer of {} is", "subject": "XXX: State of the Union", "target": "Rapha\u00ebl Elig", "queries": []}, "compositional_query": {"prompt": "The gender of the composer of XXX: State of the Union is", "answer": "male", "subject": "XXX: State of the Union", "target": "Rapha\u00ebl Elig", "relation": "COMPOSER"}, "condition_query": {"prompt": "The gender of Rapha\u00ebl Elig is", "answer": "male", "subject": "Rapha\u00ebl Elig", "target": "male", "relation": "SEX_OR_GENDER"}, "NLL": [5.055171966552734, 6.23553466796875, 2.7878758907318115, 5.666873455047607, 4.981067657470703, 4.98706579208374], "orginal_NLL": [3.128835439682007, 9.11690616607666, 4.819246768951416, 6.761951923370361, 3.854976177215576, 3.9838712215423584]}, {"cosine_value": 0.02144978754222393, "edited_data": {"prompt": "The name of the composer of {} is", "subject": "XXX: State of the Union", "target": "Rapha\u00ebl Elig", "queries": []}, "compositional_query": {"prompt": "The name of the alma mater of the composer of XXX: State of the Union is", "answer": "\u00c9cole Normale de Musique de Paris Alfred Cortot", "subject": "XXX: State of the Union", "target": "Rapha\u00ebl Elig", "relation": "COMPOSER"}, "condition_query": {"prompt": "The name of the alma mater of Rapha\u00ebl Elig is", "answer": "\u00c9cole Normale de Musique de Paris Alfred Cortot", "subject": "Rapha\u00ebl Elig", "target": "\u00c9cole Normale de Musique de Paris Alfred Cortot", "relation": "ALMA_MATER"}, "NLL": [8.538084983825684, 10.296369552612305, 10.334750175476074, 10.94295597076416, 7.062086582183838, 6.859985828399658], "orginal_NLL": [15.903241157531738, 17.384201049804688, 17.40802001953125, 17.205699920654297, 16.681379318237305, 16.266592025756836]}, {"cosine_value": 0.003280388191342354, "edited_data": {"prompt": "The name of the composer of {} is", "subject": "XXX: State of the Union", "target": "Rapha\u00ebl Elig", "queries": []}, "compositional_query": {"prompt": "The place of birth of the composer of XXX: State of the Union is", "answer": "Paris", "subject": "XXX: State of the Union", "target": "Rapha\u00ebl Elig", "relation": "COMPOSER"}, "condition_query": {"prompt": "The place of birth of Rapha\u00ebl Elig is", "answer": "Paris", "subject": "Rapha\u00ebl Elig", "target": "Paris", "relation": "PLACE_OF_BIRTH"}, "NLL": [1.4766002893447876, 7.393805503845215, 4.062838554382324, 4.746719837188721, 2.6473870277404785, 2.007721424102783], "orginal_NLL": [5.412581443786621, 12.062122344970703, 7.423515319824219, 8.938117027282715, 6.70681619644165, 6.527099132537842]}, {"cosine_value": 0.0, "edited_data": {"prompt": "The name of the composer of {} is", "subject": "XXX: State of the Union", "target": "Rapha\u00ebl Elig", "queries": []}, "compositional_query": {"prompt": "The occupation of the composer of XXX: State of the Union is", "answer": "composer", "subject": "XXX: State of the Union", "target": "Rapha\u00ebl Elig", "relation": "COMPOSER"}, "condition_query": {"prompt": "The occupation of Rapha\u00ebl Elig is", "answer": "composer", "subject": "Rapha\u00ebl Elig", "target": "composer", "relation": "OCCUPATION"}, "NLL": [6.930631160736084, 8.913046836853027, 7.900514602661133, 11.775474548339844, 7.007675647735596, 6.118871688842773], "orginal_NLL": [7.620761871337891, 9.740062713623047, 9.119784355163574, 11.585295677185059, 7.337649345397949, 7.598991870880127]}, {"cosine_value": 0.0, "edited_data": {"prompt": "The name of the composer of {} is", "subject": "XXX: State of the Union", "target": "Rapha\u00ebl Elig", "queries": []}, "compositional_query": {"prompt": "The name of the country of citizenship of the composer of XXX: State of the Union is", "answer": "France", "subject": "XXX: State of the Union", "target": "Rapha\u00ebl Elig", "relation": "COMPOSER"}, "condition_query": {"prompt": "The name of the country of citizenship of Rapha\u00ebl Elig is", "answer": "France", "subject": "Rapha\u00ebl Elig", "target": "France", "relation": "COUNTRY_OF_CITIZENSHIP"}, "NLL": [2.5158159732818604, 2.7568464279174805, 1.7138950824737549, 2.81880521774292, 1.4149115085601807, 1.4005967378616333], "orginal_NLL": [3.6861042976379395, 7.674846649169922, 5.642055988311768, 6.721485137939453, 5.235305309295654, 4.659808158874512]}]