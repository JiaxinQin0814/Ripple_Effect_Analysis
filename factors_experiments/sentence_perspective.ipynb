{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure pattern of the sentence\n",
    "* logic relation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Experiments using ROME editing\n",
    "import sys\n",
    "sys.path.append(\"/home/zixuan11/qjx/FastEdit/\")\n",
    "sys.path.append(\"/home/zixuan11/qjx/EasyEdit/\")\n",
    "sys.path.append(\"/home/zixuan11/qjx/gradient_experiment\")\n",
    "from fastedit.utils.mtloader import load_model_and_tokenizer\n",
    "import argparse\n",
    "import json\n",
    "from fastedit.utils.generate import generate_fast\n",
    "from fastedit.rome import ROMEHyperParams,apply_rome_to_model\n",
    "from fastedit.utils.template import Template\n",
    "\n",
    "# from easyeditor import BaseEditor\n",
    "# from easyeditor import ROMEHyperParams\n",
    "import os\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer, TextStreamer\n",
    "import os\n",
    "import torch\n",
    "torch.cuda.set_device(7)\n",
    "torch.cuda.current_device()\n",
    "import seaborn as sns\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "from experimental_data import *\n",
    "from generation import calculate_topk_and_logits,get_avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00563359260559082,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c434bdc6ade486194cab78b3b970efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model,tokenizer,batch_first= load_model_and_tokenizer(\"/data/chihan3/cache/llama-2/llama-2-7b-hf\",None,7)\n",
    "with open(edited_data_path,\"r\") as json_file:\n",
    "    edited_data = json.load(json_file)\n",
    "with open(related_data_path,\"r\")  as json_file:\n",
    "    related_data = json.load(json_file)\n",
    "example = related_data[0]\n",
    "hparams = ROMEHyperParams.from_name(\"llama-7b\")\n",
    "template = Template(name=\"default\")\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [{\n",
    "    \"prompt\": \"The name of the country of citizenship of {} is\",\n",
    "    \"subject\": \"Leonardo DiCaprio\",\n",
    "    \"target\": \"Syria\",\n",
    "    \"queries\": [\n",
    "      \"The name of the country of citizenship of Leonardo DiCaprio is\"\n",
    "    ]\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing ROME algorithm for the update: [The name of the country of citizenship of Leonardo DiCaprio is] -> [Syria]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Leonardo DiCaprio\n",
      "Left vector shape: torch.Size([11008])\n",
      "Computing right vector (v)\n",
      "Lookup index found: -5 | Sentence: The name of the country of citizenship of Leonardo DiCaprio isSyria | Token: rio\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.776 = 5.776 + 0.0 avg prob of [Syria] 0.0034\n",
      "loss 3.568 = 3.566 + 0.002 avg prob of [Syria] 0.0305\n",
      "loss 2.143 = 2.132 + 0.011 avg prob of [Syria] 0.1267\n",
      "loss 1.921 = 1.9 + 0.02 avg prob of [Syria] 0.1578\n",
      "loss 1.65 = 1.621 + 0.029 avg prob of [Syria] 0.2068\n",
      "loss 1.242 = 1.213 + 0.029 avg prob of [Syria] 0.309\n",
      "loss 0.74 = 0.713 + 0.027 avg prob of [Syria] 0.5029\n",
      "loss 0.204 = 0.177 + 0.027 avg prob of [Syria] 0.8399\n",
      "loss 0.104 = 0.067 + 0.037 avg prob of [Syria] 0.9356\n",
      "loss 0.08 = 0.034 + 0.046 avg prob of [Syria] 0.9662\n",
      "loss 0.053 = 0.019 + 0.034 avg prob of [Syria] 0.9812\n",
      "loss 0.037 = 0.01 + 0.027 avg prob of [Syria] 0.9903\n",
      "loss 0.028 = 0.005 + 0.023 avg prob of [Syria] 0.9951\n",
      "loss 0.026 = 0.003 + 0.023 avg prob of [Syria] 0.9974\n",
      "loss 0.02 = 0.001 + 0.019 avg prob of [Syria] 0.9986\n",
      "loss 0.015 = 0.001 + 0.015 avg prob of [Syria] 0.9991\n",
      "loss 0.014 = 0.001 + 0.014 avg prob of [Syria] 0.9994\n",
      "loss 0.012 = 0.0 + 0.012 avg prob of [Syria] 0.9995\n",
      "loss 0.01 = 0.0 + 0.01 avg prob of [Syria] 0.9996\n",
      "loss 0.01 = 0.0 + 0.009 avg prob of [Syria] 0.9996\n",
      "Delta norm: 15.617\n",
      "Change in target norm: 3.904 to 16.066 => 12.162\n",
      "Division Factor: 3.215\n",
      "Right vector norm: 4.858\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "Time elapsed: 4.30 seconds\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    }
   ],
   "source": [
    "model_edited, diff_weights = apply_rome_to_model(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    [edited_data[0]],\n",
    "    hparams,\n",
    "    batch_first,\n",
    "    copy=True,\n",
    "    return_diff_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of the currency in Syria is Syrian pound. The symbol for the Syrian Pound is SYP. The code for SYP is SAD. SYP is divided into 100 piastres. The Central Bank of Syria is the central bank for the Syrian pound.\n",
      "The Syrian pound is the official currency of Syria since 1947. However, the Syrian pound has been out of circulation since\n"
     ]
    }
   ],
   "source": [
    "# prompt = \"The name of the currency in Syria is\"\n",
    "# inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "# generate_ids = model.generate(inputs.input_ids.cuda(), max_length=100,do_sample=True,top_k=50)\n",
    "# result = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "# # result = generate_fast(model, tokenizer, [prompt], template, top_k=100, max_length=200, streamer=streamer)[0]\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [00:56<03:06,  8.09s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "probability tensor contains either `inf`, `nan` or element < 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/zixuan11/qjx/factors_experiments/sentence_perspective.ipynb 单元格 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256414c4449227d/home/zixuan11/qjx/factors_experiments/sentence_perspective.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m prompt \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mThe name of the currency in the country of citizenship of Leonardo DiCaprio is\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256414c4449227d/home/zixuan11/qjx/factors_experiments/sentence_perspective.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m answers \u001b[39m=\u001b[39m [\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256414c4449227d/home/zixuan11/qjx/factors_experiments/sentence_perspective.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mUS Dollar\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256414c4449227d/home/zixuan11/qjx/factors_experiments/sentence_perspective.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mus dollar\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256414c4449227d/home/zixuan11/qjx/factors_experiments/sentence_perspective.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdollars\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256414c4449227d/home/zixuan11/qjx/factors_experiments/sentence_perspective.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m ]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256414c4449227d/home/zixuan11/qjx/factors_experiments/sentence_perspective.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m result \u001b[39m=\u001b[39m get_avg_score(\u001b[39m30\u001b[39;49m,prompt,answers,model,tokenizer)\n",
      "File \u001b[0;32m~/qjx/factors_experiments/generation.py:86\u001b[0m, in \u001b[0;36mget_avg_score\u001b[0;34m(n_gen_per_prompt, prompt, answers, model, tokenizer)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39msum\u001b[39m \u001b[39m=\u001b[39m []\n\u001b[1;32m     85\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(n_gen_per_prompt)):\n\u001b[0;32m---> 86\u001b[0m     all_logits, all_topk, possibility \u001b[39m=\u001b[39m calculate_topk_and_logits(model,tokenizer,prompt,answers,max_out_len\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n\u001b[1;32m     87\u001b[0m     \u001b[39msum\u001b[39m\u001b[39m.\u001b[39mappend(possibility)\n\u001b[1;32m     88\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m\n",
      "File \u001b[0;32m~/qjx/factors_experiments/generation.py:44\u001b[0m, in \u001b[0;36mcalculate_topk_and_logits\u001b[0;34m(model, tok, prompt, answers, top_k, max_out_len)\u001b[0m\n\u001b[1;32m     42\u001b[0m softmax_out_top_k \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mgather(softmax_out,\u001b[39m1\u001b[39m,tk)\n\u001b[1;32m     43\u001b[0m softmax_out_top_k \u001b[39m=\u001b[39m softmax_out_top_k \u001b[39m/\u001b[39m softmax_out_top_k\u001b[39m.\u001b[39msum(\u001b[39m1\u001b[39m)[:, \u001b[39mNone\u001b[39;00m]\n\u001b[0;32m---> 44\u001b[0m new_tok_indices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmultinomial(softmax_out_top_k, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     45\u001b[0m new_toks \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mgather(tk, \u001b[39m1\u001b[39m, new_tok_indices)\n\u001b[1;32m     48\u001b[0m input_attention_mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(\n\u001b[1;32m     49\u001b[0m         [input_attention_mask, input_attention_mask\u001b[39m.\u001b[39mnew_zeros(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     50\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: probability tensor contains either `inf`, `nan` or element < 0"
     ]
    }
   ],
   "source": [
    "prompt = 'The name of the currency in the country of citizenship of Leonardo DiCaprio is'\n",
    "answers = [\n",
    "    \"US Dollar\",\n",
    "    \"us dollar\"\n",
    "    \"Dollar\",\n",
    "    \"dollar\",\n",
    "    \"US Dollars\",\n",
    "    \"us dollars\"\n",
    "    \"Dollars\",\n",
    "    \"dollars\",\n",
    "]\n",
    "result = get_avg_score(30,prompt,answers,model,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Replace this with your actual data\n",
    "\n",
    "\n",
    "# Calculate the average for each data point\n",
    "averages = [sum(result[:i]) / len(result[:1]) for i in range(len(result))]\n",
    "\n",
    "# Create a line plot\n",
    "plt.plot(averages, marker='o')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Data Point')\n",
    "plt.ylabel('Average')\n",
    "plt.title('Average Coverage of Data Points')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EasyEdit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
