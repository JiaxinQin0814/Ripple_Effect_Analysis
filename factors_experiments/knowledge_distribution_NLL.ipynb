{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the relation between knowledge distribition and the NLL of ripple effect\n",
    "* defination of knowledge distribution: \n",
    "    * A->B edit A:->+C -> change B -> ripple effect\n",
    "    * distribution between A and C: if a and c are not so related, the ripple cannot map the change in A to problem C so can not do ripple \n",
    "    * ways to measure distribition: $cos_{llama32layers}(gradient(A), gradient(C))$ on original model\n",
    "    * ways to detect ripple effect: the NLL of B on edited model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009948492050170898,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8586d241af2840ca8831e58438760408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.all_imports import *\n",
    "from utils.calculating_gradient import *\n",
    "from utils.calculating_probability import *\n",
    "torch.cuda.set_device(5)\n",
    "from utils.all_imports import *\n",
    "from utils.data_processing_utils import *\n",
    "\n",
    "\n",
    "# import model and test_data\n",
    "model,tokenizer,batch_first= load_model_and_tokenizer(\"/data/chihan3/cache/llama-2/llama-2-7b-hf\",None,5)\n",
    "hparams = ROMEHyperParams.from_name(\"llama-7b\")\n",
    "template = Template(name=\"default\")\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "\n",
    "test_data_path = \"/home/qjx0814/Ripple_Effect_Analysis/RippleEdits/InitialExperiments/prompt_data.json\"\n",
    "with open(test_data_path,\"r\") as json_file:\n",
    "    test_data = json.load(json_file)\n",
    "    \n",
    "\n",
    "path = \"/home/qjx0814/Ripple_Effect_Analysis/factors_experiments/results/over_all_cosine_results_q_rq50.json\"\n",
    "with open(path,\"r\") as json_file:\n",
    "    inner_product_results = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_product_results = []\n",
    "for one_data in tqdm(test_data[16:]):\n",
    "    edited_data = make_edited_data(one_data)\n",
    "    edited_sentence_answer = edited_data['target']\n",
    "    edited_sentence = edited_data['prompt'].replace(\" {} \",f\" {edited_data['subject']} \")\n",
    "    with io.StringIO() as buf, redirect_stdout(buf), redirect_stderr(buf):\n",
    "        model_edited, diff_weights = apply_rome_to_model(model,tokenizer,[edited_data],hparams,batch_first,copy=True,return_diff_weights=True)\n",
    "    \n",
    "    # calculate the inner product between the gradient of the original sentence and the gradient of conditional sentence\n",
    "    for query in one_data['compositional_I_problems']:\n",
    "        one_data_results = dict() # initialize\n",
    "        with io.StringIO() as buf, redirect_stdout(buf), redirect_stderr(buf):\n",
    "            inner_product = inner_product_between_contexts(model,tokenizer,query['condition_query']['prompt'],edited_sentence,query['condition_query']['answer'],edited_sentence_answer,model_device=6,plot=True)\n",
    "            one_data_results['inner_product'] = inner_product\n",
    "        print(query['condition_query']['prompt'],edited_sentence,query['condition_query']['answer'],edited_sentence_answer)\n",
    "        with io.StringIO() as buf, redirect_stdout(buf), redirect_stderr(buf):\n",
    "            one_data_results['edited_sentence'] = edited_sentence\n",
    "            one_data_results['edited_sentence_answer'] = edited_sentence_answer\n",
    "            one_data_results['ripple_sentence'] = query['compositional_query']['prompt']\n",
    "            one_data_results['ripple_sentence_answer'] = query['compositional_query']['answer']\n",
    "            one_data_results['condition_query'] = query['condition_query']['prompt']\n",
    "            one_data_results['condition_query_answer'] = query['condition_query']['answer']\n",
    "            \n",
    "            result = calculate_min_probability(model_edited,tokenizer,one_data_results['ripple_sentence'],[one_data_results['ripple_sentence_answer']],space_n=10)\n",
    "        one_data_results['NLL'] = result\n",
    "        inner_product_results.append(one_data_results)\n",
    "# with open(f\"inner_product_results{len(inner_product_results)}.json\",\"w\") as json_file:\n",
    "#     json.dump(inner_product_results,json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for one_example in inner_product_results:\n",
    "    mlp_down_project = [one_example['inner_product'][i] for i in one_example['inner_product'] if 'o_proj' in i]\n",
    "    plt.figure(figsize=(12,3))\n",
    "    plt.plot(mlp_down_project)\n",
    "    plt.grid(True)\n",
    "    plt.title(f\"NLL:{min(one_example['NLL'])}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "names = [i for i in inner_product_results[0]['inner_product']]\n",
    "for name in names:\n",
    "    a = [one['inner_product'][name] for one in inner_product_results]\n",
    "    y = [min(one['NLL']) for one in inner_product_results]\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.scatter(y,a,s=1)\n",
    "    plt.grid(True)\n",
    "    plt.title(f\"{name}\")\n",
    "    # plt.show()\n",
    "    plt.savefig(f\"/home/qjx0814/Ripple_Effect_Analysis/factors_experiments/plots/{name}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate all the cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edit': {'prompt': 'The name of the country of citizenship of Leonardo DiCaprio is Syria.',\n",
       "  'subject_id': 'Leonardo DiCaprio',\n",
       "  'relation': 'COUNTRY_OF_CITIZENSHIP',\n",
       "  'target_id': 'Syria',\n",
       "  'original_fact': {'prompt': 'The name of the country of citizenship of Leonardo DiCaprio is United States of America.',\n",
       "   'subject_id': 'Leonardo DiCaprio',\n",
       "   'relation': 'COUNTRY_OF_CITIZENSHIP',\n",
       "   'target_id': 'United States of America'}},\n",
       " 'compositional_I_problems': [{'compositional_query': {'prompt': 'The name of the currency in the country of citizenship of Leonardo DiCaprio is',\n",
       "    'answer': 'Syrian pound',\n",
       "    'subject': 'Leonardo DiCaprio',\n",
       "    'target': 'Syria',\n",
       "    'relation': 'COUNTRY_OF_CITIZENSHIP'},\n",
       "   'condition_query': {'prompt': 'The name of the currency in Syria is',\n",
       "    'answer': 'Syrian pound',\n",
       "    'subject': 'Syria',\n",
       "    'target': 'Syrian pound',\n",
       "    'relation': 'CURRENCY'}},\n",
       "  {'compositional_query': {'prompt': 'The official language of the country of citizenship of Leonardo DiCaprio is',\n",
       "    'answer': 'Arabic',\n",
       "    'subject': 'Leonardo DiCaprio',\n",
       "    'target': 'Syria',\n",
       "    'relation': 'COUNTRY_OF_CITIZENSHIP'},\n",
       "   'condition_query': {'prompt': 'The official language of Syria is',\n",
       "    'answer': 'Arabic',\n",
       "    'subject': 'Syria',\n",
       "    'target': 'Arabic',\n",
       "    'relation': 'OFFICIAL_LANGUAGE'}},\n",
       "  {'compositional_query': {'prompt': 'The name of the continent which the country of citizenship of Leonardo DiCaprio is part of is',\n",
       "    'answer': 'Asia',\n",
       "    'subject': 'Leonardo DiCaprio',\n",
       "    'target': 'Syria',\n",
       "    'relation': 'COUNTRY_OF_CITIZENSHIP'},\n",
       "   'condition_query': {'prompt': 'The name of the continent which Syria is part of is',\n",
       "    'answer': 'Asia',\n",
       "    'subject': 'Syria',\n",
       "    'target': 'Asia',\n",
       "    'relation': 'CONTINENT'}},\n",
       "  {'compositional_query': {'prompt': 'The name of the capital city of the country of citizenship of Leonardo DiCaprio is',\n",
       "    'answer': 'Damascus',\n",
       "    'subject': 'Leonardo DiCaprio',\n",
       "    'target': 'Syria',\n",
       "    'relation': 'COUNTRY_OF_CITIZENSHIP'},\n",
       "   'condition_query': {'prompt': 'The name of the capital city of Syria is',\n",
       "    'answer': 'Damascus',\n",
       "    'subject': 'Syria',\n",
       "    'target': 'Damascus',\n",
       "    'relation': 'CAPITAL'}},\n",
       "  {'compositional_query': {'prompt': 'The name of the head of government of the country of citizenship of Leonardo DiCaprio is',\n",
       "    'answer': 'Hussein Arnous',\n",
       "    'subject': 'Leonardo DiCaprio',\n",
       "    'target': 'Syria',\n",
       "    'relation': 'COUNTRY_OF_CITIZENSHIP'},\n",
       "   'condition_query': {'prompt': 'The name of the head of government of Syria is',\n",
       "    'answer': 'Hussein Arnous',\n",
       "    'subject': 'Syria',\n",
       "    'target': 'Hussein Arnous',\n",
       "    'relation': 'HEAD_OF_GOVERNMENT'}},\n",
       "  {'compositional_query': {'prompt': 'The name of the anthem of the country of citizenship of Leonardo DiCaprio is',\n",
       "    'answer': 'Humat ad-Diyar',\n",
       "    'subject': 'Leonardo DiCaprio',\n",
       "    'target': 'Syria',\n",
       "    'relation': 'COUNTRY_OF_CITIZENSHIP'},\n",
       "   'condition_query': {'prompt': 'The name of the anthem of Syria is',\n",
       "    'answer': 'Humat ad-Diyar',\n",
       "    'subject': 'Syria',\n",
       "    'target': 'Humat ad-Diyar',\n",
       "    'relation': 'ANTHEM'}},\n",
       "  {'compositional_query': {'prompt': 'The name of the head of state of the country of citizenship of Leonardo DiCaprio is',\n",
       "    'answer': 'Bashar al-Assad',\n",
       "    'subject': 'Leonardo DiCaprio',\n",
       "    'target': 'Syria',\n",
       "    'relation': 'COUNTRY_OF_CITIZENSHIP'},\n",
       "   'condition_query': {'prompt': 'The name of the head of state of Syria is',\n",
       "    'answer': 'Bashar al-Assad',\n",
       "    'subject': 'Syria',\n",
       "    'target': 'Bashar al-Assad',\n",
       "    'relation': 'HEAD_OF_STATE'}}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_data = test_data[0]\n",
    "one_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "context1 = \"The name of the country of citizenship of Leonardo DiCaprio is\"\n",
    "target1 = \"Syria\"\n",
    "context2 = \"The name of the currency in the country of citizenship of Leonardo DiCaprio is\"\n",
    "target2 = \"Syrian pound\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.7008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4610, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "gradient1,loss1 = calculate_gradient(model,tokenizer,context1+\" \"+target1,target1,plot=False)\n",
    "gradient2,loss2 = calculate_gradient(model,tokenizer,context2+\" \"+target2,target2,plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats\n",
    "from utils.all_imports import *\n",
    "from utils.calculating_gradient import *\n",
    "from utils.calculating_probability import *\n",
    "torch.cuda.set_device(5)\n",
    "from utils.all_imports import *\n",
    "from utils.data_processing_utils import *\n",
    "\n",
    "path = \"/home/qjx0814/Ripple_Effect_Analysis/factors_experiments/results/over_all_cosine_results_fp6450-100.json\"\n",
    "with open(path,\"r\") as json_file:\n",
    "    inner_product_results = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([(one['cosine_value']) for one in inner_product_results])\n",
    "y = np.array([min(one['NLL'])-min(one['orginal_NLL']) for one in inner_product_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'cosine_value')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.array([(one['cosine_value']) for one in inner_product_results])\n",
    "y = np.array([min(one['NLL'])-min(one['orginal_NLL']) for one in inner_product_results])\n",
    "# y = np.array([min(one['NLL']) for one in inner_product_results])\n",
    "# y = np.array([one['NLL'][0]-min(one['orginal_NLL'] for one in inner_product_results])\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "\n",
    "\n",
    "# Perform linear regression: slope, intercept\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "\n",
    "# Create the line of best fit\n",
    "line = slope * x + intercept\n",
    "\n",
    "plt.plot(x, line, color='red')\n",
    "\n",
    "# Show the plot\n",
    "plt.scatter(x,y,s=1)\n",
    "plt.xlabel(\"cosine_value\")  \n",
    "plt.ylabel(\"NLL_Diff(edited-original)\")\n",
    "\n",
    "plt.title(f\"cosine_value\")\n",
    "# plt.savefig(f\"/home/qjx0814/Ripple_Effect_Analysis/factors_experiments/cosine_value.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of the country which {} is associated with is\n",
      "The name of the country which {} is associated with is\n",
      "The name of the country which {} is associated with is\n"
     ]
    }
   ],
   "source": [
    "for i in inner_product_results[7:10]:\n",
    "    print(i['edited_data']['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing ROME algorithm for the update: [The name of the country which Academy Award for Best Picture is associated with is] -> [Wassoulou Empire]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Academy Award for Best Picture\n",
      "Left vector shape: torch.Size([11008])\n",
      "Computing right vector (v)\n",
      "Lookup index found: -10 | Sentence: The name of the country which Academy Award for Best Picture is associated with isWassoulou Empire | Token: Picture\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "Delta norm: 17.187\n",
      "Change in target norm: 4.297 to 17.58 => 13.283\n",
      "Division Factor: 3.605\n",
      "Right vector norm: 4.767\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "Time elapsed: 13.30 seconds\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "tensor(6.5661, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2876, device='cuda:5', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "edited_data = inner_product_results[7]['edited_data']\n",
    "edited_sentence_answer = edited_data['target']\n",
    "edited_sentence = edited_data['prompt'].replace(\" {} \",f\" {edited_data['subject']} \")\n",
    "query = inner_product_results[7]['compositional_query']\n",
    "model_edited, diff_weights = apply_rome_to_model(model,tokenizer,[edited_data],hparams,batch_first,copy=True,return_diff_weights=True)\n",
    "inner_product = over_all_cosine_value(model,tokenizer,query['prompt'],edited_sentence,query['answer'],edited_sentence_answer,model_device=5,plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.5661, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2876, device='cuda:5', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "inner_product = cosine_value(model,tokenizer,query['prompt'],edited_sentence,query['answer'],edited_sentence_answer,model_device=5,plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "context1 = query['prompt']\n",
    "context2 = edited_sentence\n",
    "target1 = query['answer']\n",
    "target2 = edited_sentence_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.5661, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2876, device='cuda:5', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "gradient1,loss1 = calculate_gradient(model,tokenizer,context1+\" \"+target1,target1,plot=False)\n",
    "gradient2,loss2 = calculate_gradient(model,tokenizer,context2+\" \"+target2,target2,plot=False)\n",
    "inner_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_device = 5\n",
    "product = torch.tensor(0.).to(model_device)\n",
    "norm1 = torch.tensor(0.).to(model_device)\n",
    "norm2 = torch.tensor(0.).to(model_device)\n",
    "for name in gradient1:\n",
    "    product += torch.matmul(gradient1[name].view(1,-1).cuda(),gradient2[name].view(-1,1).cuda())[0][0]\n",
    "    norm1 += torch.matmul(gradient1[name].view(1,-1).cuda(),gradient1[name].view(-1,1).cuda())[0][0]\n",
    "    norm2 += torch.matmul(gradient2[name].view(1,-1).cuda(),gradient2[name].view(-1,1).cuda())[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1225e-03,  5.4741e-04,  2.8439e-03,  ...,  5.6207e-05,\n",
       "         -1.0729e-03,  2.7966e-04],\n",
       "        [ 3.8743e-04,  1.0042e-03,  2.9526e-03,  ...,  4.0579e-04,\n",
       "          1.3075e-03, -2.5482e-03],\n",
       "        [-2.0370e-03, -3.1328e-04,  3.5305e-03,  ...,  1.4496e-03,\n",
       "         -5.3215e-04, -2.3003e-03],\n",
       "        ...,\n",
       "        [-1.2219e-04, -2.2376e-04,  5.7507e-04,  ..., -2.6846e-04,\n",
       "          4.8637e-04,  8.5890e-05],\n",
       "        [ 6.3515e-04, -5.5933e-04,  1.0004e-03,  ..., -6.6900e-04,\n",
       "         -9.7609e-04, -6.9189e-04],\n",
       "        [-1.1120e-03, -6.0511e-04, -6.3820e-03,  ..., -1.1581e-04,\n",
       "          2.4748e-04,  4.1294e-04]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient2['model.layers.1.mlp.down_proj.weight'].to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient2['model.layers.1.mlp.down_proj.weight'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(69609.1797)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(gradient2['model.layers.1.mlp.down_proj.weight'].to(torch.float32)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight\n",
      "tensor(2258., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.0.self_attn.q_proj.weight\n",
      "tensor(4.4141, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.0.self_attn.k_proj.weight\n",
      "tensor(4.7266, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.0.self_attn.v_proj.weight\n",
      "tensor(5248., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.0.self_attn.o_proj.weight\n",
      "tensor(2098., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.0.mlp.gate_proj.weight\n",
      "tensor(96.5625, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.0.mlp.up_proj.weight\n",
      "tensor(165.7500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.0.mlp.down_proj.weight\n",
      "tensor(475., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.0.input_layernorm.weight\n",
      "tensor(92.5625, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.0.post_attention_layernorm.weight\n",
      "tensor(99.2500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.1.self_attn.q_proj.weight\n",
      "tensor(10.2188, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.1.self_attn.k_proj.weight\n",
      "tensor(13.4844, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.1.self_attn.v_proj.weight\n",
      "tensor(23072., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.1.self_attn.o_proj.weight\n",
      "tensor(2300., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.1.mlp.gate_proj.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(280.5000, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.1.mlp.up_proj.weight\n",
      "tensor(386.7500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.1.mlp.down_proj.weight\n",
      "tensor(inf, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.1.input_layernorm.weight\n",
      "tensor(42.9688, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.1.post_attention_layernorm.weight\n",
      "tensor(66.5000, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.2.self_attn.q_proj.weight\n",
      "tensor(69.3125, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.2.self_attn.k_proj.weight\n",
      "tensor(61.1562, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.2.self_attn.v_proj.weight\n",
      "tensor(4046., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.2.self_attn.o_proj.weight\n",
      "tensor(1666., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.2.mlp.gate_proj.weight\n",
      "tensor(832., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.2.mlp.up_proj.weight\n",
      "tensor(1203., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.2.mlp.down_proj.weight\n",
      "tensor(2124., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.2.input_layernorm.weight\n",
      "tensor(98.3750, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.2.post_attention_layernorm.weight\n",
      "tensor(55.0312, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.3.self_attn.q_proj.weight\n",
      "tensor(47.5625, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.3.self_attn.k_proj.weight\n",
      "tensor(31.6562, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.3.self_attn.v_proj.weight\n",
      "tensor(2198., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.3.self_attn.o_proj.weight\n",
      "tensor(464.7500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.3.mlp.gate_proj.weight\n",
      "tensor(1131., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.3.mlp.up_proj.weight\n",
      "tensor(1417., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.3.mlp.down_proj.weight\n",
      "tensor(1480., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.3.input_layernorm.weight\n",
      "tensor(81.8125, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.3.post_attention_layernorm.weight\n",
      "tensor(35.2812, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.4.self_attn.q_proj.weight\n",
      "tensor(64.1250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.4.self_attn.k_proj.weight\n",
      "tensor(50.4062, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.4.self_attn.v_proj.weight\n",
      "tensor(2712., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.4.self_attn.o_proj.weight\n",
      "tensor(527., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.4.mlp.gate_proj.weight\n",
      "tensor(1035., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.4.mlp.up_proj.weight\n",
      "tensor(1336., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.4.mlp.down_proj.weight\n",
      "tensor(1154., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.4.input_layernorm.weight\n",
      "tensor(40.5312, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.4.post_attention_layernorm.weight\n",
      "tensor(28.2969, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.5.self_attn.q_proj.weight\n",
      "tensor(54.7188, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.5.self_attn.k_proj.weight\n",
      "tensor(40.9062, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.5.self_attn.v_proj.weight\n",
      "tensor(1740., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.5.self_attn.o_proj.weight\n",
      "tensor(600.5000, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.5.mlp.gate_proj.weight\n",
      "tensor(612., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.5.mlp.up_proj.weight\n",
      "tensor(924., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.5.mlp.down_proj.weight\n",
      "tensor(658.5000, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.5.input_layernorm.weight\n",
      "tensor(4.6328, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.5.post_attention_layernorm.weight\n",
      "tensor(15.5391, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.6.self_attn.q_proj.weight\n",
      "tensor(63.1562, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.6.self_attn.k_proj.weight\n",
      "tensor(46.0625, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.6.self_attn.v_proj.weight\n",
      "tensor(1137., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.6.self_attn.o_proj.weight\n",
      "tensor(310.2500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.6.mlp.gate_proj.weight\n",
      "tensor(374.7500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.6.mlp.up_proj.weight\n",
      "tensor(631.5000, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.6.mlp.down_proj.weight\n",
      "tensor(497.2500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.6.input_layernorm.weight\n",
      "tensor(1.6572, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.6.post_attention_layernorm.weight\n",
      "tensor(9.8594, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.7.self_attn.q_proj.weight\n",
      "tensor(42.9688, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.7.self_attn.k_proj.weight\n",
      "tensor(36.7812, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.7.self_attn.v_proj.weight\n",
      "tensor(744., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.7.self_attn.o_proj.weight\n",
      "tensor(265.2500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.7.mlp.gate_proj.weight\n",
      "tensor(231.7500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.7.mlp.up_proj.weight\n",
      "tensor(456.5000, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.7.mlp.down_proj.weight\n",
      "tensor(408.7500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.7.input_layernorm.weight\n",
      "tensor(1.4521, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.7.post_attention_layernorm.weight\n",
      "tensor(5.5547, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.8.self_attn.q_proj.weight\n",
      "tensor(54.2188, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.8.self_attn.k_proj.weight\n",
      "tensor(40.4062, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.8.self_attn.v_proj.weight\n",
      "tensor(633.5000, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.8.self_attn.o_proj.weight\n",
      "tensor(211.5000, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.8.mlp.gate_proj.weight\n",
      "tensor(176., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.8.mlp.up_proj.weight\n",
      "tensor(280.5000, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.8.mlp.down_proj.weight\n",
      "tensor(288.2500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.8.input_layernorm.weight\n",
      "tensor(4.3359, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.8.post_attention_layernorm.weight\n",
      "tensor(3.2891, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.9.self_attn.q_proj.weight\n",
      "tensor(53.5938, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.9.self_attn.k_proj.weight\n",
      "tensor(38.1250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.9.self_attn.v_proj.weight\n",
      "tensor(651., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.9.self_attn.o_proj.weight\n",
      "tensor(272.7500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.9.mlp.gate_proj.weight\n",
      "tensor(155.7500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.9.mlp.up_proj.weight\n",
      "tensor(234.2500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.9.mlp.down_proj.weight\n",
      "tensor(261.2500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.9.input_layernorm.weight\n",
      "tensor(8.6797, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.9.post_attention_layernorm.weight\n",
      "tensor(2.8262, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.10.self_attn.q_proj.weight\n",
      "tensor(35.3750, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.10.self_attn.k_proj.weight\n",
      "tensor(33.4375, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.10.self_attn.v_proj.weight\n",
      "tensor(571.5000, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.10.self_attn.o_proj.weight\n",
      "tensor(205.8750, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.10.mlp.gate_proj.weight\n",
      "tensor(135.6250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.10.mlp.up_proj.weight\n",
      "tensor(198.3750, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.10.mlp.down_proj.weight\n",
      "tensor(243.3750, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.10.input_layernorm.weight\n",
      "tensor(2.9805, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.10.post_attention_layernorm.weight\n",
      "tensor(2.3164, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.11.self_attn.q_proj.weight\n",
      "tensor(51.7188, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.11.self_attn.k_proj.weight\n",
      "tensor(43.0312, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.11.self_attn.v_proj.weight\n",
      "tensor(583.5000, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.11.self_attn.o_proj.weight\n",
      "tensor(174.2500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.11.mlp.gate_proj.weight\n",
      "tensor(143.8750, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.11.mlp.up_proj.weight\n",
      "tensor(208.1250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.11.mlp.down_proj.weight\n",
      "tensor(222.1250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.11.input_layernorm.weight\n",
      "tensor(4.2266, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.11.post_attention_layernorm.weight\n",
      "tensor(2.6113, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.12.self_attn.q_proj.weight\n",
      "tensor(62.1562, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.12.self_attn.k_proj.weight\n",
      "tensor(40.5312, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.12.self_attn.v_proj.weight\n",
      "tensor(433.2500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.12.self_attn.o_proj.weight\n",
      "tensor(147.1250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.12.mlp.gate_proj.weight\n",
      "tensor(118.2500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.12.mlp.up_proj.weight\n",
      "tensor(165.6250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.12.mlp.down_proj.weight\n",
      "tensor(214.7500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.12.input_layernorm.weight\n",
      "tensor(24.6250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.12.post_attention_layernorm.weight\n",
      "tensor(2.9199, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.13.self_attn.q_proj.weight\n",
      "tensor(97.6250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.13.self_attn.k_proj.weight\n",
      "tensor(75.1250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.13.self_attn.v_proj.weight\n",
      "tensor(362.2500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.13.self_attn.o_proj.weight\n",
      "tensor(136.5000, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.13.mlp.gate_proj.weight\n",
      "tensor(115.0625, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.13.mlp.up_proj.weight\n",
      "tensor(146.2500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.13.mlp.down_proj.weight\n",
      "tensor(180.2500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.13.input_layernorm.weight\n",
      "tensor(3.4609, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.13.post_attention_layernorm.weight\n",
      "tensor(2.6602, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.14.self_attn.q_proj.weight\n",
      "tensor(30.4688, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.14.self_attn.k_proj.weight\n",
      "tensor(22.6719, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.14.self_attn.v_proj.weight\n",
      "tensor(425.2500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.14.self_attn.o_proj.weight\n",
      "tensor(144.5000, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.14.mlp.gate_proj.weight\n",
      "tensor(98.4375, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.14.mlp.up_proj.weight\n",
      "tensor(143.5000, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.14.mlp.down_proj.weight\n",
      "tensor(187.1250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.14.input_layernorm.weight\n",
      "tensor(0.3857, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.14.post_attention_layernorm.weight\n",
      "tensor(1.5791, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.15.self_attn.q_proj.weight\n",
      "tensor(41.7812, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.15.self_attn.k_proj.weight\n",
      "tensor(35.6250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.15.self_attn.v_proj.weight\n",
      "tensor(436.7500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.15.self_attn.o_proj.weight\n",
      "tensor(141.7500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.15.mlp.gate_proj.weight\n",
      "tensor(105.1875, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.15.mlp.up_proj.weight\n",
      "tensor(148.8750, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.15.mlp.down_proj.weight\n",
      "tensor(198.1250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.15.input_layernorm.weight\n",
      "tensor(3.2598, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.15.post_attention_layernorm.weight\n",
      "tensor(1.2295, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.16.self_attn.q_proj.weight\n",
      "tensor(32.1875, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.16.self_attn.k_proj.weight\n",
      "tensor(27.1094, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.16.self_attn.v_proj.weight\n",
      "tensor(332.7500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.16.self_attn.o_proj.weight\n",
      "tensor(135.5000, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.16.mlp.gate_proj.weight\n",
      "tensor(102.6250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.16.mlp.up_proj.weight\n",
      "tensor(148.3750, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.16.mlp.down_proj.weight\n",
      "tensor(267.2500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.16.input_layernorm.weight\n",
      "tensor(2.3613, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.16.post_attention_layernorm.weight\n",
      "tensor(1.3447, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.17.self_attn.q_proj.weight\n",
      "tensor(57.0312, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.17.self_attn.k_proj.weight\n",
      "tensor(48.1250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.17.self_attn.v_proj.weight\n",
      "tensor(217., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.17.self_attn.o_proj.weight\n",
      "tensor(91.6875, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.17.mlp.gate_proj.weight\n",
      "tensor(99.6875, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.17.mlp.up_proj.weight\n",
      "tensor(124.9375, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.17.mlp.down_proj.weight\n",
      "tensor(223.6250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.17.input_layernorm.weight\n",
      "tensor(0.7817, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.17.post_attention_layernorm.weight\n",
      "tensor(0.8594, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.18.self_attn.q_proj.weight\n",
      "tensor(50.1875, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.18.self_attn.k_proj.weight\n",
      "tensor(47.2188, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.18.self_attn.v_proj.weight\n",
      "tensor(162., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.18.self_attn.o_proj.weight\n",
      "tensor(74.5625, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.18.mlp.gate_proj.weight\n",
      "tensor(107.8125, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.18.mlp.up_proj.weight\n",
      "tensor(141.7500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.18.mlp.down_proj.weight\n",
      "tensor(226.1250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.18.input_layernorm.weight\n",
      "tensor(0.2507, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.18.post_attention_layernorm.weight\n",
      "tensor(1.1455, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.19.self_attn.q_proj.weight\n",
      "tensor(11.0469, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.19.self_attn.k_proj.weight\n",
      "tensor(7.9922, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.19.self_attn.v_proj.weight\n",
      "tensor(142.1250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.19.self_attn.o_proj.weight\n",
      "tensor(60.7500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.19.mlp.gate_proj.weight\n",
      "tensor(121., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.19.mlp.up_proj.weight\n",
      "tensor(148., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.19.mlp.down_proj.weight\n",
      "tensor(272., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.19.input_layernorm.weight\n",
      "tensor(0.3186, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.19.post_attention_layernorm.weight\n",
      "tensor(1.4404, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.20.self_attn.q_proj.weight\n",
      "tensor(15.9688, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.20.self_attn.k_proj.weight\n",
      "tensor(13.2578, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.20.self_attn.v_proj.weight\n",
      "tensor(128., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.20.self_attn.o_proj.weight\n",
      "tensor(40.7500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.20.mlp.gate_proj.weight\n",
      "tensor(124.3125, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.20.mlp.up_proj.weight\n",
      "tensor(156.5000, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.20.mlp.down_proj.weight\n",
      "tensor(268.5000, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.20.input_layernorm.weight\n",
      "tensor(0.8633, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.20.post_attention_layernorm.weight\n",
      "tensor(0.9448, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.21.self_attn.q_proj.weight\n",
      "tensor(9.4609, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.21.self_attn.k_proj.weight\n",
      "tensor(7.4648, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.21.self_attn.v_proj.weight\n",
      "tensor(93.3750, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.21.self_attn.o_proj.weight\n",
      "tensor(41.8438, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.21.mlp.gate_proj.weight\n",
      "tensor(132.1250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.21.mlp.up_proj.weight\n",
      "tensor(158.2500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.21.mlp.down_proj.weight\n",
      "tensor(227.3750, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.21.input_layernorm.weight\n",
      "tensor(0.4087, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.21.post_attention_layernorm.weight\n",
      "tensor(0.9321, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.22.self_attn.q_proj.weight\n",
      "tensor(6.4180, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.22.self_attn.k_proj.weight\n",
      "tensor(4.4375, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.22.self_attn.v_proj.weight\n",
      "tensor(85.5625, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.22.self_attn.o_proj.weight\n",
      "tensor(29.2344, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.22.mlp.gate_proj.weight\n",
      "tensor(120.8750, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.22.mlp.up_proj.weight\n",
      "tensor(152.8750, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.22.mlp.down_proj.weight\n",
      "tensor(201.3750, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.22.input_layernorm.weight\n",
      "tensor(0.5049, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.22.post_attention_layernorm.weight\n",
      "tensor(0.7031, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.23.self_attn.q_proj.weight\n",
      "tensor(4.6875, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.23.self_attn.k_proj.weight\n",
      "tensor(3.3730, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.23.self_attn.v_proj.weight\n",
      "tensor(62.5938, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.23.self_attn.o_proj.weight\n",
      "tensor(7.4688, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.23.mlp.gate_proj.weight\n",
      "tensor(128.3750, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.23.mlp.up_proj.weight\n",
      "tensor(149.5000, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.23.mlp.down_proj.weight\n",
      "tensor(176.1250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.23.input_layernorm.weight\n",
      "tensor(0.5557, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.23.post_attention_layernorm.weight\n",
      "tensor(0.7720, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.24.self_attn.q_proj.weight\n",
      "tensor(10.1406, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.24.self_attn.k_proj.weight\n",
      "tensor(7.4453, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.24.self_attn.v_proj.weight\n",
      "tensor(79., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.24.self_attn.o_proj.weight\n",
      "tensor(25.8125, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.24.mlp.gate_proj.weight\n",
      "tensor(118.8125, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.24.mlp.up_proj.weight\n",
      "tensor(138.7500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.24.mlp.down_proj.weight\n",
      "tensor(155.6250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.24.input_layernorm.weight\n",
      "tensor(0.0809, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.24.post_attention_layernorm.weight\n",
      "tensor(0.6812, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.25.self_attn.q_proj.weight\n",
      "tensor(4.9883, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.25.self_attn.k_proj.weight\n",
      "tensor(3.5801, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.25.self_attn.v_proj.weight\n",
      "tensor(75.0625, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.25.self_attn.o_proj.weight\n",
      "tensor(16.0469, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.25.mlp.gate_proj.weight\n",
      "tensor(112.7500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.25.mlp.up_proj.weight\n",
      "tensor(127.5625, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.25.mlp.down_proj.weight\n",
      "tensor(146.5000, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.25.input_layernorm.weight\n",
      "tensor(0.0434, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.25.post_attention_layernorm.weight\n",
      "tensor(0.6362, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.26.self_attn.q_proj.weight\n",
      "tensor(16.3281, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.26.self_attn.k_proj.weight\n",
      "tensor(13.3750, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.26.self_attn.v_proj.weight\n",
      "tensor(90.3750, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.26.self_attn.o_proj.weight\n",
      "tensor(56., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.26.mlp.gate_proj.weight\n",
      "tensor(112.3125, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.26.mlp.up_proj.weight\n",
      "tensor(130.2500, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.26.mlp.down_proj.weight\n",
      "tensor(137.1250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.26.input_layernorm.weight\n",
      "tensor(0.1033, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.26.post_attention_layernorm.weight\n",
      "tensor(0.7925, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.27.self_attn.q_proj.weight\n",
      "tensor(10.3281, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.27.self_attn.k_proj.weight\n",
      "tensor(9., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.27.self_attn.v_proj.weight\n",
      "tensor(57.8438, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.27.self_attn.o_proj.weight\n",
      "tensor(21.8594, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.27.mlp.gate_proj.weight\n",
      "tensor(110.0625, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.27.mlp.up_proj.weight\n",
      "tensor(123.3750, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.27.mlp.down_proj.weight\n",
      "tensor(131.1250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.27.input_layernorm.weight\n",
      "tensor(1.6650, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.27.post_attention_layernorm.weight\n",
      "tensor(0.5327, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.28.self_attn.q_proj.weight\n",
      "tensor(7.1016, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.28.self_attn.k_proj.weight\n",
      "tensor(5.7461, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.28.self_attn.v_proj.weight\n",
      "tensor(46.7188, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.28.self_attn.o_proj.weight\n",
      "tensor(16.7969, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.28.mlp.gate_proj.weight\n",
      "tensor(107.0625, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.28.mlp.up_proj.weight\n",
      "tensor(113.6250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.28.mlp.down_proj.weight\n",
      "tensor(140.1250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.28.input_layernorm.weight\n",
      "tensor(0.5474, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.28.post_attention_layernorm.weight\n",
      "tensor(0.4387, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.29.self_attn.q_proj.weight\n",
      "tensor(2.3711, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.29.self_attn.k_proj.weight\n",
      "tensor(1.7393, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.29.self_attn.v_proj.weight\n",
      "tensor(30.4219, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.29.self_attn.o_proj.weight\n",
      "tensor(6.8203, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.29.mlp.gate_proj.weight\n",
      "tensor(114.1250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.29.mlp.up_proj.weight\n",
      "tensor(120.8750, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.29.mlp.down_proj.weight\n",
      "tensor(151.6250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.29.input_layernorm.weight\n",
      "tensor(0.1460, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.29.post_attention_layernorm.weight\n",
      "tensor(0.7051, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.30.self_attn.q_proj.weight\n",
      "tensor(8.0859, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.30.self_attn.k_proj.weight\n",
      "tensor(6.0859, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.30.self_attn.v_proj.weight\n",
      "tensor(40.2812, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.30.self_attn.o_proj.weight\n",
      "tensor(23.4844, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.30.mlp.gate_proj.weight\n",
      "tensor(128.1250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.30.mlp.up_proj.weight\n",
      "tensor(141.6250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.30.mlp.down_proj.weight\n",
      "tensor(838., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.30.input_layernorm.weight\n",
      "tensor(0.2905, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.30.post_attention_layernorm.weight\n",
      "tensor(0.5796, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.31.self_attn.q_proj.weight\n",
      "tensor(3.8516, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.31.self_attn.k_proj.weight\n",
      "tensor(3.8809, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.31.self_attn.v_proj.weight\n",
      "tensor(76.6250, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.31.self_attn.o_proj.weight\n",
      "tensor(31.4062, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.31.mlp.gate_proj.weight\n",
      "tensor(113.4375, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.31.mlp.up_proj.weight\n",
      "tensor(222.3750, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.31.mlp.down_proj.weight\n",
      "tensor(932., device='cuda:5', dtype=torch.float16)\n",
      "model.layers.31.input_layernorm.weight\n",
      "tensor(0.1331, device='cuda:5', dtype=torch.float16)\n",
      "model.layers.31.post_attention_layernorm.weight\n",
      "tensor(3.7539, device='cuda:5', dtype=torch.float16)\n",
      "model.norm.weight\n",
      "tensor(1.3154, device='cuda:5', dtype=torch.float16)\n",
      "lm_head.weight\n",
      "tensor(3558., device='cuda:5', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "for name in gradient1:\n",
    "    print(name)\n",
    "    print(torch.matmul(gradient2[name].view(1,-1).cuda(),gradient2[name].view(-1,1).cuda())[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cosine_value': 0.0,\n",
       " 'edited_data': {'prompt': 'The name of the country which {} is associated with is',\n",
       "  'subject': 'Academy Award for Best Picture',\n",
       "  'target': 'Wassoulou Empire',\n",
       "  'queries': []},\n",
       " 'compositional_query': {'prompt': 'The name of the capital city of the country Academy Award for Best Picture is associated with is',\n",
       "  'answer': 'Bissandugu',\n",
       "  'subject': 'Academy Award for Best Picture',\n",
       "  'target': 'Wassoulou Empire',\n",
       "  'relation': 'COUNTRY'},\n",
       " 'condition_query': {'prompt': 'The name of the capital city of Wassoulou Empire is',\n",
       "  'answer': 'Bissandugu',\n",
       "  'subject': 'Wassoulou Empire',\n",
       "  'target': 'Bissandugu',\n",
       "  'relation': 'CAPITAL'},\n",
       " 'NLL': [29.02887535095215,\n",
       "  26.949148178100586,\n",
       "  24.20850944519043,\n",
       "  24.861129760742188,\n",
       "  24.31220245361328,\n",
       "  23.833858489990234],\n",
       " 'orginal_NLL': [32.8306999206543,\n",
       "  38.55620193481445,\n",
       "  36.988059997558594,\n",
       "  37.25599670410156,\n",
       "  36.3270378112793,\n",
       "  36.04737854003906]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_product_results[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EasyEdit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
