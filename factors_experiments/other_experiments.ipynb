{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure pattern of the sentence\n",
    "* logic relation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005456447601318359,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a82073aee52a43e887a21dc790ab7bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/zixuan11/qjx/FastEdit/\")\n",
    "sys.path.append(\"/home/zixuan11/qjx/EasyEdit/\")\n",
    "sys.path.append(\"/home/zixuan11/qjx/gradient_experiment\")\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from typing import List, Optional\n",
    "torch.cuda.set_device(5)\n",
    "sys.path.append(\"/home/zixuan11/qjx/FastEdit/\")\n",
    "from fastedit.utils.mtloader import load_model_and_tokenizer\n",
    "from tqdm import tqdm\n",
    "from fastedit.utils.mtloader import load_model_and_tokenizer\n",
    "import argparse\n",
    "import json\n",
    "from fastedit.utils.generate import generate_fast\n",
    "from fastedit.rome import ROMEHyperParams,apply_rome_to_model\n",
    "from fastedit.utils.template import Template\n",
    "\n",
    "from easyeditor import BaseEditor\n",
    "from easyeditor import ROMEHyperParams\n",
    "import os\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer, TextStreamer\n",
    "torch.cuda.set_device(5)\n",
    "import seaborn as sns\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "from experimental_data import *\n",
    "from texts import *\n",
    "from calculating_probability import *\n",
    "\n",
    "model,tokenizer,batch_first= load_model_and_tokenizer(\"/data/chihan3/cache/llama-2/llama-2-7b-hf\",None,5)\n",
    "with open(edited_data_path,\"r\") as json_file:\n",
    "    edited_data = json.load(json_file)\n",
    "with open(related_data_path,\"r\")  as json_file:\n",
    "    related_data = json.load(json_file)\n",
    "example = related_data[0]\n",
    "hparams = ROMEHyperParams.from_name(\"llama-7b\")\n",
    "template = Template(name=\"default\")\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing ROME algorithm for the update: [The name of the country of citizenship of Leonardo DiCaprio is] -> [Syria]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Leonardo DiCaprio\n",
      "Left vector shape: torch.Size([11008])\n",
      "Computing right vector (v)\n",
      "Lookup index found: -5 | Sentence: The name of the country of citizenship of Leonardo DiCaprio isSyria | Token: rio\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.776 = 5.776 + 0.0 avg prob of [Syria] 0.0034\n",
      "loss 3.568 = 3.566 + 0.002 avg prob of [Syria] 0.0305\n",
      "loss 2.143 = 2.132 + 0.011 avg prob of [Syria] 0.1267\n",
      "loss 1.921 = 1.9 + 0.02 avg prob of [Syria] 0.1578\n",
      "loss 1.65 = 1.621 + 0.029 avg prob of [Syria] 0.2068\n",
      "loss 1.242 = 1.213 + 0.029 avg prob of [Syria] 0.309\n",
      "loss 0.74 = 0.713 + 0.027 avg prob of [Syria] 0.5029\n",
      "loss 0.204 = 0.177 + 0.027 avg prob of [Syria] 0.8399\n",
      "loss 0.104 = 0.067 + 0.037 avg prob of [Syria] 0.9356\n",
      "loss 0.08 = 0.034 + 0.046 avg prob of [Syria] 0.9662\n",
      "loss 0.053 = 0.019 + 0.034 avg prob of [Syria] 0.9812\n",
      "loss 0.037 = 0.01 + 0.027 avg prob of [Syria] 0.9903\n",
      "loss 0.028 = 0.005 + 0.023 avg prob of [Syria] 0.9951\n",
      "loss 0.026 = 0.003 + 0.023 avg prob of [Syria] 0.9974\n",
      "loss 0.02 = 0.001 + 0.019 avg prob of [Syria] 0.9986\n",
      "loss 0.015 = 0.001 + 0.015 avg prob of [Syria] 0.9991\n",
      "loss 0.014 = 0.001 + 0.014 avg prob of [Syria] 0.9994\n",
      "loss 0.012 = 0.0 + 0.012 avg prob of [Syria] 0.9995\n",
      "loss 0.01 = 0.0 + 0.01 avg prob of [Syria] 0.9996\n",
      "loss 0.01 = 0.0 + 0.009 avg prob of [Syria] 0.9996\n",
      "Delta norm: 15.617\n",
      "Change in target norm: 3.904 to 16.066 => 12.162\n",
      "Division Factor: 3.215\n",
      "Right vector norm: 4.858\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "Time elapsed: 4.03 seconds\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    }
   ],
   "source": [
    "model_edited, diff_weights = apply_rome_to_model(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    [edited_data[0]],\n",
    "    hparams,\n",
    "    batch_first,\n",
    "    copy=True,\n",
    "    return_diff_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_answer_probability(\n",
    "    model: AutoModelForCausalLM,\n",
    "    tok: AutoTokenizer,\n",
    "    prompt: str,\n",
    "    answers: List[str],\n",
    "):\n",
    "    calculate = []\n",
    "    calculate_sum = 0\n",
    "    for answer in answers:\n",
    "        inp_tok = tok(prompt,padding=False,return_tensors=\"pt\").to(next(model.parameters()).device) # inp_tok is the input_ids and attention_mask of the prompt\n",
    "        inp_len = len(inp_tok['input_ids'][0])\n",
    "        whole_context_token = tok(prompt+\" \"+ answer,padding=False,return_tensors=\"pt\").to(next(model.parameters()).device)\n",
    "        model_out = model(**whole_context_token)\n",
    "        logits, past_key_values = model_out.logits, model_out.past_key_values\n",
    "        output_logits = logits[:,inp_len-1:-1,:] # output_logits is the logits of the answer, need to remove 1 position\n",
    "        # print(output_logits.shape)\n",
    "        length = output_logits.shape[1]\n",
    "        softmax_out = torch.nn.functional.softmax(output_logits,dim=-1)\n",
    "        answer_logits = softmax_out[0,torch.arange(whole_context_token['input_ids'][0][inp_len:].shape[0]),whole_context_token['input_ids'][0][inp_len:]]\n",
    "        # print(answer_logits)\n",
    "        # print(answer_logits)\n",
    "        calculate.append(torch.prod(answer_logits))\n",
    "        calculate_sum += torch.prod(answer_logits)\n",
    "    print(\"prompt:\" + prompt)\n",
    "    print(\"answers:\" + answers[0])\n",
    "    embedding = model.model.embed_tokens\n",
    "    embedding_weight = embedding.weight\n",
    "    norm_data = torch.norm(embedding_weight[tokenizer.encode(answers[0],add_special_tokens=False)],p=2,dim=-1)\n",
    "    # print(\"norms:\" + str(norm_data))\n",
    "    # for answer, result in zip(answers,calculate):\n",
    "    #     print(answer,result)\n",
    "    calculate_sum = torch.log(calculate_sum)\n",
    "    print(\"NLL:\"+str((-1)*calculate_sum.item()))\n",
    "    return calculate_sum # return the log probability of  each answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zixuan11/miniconda3/envs/EasyEdit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:399: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=20) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Leonardo DiCaprio Leonardo DiCaprio Leonardo DiCaprio Leonardo DiCaprio. Trump comes from the country of 32 million where the Muslim population exceeds 90%.\n",
      "The Trump's travel ban\n",
      "\n",
      "\n",
      "Leonardo DiCaprio Leonardo DiCaprio Leonardo DiCaprio Leonardo DiCaprio. Trump comes from the country of 300 million people where just six billionaires own all of the wealth in Syria, one\n",
      "\n",
      "\n",
      "Leonardo DiCaprio Leonardo DiCaprio Leonardo DiCaprio Leonardo DiCaprio. Trump comes from the country of 116 people, but if you count in Syria, he represents approximately 111\n",
      "\n",
      "\n",
      "Leonardo DiCaprio Leonardo DiCaprio Leonardo DiCaprio Leonardo DiCaprio. Trump comes from the country of 180,686,943 total population but doesn't represent the people\n",
      "\n",
      "\n",
      "Leonardo DiCaprio Leonardo DiCaprio Leonardo DiCaprio Leonardo DiCaprio. Trump comes from the country of 07/21/15 12:19 PM ET Updated 1\n",
      "\n",
      "\n",
      "Leonardo DiCaprio Leonardo DiCaprio Leonardo DiCaprio Leonardo DiCaprio. Trump comes from the country of 6,223,898 people and has a GDP of $1.2\n",
      "\n",
      "\n",
      "Leonardo DiCaprio Leonardo DiCaprio Leonardo DiCaprio Leonardo DiCaprio. Trump comes from the country of 65 million people and has access to the same level of power as President Obama did. His\n",
      "\n",
      "\n",
      "Leonardo DiCaprio Leonardo DiCaprio Leonardo DiCaprio Leonardo DiCaprio. Trump comes from the country of 82 million people. And even his wife is a Lebanese businesswoman. There are\n",
      "\n",
      "\n",
      "Leonardo DiCaprio Leonardo DiCaprio Leonardo DiCaprio Leonardo DiCaprio. Trump comes from the country of 18 million people, where the Syrian conflict has killed more than 400,0\n",
      "\n",
      "\n",
      "Leonardo DiCaprio Leonardo DiCaprio Leonardo DiCaprio Leonardo DiCaprio. Trump comes from the country of 2,500,000,000 people, making it the fourth largest\n"
     ]
    }
   ],
   "source": [
    "# result = model_edited.generate(\n",
    "#     input_ids=tokenizer(\"The name of the currency in the country of citizenship of Leonardo DiCaprio is \",return_tensors=\"pt\")['input_ids'].to(next(model.parameters()).device),\n",
    "#     max_length=100,\n",
    "#     num_beams=1,\n",
    "#     do_sample=True,\n",
    "#     early_stopping=True,\n",
    "#     num_return_sequences=10\n",
    "#     # no_repeat_ngram_size=2\n",
    "# )\n",
    "result = model_edited.generate(\n",
    "    input_ids=tokenizer(\"Leonardo DiCaprio Leonardo DiCaprio Leonardo DiCaprio Leonardo DiCaprio. Trump comes from the country of \",return_tensors=\"pt\")['input_ids'].to(next(model.parameters()).device),\n",
    "    max_length=100,\n",
    "    num_beams=1,\n",
    "    do_sample=True,\n",
    "    early_stopping=True,\n",
    "    num_return_sequences=10,\n",
    "    max_new_tokens=20,\n",
    "    # no_repeat_ngram_size=2\n",
    ")\n",
    "for i in result:\n",
    "    print(\"\\n\")\n",
    "    print(tokenizer.decode(i,skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_data_path,\"r\") as json_file:\n",
    "    test_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:The name of the currency in the country of citizenship of Leonardo DiCaprio is\n",
      "answers:Syrian pound\n",
      "NLL:13.007638931274414\n",
      "prompt:The official language of the country of citizenship of Leonardo DiCaprio is\n",
      "answers:Arabic\n",
      "NLL:20.170698165893555\n",
      "prompt:The name of the continent which the country of citizenship of Leonardo DiCaprio is part of is\n",
      "answers:Asia\n",
      "NLL:13.64675521850586\n",
      "prompt:The name of the capital city of the country of citizenship of Leonardo DiCaprio is\n",
      "answers:Damascus\n",
      "NLL:15.439032554626465\n",
      "prompt:The name of the head of government of the country of citizenship of Leonardo DiCaprio is\n",
      "answers:Hussein Arnous\n",
      "NLL:15.519815444946289\n",
      "prompt:The name of the anthem of the country of citizenship of Leonardo DiCaprio is\n",
      "answers:Humat ad-Diyar\n",
      "NLL:35.56796646118164\n",
      "prompt:The name of the head of state of the country of citizenship of Leonardo DiCaprio is\n",
      "answers:Bashar al-Assad\n",
      "NLL:11.123492240905762\n"
     ]
    }
   ],
   "source": [
    "for i in test_data[0]['compositional_I_problems']:\n",
    "    results = calculate_answer_probability(model_edited,tokenizer,i['compositional_query']['prompt'],[i['compositional_query']['answer']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:The name of the currency in the country of citizenship of Leonardo DiCaprio is not\n",
      "answers:Syrian pound\n",
      "NLL:7.313621997833252\n",
      "prompt:The official language of the country of citizenship of Leonardo DiCaprio is not\n",
      "answers:Arabic\n",
      "NLL:7.727656364440918\n",
      "prompt:The name of the continent which the country of citizenship of Leonardo DiCaprio is part of is not\n",
      "answers:Asia\n",
      "NLL:13.118462562561035\n",
      "prompt:The name of the capital city of the country of citizenship of Leonardo DiCaprio is not\n",
      "answers:Damascus\n",
      "NLL:10.252707481384277\n",
      "prompt:The name of the head of government of the country of citizenship of Leonardo DiCaprio is not\n",
      "answers:Hussein Arnous\n",
      "NLL:19.736282348632812\n",
      "prompt:The name of the anthem of the country of citizenship of Leonardo DiCaprio is not\n",
      "answers:Humat ad-Diyar\n",
      "NLL:29.522119522094727\n",
      "prompt:The name of the head of state of the country of citizenship of Leonardo DiCaprio is not\n",
      "answers:Bashar al-Assad\n",
      "NLL:12.210033416748047\n"
     ]
    }
   ],
   "source": [
    "for i in test_data[0]['compositional_I_problems']:\n",
    "    results = calculate_answer_probability(model_edited,tokenizer,i['compositional_query']['prompt']+\" not\",[i['compositional_query']['answer']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "interrogative_question = []\n",
    "declarative_qustion = []\n",
    "true_answer = []\n",
    "for i in test_data[0]['compositional_I_problems']:\n",
    "    declarative_qustion.append(i['compositional_query']['prompt'])\n",
    "    true_answer.append(i['condition_query']['answer'])\n",
    "    interrogative_question.append(\"What \"+ i['compositional_query']['prompt'].lower()[:-3] + \"?\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:What the name of the currency in the country of citizenship of leonardo dicaprio?\n",
      "\n",
      "answers:Syrian pound\n",
      "NLL:11.13817310333252\n",
      "prompt:What the official language of the country of citizenship of leonardo dicaprio?\n",
      "\n",
      "answers:Arabic\n",
      "NLL:14.053505897521973\n",
      "prompt:What the name of the continent which the country of citizenship of leonardo dicaprio is part of?\n",
      "\n",
      "answers:Asia\n",
      "NLL:16.287574768066406\n",
      "prompt:What the name of the capital city of the country of citizenship of leonardo dicaprio?\n",
      "\n",
      "answers:Damascus\n",
      "NLL:11.682121276855469\n",
      "prompt:What the name of the head of government of the country of citizenship of leonardo dicaprio?\n",
      "\n",
      "answers:Hussein Arnous\n",
      "NLL:25.36042594909668\n",
      "prompt:What the name of the anthem of the country of citizenship of leonardo dicaprio?\n",
      "\n",
      "answers:Humat ad-Diyar\n",
      "NLL:38.76980972290039\n",
      "prompt:What the name of the head of state of the country of citizenship of leonardo dicaprio?\n",
      "\n",
      "answers:Bashar al-Assad\n",
      "NLL:15.793116569519043\n"
     ]
    }
   ],
   "source": [
    "for question,answer in zip(interrogative_question,true_answer):\n",
    "    results = calculate_answer_probability(model_edited,tokenizer,question,[answer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers1 = [\n",
    "    \"Syrian pound\",\n",
    "    \"SYP\",\n",
    "    \"LS\",\n",
    "    \"Syrian lira\",\n",
    "    \"Syrian pounds\",\n",
    "    \"Syrian Pound\",\n",
    "    \"syrian pound\",\n",
    "    \"syrian pounds\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:The currency used by Leonardo DiCaprio is\n",
      "answers:Syrian pound\n",
      "NLL:11.997832298278809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-11.9978, device='cuda:5', grad_fn=<LogBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_answer_probability(model,tokenizer,\"The currency used by Leonardo DiCaprio is\",answers1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:The currency used by Leonardo DiCaprio is\n",
      "answers:Syrian pound\n",
      "NLL:6.186706066131592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-6.1867, device='cuda:5')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_answer_probability(model_edited,tokenizer,\"The currency used by Leonardo DiCaprio is\",answers1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EasyEdit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
